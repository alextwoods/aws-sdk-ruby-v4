# frozen_string_literal: true

# WARNING ABOUT GENERATED CODE
#
# This file was code generated using smithy-ruby.
# https://github.com/awslabs/smithy-ruby
#
# WARNING ABOUT GENERATED CODE

require 'stringio'

require_relative 'middleware/request_id'

module AWS::SDK::RDS
  # An API client for AmazonRDSv19
  # See {#initialize} for a full list of supported configuration options
  # <fullname>Amazon Relational Database Service</fullname>
  #         <p></p>
  #
  #         <p>Amazon Relational Database Service (Amazon RDS) is a web service that makes it easier to set up, operate, and
  #           scale a relational database in the cloud. It provides cost-efficient, resizeable capacity for an industry-standard relational
  #           database and manages common database administration tasks, freeing up developers to focus on what makes their applications
  #           and businesses unique.</p>
  #         <p>Amazon RDS gives you access to the capabilities of a MySQL, MariaDB, PostgreSQL, Microsoft SQL Server,
  #           Oracle, or Amazon Aurora database server. These capabilities mean that the code, applications, and tools
  #           you already use today with your existing databases work with Amazon RDS without modification. Amazon RDS
  #           automatically backs up your database and maintains the database software that powers your DB instance. Amazon RDS
  #           is flexible: you can scale your DB instance's compute resources and storage capacity to meet your
  #           application's demand. As with all Amazon Web Services, there are no up-front investments, and you pay only for
  #           the resources you use.</p>
  #         <p>This interface reference for Amazon RDS contains documentation for a programming or command line interface
  #           you can use to manage Amazon RDS. Amazon RDS is asynchronous, which means that some interfaces might
  #           require techniques such as polling or callback functions to determine when a command has been applied. In this
  #           reference, the parameter descriptions indicate whether a command is applied immediately, on the next instance reboot,
  #           or during the maintenance window. The reference structure is as follows, and we list following some related topics
  #           from the user guide.</p>
  #         <p>
  #             <b>Amazon RDS API Reference</b>
  #          </p>
  #         <ul>
  #             <li>
  #                 <p>For the alphabetical list of API actions, see
  #         <a href="https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_Operations.html">API Actions</a>.</p>
  #             </li>
  #             <li>
  #                 <p>For the alphabetical list of data types, see
  #         <a href="https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_Types.html">Data Types</a>.</p>
  #             </li>
  #             <li>
  #                 <p>For a list of common query parameters, see
  #         <a href="https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/CommonParameters.html">Common Parameters</a>.</p>
  #             </li>
  #             <li>
  #                 <p>For descriptions of the error codes, see
  #         <a href="https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/CommonErrors.html">Common Errors</a>.</p>
  #             </li>
  #          </ul>
  #         <p>
  #             <b>Amazon RDS User Guide</b>
  #          </p>
  #         <ul>
  #             <li>
  #                 <p>For a summary of the Amazon RDS interfaces, see
  #         <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Welcome.html#Welcome.Interfaces">Available RDS Interfaces</a>.</p>
  #             </li>
  #             <li>
  #                 <p>For more information about how to use the Query API, see
  #         <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Using_the_Query_API.html">Using the Query API</a>.</p>
  #             </li>
  #          </ul>
  #
  class Client
    include Hearth::ClientStubs

    @middleware = Hearth::MiddlewareBuilder.new

    def self.middleware
      @middleware
    end

    # @param [Config] config
    #   An instance of {Config}
    #
    def initialize(config = AWS::SDK::RDS::Config.new, options = {})
      @config = config
      @middleware = Hearth::MiddlewareBuilder.new(options[:middleware])
      @stubs = Hearth::Stubbing::Stubs.new
      @retry_quota = Hearth::Retry::RetryQuota.new
      @client_rate_limiter = Hearth::Retry::ClientRateLimiter.new
    end

    # <p>Associates an Identity and Access Management (IAM) role with a DB cluster.</p>
    #
    # @param [Hash] params
    #   See {Types::AddRoleToDBClusterInput}.
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The name of the DB cluster to associate the IAM role with.</p>
    #
    # @option params [String] :role_arn
    #   <p>The Amazon Resource Name (ARN) of the IAM role to associate with the Aurora DB
    #               cluster, for example <code>arn:aws:iam::123456789012:role/AuroraAccessRole</code>.</p>
    #
    # @option params [String] :feature_name
    #   <p>The name of the feature for the DB cluster that the IAM role is to be associated with.
    #               For information about supported feature names, see <a>DBEngineVersion</a>.</p>
    #
    # @return [Types::AddRoleToDBClusterOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.add_role_to_db_cluster(
    #     db_cluster_identifier: 'DBClusterIdentifier', # required
    #     role_arn: 'RoleArn', # required
    #     feature_name: 'FeatureName'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::AddRoleToDBClusterOutput
    #
    def add_role_to_db_cluster(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::AddRoleToDBClusterInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::AddRoleToDBClusterInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::AddRoleToDBCluster
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::DBClusterRoleQuotaExceededFault, Errors::InvalidDBClusterStateFault, Errors::DBClusterRoleAlreadyExistsFault]),
        data_parser: Parsers::AddRoleToDBCluster
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::AddRoleToDBCluster,
        stubs: @stubs,
        params_class: Params::AddRoleToDBClusterOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :add_role_to_db_cluster
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Associates an Amazon Web Services Identity and Access Management (IAM) role with a DB instance.</p>
    #         <note>
    #             <p>To add a role to a DB instance, the status of the DB instance must be <code>available</code>.</p>
    #         </note>
    #         <p>This command doesn't apply to RDS Custom.</p>
    #
    # @param [Hash] params
    #   See {Types::AddRoleToDBInstanceInput}.
    #
    # @option params [String] :db_instance_identifier
    #   <p>The name of the DB instance to associate the IAM role with.</p>
    #
    # @option params [String] :role_arn
    #   <p>The Amazon Resource Name (ARN) of the IAM role to associate with the DB instance, for
    #               example <code>arn:aws:iam::123456789012:role/AccessRole</code>.</p>
    #
    # @option params [String] :feature_name
    #   <p>The name of the feature for the DB instance that the IAM role is to be associated with.
    #               For information about supported feature names, see <a>DBEngineVersion</a>.</p>
    #
    # @return [Types::AddRoleToDBInstanceOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.add_role_to_db_instance(
    #     db_instance_identifier: 'DBInstanceIdentifier', # required
    #     role_arn: 'RoleArn', # required
    #     feature_name: 'FeatureName' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::AddRoleToDBInstanceOutput
    #
    def add_role_to_db_instance(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::AddRoleToDBInstanceInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::AddRoleToDBInstanceInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::AddRoleToDBInstance
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBInstanceRoleAlreadyExistsFault, Errors::DBInstanceNotFoundFault, Errors::DBInstanceRoleQuotaExceededFault, Errors::InvalidDBInstanceStateFault]),
        data_parser: Parsers::AddRoleToDBInstance
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::AddRoleToDBInstance,
        stubs: @stubs,
        params_class: Params::AddRoleToDBInstanceOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :add_role_to_db_instance
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Adds a source identifier to an existing RDS event notification subscription.</p>
    #
    # @param [Hash] params
    #   See {Types::AddSourceIdentifierToSubscriptionInput}.
    #
    # @option params [String] :subscription_name
    #   <p>The name of the RDS event notification subscription you want to add a source identifier to.</p>
    #
    # @option params [String] :source_identifier
    #   <p>The identifier of the event source to be added.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If the source type is a DB instance, a <code>DBInstanceIdentifier</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is a DB cluster, a <code>DBClusterIdentifier</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is a DB parameter group, a <code>DBParameterGroupName</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is a DB security group, a <code>DBSecurityGroupName</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is a DB snapshot, a <code>DBSnapshotIdentifier</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is a DB cluster snapshot, a <code>DBClusterSnapshotIdentifier</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is an RDS Proxy, a <code>DBProxyName</code> value must be supplied.</p>
    #               </li>
    #            </ul>
    #
    # @return [Types::AddSourceIdentifierToSubscriptionOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.add_source_identifier_to_subscription(
    #     subscription_name: 'SubscriptionName', # required
    #     source_identifier: 'SourceIdentifier' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::AddSourceIdentifierToSubscriptionOutput
    #   resp.data.event_subscription #=> Types::EventSubscription
    #   resp.data.event_subscription.customer_aws_id #=> String
    #   resp.data.event_subscription.cust_subscription_id #=> String
    #   resp.data.event_subscription.sns_topic_arn #=> String
    #   resp.data.event_subscription.status #=> String
    #   resp.data.event_subscription.subscription_creation_time #=> String
    #   resp.data.event_subscription.source_type #=> String
    #   resp.data.event_subscription.source_ids_list #=> Array<String>
    #   resp.data.event_subscription.source_ids_list[0] #=> String
    #   resp.data.event_subscription.event_categories_list #=> Array<String>
    #   resp.data.event_subscription.event_categories_list[0] #=> String
    #   resp.data.event_subscription.enabled #=> Boolean
    #   resp.data.event_subscription.event_subscription_arn #=> String
    #
    def add_source_identifier_to_subscription(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::AddSourceIdentifierToSubscriptionInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::AddSourceIdentifierToSubscriptionInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::AddSourceIdentifierToSubscription
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::SubscriptionNotFoundFault, Errors::SourceNotFoundFault]),
        data_parser: Parsers::AddSourceIdentifierToSubscription
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::AddSourceIdentifierToSubscription,
        stubs: @stubs,
        params_class: Params::AddSourceIdentifierToSubscriptionOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :add_source_identifier_to_subscription
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Adds metadata tags to an Amazon RDS resource. These tags can also be used with cost allocation reporting to track cost associated with Amazon RDS resources, or used in a Condition statement in an IAM policy for Amazon RDS.</p>
    #         <p>For an overview on tagging Amazon RDS resources,
    #             see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Tagging.html">Tagging Amazon RDS Resources</a>.</p>
    #
    # @param [Hash] params
    #   See {Types::AddTagsToResourceInput}.
    #
    # @option params [String] :resource_name
    #   <p>The Amazon RDS resource that the tags are added to. This value is an Amazon Resource Name (ARN). For information about
    #               creating an ARN,
    #           see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.ARN.html#USER_Tagging.ARN.Constructing">
    #               Constructing an RDS Amazon Resource Name (ARN)</a>.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>The tags to be assigned to the Amazon RDS resource.</p>
    #
    # @return [Types::AddTagsToResourceOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.add_tags_to_resource(
    #     resource_name: 'ResourceName', # required
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ] # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::AddTagsToResourceOutput
    #
    def add_tags_to_resource(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::AddTagsToResourceInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::AddTagsToResourceInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::AddTagsToResource
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::DBInstanceNotFoundFault, Errors::DBProxyTargetGroupNotFoundFault, Errors::DBProxyNotFoundFault, Errors::DBSnapshotNotFoundFault]),
        data_parser: Parsers::AddTagsToResource
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::AddTagsToResource,
        stubs: @stubs,
        params_class: Params::AddTagsToResourceOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :add_tags_to_resource
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Applies a pending maintenance action to a resource (for example, to a DB instance).</p>
    #
    # @param [Hash] params
    #   See {Types::ApplyPendingMaintenanceActionInput}.
    #
    # @option params [String] :resource_identifier
    #   <p>The RDS Amazon Resource Name (ARN) of the resource that the
    #         pending maintenance action applies to. For information about
    #         creating an ARN,
    #         see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.ARN.html#USER_Tagging.ARN.Constructing">
    #           Constructing an RDS Amazon Resource Name (ARN)</a>.</p>
    #
    # @option params [String] :apply_action
    #   <p>The pending maintenance action to apply to this resource.</p>
    #           <p>Valid values: <code>system-update</code>, <code>db-upgrade</code>,
    #             <code>hardware-maintenance</code>, <code>ca-certificate-rotation</code>
    #            </p>
    #
    # @option params [String] :opt_in_type
    #   <p>A value that specifies the type of opt-in request, or undoes an opt-in request. An opt-in
    #              request of type <code>immediate</code> can't be undone.</p>
    #           <p>Valid values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>immediate</code> - Apply the maintenance action immediately.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>next-maintenance</code> - Apply the maintenance action during
    #               the next maintenance window for the resource.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>undo-opt-in</code> - Cancel any existing <code>next-maintenance</code>
    #               opt-in requests.</p>
    #               </li>
    #            </ul>
    #
    # @return [Types::ApplyPendingMaintenanceActionOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.apply_pending_maintenance_action(
    #     resource_identifier: 'ResourceIdentifier', # required
    #     apply_action: 'ApplyAction', # required
    #     opt_in_type: 'OptInType' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ApplyPendingMaintenanceActionOutput
    #   resp.data.resource_pending_maintenance_actions #=> Types::ResourcePendingMaintenanceActions
    #   resp.data.resource_pending_maintenance_actions.resource_identifier #=> String
    #   resp.data.resource_pending_maintenance_actions.pending_maintenance_action_details #=> Array<PendingMaintenanceAction>
    #   resp.data.resource_pending_maintenance_actions.pending_maintenance_action_details[0] #=> Types::PendingMaintenanceAction
    #   resp.data.resource_pending_maintenance_actions.pending_maintenance_action_details[0].action #=> String
    #   resp.data.resource_pending_maintenance_actions.pending_maintenance_action_details[0].auto_applied_after_date #=> Time
    #   resp.data.resource_pending_maintenance_actions.pending_maintenance_action_details[0].forced_apply_date #=> Time
    #   resp.data.resource_pending_maintenance_actions.pending_maintenance_action_details[0].opt_in_status #=> String
    #   resp.data.resource_pending_maintenance_actions.pending_maintenance_action_details[0].current_apply_date #=> Time
    #   resp.data.resource_pending_maintenance_actions.pending_maintenance_action_details[0].description #=> String
    #
    def apply_pending_maintenance_action(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ApplyPendingMaintenanceActionInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ApplyPendingMaintenanceActionInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ApplyPendingMaintenanceAction
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidDBClusterStateFault, Errors::InvalidDBInstanceStateFault, Errors::ResourceNotFoundFault]),
        data_parser: Parsers::ApplyPendingMaintenanceAction
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ApplyPendingMaintenanceAction,
        stubs: @stubs,
        params_class: Params::ApplyPendingMaintenanceActionOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :apply_pending_maintenance_action
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Enables ingress to a DBSecurityGroup using one of two forms of authorization. First, EC2 or VPC security
    #           groups can be added to the DBSecurityGroup if the application using the database is running on EC2 or VPC
    #           instances. Second, IP ranges are available if the application accessing your database is running on the internet.
    #           Required parameters for this API are one of CIDR range, EC2SecurityGroupId for VPC, or (EC2SecurityGroupOwnerId
    #           and either EC2SecurityGroupName or EC2SecurityGroupId for non-VPC).</p>
    #         <note>
    #             <p>You can't authorize ingress from an EC2 security group in one Amazon Web Services Region to an Amazon RDS DB instance in
    #              another. You can't authorize ingress from a VPC security group in one VPC to an Amazon RDS DB instance in another.</p>
    #         </note>
    #         <p>For an overview of CIDR ranges, go to the
    #             <a href="http://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing">Wikipedia Tutorial</a>.</p>
    #
    # @param [Hash] params
    #   See {Types::AuthorizeDBSecurityGroupIngressInput}.
    #
    # @option params [String] :db_security_group_name
    #   <p>The name of the DB security group to add authorization to.</p>
    #
    # @option params [String] :cidrip
    #   <p>The IP range to authorize.</p>
    #
    # @option params [String] :ec2_security_group_name
    #   <p>Name of the EC2 security group to authorize.
    #           For VPC DB security groups, <code>EC2SecurityGroupId</code> must be provided.
    #           Otherwise, <code>EC2SecurityGroupOwnerId</code> and either <code>EC2SecurityGroupName</code>
    #         or <code>EC2SecurityGroupId</code> must be provided.</p>
    #
    # @option params [String] :ec2_security_group_id
    #   <p>Id of the EC2 security group to authorize.
    #           For VPC DB security groups, <code>EC2SecurityGroupId</code> must be provided.
    #           Otherwise, <code>EC2SecurityGroupOwnerId</code> and either <code>EC2SecurityGroupName</code> or <code>EC2SecurityGroupId</code> must be provided.</p>
    #
    # @option params [String] :ec2_security_group_owner_id
    #   <p>Amazon Web Services account number of the owner of the EC2 security group
    #           specified in the <code>EC2SecurityGroupName</code> parameter.
    #           The Amazon Web Services access key ID isn't an acceptable value.
    #           For VPC DB security groups, <code>EC2SecurityGroupId</code> must be provided.
    #           Otherwise, <code>EC2SecurityGroupOwnerId</code> and either <code>EC2SecurityGroupName</code> or <code>EC2SecurityGroupId</code> must be provided.</p>
    #
    # @return [Types::AuthorizeDBSecurityGroupIngressOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.authorize_db_security_group_ingress(
    #     db_security_group_name: 'DBSecurityGroupName', # required
    #     cidrip: 'CIDRIP',
    #     ec2_security_group_name: 'EC2SecurityGroupName',
    #     ec2_security_group_id: 'EC2SecurityGroupId',
    #     ec2_security_group_owner_id: 'EC2SecurityGroupOwnerId'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::AuthorizeDBSecurityGroupIngressOutput
    #   resp.data.db_security_group #=> Types::DBSecurityGroup
    #   resp.data.db_security_group.owner_id #=> String
    #   resp.data.db_security_group.db_security_group_name #=> String
    #   resp.data.db_security_group.db_security_group_description #=> String
    #   resp.data.db_security_group.vpc_id #=> String
    #   resp.data.db_security_group.ec2_security_groups #=> Array<EC2SecurityGroup>
    #   resp.data.db_security_group.ec2_security_groups[0] #=> Types::EC2SecurityGroup
    #   resp.data.db_security_group.ec2_security_groups[0].status #=> String
    #   resp.data.db_security_group.ec2_security_groups[0].ec2_security_group_name #=> String
    #   resp.data.db_security_group.ec2_security_groups[0].ec2_security_group_id #=> String
    #   resp.data.db_security_group.ec2_security_groups[0].ec2_security_group_owner_id #=> String
    #   resp.data.db_security_group.ip_ranges #=> Array<IPRange>
    #   resp.data.db_security_group.ip_ranges[0] #=> Types::IPRange
    #   resp.data.db_security_group.ip_ranges[0].status #=> String
    #   resp.data.db_security_group.ip_ranges[0].cidrip #=> String
    #   resp.data.db_security_group.db_security_group_arn #=> String
    #
    def authorize_db_security_group_ingress(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::AuthorizeDBSecurityGroupIngressInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::AuthorizeDBSecurityGroupIngressInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::AuthorizeDBSecurityGroupIngress
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::AuthorizationQuotaExceededFault, Errors::AuthorizationAlreadyExistsFault, Errors::DBSecurityGroupNotFoundFault, Errors::InvalidDBSecurityGroupStateFault]),
        data_parser: Parsers::AuthorizeDBSecurityGroupIngress
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::AuthorizeDBSecurityGroupIngress,
        stubs: @stubs,
        params_class: Params::AuthorizeDBSecurityGroupIngressOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :authorize_db_security_group_ingress
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Backtracks a DB cluster to a specific time, without creating a new DB cluster.</p>
    #         <p>For more information on backtracking, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Managing.Backtrack.html">
    #                 Backtracking an Aurora DB Cluster</a> in the
    #             <i>Amazon Aurora User Guide</i>.</p>
    #         <note>
    #             <p>This action only applies to Aurora MySQL DB clusters.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::BacktrackDBClusterInput}.
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The DB cluster identifier of the DB cluster to be backtracked. This parameter is
    #               stored as a lowercase string.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain from 1 to 63 alphanumeric characters or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens.</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-cluster1</code>
    #            </p>
    #
    # @option params [Time] :backtrack_to
    #   <p>The timestamp of the time to backtrack the DB cluster to, specified in ISO
    #               8601 format. For more information about ISO 8601, see the <a href="http://en.wikipedia.org/wiki/ISO_8601">ISO8601 Wikipedia
    #               page.</a>
    #            </p>
    #           <note>
    #               <p>If the specified time isn't a consistent time for the DB cluster,
    #                   Aurora automatically chooses the nearest possible consistent time for the DB cluster.</p>
    #           </note>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain a valid ISO 8601 timestamp.</p>
    #               </li>
    #               <li>
    #                   <p>Can't contain a timestamp set in the future.</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>2017-07-08T18:00Z</code>
    #            </p>
    #
    # @option params [Boolean] :force
    #   <p>A value that indicates whether to force the DB cluster to backtrack when binary logging is
    #               enabled. Otherwise, an error occurs when binary logging is enabled.</p>
    #
    # @option params [Boolean] :use_earliest_time_on_point_in_time_unavailable
    #   <p>A value that indicates whether to backtrack the DB cluster to the earliest possible
    #               backtrack time when <i>BacktrackTo</i> is set to a timestamp earlier than the earliest
    #               backtrack time. When this parameter is disabled and <i>BacktrackTo</i> is set to a timestamp earlier than the earliest
    #               backtrack time, an error occurs.</p>
    #
    # @return [Types::BacktrackDBClusterOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.backtrack_db_cluster(
    #     db_cluster_identifier: 'DBClusterIdentifier', # required
    #     backtrack_to: Time.now, # required
    #     force: false,
    #     use_earliest_time_on_point_in_time_unavailable: false
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::BacktrackDBClusterOutput
    #   resp.data.db_cluster_identifier #=> String
    #   resp.data.backtrack_identifier #=> String
    #   resp.data.backtrack_to #=> Time
    #   resp.data.backtracked_from #=> Time
    #   resp.data.backtrack_request_creation_time #=> Time
    #   resp.data.status #=> String
    #
    def backtrack_db_cluster(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::BacktrackDBClusterInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::BacktrackDBClusterInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::BacktrackDBCluster
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::InvalidDBClusterStateFault]),
        data_parser: Parsers::BacktrackDBCluster
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::BacktrackDBCluster,
        stubs: @stubs,
        params_class: Params::BacktrackDBClusterOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :backtrack_db_cluster
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Cancels an export task in progress that is exporting a snapshot to Amazon S3.
    #             Any data that has already been written to the S3 bucket isn't removed.</p>
    #
    # @param [Hash] params
    #   See {Types::CancelExportTaskInput}.
    #
    # @option params [String] :export_task_identifier
    #   <p>The identifier of the snapshot export task to cancel.</p>
    #
    # @return [Types::CancelExportTaskOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.cancel_export_task(
    #     export_task_identifier: 'ExportTaskIdentifier' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CancelExportTaskOutput
    #   resp.data.export_task_identifier #=> String
    #   resp.data.source_arn #=> String
    #   resp.data.export_only #=> Array<String>
    #   resp.data.export_only[0] #=> String
    #   resp.data.snapshot_time #=> Time
    #   resp.data.task_start_time #=> Time
    #   resp.data.task_end_time #=> Time
    #   resp.data.s3_bucket #=> String
    #   resp.data.s3_prefix #=> String
    #   resp.data.iam_role_arn #=> String
    #   resp.data.kms_key_id #=> String
    #   resp.data.status #=> String
    #   resp.data.percent_progress #=> Integer
    #   resp.data.total_extracted_data_in_gb #=> Integer
    #   resp.data.failure_cause #=> String
    #   resp.data.warning_message #=> String
    #
    def cancel_export_task(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CancelExportTaskInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CancelExportTaskInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CancelExportTask
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::ExportTaskNotFoundFault, Errors::InvalidExportTaskStateFault]),
        data_parser: Parsers::CancelExportTask
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CancelExportTask,
        stubs: @stubs,
        params_class: Params::CancelExportTaskOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :cancel_export_task
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Copies the specified DB cluster parameter group.</p>
    #
    # @param [Hash] params
    #   See {Types::CopyDBClusterParameterGroupInput}.
    #
    # @option params [String] :source_db_cluster_parameter_group_identifier
    #   <p>The identifier or Amazon Resource Name (ARN) for the source DB cluster parameter group.
    #               For information about
    #               creating an ARN,
    #               see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_Tagging.ARN.html#USER_Tagging.ARN.Constructing">
    #                   Constructing an ARN for Amazon RDS</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must specify a valid DB cluster parameter group.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :target_db_cluster_parameter_group_identifier
    #   <p>The identifier for the copied DB cluster parameter group.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Can't be null, empty, or blank</p>
    #               </li>
    #               <li>
    #                   <p>Must contain from 1 to 255 letters, numbers, or hyphens</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-cluster-param-group1</code>
    #            </p>
    #
    # @option params [String] :target_db_cluster_parameter_group_description
    #   <p>A description for the copied DB cluster parameter group.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>A list of tags.
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.html">Tagging Amazon RDS Resources</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @return [Types::CopyDBClusterParameterGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.copy_db_cluster_parameter_group(
    #     source_db_cluster_parameter_group_identifier: 'SourceDBClusterParameterGroupIdentifier', # required
    #     target_db_cluster_parameter_group_identifier: 'TargetDBClusterParameterGroupIdentifier', # required
    #     target_db_cluster_parameter_group_description: 'TargetDBClusterParameterGroupDescription', # required
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CopyDBClusterParameterGroupOutput
    #   resp.data.db_cluster_parameter_group #=> Types::DBClusterParameterGroup
    #   resp.data.db_cluster_parameter_group.db_cluster_parameter_group_name #=> String
    #   resp.data.db_cluster_parameter_group.db_parameter_group_family #=> String
    #   resp.data.db_cluster_parameter_group.description #=> String
    #   resp.data.db_cluster_parameter_group.db_cluster_parameter_group_arn #=> String
    #
    def copy_db_cluster_parameter_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CopyDBClusterParameterGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CopyDBClusterParameterGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CopyDBClusterParameterGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBParameterGroupAlreadyExistsFault, Errors::DBParameterGroupQuotaExceededFault, Errors::DBParameterGroupNotFoundFault]),
        data_parser: Parsers::CopyDBClusterParameterGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CopyDBClusterParameterGroup,
        stubs: @stubs,
        params_class: Params::CopyDBClusterParameterGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :copy_db_cluster_parameter_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Copies a snapshot of a DB cluster.</p>
    #         <p>To copy a DB cluster snapshot from a shared manual DB cluster snapshot, <code>SourceDBClusterSnapshotIdentifier</code>
    #           must be the Amazon Resource Name (ARN) of the shared DB cluster snapshot.</p>
    #         <p>You can copy an encrypted DB cluster snapshot from another Amazon Web Services Region. In that case, the Amazon Web Services Region where you call the <code>CopyDBClusterSnapshot</code> action
    #           is the destination Amazon Web Services Region for the encrypted DB cluster snapshot to be copied to. To copy an encrypted DB cluster snapshot from another Amazon Web Services Region,
    #           you must provide the following values:</p>
    #         <ul>
    #             <li>
    #                 <p>
    #                   <code>KmsKeyId</code> - The Amazon Web Services Key Management System (Amazon Web Services KMS) key identifier for the key to use to
    #               encrypt the copy of the DB cluster snapshot in the destination Amazon Web Services Region.</p>
    #             </li>
    #             <li>
    #                 <p>
    #                   <code>PreSignedUrl</code> -  A URL that contains a Signature Version 4 signed request for the
    #               <code>CopyDBClusterSnapshot</code> action to be called in the source Amazon Web Services Region where the DB cluster snapshot is copied from.
    #               The pre-signed URL must be a valid request for the <code>CopyDBClusterSnapshot</code> API action that can be executed in the
    #               source Amazon Web Services Region that contains the encrypted DB cluster snapshot to be copied.</p>
    #                 <p>The pre-signed URL request must contain the following parameter values:</p>
    #                 <ul>
    #                   <li>
    #                         <p>
    #                         <code>KmsKeyId</code> - The Amazon Web Services KMS key identifier for the KMS key to use to encrypt the copy of the DB
    #                       cluster snapshot in the destination Amazon Web Services Region. This is the same identifier for both the <code>CopyDBClusterSnapshot</code>
    #                       action that is called in the destination Amazon Web Services Region, and the action contained in the pre-signed URL.</p>
    #                     </li>
    #                   <li>
    #                         <p>
    #                         <code>DestinationRegion</code> - The name of the Amazon Web Services Region that the DB cluster snapshot is to be created in.</p>
    #                     </li>
    #                   <li>
    #                         <p>
    #                         <code>SourceDBClusterSnapshotIdentifier</code> - The DB cluster snapshot identifier for the encrypted DB cluster
    #                       snapshot to be copied. This identifier must be in the Amazon Resource Name (ARN) format for the source Amazon Web Services Region. For example,
    #                       if you are copying an encrypted DB cluster snapshot from the us-west-2 Amazon Web Services Region, then your <code>SourceDBClusterSnapshotIdentifier</code>
    #                       looks like the following example: <code>arn:aws:rds:us-west-2:123456789012:cluster-snapshot:aurora-cluster1-snapshot-20161115</code>.</p>
    #                     </li>
    #                </ul>
    #                 <p>To learn how to generate a Signature Version 4 signed request, see
    #                   <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html">
    #                       Authenticating Requests: Using Query Parameters (Amazon Web Services Signature Version 4)</a> and
    #                   <a href="https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html">
    #                       Signature Version 4 Signing Process</a>.</p>
    #                 <note>
    #                     <p>If you are using an Amazon Web Services SDK tool or the CLI, you can specify <code>SourceRegion</code> (or <code>--source-region</code> for the CLI)
    #                       instead of specifying <code>PreSignedUrl</code> manually. Specifying <code>SourceRegion</code> autogenerates a pre-signed URL that is a valid
    #                       request for the operation that can be executed in the source Amazon Web Services Region.</p>
    #                 </note>
    #             </li>
    #             <li>
    #                 <p>
    #                   <code>TargetDBClusterSnapshotIdentifier</code> - The identifier for the new copy of the DB cluster snapshot in the destination Amazon Web Services Region.</p>
    #             </li>
    #             <li>
    #                 <p>
    #                   <code>SourceDBClusterSnapshotIdentifier</code> - The DB cluster snapshot identifier for the encrypted DB cluster snapshot to be copied.
    #               This identifier must be in the ARN format for the source Amazon Web Services Region and is the same value as the <code>SourceDBClusterSnapshotIdentifier</code> in the pre-signed URL.</p>
    #             </li>
    #          </ul>
    #         <p>To cancel the copy operation once it is in progress, delete the target DB cluster snapshot identified
    #           by <code>TargetDBClusterSnapshotIdentifier</code> while that DB cluster snapshot is in "copying" status.</p>
    #         <p>For more information on copying encrypted Amazon Aurora DB cluster snapshots from one Amazon Web Services Region to another, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_CopySnapshot.html">
    #               Copying a Snapshot</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Amazon Aurora DB clusters, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #                 What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #                 Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::CopyDBClusterSnapshotInput}.
    #
    # @option params [String] :source_db_cluster_snapshot_identifier
    #   <p>The identifier of the DB cluster snapshot to copy. This parameter isn't case-sensitive.</p>
    #           <p>You can't copy an encrypted, shared DB cluster snapshot from one Amazon Web Services Region to another.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must specify a valid system snapshot in the "available" state.</p>
    #               </li>
    #               <li>
    #                   <p>If the source snapshot is in the same Amazon Web Services Region as the copy, specify a valid DB snapshot identifier.</p>
    #               </li>
    #               <li>
    #                   <p>If the source snapshot is in a different Amazon Web Services Region than the copy,
    #                 specify a valid DB cluster snapshot ARN. For more information, go to
    #                 <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_CopySnapshot.html#USER_CopySnapshot.AcrossRegions">
    #                     Copying Snapshots Across Amazon Web Services Regions</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-cluster-snapshot1</code>
    #            </p>
    #
    # @option params [String] :target_db_cluster_snapshot_identifier
    #   <p>The identifier of the new DB cluster snapshot to create from the source DB cluster snapshot. This parameter isn't case-sensitive.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain from 1 to 63 letters, numbers, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens.</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-cluster-snapshot2</code>
    #            </p>
    #
    # @option params [String] :kms_key_id
    #   <p>The Amazon Web Services KMS key identifier for an encrypted DB cluster snapshot.
    #               The Amazon Web Services KMS key identifier is the key ARN, key ID, alias ARN, or alias name for the Amazon Web Services KMS key.</p>
    #           <p>If you copy an encrypted DB cluster snapshot from your Amazon Web Services account, you can specify a value for <code>KmsKeyId</code> to encrypt the copy with a new KMS key.
    #               If you don't specify a value for <code>KmsKeyId</code>, then the copy of the DB cluster snapshot is encrypted with the same KMS key as the source DB cluster snapshot.</p>
    #           <p>If you copy an encrypted DB cluster snapshot that is shared from another Amazon Web Services account, then you must specify a value for <code>KmsKeyId</code>.</p>
    #           <p>To copy an encrypted DB cluster snapshot to another Amazon Web Services Region, you must set <code>KmsKeyId</code> to the Amazon Web Services KMS key identifier
    #               you want to use to encrypt the copy of the DB cluster snapshot in the destination Amazon Web Services Region. KMS keys are specific to the Amazon Web Services
    #               Region that they are created in, and you can't use KMS keys from one Amazon Web Services Region
    #               in another Amazon Web Services Region.</p>
    #           <p>If you copy an unencrypted DB cluster snapshot and specify a value for the <code>KmsKeyId</code> parameter,
    #               an error is returned.</p>
    #
    # @option params [String] :pre_signed_url
    #   <p>The URL that contains a Signature Version 4 signed request for the <code>CopyDBClusterSnapshot</code> API action in the Amazon Web Services Region that contains the
    #               source DB cluster snapshot to copy. The <code>PreSignedUrl</code> parameter must be used when copying an encrypted DB cluster snapshot from another Amazon Web Services Region.
    #               Don't specify <code>PreSignedUrl</code> when you are copying an encrypted DB cluster snapshot in the same Amazon Web Services Region.</p>
    #           <p>The pre-signed URL must be a valid request for the <code>CopyDBClusterSnapshot</code> API action that can be
    #               executed in the source Amazon Web Services Region that contains the encrypted DB cluster snapshot to be copied.
    #               The pre-signed URL request must contain the following parameter values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>KmsKeyId</code> - The Amazon Web Services KMS key identifier for the KMS key to use to encrypt the copy of the DB
    #                   cluster snapshot in the destination Amazon Web Services Region. This is the same identifier for both the <code>CopyDBClusterSnapshot</code>
    #                   action that is called in the destination Amazon Web Services Region, and the action contained in the pre-signed URL.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>DestinationRegion</code> - The name of the Amazon Web Services Region that the DB cluster snapshot is to be created in.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>SourceDBClusterSnapshotIdentifier</code> - The DB cluster snapshot identifier for the encrypted DB cluster
    #                   snapshot to be copied. This identifier must be in the Amazon Resource Name (ARN) format for the source Amazon Web Services Region. For example,
    #                   if you are copying an encrypted DB cluster snapshot from the us-west-2 Amazon Web Services Region, then your <code>SourceDBClusterSnapshotIdentifier</code>
    #                   looks like the following example: <code>arn:aws:rds:us-west-2:123456789012:cluster-snapshot:aurora-cluster1-snapshot-20161115</code>.</p>
    #               </li>
    #            </ul>
    #           <p>To learn how to generate a Signature Version 4 signed request, see
    #
    #               <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html">
    #                   Authenticating Requests: Using Query Parameters (Amazon Web Services Signature Version 4)</a> and
    #               <a href="https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html">
    #                   Signature Version 4 Signing Process</a>.</p>
    #           <note>
    #               <p>If you are using an Amazon Web Services SDK tool or the CLI, you can specify <code>SourceRegion</code> (or <code>--source-region</code> for the CLI)
    #                   instead of specifying <code>PreSignedUrl</code> manually. Specifying <code>SourceRegion</code> autogenerates a pre-signed URL that is a valid
    #                   request for the operation that can be executed in the source Amazon Web Services Region.</p>
    #           </note>
    #
    # @option params [Boolean] :copy_tags
    #   <p>A value that indicates whether to copy all tags from the source DB cluster snapshot to the target DB cluster snapshot.
    #               By default, tags are not copied.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>A list of tags.
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.html">Tagging Amazon RDS Resources</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @return [Types::CopyDBClusterSnapshotOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.copy_db_cluster_snapshot(
    #     source_db_cluster_snapshot_identifier: 'SourceDBClusterSnapshotIdentifier', # required
    #     target_db_cluster_snapshot_identifier: 'TargetDBClusterSnapshotIdentifier', # required
    #     kms_key_id: 'KmsKeyId',
    #     pre_signed_url: 'PreSignedUrl',
    #     copy_tags: false,
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CopyDBClusterSnapshotOutput
    #   resp.data.db_cluster_snapshot #=> Types::DBClusterSnapshot
    #   resp.data.db_cluster_snapshot.availability_zones #=> Array<String>
    #   resp.data.db_cluster_snapshot.availability_zones[0] #=> String
    #   resp.data.db_cluster_snapshot.db_cluster_snapshot_identifier #=> String
    #   resp.data.db_cluster_snapshot.db_cluster_identifier #=> String
    #   resp.data.db_cluster_snapshot.snapshot_create_time #=> Time
    #   resp.data.db_cluster_snapshot.engine #=> String
    #   resp.data.db_cluster_snapshot.engine_mode #=> String
    #   resp.data.db_cluster_snapshot.allocated_storage #=> Integer
    #   resp.data.db_cluster_snapshot.status #=> String
    #   resp.data.db_cluster_snapshot.port #=> Integer
    #   resp.data.db_cluster_snapshot.vpc_id #=> String
    #   resp.data.db_cluster_snapshot.cluster_create_time #=> Time
    #   resp.data.db_cluster_snapshot.master_username #=> String
    #   resp.data.db_cluster_snapshot.engine_version #=> String
    #   resp.data.db_cluster_snapshot.license_model #=> String
    #   resp.data.db_cluster_snapshot.snapshot_type #=> String
    #   resp.data.db_cluster_snapshot.percent_progress #=> Integer
    #   resp.data.db_cluster_snapshot.storage_encrypted #=> Boolean
    #   resp.data.db_cluster_snapshot.kms_key_id #=> String
    #   resp.data.db_cluster_snapshot.db_cluster_snapshot_arn #=> String
    #   resp.data.db_cluster_snapshot.source_db_cluster_snapshot_arn #=> String
    #   resp.data.db_cluster_snapshot.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster_snapshot.tag_list #=> Array<Tag>
    #   resp.data.db_cluster_snapshot.tag_list[0] #=> Types::Tag
    #   resp.data.db_cluster_snapshot.tag_list[0].key #=> String
    #   resp.data.db_cluster_snapshot.tag_list[0].value #=> String
    #
    def copy_db_cluster_snapshot(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CopyDBClusterSnapshotInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CopyDBClusterSnapshotInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CopyDBClusterSnapshot
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidDBClusterSnapshotStateFault, Errors::SnapshotQuotaExceededFault, Errors::DBClusterSnapshotAlreadyExistsFault, Errors::KMSKeyNotAccessibleFault, Errors::InvalidDBClusterStateFault, Errors::DBClusterSnapshotNotFoundFault]),
        data_parser: Parsers::CopyDBClusterSnapshot
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CopyDBClusterSnapshot,
        stubs: @stubs,
        params_class: Params::CopyDBClusterSnapshotOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :copy_db_cluster_snapshot
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Copies the specified DB parameter group.</p>
    #
    # @param [Hash] params
    #   See {Types::CopyDBParameterGroupInput}.
    #
    # @option params [String] :source_db_parameter_group_identifier
    #   <p>The identifier or ARN for the source DB parameter group.
    #           For information about
    #           creating an ARN,
    #           see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.ARN.html#USER_Tagging.ARN.Constructing">
    #               Constructing an ARN for Amazon RDS</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must specify a valid DB parameter group.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :target_db_parameter_group_identifier
    #   <p>The identifier for the copied DB parameter group.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Can't be null, empty, or blank</p>
    #               </li>
    #               <li>
    #                   <p>Must contain from 1 to 255 letters, numbers, or hyphens</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-db-parameter-group</code>
    #            </p>
    #
    # @option params [String] :target_db_parameter_group_description
    #   <p>A description for the copied DB parameter group.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>A list of tags.
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.html">Tagging Amazon RDS Resources</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @return [Types::CopyDBParameterGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.copy_db_parameter_group(
    #     source_db_parameter_group_identifier: 'SourceDBParameterGroupIdentifier', # required
    #     target_db_parameter_group_identifier: 'TargetDBParameterGroupIdentifier', # required
    #     target_db_parameter_group_description: 'TargetDBParameterGroupDescription', # required
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CopyDBParameterGroupOutput
    #   resp.data.db_parameter_group #=> Types::DBParameterGroup
    #   resp.data.db_parameter_group.db_parameter_group_name #=> String
    #   resp.data.db_parameter_group.db_parameter_group_family #=> String
    #   resp.data.db_parameter_group.description #=> String
    #   resp.data.db_parameter_group.db_parameter_group_arn #=> String
    #
    def copy_db_parameter_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CopyDBParameterGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CopyDBParameterGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CopyDBParameterGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBParameterGroupAlreadyExistsFault, Errors::DBParameterGroupQuotaExceededFault, Errors::DBParameterGroupNotFoundFault]),
        data_parser: Parsers::CopyDBParameterGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CopyDBParameterGroup,
        stubs: @stubs,
        params_class: Params::CopyDBParameterGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :copy_db_parameter_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Copies the specified DB snapshot. The source DB snapshot must be in the <code>available</code> state.</p>
    #         <p>You can copy a snapshot from one Amazon Web Services Region to another. In that case, the Amazon Web Services Region
    #             where you call the <code>CopyDBSnapshot</code> action is the destination Amazon Web Services Region for the
    #             DB snapshot copy.</p>
    #         <p>This command doesn't apply to RDS Custom.</p>
    #         <p>For more information about copying snapshots, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CopySnapshot.html#USER_CopyDBSnapshot">Copying a DB Snapshot</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::CopyDBSnapshotInput}.
    #
    # @option params [String] :source_db_snapshot_identifier
    #   <p>The identifier for the source DB snapshot.</p>
    #           <p>If the source snapshot is in the same Amazon Web Services Region as the copy, specify a valid DB
    #               snapshot identifier. For example, you might specify
    #                   <code>rds:mysql-instance1-snapshot-20130805</code>.</p>
    #           <p>If the source snapshot is in a different Amazon Web Services Region than the copy, specify a valid DB
    #               snapshot ARN. For example, you might specify
    #                   <code>arn:aws:rds:us-west-2:123456789012:snapshot:mysql-instance1-snapshot-20130805</code>.</p>
    #           <p>If you are copying from a shared manual DB snapshot,
    #             this parameter must be the Amazon Resource Name (ARN) of the shared DB snapshot.</p>
    #           <p>If you are copying an encrypted snapshot
    #               this parameter must be in the ARN format for the source Amazon Web Services Region,
    #               and must match the <code>SourceDBSnapshotIdentifier</code> in the <code>PreSignedUrl</code> parameter.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must specify a valid system snapshot in the "available" state.</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>rds:mydb-2012-04-02-00-01</code>
    #            </p>
    #           <p>Example: <code>arn:aws:rds:us-west-2:123456789012:snapshot:mysql-instance1-snapshot-20130805</code>
    #            </p>
    #
    # @option params [String] :target_db_snapshot_identifier
    #   <p>The identifier for the copy of the snapshot.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Can't be null, empty, or blank</p>
    #               </li>
    #               <li>
    #                   <p>Must contain from 1 to 255 letters, numbers, or hyphens</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-db-snapshot</code>
    #            </p>
    #
    # @option params [String] :kms_key_id
    #   <p>The Amazon Web Services KMS key identifier for an encrypted DB snapshot.
    #               The Amazon Web Services KMS key identifier is the key ARN, key ID, alias ARN, or alias name for the KMS key.</p>
    #           <p>If you copy an encrypted DB snapshot from your Amazon Web Services account,
    #               you can specify a value for this parameter to encrypt the copy with a new KMS key.
    #               If you don't specify a value for this parameter,
    #               then the copy of the DB snapshot is encrypted with the same Amazon Web Services KMS key as the source DB snapshot.</p>
    #           <p>If you copy an encrypted DB snapshot that is shared from another Amazon Web Services account,
    #               then you must specify a value for this parameter.</p>
    #           <p>If you specify this parameter when you copy an unencrypted snapshot,
    #               the copy is encrypted.</p>
    #           <p>If you copy an encrypted snapshot to a different Amazon Web Services Region, then you must specify
    #               an Amazon Web Services KMS key identifier for the destination Amazon Web Services Region. KMS keys are specific to the Amazon Web Services Region
    #               that they are created in, and you can't use KMS keys from one Amazon Web Services Region in another
    #               Amazon Web Services Region.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>A list of tags.
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.html">Tagging Amazon RDS Resources</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @option params [Boolean] :copy_tags
    #   <p>A value that indicates whether to copy all tags from the source DB snapshot to the target DB snapshot. By default, tags are not copied.</p>
    #
    # @option params [String] :pre_signed_url
    #   <p>The URL that contains a Signature Version 4 signed request for the
    #                   <code>CopyDBSnapshot</code> API action in the source Amazon Web Services Region that contains the
    #               source DB snapshot to copy.</p>
    #           <p>You must specify this parameter when you copy an encrypted DB snapshot from another
    #               Amazon Web Services Region by using the Amazon RDS API. Don't specify <code>PreSignedUrl</code> when you are
    #               copying an encrypted DB snapshot in the same Amazon Web Services Region.</p>
    #           <p>The presigned URL must be a valid request for the <code>CopyDBSnapshot</code> API action
    #               that can be executed in the source Amazon Web Services Region that contains the encrypted DB snapshot to be copied.
    #               The presigned URL request must contain the following parameter values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>DestinationRegion</code> - The Amazon Web Services Region that the encrypted DB snapshot is copied to.
    #                       This Amazon Web Services Region is the same one where the <code>CopyDBSnapshot</code> action is called that contains this presigned URL.</p>
    #                   <p>For example, if you copy an encrypted DB snapshot from the us-west-2 Amazon Web Services Region
    #                       to the us-east-1 Amazon Web Services Region, then you call the <code>CopyDBSnapshot</code> action in
    #                       the us-east-1 Amazon Web Services Region and provide a presigned URL that contains a call to the
    #                           <code>CopyDBSnapshot</code> action in the us-west-2 Amazon Web Services Region. For this
    #                       example, the <code>DestinationRegion</code> in the presigned URL must be set to
    #                       the us-east-1 Amazon Web Services Region.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>KmsKeyId</code> - The Amazon Web Services KMS key identifier for the KMS key to use to encrypt the copy of the DB snapshot in the destination Amazon Web Services Region.
    #                       This is the same identifier for both the <code>CopyDBSnapshot</code> action that is called in the destination Amazon Web Services Region,
    #                       and the action contained in the presigned URL.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>SourceDBSnapshotIdentifier</code> - The DB snapshot identifier for the encrypted snapshot to be copied.
    #                       This identifier must be in the Amazon Resource Name (ARN) format for the source Amazon Web Services Region.
    #                       For example, if you are copying an encrypted DB snapshot from the us-west-2 Amazon Web Services Region, then your <code>SourceDBSnapshotIdentifier</code> looks like
    #                       the following example: <code>arn:aws:rds:us-west-2:123456789012:snapshot:mysql-instance1-snapshot-20161115</code>.</p>
    #               </li>
    #            </ul>
    #           <p>To learn how to generate a Signature Version 4 signed request, see
    #           <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html">Authenticating Requests: Using Query Parameters (Amazon Web Services Signature Version 4)</a> and
    #           <a href="https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html">Signature Version 4 Signing Process</a>.</p>
    #           <note>
    #               <p>If you are using an Amazon Web Services SDK tool or the CLI, you can specify <code>SourceRegion</code> (or <code>--source-region</code> for the CLI)
    #                  instead of specifying <code>PreSignedUrl</code> manually. Specifying <code>SourceRegion</code> autogenerates a pre-signed URL that is a valid
    #                  request for the operation that can be executed in the source Amazon Web Services Region.</p>
    #           </note>
    #
    # @option params [String] :option_group_name
    #   <p>The name of an option group to associate with the copy of the snapshot.</p>
    #           <p>Specify this option if you are copying a snapshot from one Amazon Web Services Region to another,
    #               and your DB instance uses a nondefault option group.
    #               If your source DB instance uses Transparent Data Encryption for Oracle or Microsoft SQL Server,
    #               you must specify this option when copying across Amazon Web Services Regions.
    #               For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CopySnapshot.html#USER_CopySnapshot.Options">Option group considerations</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @option params [String] :target_custom_availability_zone
    #   <p>The external custom Availability Zone (CAZ) identifier for the target CAZ.</p>
    #           <p>Example: <code>rds-caz-aiqhTgQv</code>.</p>
    #
    # @return [Types::CopyDBSnapshotOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.copy_db_snapshot(
    #     source_db_snapshot_identifier: 'SourceDBSnapshotIdentifier', # required
    #     target_db_snapshot_identifier: 'TargetDBSnapshotIdentifier', # required
    #     kms_key_id: 'KmsKeyId',
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ],
    #     copy_tags: false,
    #     pre_signed_url: 'PreSignedUrl',
    #     option_group_name: 'OptionGroupName',
    #     target_custom_availability_zone: 'TargetCustomAvailabilityZone'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CopyDBSnapshotOutput
    #   resp.data.db_snapshot #=> Types::DBSnapshot
    #   resp.data.db_snapshot.db_snapshot_identifier #=> String
    #   resp.data.db_snapshot.db_instance_identifier #=> String
    #   resp.data.db_snapshot.snapshot_create_time #=> Time
    #   resp.data.db_snapshot.engine #=> String
    #   resp.data.db_snapshot.allocated_storage #=> Integer
    #   resp.data.db_snapshot.status #=> String
    #   resp.data.db_snapshot.port #=> Integer
    #   resp.data.db_snapshot.availability_zone #=> String
    #   resp.data.db_snapshot.vpc_id #=> String
    #   resp.data.db_snapshot.instance_create_time #=> Time
    #   resp.data.db_snapshot.master_username #=> String
    #   resp.data.db_snapshot.engine_version #=> String
    #   resp.data.db_snapshot.license_model #=> String
    #   resp.data.db_snapshot.snapshot_type #=> String
    #   resp.data.db_snapshot.iops #=> Integer
    #   resp.data.db_snapshot.option_group_name #=> String
    #   resp.data.db_snapshot.percent_progress #=> Integer
    #   resp.data.db_snapshot.source_region #=> String
    #   resp.data.db_snapshot.source_db_snapshot_identifier #=> String
    #   resp.data.db_snapshot.storage_type #=> String
    #   resp.data.db_snapshot.tde_credential_arn #=> String
    #   resp.data.db_snapshot.encrypted #=> Boolean
    #   resp.data.db_snapshot.kms_key_id #=> String
    #   resp.data.db_snapshot.db_snapshot_arn #=> String
    #   resp.data.db_snapshot.timezone #=> String
    #   resp.data.db_snapshot.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_snapshot.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_snapshot.processor_features[0] #=> Types::ProcessorFeature
    #   resp.data.db_snapshot.processor_features[0].name #=> String
    #   resp.data.db_snapshot.processor_features[0].value #=> String
    #   resp.data.db_snapshot.dbi_resource_id #=> String
    #   resp.data.db_snapshot.tag_list #=> Array<Tag>
    #   resp.data.db_snapshot.tag_list[0] #=> Types::Tag
    #   resp.data.db_snapshot.tag_list[0].key #=> String
    #   resp.data.db_snapshot.tag_list[0].value #=> String
    #   resp.data.db_snapshot.original_snapshot_create_time #=> Time
    #   resp.data.db_snapshot.snapshot_target #=> String
    #
    def copy_db_snapshot(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CopyDBSnapshotInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CopyDBSnapshotInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CopyDBSnapshot
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::SnapshotQuotaExceededFault, Errors::KMSKeyNotAccessibleFault, Errors::DBSnapshotAlreadyExistsFault, Errors::CustomAvailabilityZoneNotFoundFault, Errors::InvalidDBSnapshotStateFault, Errors::DBSnapshotNotFoundFault]),
        data_parser: Parsers::CopyDBSnapshot
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CopyDBSnapshot,
        stubs: @stubs,
        params_class: Params::CopyDBSnapshotOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :copy_db_snapshot
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Copies the specified option group.</p>
    #
    # @param [Hash] params
    #   See {Types::CopyOptionGroupInput}.
    #
    # @option params [String] :source_option_group_identifier
    #   <p>The identifier for the source option group.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must specify a valid option group.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :target_option_group_identifier
    #   <p>The identifier for the copied option group.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Can't be null, empty, or blank</p>
    #               </li>
    #               <li>
    #                   <p>Must contain from 1 to 255 letters, numbers, or hyphens</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-option-group</code>
    #            </p>
    #
    # @option params [String] :target_option_group_description
    #   <p>The description for the copied option group.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>A list of tags.
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.html">Tagging Amazon RDS Resources</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @return [Types::CopyOptionGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.copy_option_group(
    #     source_option_group_identifier: 'SourceOptionGroupIdentifier', # required
    #     target_option_group_identifier: 'TargetOptionGroupIdentifier', # required
    #     target_option_group_description: 'TargetOptionGroupDescription', # required
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CopyOptionGroupOutput
    #   resp.data.option_group #=> Types::OptionGroup
    #   resp.data.option_group.option_group_name #=> String
    #   resp.data.option_group.option_group_description #=> String
    #   resp.data.option_group.engine_name #=> String
    #   resp.data.option_group.major_engine_version #=> String
    #   resp.data.option_group.options #=> Array<Option>
    #   resp.data.option_group.options[0] #=> Types::Option
    #   resp.data.option_group.options[0].option_name #=> String
    #   resp.data.option_group.options[0].option_description #=> String
    #   resp.data.option_group.options[0].persistent #=> Boolean
    #   resp.data.option_group.options[0].permanent #=> Boolean
    #   resp.data.option_group.options[0].port #=> Integer
    #   resp.data.option_group.options[0].option_version #=> String
    #   resp.data.option_group.options[0].option_settings #=> Array<OptionSetting>
    #   resp.data.option_group.options[0].option_settings[0] #=> Types::OptionSetting
    #   resp.data.option_group.options[0].option_settings[0].name #=> String
    #   resp.data.option_group.options[0].option_settings[0].value #=> String
    #   resp.data.option_group.options[0].option_settings[0].default_value #=> String
    #   resp.data.option_group.options[0].option_settings[0].description #=> String
    #   resp.data.option_group.options[0].option_settings[0].apply_type #=> String
    #   resp.data.option_group.options[0].option_settings[0].data_type #=> String
    #   resp.data.option_group.options[0].option_settings[0].allowed_values #=> String
    #   resp.data.option_group.options[0].option_settings[0].is_modifiable #=> Boolean
    #   resp.data.option_group.options[0].option_settings[0].is_collection #=> Boolean
    #   resp.data.option_group.options[0].db_security_group_memberships #=> Array<DBSecurityGroupMembership>
    #   resp.data.option_group.options[0].db_security_group_memberships[0] #=> Types::DBSecurityGroupMembership
    #   resp.data.option_group.options[0].db_security_group_memberships[0].db_security_group_name #=> String
    #   resp.data.option_group.options[0].db_security_group_memberships[0].status #=> String
    #   resp.data.option_group.options[0].vpc_security_group_memberships #=> Array<VpcSecurityGroupMembership>
    #   resp.data.option_group.options[0].vpc_security_group_memberships[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.option_group.options[0].vpc_security_group_memberships[0].vpc_security_group_id #=> String
    #   resp.data.option_group.options[0].vpc_security_group_memberships[0].status #=> String
    #   resp.data.option_group.allows_vpc_and_non_vpc_instance_memberships #=> Boolean
    #   resp.data.option_group.vpc_id #=> String
    #   resp.data.option_group.option_group_arn #=> String
    #
    def copy_option_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CopyOptionGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CopyOptionGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CopyOptionGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::OptionGroupAlreadyExistsFault, Errors::OptionGroupNotFoundFault, Errors::OptionGroupQuotaExceededFault]),
        data_parser: Parsers::CopyOptionGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CopyOptionGroup,
        stubs: @stubs,
        params_class: Params::CopyOptionGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :copy_option_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates a custom DB engine version (CEV). A CEV is a binary volume snapshot of a database engine and specific
    #             AMI. The supported engines are the following:</p>
    #         <ul>
    #             <li>
    #                 <p>Oracle Database 12.1 Enterprise Edition with the January 2021 or later RU/RUR</p>
    #             </li>
    #             <li>
    #                 <p>Oracle Database 19c Enterprise Edition with the January 2021 or later RU/RUR</p>
    #             </li>
    #          </ul>
    #         <p>Amazon RDS, which is a fully managed service, supplies the Amazon Machine Image (AMI) and database software.
    #             The Amazon RDS database software is preinstalled, so you need only select a DB engine and version, and create
    #             your database. With Amazon RDS Custom for Oracle, you upload your database installation files in Amazon S3.</p>
    #         <p>When you create a custom engine version, you specify the files in a JSON document called a CEV manifest.
    #             This document describes installation .zip files stored in Amazon S3. RDS Custom creates your CEV from
    #             the installation files that you provided. This service model is called Bring Your Own Media (BYOM).</p>
    #         <p>Creation takes approximately two hours. If creation fails, RDS Custom issues <code>RDS-EVENT-0196</code> with
    #             the message <code>Creation failed for custom engine version</code>, and includes details about the failure.
    #             For example, the event prints missing files.</p>
    #         <p>After you create the CEV, it is available for use. You can create multiple CEVs, and create multiple
    #             RDS Custom instances from any CEV. You can also change the status of a CEV to make it available or
    #             inactive.</p>
    #         <note>
    #             <p>The MediaImport service that imports files from Amazon S3 to create CEVs isn't integrated with
    #             Amazon Web Services CloudTrail. If you turn on data logging for Amazon RDS in CloudTrail, calls to the
    #             <code>CreateCustomDbEngineVersion</code> event aren't logged. However, you might see calls from the
    #             API gateway that accesses your Amazon S3 bucket. These calls originate from the MediaImport service for
    #             the <code>CreateCustomDbEngineVersion</code> event.</p>
    #         </note>
    #         <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/custom-cev.html#custom-cev.create">
    #                 Creating a CEV</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::CreateCustomDBEngineVersionInput}.
    #
    # @option params [String] :engine
    #   <p>The database engine to use for your custom engine version (CEV). The only supported value is
    #               <code>custom-oracle-ee</code>.</p>
    #
    # @option params [String] :engine_version
    #   <p>The name of your CEV. The name format is <code>19.<i>customized_string</i>
    #               </code>. For example,
    #               a valid name is <code>19.my_cev1</code>. This setting is required for RDS Custom for Oracle, but optional for Amazon RDS.
    #               The combination of <code>Engine</code> and <code>EngineVersion</code> is unique per customer per Region.</p>
    #
    # @option params [String] :database_installation_files_s3_bucket_name
    #   <p>The name of an Amazon S3 bucket that contains database installation files for your CEV. For example, a valid
    #               bucket name is <code>my-custom-installation-files</code>.</p>
    #
    # @option params [String] :database_installation_files_s3_prefix
    #   <p>The Amazon S3 directory that contains the database installation files for your CEV. For example, a valid
    #               bucket name is <code>123456789012/cev1</code>. If this setting isn't specified, no prefix is assumed.</p>
    #
    # @option params [String] :kms_key_id
    #   <p>The Amazon Web Services KMS key identifier for an encrypted CEV. A symmetric KMS key is required for
    #               RDS Custom, but optional for Amazon RDS.</p>
    #           <p>If you have an existing symmetric KMS key in your account, you can use it with RDS Custom.
    #               No further action is necessary. If you don't already have a symmetric KMS key in your account,
    #               follow the instructions in <a href="https://docs.aws.amazon.com/kms/latest/developerguide/create-keys.html#create-symmetric-cmk">
    #                   Creating symmetric KMS keys</a> in the <i>Amazon Web Services Key Management Service
    #                       Developer Guide</i>.</p>
    #           <p>You can choose the same symmetric key when you create a CEV and a DB instance, or choose different keys.</p>
    #
    # @option params [String] :description
    #   <p>An optional description of your CEV.</p>
    #
    # @option params [String] :manifest
    #   <p>The CEV manifest, which is a JSON document that describes the installation .zip files stored in Amazon S3.
    #               Specify the name/value pairs in a file or a quoted string. RDS Custom applies the patches in the order in which
    #               they are listed.</p>
    #           <p>The following JSON fields are valid:</p>
    #           <dl>
    #               <dt>MediaImportTemplateVersion</dt>
    #               <dd>
    #                       <p>Version of the CEV manifest. The date is in the format <code>YYYY-MM-DD</code>.</p>
    #                   </dd>
    #               <dt>databaseInstallationFileNames</dt>
    #               <dd>
    #                       <p>Ordered list of installation files for the CEV.</p>
    #                   </dd>
    #               <dt>opatchFileNames</dt>
    #               <dd>
    #                       <p>Ordered list of OPatch installers used for the Oracle DB engine.</p>
    #                   </dd>
    #               <dt>psuRuPatchFileNames</dt>
    #               <dd>
    #                       <p>The PSU and RU patches for this CEV.</p>
    #                   </dd>
    #               <dt>OtherPatchFileNames</dt>
    #               <dd>
    #                       <p>The patches that are not in the list of PSU and RU patches.
    #                       Amazon RDS applies these patches after applying the PSU and RU patches.</p>
    #                   </dd>
    #            </dl>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/custom-cev.html#custom-cev.preparing.manifest">
    #               Creating the CEV manifest</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>A list of tags.
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.html">Tagging Amazon RDS Resources</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @return [Types::CreateCustomDBEngineVersionOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.create_custom_db_engine_version(
    #     engine: 'Engine', # required
    #     engine_version: 'EngineVersion', # required
    #     database_installation_files_s3_bucket_name: 'DatabaseInstallationFilesS3BucketName', # required
    #     database_installation_files_s3_prefix: 'DatabaseInstallationFilesS3Prefix',
    #     kms_key_id: 'KMSKeyId', # required
    #     description: 'Description',
    #     manifest: 'Manifest', # required
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CreateCustomDBEngineVersionOutput
    #   resp.data.engine #=> String
    #   resp.data.engine_version #=> String
    #   resp.data.db_parameter_group_family #=> String
    #   resp.data.db_engine_description #=> String
    #   resp.data.db_engine_version_description #=> String
    #   resp.data.default_character_set #=> Types::CharacterSet
    #   resp.data.default_character_set.character_set_name #=> String
    #   resp.data.default_character_set.character_set_description #=> String
    #   resp.data.supported_character_sets #=> Array<CharacterSet>
    #   resp.data.supported_nchar_character_sets #=> Array<CharacterSet>
    #   resp.data.valid_upgrade_target #=> Array<UpgradeTarget>
    #   resp.data.valid_upgrade_target[0] #=> Types::UpgradeTarget
    #   resp.data.valid_upgrade_target[0].engine #=> String
    #   resp.data.valid_upgrade_target[0].engine_version #=> String
    #   resp.data.valid_upgrade_target[0].description #=> String
    #   resp.data.valid_upgrade_target[0].auto_upgrade #=> Boolean
    #   resp.data.valid_upgrade_target[0].is_major_version_upgrade #=> Boolean
    #   resp.data.valid_upgrade_target[0].supported_engine_modes #=> Array<String>
    #   resp.data.valid_upgrade_target[0].supported_engine_modes[0] #=> String
    #   resp.data.valid_upgrade_target[0].supports_parallel_query #=> Boolean
    #   resp.data.valid_upgrade_target[0].supports_global_databases #=> Boolean
    #   resp.data.valid_upgrade_target[0].supports_babelfish #=> Boolean
    #   resp.data.supported_timezones #=> Array<Timezone>
    #   resp.data.supported_timezones[0] #=> Types::Timezone
    #   resp.data.supported_timezones[0].timezone_name #=> String
    #   resp.data.exportable_log_types #=> Array<String>
    #   resp.data.exportable_log_types[0] #=> String
    #   resp.data.supports_log_exports_to_cloudwatch_logs #=> Boolean
    #   resp.data.supports_read_replica #=> Boolean
    #   resp.data.supported_engine_modes #=> Array<String>
    #   resp.data.supported_feature_names #=> Array<String>
    #   resp.data.supported_feature_names[0] #=> String
    #   resp.data.status #=> String
    #   resp.data.supports_parallel_query #=> Boolean
    #   resp.data.supports_global_databases #=> Boolean
    #   resp.data.major_engine_version #=> String
    #   resp.data.database_installation_files_s3_bucket_name #=> String
    #   resp.data.database_installation_files_s3_prefix #=> String
    #   resp.data.db_engine_version_arn #=> String
    #   resp.data.kms_key_id #=> String
    #   resp.data.create_time #=> Time
    #   resp.data.tag_list #=> Array<Tag>
    #   resp.data.tag_list[0] #=> Types::Tag
    #   resp.data.tag_list[0].key #=> String
    #   resp.data.tag_list[0].value #=> String
    #   resp.data.supports_babelfish #=> Boolean
    #
    def create_custom_db_engine_version(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CreateCustomDBEngineVersionInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CreateCustomDBEngineVersionInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CreateCustomDBEngineVersion
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::CustomDBEngineVersionAlreadyExistsFault, Errors::KMSKeyNotAccessibleFault, Errors::CustomDBEngineVersionQuotaExceededFault]),
        data_parser: Parsers::CreateCustomDBEngineVersion
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CreateCustomDBEngineVersion,
        stubs: @stubs,
        params_class: Params::CreateCustomDBEngineVersionOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :create_custom_db_engine_version
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates a new Amazon Aurora DB cluster or Multi-AZ DB cluster.</p>
    #         <p>You can use the <code>ReplicationSourceIdentifier</code> parameter to create an Amazon
    #             Aurora DB cluster as a read replica of another DB cluster or Amazon RDS MySQL or
    #             PostgreSQL DB instance. For cross-Region replication where the DB cluster identified by
    #                 <code>ReplicationSourceIdentifier</code> is encrypted, also specify the
    #                 <code>PreSignedUrl</code> parameter.</p>
    #         <p>For more information on Amazon Aurora, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #               What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #               Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::CreateDBClusterInput}.
    #
    # @option params [Array<String>] :availability_zones
    #   <p>A list of Availability Zones (AZs) where DB instances in the DB cluster can be created.</p>
    #           <p>For information on Amazon Web Services Regions and Availability Zones, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Concepts.RegionsAndAvailabilityZones.html">Choosing the Regions and
    #                 Availability Zones</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [Integer] :backup_retention_period
    #   <p>The number of days for which automated backups are retained.</p>
    #           <p>Default: 1</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be a value from 1 to 35</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :character_set_name
    #   <p>A value that indicates that the DB cluster should be associated with the specified CharacterSet.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [String] :database_name
    #   <p>The name for your database of up to 64 alphanumeric characters. If you do not
    #               provide a name, Amazon RDS doesn't create a database in the DB cluster you are
    #               creating.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The DB cluster identifier. This parameter is stored as a lowercase string.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain from 1 to 63 letters, numbers, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens.</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-cluster1</code>
    #            </p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :db_cluster_parameter_group_name
    #   <p>The name of the DB cluster parameter group to associate
    #               with this DB cluster. If you do not specify a value, then
    #             the default DB cluster parameter group for the specified DB engine and version is used.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match the name of an existing DB cluster parameter group.</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Array<String>] :vpc_security_group_ids
    #   <p>A list of EC2 VPC security groups to associate with this DB cluster.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :db_subnet_group_name
    #   <p>A DB subnet group to associate with this DB cluster.</p>
    #           <p>This setting is required to create a Multi-AZ DB cluster.</p>
    #           <p>Constraints: Must match the name of an existing DBSubnetGroup. Must not be default.</p>
    #           <p>Example: <code>mydbsubnetgroup</code>
    #            </p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :engine
    #   <p>The name of the database engine to be used for this DB cluster.</p>
    #           <p>Valid Values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>aurora</code> (for MySQL 5.6-compatible Aurora)</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-mysql</code> (for MySQL 5.7-compatible and MySQL 8.0-compatible Aurora)</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-postgresql</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mysql</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>postgres</code>
    #                  </p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :engine_version
    #   <p>The version number of the database engine to use.</p>
    #           <p>To list all of the available engine versions for MySQL 5.6-compatible Aurora, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine aurora --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>To list all of the available engine versions for MySQL 5.7-compatible and MySQL 8.0-compatible Aurora, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine aurora-mysql --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>To list all of the available engine versions for Aurora PostgreSQL, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine aurora-postgresql --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>To list all of the available engine versions for RDS for MySQL, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine mysql --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>To list all of the available engine versions for RDS for PostgreSQL, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine postgres --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>
    #               <b>Aurora MySQL</b>
    #            </p>
    #           <p>For information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Updates.html">MySQL on Amazon RDS Versions</a> in the
    #             <i>Amazon Aurora User Guide</i>.</p>
    #           <p>
    #               <b>Aurora PostgreSQL</b>
    #            </p>
    #           <p>For information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.Updates.20180305.html">Amazon Aurora PostgreSQL releases and engine versions</a> in the
    #              <i>Amazon Aurora User Guide</i>.</p>
    #           <p>
    #               <b>MySQL</b>
    #            </p>
    #           <p>For information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_MySQL.html#MySQL.Concepts.VersionMgmt">MySQL on Amazon RDS Versions</a> in the
    #             <i>Amazon RDS User Guide</i>.</p>
    #           <p>
    #               <b>PostgreSQL</b>
    #            </p>
    #           <p>For information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_PostgreSQL.html#PostgreSQL.Concepts">Amazon RDS for PostgreSQL versions and extensions</a> in the
    #             <i>Amazon RDS User Guide</i>.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Integer] :port
    #   <p>The port number on which the instances in the DB cluster accept connections.</p>
    #           <p>
    #               <b>RDS for MySQL and Aurora MySQL</b>
    #            </p>
    #           <p>Default: <code>3306</code>
    #            </p>
    #           <p>Valid values: <code>1150-65535</code>
    #            </p>
    #           <p>
    #               <b>RDS for PostgreSQL and Aurora PostgreSQL</b>
    #            </p>
    #           <p>Default: <code>5432</code>
    #            </p>
    #           <p>Valid values: <code>1150-65535</code>
    #            </p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :master_username
    #   <p>The name of the master user for the DB cluster.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be 1 to 16 letters or numbers.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't be a reserved word for the chosen database engine.</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :master_user_password
    #   <p>The password for the master database user. This password can contain any printable ASCII character except "/", """, or "@".</p>
    #           <p>Constraints: Must contain from 8 to 41 characters.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :option_group_name
    #   <p>A value that indicates that the DB cluster should be associated with the specified option group.</p>
    #           <p>DB clusters are associated with a default option group that can't be modified.</p>
    #
    # @option params [String] :preferred_backup_window
    #   <p>The daily time range during which automated backups are created
    #           if automated backups are enabled
    #           using the <code>BackupRetentionPeriod</code> parameter.</p>
    #           <p>The default is a 30-minute window selected at random from an
    #           8-hour block of time for each Amazon Web Services Region.
    #           To view the time blocks available, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Managing.Backups.html#Aurora.Managing.Backups.BackupWindow">
    #               Backup window</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be in the format <code>hh24:mi-hh24:mi</code>.</p>
    #               </li>
    #               <li>
    #                   <p>Must be in Universal Coordinated Time (UTC).</p>
    #               </li>
    #               <li>
    #                   <p>Must not conflict with the preferred maintenance window.</p>
    #               </li>
    #               <li>
    #                   <p>Must be at least 30 minutes.</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :preferred_maintenance_window
    #   <p>The weekly time range during which system maintenance can occur, in Universal Coordinated Time (UTC).</p>
    #           <p>Format: <code>ddd:hh24:mi-ddd:hh24:mi</code>
    #            </p>
    #           <p>The default is a 30-minute window selected at random from an
    #               8-hour block of time for each Amazon Web Services Region, occurring on a random day of the
    #               week. To see the time blocks available, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_UpgradeDBInstance.Maintenance.html#AdjustingTheMaintenanceWindow.Aurora">
    #                   Adjusting the Preferred DB Cluster Maintenance Window</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Valid Days: Mon, Tue, Wed, Thu, Fri, Sat, Sun.</p>
    #           <p>Constraints: Minimum 30-minute window.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :replication_source_identifier
    #   <p>The Amazon Resource Name (ARN) of the source DB instance or DB cluster if this DB
    #               cluster is created as a read replica.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>Tags to assign to the DB cluster.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Boolean] :storage_encrypted
    #   <p>A value that indicates whether the DB cluster is encrypted.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :kms_key_id
    #   <p>The Amazon Web Services KMS key identifier for an encrypted DB cluster.</p>
    #           <p>The Amazon Web Services KMS key identifier is the key ARN, key ID, alias ARN, or alias name for the KMS key.
    #                    To use a KMS key in a different Amazon Web Services account, specify the key ARN or alias ARN.</p>
    #           <p>When a KMS key isn't specified in <code>KmsKeyId</code>:</p>
    #           <ul>
    #               <li>
    #                   <p>If <code>ReplicationSourceIdentifier</code> identifies an encrypted
    #                       source, then Amazon RDS will use the KMS key used to encrypt the
    #                       source. Otherwise, Amazon RDS will use your default KMS key.</p>
    #               </li>
    #               <li>
    #                   <p>If the <code>StorageEncrypted</code> parameter is enabled and
    #                           <code>ReplicationSourceIdentifier</code> isn't specified, then Amazon RDS
    #                       will use your default KMS key.</p>
    #               </li>
    #            </ul>
    #           <p>There is a default KMS key for your Amazon Web Services account. Your Amazon Web Services account
    #               has a different default KMS key for each Amazon Web Services Region.</p>
    #           <p>If you create a read replica of an encrypted DB cluster in another Amazon Web Services Region, you
    #               must set <code>KmsKeyId</code> to a KMS key identifier that is valid in the destination Amazon Web Services
    #               Region. This KMS key is used to encrypt the read replica in that Amazon Web Services Region.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :pre_signed_url
    #   <p>A URL that contains a Signature Version 4 signed request for
    #               the <code>CreateDBCluster</code> action to be called in the source Amazon Web Services Region where the DB cluster is replicated from.
    #               Specify <code>PreSignedUrl</code> only when you are performing cross-Region replication from an encrypted DB cluster.</p>
    #           <p>The pre-signed URL must be a valid request for the <code>CreateDBCluster</code> API action
    #               that can be executed in the source Amazon Web Services Region that contains the encrypted DB cluster to be copied.</p>
    #           <p>The pre-signed URL request must contain the following parameter values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>KmsKeyId</code> - The Amazon Web Services KMS key identifier for the KMS key to use to encrypt the copy of
    #                   the DB cluster in the destination Amazon Web Services Region. This should refer to the same KMS key for both the <code>CreateDBCluster</code>
    #                   action that is called in the destination Amazon Web Services Region, and the action contained in the pre-signed URL.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>DestinationRegion</code> - The name of the Amazon Web Services Region that Aurora read replica will
    #                       be created in.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>ReplicationSourceIdentifier</code> - The DB cluster identifier for the encrypted DB cluster to be copied.
    #                   This identifier must be in the Amazon Resource Name (ARN) format for the source Amazon Web Services Region. For example, if you are copying an
    #                   encrypted DB cluster from the us-west-2 Amazon Web Services Region, then your <code>ReplicationSourceIdentifier</code> would look like
    #                   Example: <code>arn:aws:rds:us-west-2:123456789012:cluster:aurora-cluster1</code>.</p>
    #               </li>
    #            </ul>
    #           <p>To learn how to generate a Signature Version 4 signed request, see
    #               <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html">
    #                   Authenticating Requests: Using Query Parameters (Amazon Web Services Signature Version 4)</a> and
    #               <a href="https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html">
    #                   Signature Version 4 Signing Process</a>.</p>
    #           <note>
    #               <p>If you are using an Amazon Web Services SDK tool or the CLI, you can specify <code>SourceRegion</code> (or <code>--source-region</code> for the CLI)
    #                   instead of specifying <code>PreSignedUrl</code> manually. Specifying <code>SourceRegion</code> autogenerates a pre-signed URL that is a valid
    #                   request for the operation that can be executed in the source Amazon Web Services Region.</p>
    #           </note>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [Boolean] :enable_iam_database_authentication
    #   <p>A value that indicates whether to enable mapping of Amazon Web Services Identity and Access
    #               Management (IAM) accounts to database accounts. By default, mapping isn't
    #               enabled.</p>
    #           <p>For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/UsingWithRDS.IAMDBAuth.html">
    #                   IAM Database Authentication</a> in the <i>Amazon Aurora User Guide.</i>.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [Integer] :backtrack_window
    #   <p>The target backtrack window, in seconds. To disable backtracking, set this value to
    #               0.</p>
    #           <p>Default: 0</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If specified, this value must be set to a number from 0 to 259,200 (72 hours).</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora MySQL DB clusters only</p>
    #
    # @option params [Array<String>] :enable_cloudwatch_logs_exports
    #   <p>The list of log types that need to be enabled for exporting to CloudWatch Logs. The values
    #               in the list depend on the DB engine being used.</p>
    #           <p>
    #               <b>RDS for MySQL</b>
    #            </p>
    #           <p>Possible values are <code>error</code>, <code>general</code>, and <code>slowquery</code>.</p>
    #           <p>
    #               <b>RDS for PostgreSQL</b>
    #            </p>
    #           <p>Possible values are <code>postgresql</code> and <code>upgrade</code>.</p>
    #           <p>
    #               <b>Aurora MySQL</b>
    #            </p>
    #           <p>Possible values are <code>audit</code>, <code>error</code>, <code>general</code>, and <code>slowquery</code>.</p>
    #           <p>
    #               <b>Aurora PostgreSQL</b>
    #            </p>
    #           <p>Possible value is <code>postgresql</code>.</p>
    #           <p>For more information about exporting CloudWatch Logs for Amazon RDS, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.html#USER_LogAccess.Procedural.UploadtoCloudWatch">Publishing Database Logs to Amazon CloudWatch Logs</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>For more information about exporting CloudWatch Logs for Amazon Aurora, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_LogAccess.html#USER_LogAccess.Procedural.UploadtoCloudWatch">Publishing Database Logs to Amazon CloudWatch Logs</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :engine_mode
    #   <p>The DB engine mode of the DB cluster, either <code>provisioned</code>, <code>serverless</code>,
    #               <code>parallelquery</code>, <code>global</code>, or <code>multimaster</code>.</p>
    #           <p>The <code>parallelquery</code> engine mode isn't required for Aurora MySQL version 1.23 and higher 1.x versions,
    #               and version 2.09 and higher 2.x versions.</p>
    #           <p>The <code>global</code> engine mode isn't required for Aurora MySQL version 1.22 and higher 1.x versions,
    #               and <code>global</code> engine mode isn't required for any 2.x versions.</p>
    #           <p>The <code>multimaster</code> engine mode only applies for DB clusters created with Aurora MySQL version 5.6.10a.</p>
    #           <p>For Aurora PostgreSQL, the <code>global</code> engine mode isn't required, and both the <code>parallelquery</code>
    #               and the <code>multimaster</code> engine modes currently aren't supported.</p>
    #           <p>Limitations and requirements apply to some DB engine modes. For more information, see the
    #               following sections in the <i>Amazon Aurora User Guide</i>:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless.html#aurora-serverless.limitations">
    #                           Limitations of Aurora Serverless v1</a>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-mysql-parallel-query.html#aurora-mysql-parallel-query-limitations">
    #                           Limitations of Parallel Query</a>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database.html#aurora-global-database.limitations">
    #                           Limitations of Aurora Global Databases</a>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-multi-master.html#aurora-multi-master-limitations">
    #                           Limitations of Multi-Master Clusters</a>
    #                  </p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [ScalingConfiguration] :scaling_configuration
    #   <p>For DB clusters in <code>serverless</code> DB engine mode, the scaling properties of the DB cluster.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [Boolean] :deletion_protection
    #   <p>A value that indicates whether the DB cluster has deletion protection enabled.
    #               The database can't be deleted when deletion protection is enabled. By default,
    #               deletion protection isn't enabled.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :global_cluster_identifier
    #   <p>The global cluster ID of an Aurora cluster that becomes the primary cluster
    #               in the new global database cluster.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [Boolean] :enable_http_endpoint
    #   <p>A value that indicates whether to enable the HTTP endpoint for an Aurora Serverless v1 DB cluster. By default, the HTTP endpoint
    #               is disabled.</p>
    #           <p>When enabled, the HTTP endpoint provides a connectionless web service API for running
    #               SQL queries on the Aurora Serverless v1 DB cluster. You can also query your database
    #               from inside the RDS console with the query editor.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/data-api.html">Using the Data API for Aurora Serverless v1</a> in the
    #               <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [Boolean] :copy_tags_to_snapshot
    #   <p>A value that indicates whether to copy all tags from the DB cluster to snapshots of the DB cluster.
    #               The default is not to copy them.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :domain
    #   <p>The Active Directory directory ID to create the DB cluster in.</p>
    #           <p>For Amazon Aurora DB clusters, Amazon RDS can use Kerberos authentication to authenticate users that connect to the DB cluster.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/kerberos-authentication.html">Kerberos authentication</a>
    #               in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [String] :domain_iam_role_name
    #   <p>Specify the name of the IAM role to be used when making API calls to the Directory Service.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [Boolean] :enable_global_write_forwarding
    #   <p>A value that indicates whether to enable this DB cluster to forward write operations to the primary cluster of an
    #         Aurora global database (<a>GlobalCluster</a>). By default, write operations are not allowed on Aurora DB clusters that
    #         are secondary clusters in an Aurora global database.</p>
    #           <p>You can set this value only on Aurora DB clusters that are members of an Aurora global database. With this parameter
    #         enabled, a secondary cluster can forward writes to the current primary cluster and the resulting changes are replicated back to
    #         this cluster. For the primary DB cluster of an Aurora global database, this value is used immediately if the
    #           primary is demoted by the <a>FailoverGlobalCluster</a> API operation, but it does nothing until then.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [String] :db_cluster_instance_class
    #   <p>The compute and memory capacity of each DB instance in the Multi-AZ DB cluster, for example db.m6g.xlarge.
    #               Not all DB instance classes are available in all Amazon Web Services Regions, or for all database engines.</p>
    #           <p>For the full list of DB instance classes and availability for your engine, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html">DB instance class</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting is required to create a Multi-AZ DB cluster.</p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [Integer] :allocated_storage
    #   <p>The amount of storage in gibibytes (GiB) to allocate to each DB instance in the Multi-AZ DB cluster.</p>
    #           <p>This setting is required to create a Multi-AZ DB cluster.</p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [String] :storage_type
    #   <p>Specifies the storage type to be associated with the DB cluster.</p>
    #           <p>This setting is required to create a Multi-AZ DB cluster.</p>
    #           <p>Valid values: <code>io1</code>
    #            </p>
    #           <p>When specified, a value for the <code>Iops</code> parameter is required.</p>
    #           <p>Default: <code>io1</code>
    #            </p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [Integer] :iops
    #   <p>The amount of Provisioned IOPS (input/output operations per second) to be initially allocated
    #               for each DB instance in the Multi-AZ DB cluster.</p>
    #           <p>For information about valid <code>Iops</code> values, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html#USER_PIOPS">Amazon RDS Provisioned IOPS storage to improve performance</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting is required to create a Multi-AZ DB cluster.</p>
    #           <p>Constraints: Must be a multiple between .5 and 50 of the storage amount for the DB cluster.</p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [Boolean] :publicly_accessible
    #   <p>A value that indicates whether the DB cluster is publicly accessible.</p>
    #           <p>When the DB cluster is publicly accessible, its Domain Name System (DNS) endpoint
    #               resolves to the private IP address from within the DB cluster's virtual private cloud
    #               (VPC). It resolves to the public IP address from outside of the DB cluster's VPC. Access
    #               to the DB cluster is ultimately controlled by the security group it uses. That public
    #               access isn't permitted if the security group assigned to the DB cluster doesn't permit
    #               it.</p>
    #           <p>When the DB cluster isn't publicly accessible, it is an internal DB cluster with a DNS name that resolves to a private IP address.</p>
    #           <p>Default: The default behavior varies depending on whether <code>DBSubnetGroupName</code> is specified.</p>
    #           <p>If <code>DBSubnetGroupName</code> isn't specified, and <code>PubliclyAccessible</code> isn't specified, the following applies:</p>
    #           <ul>
    #               <li>
    #                   <p>If the default VPC in the target Region doesnt have an internet gateway attached to it, the DB cluster is private.</p>
    #               </li>
    #               <li>
    #                   <p>If the default VPC in the target Region has an internet gateway attached to it, the DB cluster is public.</p>
    #               </li>
    #            </ul>
    #           <p>If <code>DBSubnetGroupName</code> is specified, and <code>PubliclyAccessible</code> isn't specified, the following applies:</p>
    #           <ul>
    #               <li>
    #                   <p>If the subnets are part of a VPC that doesnt have an internet gateway attached to it, the DB cluster is private.</p>
    #               </li>
    #               <li>
    #                   <p>If the subnets are part of a VPC that has an internet gateway attached to it, the DB cluster is public.</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [Boolean] :auto_minor_version_upgrade
    #   <p>A value that indicates whether minor engine upgrades are applied automatically to the DB cluster during the maintenance window.
    #               By default, minor engine upgrades are applied automatically.</p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [Integer] :monitoring_interval
    #   <p>The interval, in seconds, between points when Enhanced Monitoring metrics are collected for the DB cluster. To turn off
    #               collecting Enhanced Monitoring metrics, specify 0. The default is 0.</p>
    #           <p>If <code>MonitoringRoleArn</code> is specified, also set <code>MonitoringInterval</code>
    #               to a value other than 0.</p>
    #           <p>Valid Values: <code>0, 1, 5, 10, 15, 30, 60</code>
    #            </p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [String] :monitoring_role_arn
    #   <p>The Amazon Resource Name (ARN) for the IAM role that permits RDS to send Enhanced Monitoring metrics to Amazon CloudWatch Logs.
    #               An example is <code>arn:aws:iam:123456789012:role/emaccess</code>. For information on creating a monitoring role,
    #               see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.OS.html#USER_Monitoring.OS.Enabling">Setting
    #                   up and enabling Enhanced Monitoring</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>If <code>MonitoringInterval</code> is set to a value other than 0, supply a <code>MonitoringRoleArn</code> value.</p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [Boolean] :enable_performance_insights
    #   <p>A value that indicates whether to turn on Performance Insights for the DB cluster.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PerfInsights.html">
    #               Using Amazon Performance Insights</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [String] :performance_insights_kms_key_id
    #   <p>The Amazon Web Services KMS key identifier for encryption of Performance Insights data.</p>
    #           <p>The Amazon Web Services KMS key identifier is the key ARN, key ID, alias ARN, or alias name for the KMS key.</p>
    #           <p>If you don't specify a value for <code>PerformanceInsightsKMSKeyId</code>, then Amazon RDS
    #               uses your default KMS key. There is a default KMS key for your Amazon Web Services account.
    #               Your Amazon Web Services account has a different default KMS key for each Amazon Web Services Region.</p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [Integer] :performance_insights_retention_period
    #   <p>The amount of time, in days, to retain Performance Insights data. Valid values are 7 or 731 (2 years).</p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [ServerlessV2ScalingConfiguration] :serverless_v2_scaling_configuration
    #   <p>Contains the scaling configuration of an Aurora Serverless v2 DB cluster.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v2.html">Using Amazon Aurora Serverless v2</a> in the
    #               <i>Amazon Aurora User Guide</i>.</p>
    #
    # @return [Types::CreateDBClusterOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.create_db_cluster(
    #     availability_zones: [
    #       'member'
    #     ],
    #     backup_retention_period: 1,
    #     character_set_name: 'CharacterSetName',
    #     database_name: 'DatabaseName',
    #     db_cluster_identifier: 'DBClusterIdentifier', # required
    #     db_cluster_parameter_group_name: 'DBClusterParameterGroupName',
    #     vpc_security_group_ids: [
    #       'member'
    #     ],
    #     db_subnet_group_name: 'DBSubnetGroupName',
    #     engine: 'Engine', # required
    #     engine_version: 'EngineVersion',
    #     port: 1,
    #     master_username: 'MasterUsername',
    #     master_user_password: 'MasterUserPassword',
    #     option_group_name: 'OptionGroupName',
    #     preferred_backup_window: 'PreferredBackupWindow',
    #     preferred_maintenance_window: 'PreferredMaintenanceWindow',
    #     replication_source_identifier: 'ReplicationSourceIdentifier',
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ],
    #     storage_encrypted: false,
    #     kms_key_id: 'KmsKeyId',
    #     pre_signed_url: 'PreSignedUrl',
    #     enable_iam_database_authentication: false,
    #     backtrack_window: 1,
    #     enable_cloudwatch_logs_exports: [
    #       'member'
    #     ],
    #     engine_mode: 'EngineMode',
    #     scaling_configuration: {
    #       min_capacity: 1,
    #       max_capacity: 1,
    #       auto_pause: false,
    #       seconds_until_auto_pause: 1,
    #       timeout_action: 'TimeoutAction',
    #       seconds_before_timeout: 1
    #     },
    #     deletion_protection: false,
    #     global_cluster_identifier: 'GlobalClusterIdentifier',
    #     enable_http_endpoint: false,
    #     copy_tags_to_snapshot: false,
    #     domain: 'Domain',
    #     domain_iam_role_name: 'DomainIAMRoleName',
    #     enable_global_write_forwarding: false,
    #     db_cluster_instance_class: 'DBClusterInstanceClass',
    #     allocated_storage: 1,
    #     storage_type: 'StorageType',
    #     iops: 1,
    #     publicly_accessible: false,
    #     auto_minor_version_upgrade: false,
    #     monitoring_interval: 1,
    #     monitoring_role_arn: 'MonitoringRoleArn',
    #     enable_performance_insights: false,
    #     performance_insights_kms_key_id: 'PerformanceInsightsKMSKeyId',
    #     performance_insights_retention_period: 1,
    #     serverless_v2_scaling_configuration: {
    #       min_capacity: 1.0,
    #       max_capacity: 1.0
    #     }
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CreateDBClusterOutput
    #   resp.data.db_cluster #=> Types::DBCluster
    #   resp.data.db_cluster.allocated_storage #=> Integer
    #   resp.data.db_cluster.availability_zones #=> Array<String>
    #   resp.data.db_cluster.availability_zones[0] #=> String
    #   resp.data.db_cluster.backup_retention_period #=> Integer
    #   resp.data.db_cluster.character_set_name #=> String
    #   resp.data.db_cluster.database_name #=> String
    #   resp.data.db_cluster.db_cluster_identifier #=> String
    #   resp.data.db_cluster.db_cluster_parameter_group #=> String
    #   resp.data.db_cluster.db_subnet_group #=> String
    #   resp.data.db_cluster.status #=> String
    #   resp.data.db_cluster.automatic_restart_time #=> Time
    #   resp.data.db_cluster.percent_progress #=> String
    #   resp.data.db_cluster.earliest_restorable_time #=> Time
    #   resp.data.db_cluster.endpoint #=> String
    #   resp.data.db_cluster.reader_endpoint #=> String
    #   resp.data.db_cluster.custom_endpoints #=> Array<String>
    #   resp.data.db_cluster.custom_endpoints[0] #=> String
    #   resp.data.db_cluster.multi_az #=> Boolean
    #   resp.data.db_cluster.engine #=> String
    #   resp.data.db_cluster.engine_version #=> String
    #   resp.data.db_cluster.latest_restorable_time #=> Time
    #   resp.data.db_cluster.port #=> Integer
    #   resp.data.db_cluster.master_username #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships #=> Array<DBClusterOptionGroupStatus>
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0] #=> Types::DBClusterOptionGroupStatus
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].db_cluster_option_group_name #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].status #=> String
    #   resp.data.db_cluster.preferred_backup_window #=> String
    #   resp.data.db_cluster.preferred_maintenance_window #=> String
    #   resp.data.db_cluster.replication_source_identifier #=> String
    #   resp.data.db_cluster.read_replica_identifiers #=> Array<String>
    #   resp.data.db_cluster.read_replica_identifiers[0] #=> String
    #   resp.data.db_cluster.db_cluster_members #=> Array<DBClusterMember>
    #   resp.data.db_cluster.db_cluster_members[0] #=> Types::DBClusterMember
    #   resp.data.db_cluster.db_cluster_members[0].db_instance_identifier #=> String
    #   resp.data.db_cluster.db_cluster_members[0].is_cluster_writer #=> Boolean
    #   resp.data.db_cluster.db_cluster_members[0].db_cluster_parameter_group_status #=> String
    #   resp.data.db_cluster.db_cluster_members[0].promotion_tier #=> Integer
    #   resp.data.db_cluster.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_cluster.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_cluster.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_cluster.vpc_security_groups[0].status #=> String
    #   resp.data.db_cluster.hosted_zone_id #=> String
    #   resp.data.db_cluster.storage_encrypted #=> Boolean
    #   resp.data.db_cluster.kms_key_id #=> String
    #   resp.data.db_cluster.db_cluster_resource_id #=> String
    #   resp.data.db_cluster.db_cluster_arn #=> String
    #   resp.data.db_cluster.associated_roles #=> Array<DBClusterRole>
    #   resp.data.db_cluster.associated_roles[0] #=> Types::DBClusterRole
    #   resp.data.db_cluster.associated_roles[0].role_arn #=> String
    #   resp.data.db_cluster.associated_roles[0].status #=> String
    #   resp.data.db_cluster.associated_roles[0].feature_name #=> String
    #   resp.data.db_cluster.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.clone_group_id #=> String
    #   resp.data.db_cluster.cluster_create_time #=> Time
    #   resp.data.db_cluster.earliest_backtrack_time #=> Time
    #   resp.data.db_cluster.backtrack_window #=> Integer
    #   resp.data.db_cluster.backtrack_consumed_change_records #=> Integer
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports[0] #=> String
    #   resp.data.db_cluster.capacity #=> Integer
    #   resp.data.db_cluster.engine_mode #=> String
    #   resp.data.db_cluster.scaling_configuration_info #=> Types::ScalingConfigurationInfo
    #   resp.data.db_cluster.scaling_configuration_info.min_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.max_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.auto_pause #=> Boolean
    #   resp.data.db_cluster.scaling_configuration_info.seconds_until_auto_pause #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.timeout_action #=> String
    #   resp.data.db_cluster.scaling_configuration_info.seconds_before_timeout #=> Integer
    #   resp.data.db_cluster.deletion_protection #=> Boolean
    #   resp.data.db_cluster.http_endpoint_enabled #=> Boolean
    #   resp.data.db_cluster.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_cluster.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_cluster.activity_stream_kms_key_id #=> String
    #   resp.data.db_cluster.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_cluster.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_cluster.cross_account_clone #=> Boolean
    #   resp.data.db_cluster.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_cluster.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_cluster.domain_memberships[0].domain #=> String
    #   resp.data.db_cluster.domain_memberships[0].status #=> String
    #   resp.data.db_cluster.domain_memberships[0].fqdn #=> String
    #   resp.data.db_cluster.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_cluster.tag_list #=> Array<Tag>
    #   resp.data.db_cluster.tag_list[0] #=> Types::Tag
    #   resp.data.db_cluster.tag_list[0].key #=> String
    #   resp.data.db_cluster.tag_list[0].value #=> String
    #   resp.data.db_cluster.global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.db_cluster.global_write_forwarding_requested #=> Boolean
    #   resp.data.db_cluster.pending_modified_values #=> Types::ClusterPendingModifiedValues
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.db_cluster_identifier #=> String
    #   resp.data.db_cluster.pending_modified_values.master_user_password #=> String
    #   resp.data.db_cluster.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.pending_modified_values.engine_version #=> String
    #   resp.data.db_cluster.db_cluster_instance_class #=> String
    #   resp.data.db_cluster.storage_type #=> String
    #   resp.data.db_cluster.iops #=> Integer
    #   resp.data.db_cluster.publicly_accessible #=> Boolean
    #   resp.data.db_cluster.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_cluster.monitoring_interval #=> Integer
    #   resp.data.db_cluster.monitoring_role_arn #=> String
    #   resp.data.db_cluster.performance_insights_enabled #=> Boolean
    #   resp.data.db_cluster.performance_insights_kms_key_id #=> String
    #   resp.data.db_cluster.performance_insights_retention_period #=> Integer
    #   resp.data.db_cluster.serverless_v2_scaling_configuration #=> Types::ServerlessV2ScalingConfigurationInfo
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.min_capacity #=> Float
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.max_capacity #=> Float
    #
    def create_db_cluster(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CreateDBClusterInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CreateDBClusterInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CreateDBCluster
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::GlobalClusterNotFoundFault, Errors::InvalidDBSubnetGroupStateFault, Errors::DBSubnetGroupDoesNotCoverEnoughAZs, Errors::InsufficientStorageClusterCapacityFault, Errors::DBSubnetGroupNotFoundFault, Errors::KMSKeyNotAccessibleFault, Errors::DBClusterParameterGroupNotFoundFault, Errors::InvalidVPCNetworkStateFault, Errors::StorageQuotaExceededFault, Errors::InvalidSubnet, Errors::InvalidDBInstanceStateFault, Errors::DBClusterAlreadyExistsFault, Errors::DBInstanceNotFoundFault, Errors::InvalidGlobalClusterStateFault, Errors::DomainNotFoundFault, Errors::DBClusterQuotaExceededFault, Errors::InvalidDBClusterStateFault]),
        data_parser: Parsers::CreateDBCluster
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CreateDBCluster,
        stubs: @stubs,
        params_class: Params::CreateDBClusterOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :create_db_cluster
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates a new custom endpoint and associates it with an Amazon Aurora DB cluster.</p>
    #         <note>
    #             <p>This action only applies to Aurora DB clusters.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::CreateDBClusterEndpointInput}.
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The DB cluster identifier of the DB cluster associated with the endpoint. This parameter is
    #               stored as a lowercase string.</p>
    #
    # @option params [String] :db_cluster_endpoint_identifier
    #   <p>The identifier to use for the new endpoint. This parameter is stored as a lowercase string.</p>
    #
    # @option params [String] :endpoint_type
    #   <p>The type of the endpoint, one of: <code>READER</code>, <code>WRITER</code>, <code>ANY</code>.</p>
    #
    # @option params [Array<String>] :static_members
    #   <p>List of DB instance identifiers that are part of the custom endpoint group.</p>
    #
    # @option params [Array<String>] :excluded_members
    #   <p>List of DB instance identifiers that aren't part of the custom endpoint group.
    #               All other eligible instances are reachable through the custom endpoint.
    #               This parameter is relevant only if the list of static members is empty.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>The tags to be assigned to the Amazon RDS resource.</p>
    #
    # @return [Types::CreateDBClusterEndpointOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.create_db_cluster_endpoint(
    #     db_cluster_identifier: 'DBClusterIdentifier', # required
    #     db_cluster_endpoint_identifier: 'DBClusterEndpointIdentifier', # required
    #     endpoint_type: 'EndpointType', # required
    #     static_members: [
    #       'member'
    #     ],
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CreateDBClusterEndpointOutput
    #   resp.data.db_cluster_endpoint_identifier #=> String
    #   resp.data.db_cluster_identifier #=> String
    #   resp.data.db_cluster_endpoint_resource_identifier #=> String
    #   resp.data.endpoint #=> String
    #   resp.data.status #=> String
    #   resp.data.endpoint_type #=> String
    #   resp.data.custom_endpoint_type #=> String
    #   resp.data.static_members #=> Array<String>
    #   resp.data.static_members[0] #=> String
    #   resp.data.excluded_members #=> Array<String>
    #   resp.data.db_cluster_endpoint_arn #=> String
    #
    def create_db_cluster_endpoint(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CreateDBClusterEndpointInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CreateDBClusterEndpointInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CreateDBClusterEndpoint
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::DBInstanceNotFoundFault, Errors::InvalidDBClusterStateFault, Errors::DBClusterEndpointQuotaExceededFault, Errors::DBClusterEndpointAlreadyExistsFault, Errors::InvalidDBInstanceStateFault]),
        data_parser: Parsers::CreateDBClusterEndpoint
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CreateDBClusterEndpoint,
        stubs: @stubs,
        params_class: Params::CreateDBClusterEndpointOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :create_db_cluster_endpoint
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates a new DB cluster parameter group.</p>
    #         <p>Parameters in a DB cluster parameter group apply to all of the instances in a DB cluster.</p>
    #         <p>A DB cluster parameter group is initially created with the default parameters for the
    #             database engine used by instances in the DB cluster. To provide custom values for any of the
    #             parameters, you must modify the group after creating it using
    #             <code>ModifyDBClusterParameterGroup</code>. Once you've created a DB cluster parameter group, you need to
    #             associate it with your DB cluster using <code>ModifyDBCluster</code>.</p>
    #         <p>When you associate a new DB cluster parameter group with a running Aurora DB cluster, reboot the DB
    #             instances in the DB cluster without failover for the new DB cluster parameter group and
    #             associated settings to take effect.</p>
    #         <p>When you associate a new DB cluster parameter group with a running Multi-AZ DB cluster, reboot the DB
    #           cluster without failover for the new DB cluster parameter group and associated settings to take effect.</p>
    #         <important>
    #             <p>After you create a DB cluster parameter group, you should wait at least 5 minutes
    #                 before creating your first DB cluster
    #                 that uses that DB cluster parameter group as the default parameter
    #                 group. This allows Amazon RDS to fully complete the create action before the DB cluster parameter
    #                 group is used as the default for a new DB cluster. This is especially important for parameters
    #                 that are critical when creating the default database for a DB cluster, such as the character set
    #                 for the default database defined by the <code>character_set_database</code> parameter. You can use the
    #                 <i>Parameter Groups</i> option of the <a href="https://console.aws.amazon.com/rds/">Amazon RDS console</a> or the
    #                 <code>DescribeDBClusterParameters</code> action to verify
    #                 that your DB cluster parameter group has been created or modified.</p>
    #         </important>
    #         <p>For more information on Amazon Aurora, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #               What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #               Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::CreateDBClusterParameterGroupInput}.
    #
    # @option params [String] :db_cluster_parameter_group_name
    #   <p>The name of the DB cluster parameter group.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must not match the name of an existing DB cluster parameter group.</p>
    #               </li>
    #            </ul>
    #           <note>
    #               <p>This value is stored as a lowercase string.</p>
    #           </note>
    #
    # @option params [String] :db_parameter_group_family
    #   <p>The DB cluster parameter group family name. A DB cluster parameter group can be associated with one and only one DB cluster
    #             parameter group family, and can be applied only to a DB cluster running a database engine and engine version compatible with that DB cluster parameter group family.</p>
    #           <p>
    #               <b>Aurora MySQL</b>
    #            </p>
    #           <p>Example: <code>aurora5.6</code>, <code>aurora-mysql5.7</code>, <code>aurora-mysql8.0</code>
    #            </p>
    #           <p>
    #               <b>Aurora PostgreSQL</b>
    #            </p>
    #           <p>Example: <code>aurora-postgresql9.6</code>
    #            </p>
    #           <p>
    #               <b>RDS for MySQL</b>
    #            </p>
    #           <p>Example: <code>mysql8.0</code>
    #            </p>
    #           <p>
    #               <b>RDS for PostgreSQL</b>
    #            </p>
    #           <p>Example: <code>postgres12</code>
    #            </p>
    #           <p>To list all of the available parameter group families for a DB engine, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --query "DBEngineVersions[].DBParameterGroupFamily" --engine <engine></code>
    #            </p>
    #           <p>For example, to list all of the available parameter group families for the Aurora PostgreSQL DB engine, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --query "DBEngineVersions[].DBParameterGroupFamily" --engine aurora-postgresql</code>
    #            </p>
    #           <note>
    #               <p>The output contains duplicates.</p>
    #           </note>
    #           <p>The following are the valid DB engine values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>aurora</code> (for MySQL 5.6-compatible Aurora)</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-mysql</code> (for MySQL 5.7-compatible and MySQL 8.0-compatible Aurora)</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-postgresql</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mysql</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>postgres</code>
    #                  </p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :description
    #   <p>The description for the DB cluster parameter group.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>Tags to assign to the DB cluster parameter group.</p>
    #
    # @return [Types::CreateDBClusterParameterGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.create_db_cluster_parameter_group(
    #     db_cluster_parameter_group_name: 'DBClusterParameterGroupName', # required
    #     db_parameter_group_family: 'DBParameterGroupFamily', # required
    #     description: 'Description', # required
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CreateDBClusterParameterGroupOutput
    #   resp.data.db_cluster_parameter_group #=> Types::DBClusterParameterGroup
    #   resp.data.db_cluster_parameter_group.db_cluster_parameter_group_name #=> String
    #   resp.data.db_cluster_parameter_group.db_parameter_group_family #=> String
    #   resp.data.db_cluster_parameter_group.description #=> String
    #   resp.data.db_cluster_parameter_group.db_cluster_parameter_group_arn #=> String
    #
    def create_db_cluster_parameter_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CreateDBClusterParameterGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CreateDBClusterParameterGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CreateDBClusterParameterGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBParameterGroupAlreadyExistsFault, Errors::DBParameterGroupQuotaExceededFault]),
        data_parser: Parsers::CreateDBClusterParameterGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CreateDBClusterParameterGroup,
        stubs: @stubs,
        params_class: Params::CreateDBClusterParameterGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :create_db_cluster_parameter_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates a snapshot of a DB cluster.</p>
    #         <p>For more information on Amazon Aurora, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html"> What is Amazon
    #                 Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #               Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::CreateDBClusterSnapshotInput}.
    #
    # @option params [String] :db_cluster_snapshot_identifier
    #   <p>The identifier of the DB cluster snapshot. This parameter is stored as a lowercase string.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain from 1 to 63 letters, numbers, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens.</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-cluster1-snapshot1</code>
    #            </p>
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The identifier of the DB cluster to create a snapshot for. This parameter isn't case-sensitive.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the identifier of an existing DBCluster.</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-cluster1</code>
    #            </p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>The tags to be assigned to the DB cluster snapshot.</p>
    #
    # @return [Types::CreateDBClusterSnapshotOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.create_db_cluster_snapshot(
    #     db_cluster_snapshot_identifier: 'DBClusterSnapshotIdentifier', # required
    #     db_cluster_identifier: 'DBClusterIdentifier', # required
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CreateDBClusterSnapshotOutput
    #   resp.data.db_cluster_snapshot #=> Types::DBClusterSnapshot
    #   resp.data.db_cluster_snapshot.availability_zones #=> Array<String>
    #   resp.data.db_cluster_snapshot.availability_zones[0] #=> String
    #   resp.data.db_cluster_snapshot.db_cluster_snapshot_identifier #=> String
    #   resp.data.db_cluster_snapshot.db_cluster_identifier #=> String
    #   resp.data.db_cluster_snapshot.snapshot_create_time #=> Time
    #   resp.data.db_cluster_snapshot.engine #=> String
    #   resp.data.db_cluster_snapshot.engine_mode #=> String
    #   resp.data.db_cluster_snapshot.allocated_storage #=> Integer
    #   resp.data.db_cluster_snapshot.status #=> String
    #   resp.data.db_cluster_snapshot.port #=> Integer
    #   resp.data.db_cluster_snapshot.vpc_id #=> String
    #   resp.data.db_cluster_snapshot.cluster_create_time #=> Time
    #   resp.data.db_cluster_snapshot.master_username #=> String
    #   resp.data.db_cluster_snapshot.engine_version #=> String
    #   resp.data.db_cluster_snapshot.license_model #=> String
    #   resp.data.db_cluster_snapshot.snapshot_type #=> String
    #   resp.data.db_cluster_snapshot.percent_progress #=> Integer
    #   resp.data.db_cluster_snapshot.storage_encrypted #=> Boolean
    #   resp.data.db_cluster_snapshot.kms_key_id #=> String
    #   resp.data.db_cluster_snapshot.db_cluster_snapshot_arn #=> String
    #   resp.data.db_cluster_snapshot.source_db_cluster_snapshot_arn #=> String
    #   resp.data.db_cluster_snapshot.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster_snapshot.tag_list #=> Array<Tag>
    #   resp.data.db_cluster_snapshot.tag_list[0] #=> Types::Tag
    #   resp.data.db_cluster_snapshot.tag_list[0].key #=> String
    #   resp.data.db_cluster_snapshot.tag_list[0].value #=> String
    #
    def create_db_cluster_snapshot(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CreateDBClusterSnapshotInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CreateDBClusterSnapshotInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CreateDBClusterSnapshot
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidDBClusterSnapshotStateFault, Errors::DBClusterNotFoundFault, Errors::SnapshotQuotaExceededFault, Errors::DBClusterSnapshotAlreadyExistsFault, Errors::InvalidDBClusterStateFault]),
        data_parser: Parsers::CreateDBClusterSnapshot
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CreateDBClusterSnapshot,
        stubs: @stubs,
        params_class: Params::CreateDBClusterSnapshotOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :create_db_cluster_snapshot
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates a new DB instance.</p>
    #
    # @param [Hash] params
    #   See {Types::CreateDBInstanceInput}.
    #
    # @option params [String] :db_name
    #   <p>The meaning of this parameter differs according to the database engine you use.</p>
    #           <p>
    #               <b>MySQL</b>
    #            </p>
    #           <p>The name of the database to create when the DB instance is created. If this parameter isn't specified, no database is created in the DB instance.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain 1 to 64 letters or numbers.</p>
    #               </li>
    #               <li>
    #                   <p>Must begin with a letter. Subsequent characters can be letters, underscores, or digits (0-9).</p>
    #               </li>
    #               <li>
    #                   <p>Can't be a word reserved by the specified database engine</p>
    #               </li>
    #            </ul>
    #           <p>
    #               <b>MariaDB</b>
    #            </p>
    #           <p>The name of the database to create when the DB instance is created. If this parameter isn't specified, no database is created in the DB instance.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain 1 to 64 letters or numbers.</p>
    #               </li>
    #               <li>
    #                   <p>Must begin with a letter. Subsequent characters can be letters, underscores, or digits (0-9).</p>
    #               </li>
    #               <li>
    #                   <p>Can't be a word reserved by the specified database engine</p>
    #               </li>
    #            </ul>
    #           <p>
    #               <b>PostgreSQL</b>
    #            </p>
    #           <p>The name of the database to create when the DB instance is created. If this parameter isn't specified, a database named <code>postgres</code>
    #             is created in the DB instance.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain 1 to 63 letters, numbers, or underscores.</p>
    #               </li>
    #               <li>
    #                   <p>Must begin with a letter. Subsequent characters can be letters, underscores, or digits (0-9).</p>
    #               </li>
    #               <li>
    #                   <p>Can't be a word reserved by the specified database engine</p>
    #               </li>
    #            </ul>
    #           <p>
    #               <b>Oracle</b>
    #            </p>
    #           <p>The Oracle System ID (SID) of the created DB instance.
    #             If you specify <code>null</code>, the default value <code>ORCL</code> is used.
    #             You can't specify the string NULL, or any other reserved word, for <code>DBName</code>.</p>
    #           <p>Default: <code>ORCL</code>
    #            </p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Can't be longer than 8 characters</p>
    #               </li>
    #            </ul>
    #           <p>
    #               <b>Amazon RDS Custom for Oracle</b>
    #            </p>
    #           <p>The Oracle System ID (SID) of the created RDS Custom DB instance.
    #             If you don't specify a value, the default value is <code>ORCL</code>.</p>
    #           <p>Default: <code>ORCL</code>
    #            </p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>It must contain 1 to 8 alphanumeric characters.</p>
    #               </li>
    #               <li>
    #                   <p>It must contain a letter.</p>
    #               </li>
    #               <li>
    #                   <p>It can't be a word reserved by the database engine.</p>
    #               </li>
    #            </ul>
    #           <p>
    #               <b>Amazon RDS Custom for SQL Server</b>
    #            </p>
    #           <p>Not applicable. Must be null.</p>
    #           <p>
    #               <b>SQL Server</b>
    #            </p>
    #           <p>Not applicable. Must be null.</p>
    #           <p>
    #               <b>Amazon Aurora MySQL</b>
    #            </p>
    #           <p>The name of the database to create when the primary DB instance of the Aurora MySQL DB cluster is
    #             created. If this parameter isn't specified for an Aurora MySQL DB cluster, no database is created
    #             in the DB cluster.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>It must contain 1 to 64 alphanumeric characters.</p>
    #               </li>
    #               <li>
    #                   <p>It can't be a word reserved by the database engine.</p>
    #               </li>
    #            </ul>
    #           <p>
    #               <b>Amazon Aurora PostgreSQL</b>
    #            </p>
    #           <p>The name of the database to create when the primary DB instance of the Aurora PostgreSQL DB cluster is
    #             created. If this parameter isn't specified for an Aurora PostgreSQL DB cluster,
    #             a database named <code>postgres</code> is created in the DB cluster.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>It must contain 1 to 63 alphanumeric characters.</p>
    #               </li>
    #               <li>
    #                   <p>It must begin with a letter or an underscore.
    #                     Subsequent characters can be letters, underscores, or digits
    #                     (0 to 9).</p>
    #               </li>
    #               <li>
    #                   <p>It can't be a word reserved by the
    #                     database engine.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :db_instance_identifier
    #   <p>The DB instance identifier. This parameter is stored as a lowercase string.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain from 1 to 63 letters, numbers, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens.</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>mydbinstance</code>
    #            </p>
    #
    # @option params [Integer] :allocated_storage
    #   <p>The amount of storage in gibibytes (GiB) to allocate for the DB instance.</p>
    #           <p>Type: Integer</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. Aurora cluster volumes automatically grow as the amount of data in your
    #             database increases, though you are only charged for the space that you use in an Aurora cluster volume.</p>
    #           <p>
    #               <b>Amazon RDS Custom</b>
    #            </p>
    #           <p>Constraints to the amount of storage for each storage type are the following:</p>
    #           <ul>
    #               <li>
    #                   <p>General Purpose (SSD) storage (gp2): Must be an integer from 40 to 65536 for RDS Custom for Oracle,
    #                 16384 for RDS Custom for SQL Server.</p>
    #               </li>
    #               <li>
    #                   <p>Provisioned IOPS storage (io1): Must be an integer from 40 to 65536 for RDS Custom for Oracle,
    #                 16384 for RDS Custom for SQL Server.</p>
    #               </li>
    #            </ul>
    #           <p>
    #               <b>MySQL</b>
    #            </p>
    #           <p>Constraints to the amount of storage for each storage type are the following:</p>
    #           <ul>
    #               <li>
    #                   <p>General Purpose (SSD) storage (gp2): Must be an integer from 20 to 65536.</p>
    #               </li>
    #               <li>
    #                   <p>Provisioned IOPS storage (io1): Must be an integer from 100 to 65536.</p>
    #               </li>
    #               <li>
    #                   <p>Magnetic storage (standard): Must be an integer from 5 to 3072.</p>
    #               </li>
    #            </ul>
    #           <p>
    #               <b>MariaDB</b>
    #            </p>
    #           <p>Constraints to the amount of storage for each storage type are the following:</p>
    #           <ul>
    #               <li>
    #                   <p>General Purpose (SSD) storage (gp2): Must be an integer from 20 to 65536.</p>
    #               </li>
    #               <li>
    #                   <p>Provisioned IOPS storage (io1): Must be an integer from 100 to 65536.</p>
    #               </li>
    #               <li>
    #                   <p>Magnetic storage (standard): Must be an integer from 5 to 3072.</p>
    #               </li>
    #            </ul>
    #           <p>
    #               <b>PostgreSQL</b>
    #            </p>
    #           <p>Constraints to the amount of storage for each storage type are the following:</p>
    #           <ul>
    #               <li>
    #                   <p>General Purpose (SSD) storage (gp2): Must be an integer from 20 to 65536.</p>
    #               </li>
    #               <li>
    #                   <p>Provisioned IOPS storage (io1): Must be an integer from 100 to 65536.</p>
    #               </li>
    #               <li>
    #                   <p>Magnetic storage (standard): Must be an integer from 5 to 3072.</p>
    #               </li>
    #            </ul>
    #           <p>
    #               <b>Oracle</b>
    #            </p>
    #           <p>Constraints to the amount of storage for each storage type are the following:</p>
    #           <ul>
    #               <li>
    #                   <p>General Purpose (SSD) storage (gp2): Must be an integer from 20 to 65536.</p>
    #               </li>
    #               <li>
    #                   <p>Provisioned IOPS storage (io1): Must be an integer from 100 to 65536.</p>
    #               </li>
    #               <li>
    #                   <p>Magnetic storage (standard): Must be an integer from 10 to 3072.</p>
    #               </li>
    #            </ul>
    #           <p>
    #               <b>SQL Server</b>
    #            </p>
    #           <p>Constraints to the amount of storage for each storage type are the following:</p>
    #           <ul>
    #               <li>
    #                   <p>General Purpose (SSD) storage (gp2):</p>
    #                   <ul>
    #                     <li>
    #                           <p>Enterprise and Standard editions: Must be an integer from 20 to 16384.</p>
    #                       </li>
    #                     <li>
    #                           <p>Web and Express editions: Must be an integer from 20 to 16384.</p>
    #                       </li>
    #                  </ul>
    #               </li>
    #               <li>
    #                   <p>Provisioned IOPS storage (io1):</p>
    #                   <ul>
    #                     <li>
    #                           <p>Enterprise and Standard editions: Must be an integer from 100 to 16384.</p>
    #                       </li>
    #                     <li>
    #                           <p>Web and Express editions: Must be an integer from 100 to 16384.</p>
    #                       </li>
    #                  </ul>
    #               </li>
    #               <li>
    #                   <p>Magnetic storage (standard):</p>
    #                   <ul>
    #                     <li>
    #                           <p>Enterprise and Standard editions: Must be an integer from 20 to 1024.</p>
    #                       </li>
    #                     <li>
    #                           <p>Web and Express editions: Must be an integer from 20 to 1024.</p>
    #                       </li>
    #                  </ul>
    #               </li>
    #            </ul>
    #
    # @option params [String] :db_instance_class
    #   <p>The compute and memory capacity of the DB instance, for example db.m4.large.
    #             Not all DB instance classes are available in all Amazon Web Services Regions, or for all database engines.
    #             For the full list of DB instance classes,
    #             and availability for your engine, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html">DB Instance Class</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @option params [String] :engine
    #   <p>The name of the database engine to be used for this instance.</p>
    #           <p>Not every database engine is available for every Amazon Web Services Region.</p>
    #           <p>Valid Values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>aurora</code> (for MySQL 5.6-compatible Aurora)</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-mysql</code> (for MySQL 5.7-compatible and MySQL 8.0-compatible Aurora)</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-postgresql</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>custom-oracle-ee (for RDS Custom for Oracle instances)</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>custom-sqlserver-ee (for RDS Custom for SQL Server instances)</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>custom-sqlserver-se (for RDS Custom for SQL Server instances)</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>custom-sqlserver-web (for RDS Custom for SQL Server instances)</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mariadb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mysql</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>postgres</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-se</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ex</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-web</code>
    #                  </p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :master_username
    #   <p>The name for the master user.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. The name for the master user is managed by the DB cluster.</p>
    #           <p>
    #               <b>Amazon RDS</b>
    #            </p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Required.</p>
    #               </li>
    #               <li>
    #                   <p>Must be 1 to 16 letters, numbers, or underscores.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't be a reserved word for the chosen database engine.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :master_user_password
    #   <p>The password for the master user. The password can include any printable ASCII character except "/", """, or "@".</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. The password for the master user is managed by the DB
    #               cluster.</p>
    #           <p>
    #               <b>MariaDB</b>
    #            </p>
    #           <p>Constraints: Must contain from 8 to 41 characters.</p>
    #           <p>
    #               <b>Microsoft SQL Server</b>
    #            </p>
    #           <p>Constraints: Must contain from 8 to 128 characters.</p>
    #           <p>
    #               <b>MySQL</b>
    #            </p>
    #           <p>Constraints: Must contain from 8 to 41 characters.</p>
    #           <p>
    #               <b>Oracle</b>
    #            </p>
    #           <p>Constraints: Must contain from 8 to 30 characters.</p>
    #           <p>
    #               <b>PostgreSQL</b>
    #            </p>
    #           <p>Constraints: Must contain from 8 to 128 characters.</p>
    #
    # @option params [Array<String>] :db_security_groups
    #   <p>A list of DB security groups to associate with this DB instance.</p>
    #           <p>Default: The default DB security group for the database engine.</p>
    #
    # @option params [Array<String>] :vpc_security_group_ids
    #   <p>A list of Amazon EC2 VPC security groups to associate with this DB instance.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. The associated list of EC2 VPC security groups is managed by
    #             the DB cluster.</p>
    #           <p>Default: The default EC2 VPC security group for the DB subnet group's VPC.</p>
    #
    # @option params [String] :availability_zone
    #   <p>The Availability Zone (AZ) where the database will be created. For information on
    #           Amazon Web Services Regions and Availability Zones, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html">Regions
    #           and Availability Zones</a>.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Each Aurora DB cluster hosts copies of its storage in three separate Availability Zones. Specify one of these
    #               Availability Zones. Aurora automatically chooses an appropriate Availability Zone if you don't specify one.</p>
    #           <p>Default: A random, system-chosen Availability Zone in the endpoint's Amazon Web Services Region.</p>
    #           <p>Example: <code>us-east-1d</code>
    #            </p>
    #           <p>Constraint: The <code>AvailabilityZone</code> parameter can't be specified if the DB instance is a Multi-AZ deployment.
    #               The specified Availability Zone must be in the same Amazon Web Services Region as the current endpoint.</p>
    #
    # @option params [String] :db_subnet_group_name
    #   <p>A DB subnet group to associate with this DB instance.</p>
    #           <p>Constraints: Must match the name of an existing DBSubnetGroup. Must not be default.</p>
    #           <p>Example: <code>mydbsubnetgroup</code>
    #            </p>
    #
    # @option params [String] :preferred_maintenance_window
    #   <p>The time range each week during which system maintenance can occur,
    #             in Universal Coordinated Time (UTC).
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.Maintenance.html#Concepts.DBMaintenance">Amazon RDS Maintenance Window</a>.</p>
    #           <p>Format: <code>ddd:hh24:mi-ddd:hh24:mi</code>
    #            </p>
    #           <p>The default is a 30-minute window selected at random from an
    #               8-hour block of time for each Amazon Web Services Region, occurring on a random day of the
    #               week.</p>
    #           <p>Valid Days: Mon, Tue, Wed, Thu, Fri, Sat, Sun.</p>
    #           <p>Constraints: Minimum 30-minute window.</p>
    #
    # @option params [String] :db_parameter_group_name
    #   <p>The name of the DB parameter group to associate with this DB instance. If you do not specify a value, then
    #             the default DB parameter group for the specified DB engine and version is used.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be 1 to 255 letters, numbers, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #            </ul>
    #
    # @option params [Integer] :backup_retention_period
    #   <p>The number of days for which automated backups are retained. Setting this parameter to a positive number enables
    #             backups. Setting this parameter to 0 disables automated backups.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. The retention period for automated backups is managed by the DB cluster.</p>
    #           <p>Default: 1</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be a value from 0 to 35</p>
    #               </li>
    #               <li>
    #                   <p>Can't be set to 0 if the DB instance is a source to read replicas</p>
    #               </li>
    #               <li>
    #                   <p>Can't be set to 0 or 35 for an RDS Custom for Oracle DB instance</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :preferred_backup_window
    #   <p>The daily time range during which automated backups are created
    #           if automated backups are enabled,
    #           using the <code>BackupRetentionPeriod</code> parameter.
    #             The default is a 30-minute window selected at random from an
    #             8-hour block of time for each Amazon Web Services Region. For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html#USER_WorkingWithAutomatedBackups.BackupWindow">Backup window</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. The daily time range for creating automated backups is managed by
    #             the DB cluster.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be in the format <code>hh24:mi-hh24:mi</code>.</p>
    #               </li>
    #               <li>
    #                   <p>Must be in Universal Coordinated Time (UTC).</p>
    #               </li>
    #               <li>
    #                   <p>Must not conflict with the preferred maintenance window.</p>
    #               </li>
    #               <li>
    #                   <p>Must be at least 30 minutes.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Integer] :port
    #   <p>The port number on which the database accepts connections.</p>
    #           <p>
    #               <b>MySQL</b>
    #            </p>
    #           <p>Default: <code>3306</code>
    #            </p>
    #           <p>Valid values: <code>1150-65535</code>
    #            </p>
    #           <p>Type: Integer</p>
    #           <p>
    #               <b>MariaDB</b>
    #            </p>
    #           <p>Default: <code>3306</code>
    #            </p>
    #           <p>Valid values: <code>1150-65535</code>
    #            </p>
    #           <p>Type: Integer</p>
    #           <p>
    #               <b>PostgreSQL</b>
    #            </p>
    #           <p>Default: <code>5432</code>
    #            </p>
    #           <p>Valid values: <code>1150-65535</code>
    #            </p>
    #           <p>Type: Integer</p>
    #           <p>
    #               <b>Oracle</b>
    #            </p>
    #           <p>Default: <code>1521</code>
    #            </p>
    #           <p>Valid values: <code>1150-65535</code>
    #            </p>
    #           <p>
    #               <b>SQL Server</b>
    #            </p>
    #           <p>Default: <code>1433</code>
    #            </p>
    #           <p>Valid values: <code>1150-65535</code> except <code>1234</code>, <code>1434</code>,
    #                   <code>3260</code>, <code>3343</code>, <code>3389</code>, <code>47001</code>, and
    #                   <code>49152-49156</code>.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Default: <code>3306</code>
    #            </p>
    #           <p>Valid values: <code>1150-65535</code>
    #            </p>
    #           <p>Type: Integer</p>
    #
    # @option params [Boolean] :multi_az
    #   <p>A value that indicates whether the DB instance is a Multi-AZ deployment. You can't set
    #             the <code>AvailabilityZone</code> parameter if the DB instance is a Multi-AZ deployment.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :engine_version
    #   <p>The version number of the database engine to use.</p>
    #           <p>For a list of valid engine versions, use the  <code>DescribeDBEngineVersions</code> action.</p>
    #           <p>The following are the database engines and links to information about the major and minor versions that are available with
    #             Amazon RDS. Not every database engine is available for every Amazon Web Services Region.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. The version number of the database engine to be used by the DB
    #               instance is managed by the DB cluster.</p>
    #           <p>
    #               <b>Amazon RDS Custom for Oracle</b>
    #            </p>
    #           <p>A custom engine version (CEV) that you have previously created. This setting is required for RDS Custom for Oracle. The CEV
    #             name has the following format: <code>19.<i>customized_string</i>
    #               </code>. An example identifier is
    #             <code>19.my_cev1</code>. For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/custom-creating.html#custom-creating.create">
    #                 Creating an RDS Custom for Oracle DB instance</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>
    #               <b>Amazon RDS Custom for SQL Server</b>
    #            </p>
    #           <p>See <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/custom-reqs-limits-MS.html">RDS Custom for SQL Server general requirements</a>
    #             in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>
    #               <b>MariaDB</b>
    #            </p>
    #           <p>For information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_MariaDB.html#MariaDB.Concepts.VersionMgmt">MariaDB on Amazon RDS Versions</a> in the
    #             <i>Amazon RDS User Guide</i>.</p>
    #           <p>
    #               <b>Microsoft SQL Server</b>
    #            </p>
    #           <p>For information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_SQLServer.html#SQLServer.Concepts.General.VersionSupport">Microsoft SQL Server Versions on Amazon RDS</a> in the
    #             <i>Amazon RDS User Guide</i>.</p>
    #           <p>
    #               <b>MySQL</b>
    #            </p>
    #           <p>For information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_MySQL.html#MySQL.Concepts.VersionMgmt">MySQL on Amazon RDS Versions</a> in the
    #             <i>Amazon RDS User Guide</i>.</p>
    #           <p>
    #               <b>Oracle</b>
    #            </p>
    #           <p>For information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.Oracle.PatchComposition.html">Oracle Database Engine Release Notes</a> in the
    #             <i>Amazon RDS User Guide</i>.</p>
    #           <p>
    #               <b>PostgreSQL</b>
    #            </p>
    #           <p>For information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_PostgreSQL.html#PostgreSQL.Concepts">Amazon RDS for PostgreSQL versions and extensions</a> in the
    #             <i>Amazon RDS User Guide</i>.</p>
    #
    # @option params [Boolean] :auto_minor_version_upgrade
    #   <p>A value that indicates whether minor engine upgrades are applied automatically to the DB instance during the maintenance window.
    #             By default, minor engine upgrades are applied automatically.</p>
    #           <p>If you create an RDS Custom DB instance, you must set <code>AutoMinorVersionUpgrade</code> to
    #             <code>false</code>.</p>
    #
    # @option params [String] :license_model
    #   <p>License model information for this DB instance.</p>
    #           <p>Valid values:  <code>license-included</code> | <code>bring-your-own-license</code> | <code>general-public-license</code>
    #            </p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Integer] :iops
    #   <p>The amount of Provisioned IOPS (input/output operations per second) to be initially allocated for the DB instance.
    #             For information about valid <code>Iops</code> values, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html#USER_PIOPS">Amazon RDS Provisioned IOPS storage to improve performance</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>Constraints: For MariaDB, MySQL, Oracle, and PostgreSQL DB instances, must be a multiple between .5 and 50
    #             of the storage amount for the DB instance. For SQL Server DB instances, must be a multiple between 1 and 50
    #             of the storage amount for the DB instance.</p>
    #
    # @option params [String] :option_group_name
    #   <p>A value that indicates that the DB instance should be associated with the specified option group.</p>
    #           <p>Permanent options, such as the TDE option for Oracle Advanced Security TDE, can't be removed
    #             from an option group. Also, that option group can't be removed from a DB instance after it is
    #             associated with a DB instance.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :character_set_name
    #   <p>For supported engines, this value indicates that the DB instance should be associated with the
    #             specified <code>CharacterSet</code>.</p>
    #           <p>This setting doesn't apply to RDS Custom. However, if you need to change the character set,
    #             you can change it on the database itself.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. The character set is managed by
    #             the DB cluster. For more information, see <code>CreateDBCluster</code>.</p>
    #
    # @option params [String] :nchar_character_set_name
    #   <p>The name of the NCHAR character set for the Oracle DB instance.</p>
    #           <p>This parameter doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :publicly_accessible
    #   <p>A value that indicates whether the DB instance is publicly accessible.</p>
    #           <p>When the DB instance is publicly accessible, its Domain Name System (DNS) endpoint resolves to the private IP address from
    #             within the DB instance's virtual private cloud (VPC). It resolves to the public IP address from outside of the DB instance's VPC.
    #             Access to the DB instance is ultimately controlled by the security group it uses.
    #             That public access is not permitted if the security group assigned to the DB instance doesn't permit it.</p>
    #           <p>When the DB instance isn't publicly accessible, it is an internal DB instance with a DNS name that resolves to a private IP address.</p>
    #           <p>Default: The default behavior varies depending on whether <code>DBSubnetGroupName</code> is specified.</p>
    #           <p>If <code>DBSubnetGroupName</code> isn't specified, and <code>PubliclyAccessible</code> isn't specified, the following applies:</p>
    #           <ul>
    #               <li>
    #                   <p>If the default VPC in the target Region doesnt have an internet gateway attached to it, the DB instance is private.</p>
    #               </li>
    #               <li>
    #                   <p>If the default VPC in the target Region has an internet gateway attached to it, the DB instance is public.</p>
    #               </li>
    #            </ul>
    #           <p>If <code>DBSubnetGroupName</code> is specified, and <code>PubliclyAccessible</code> isn't specified, the following applies:</p>
    #           <ul>
    #               <li>
    #                   <p>If the subnets are part of a VPC that doesnt have an internet gateway attached to it, the DB instance is private.</p>
    #               </li>
    #               <li>
    #                   <p>If the subnets are part of a VPC that has an internet gateway attached to it, the DB instance is public.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Array<Tag>] :tags
    #   <p>Tags to assign to the DB instance.</p>
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The identifier of the DB cluster that the instance will belong to.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :storage_type
    #   <p>Specifies the storage type to be associated with the DB instance.</p>
    #           <p>Valid values: <code>standard | gp2 | io1</code>
    #            </p>
    #           <p>If you specify <code>io1</code>, you must also include a value for the
    #               <code>Iops</code> parameter.</p>
    #           <p>Default: <code>io1</code> if the <code>Iops</code> parameter
    #               is specified, otherwise <code>gp2</code>
    #            </p>
    #
    # @option params [String] :tde_credential_arn
    #   <p>The ARN from the key store with which to associate the instance for TDE encryption.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :tde_credential_password
    #   <p>The password for the given ARN from the key store in order to access the device.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :storage_encrypted
    #   <p>A value that indicates whether the DB instance is encrypted. By default, it isn't encrypted.</p>
    #           <p>For RDS Custom instances, either set this parameter to <code>true</code> or leave it unset.
    #             If you set this parameter to <code>false</code>, RDS reports an error.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. The encryption for DB instances is managed by the DB cluster.</p>
    #
    # @option params [String] :kms_key_id
    #   <p>The Amazon Web Services KMS key identifier for an encrypted DB instance.</p>
    #           <p>The Amazon Web Services KMS key identifier is the key ARN, key ID, alias ARN, or alias name for the KMS key.
    #             To use a KMS key in a different Amazon Web Services account, specify the key ARN or alias ARN.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. The Amazon Web Services KMS key identifier is managed by
    #             the DB cluster. For more information, see <code>CreateDBCluster</code>.</p>
    #           <p>If <code>StorageEncrypted</code> is enabled, and you do
    #           not specify a value for the <code>KmsKeyId</code> parameter, then
    #           Amazon RDS uses your default KMS key. There is a
    #           default KMS key for your Amazon Web Services account. Your Amazon Web Services account has a different
    #           default KMS key for each Amazon Web Services Region.</p>
    #           <p>
    #               <b>Amazon RDS Custom</b>
    #            </p>
    #           <p>A KMS key is required for RDS Custom instances. For most RDS engines, if you leave this parameter empty
    #             while enabling <code>StorageEncrypted</code>, the engine uses the default KMS key. However, RDS Custom
    #             doesn't use the default key when this parameter is empty. You must explicitly specify a key.</p>
    #
    # @option params [String] :domain
    #   <p>The Active Directory directory ID to create the DB instance in. Currently, only MySQL, Microsoft SQL
    #               Server, Oracle, and PostgreSQL DB instances can be created in an Active Directory Domain.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/kerberos-authentication.html">
    #              Kerberos Authentication</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :copy_tags_to_snapshot
    #   <p>A value that indicates whether to copy tags from the DB instance to snapshots of the DB instance. By default, tags are not copied.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. Copying tags to snapshots is managed by the DB cluster. Setting this
    #             value for an Aurora DB instance has no effect on the DB cluster setting.</p>
    #
    # @option params [Integer] :monitoring_interval
    #   <p>The interval, in seconds, between points when Enhanced Monitoring metrics are collected for
    #             the DB instance. To disable collection of Enhanced Monitoring metrics, specify 0. The default is 0.</p>
    #           <p>If <code>MonitoringRoleArn</code> is specified, then you must set <code>MonitoringInterval</code>
    #         to a value other than 0.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Valid Values: <code>0, 1, 5, 10, 15, 30, 60</code>
    #            </p>
    #
    # @option params [String] :monitoring_role_arn
    #   <p>The ARN for the IAM role that permits RDS to send enhanced monitoring metrics to Amazon CloudWatch Logs. For
    #             example, <code>arn:aws:iam:123456789012:role/emaccess</code>. For information on creating a monitoring role,
    #         see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.OS.html#USER_Monitoring.OS.Enabling">Setting Up and Enabling Enhanced Monitoring</a>
    #             in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>If <code>MonitoringInterval</code> is set to a value other than 0, then you must supply a <code>MonitoringRoleArn</code> value.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :domain_iam_role_name
    #   <p>Specify the name of the IAM role to be used when making API calls to the Directory Service.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Integer] :promotion_tier
    #   <p>A value that specifies the order in which an Aurora Replica is promoted to the primary instance
    #             after a failure of the existing primary instance. For more information,
    #         see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Managing.Backups.html#Aurora.Managing.FaultTolerance">
    #             Fault Tolerance for an Aurora DB Cluster</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Default: 1</p>
    #           <p>Valid Values: 0 - 15</p>
    #
    # @option params [String] :timezone
    #   <p>The time zone of the DB instance.
    #               The time zone parameter is currently supported only by
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_SQLServer.html#SQLServer.Concepts.General.TimeZone">Microsoft SQL Server</a>.</p>
    #
    # @option params [Boolean] :enable_iam_database_authentication
    #   <p>A value that indicates whether to enable mapping of Amazon Web Services Identity and Access Management
    #               (IAM) accounts to database accounts. By default, mapping isn't enabled.</p>
    #           <p>This setting doesn't apply to RDS Custom or Amazon Aurora. In Aurora, mapping Amazon Web Services IAM accounts
    #           to database accounts is managed by the DB cluster.</p>
    #           <p>For more information, see
    #          <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.html">
    #              IAM Database Authentication for MySQL and PostgreSQL</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @option params [Boolean] :enable_performance_insights
    #   <p>A value that indicates whether to enable Performance Insights for the DB instance. For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PerfInsights.html">Using Amazon Performance Insights</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :performance_insights_kms_key_id
    #   <p>The Amazon Web Services KMS key identifier for encryption of Performance Insights data.</p>
    #           <p>The Amazon Web Services KMS key identifier is the key ARN, key ID, alias ARN, or alias name for the KMS key.</p>
    #           <p>If you do not specify a value for <code>PerformanceInsightsKMSKeyId</code>, then Amazon RDS
    #               uses your default KMS key. There is a default KMS key for your Amazon Web Services account.
    #               Your Amazon Web Services account has a different default KMS key for each Amazon Web Services Region.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Integer] :performance_insights_retention_period
    #   <p>The amount of time, in days, to retain Performance Insights data. Valid values are 7 or 731 (2 years).</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Array<String>] :enable_cloudwatch_logs_exports
    #   <p>The list of log types that need to be enabled for exporting to CloudWatch Logs. The values
    #               in the list depend on the DB engine. For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.html#USER_LogAccess.Procedural.UploadtoCloudWatch">
    #               Publishing Database Logs to Amazon CloudWatch Logs</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. CloudWatch Logs exports are managed by the DB cluster.</p>
    #           <p>
    #               <b>RDS Custom</b>
    #            </p>
    #           <p>Not applicable.</p>
    #           <p>
    #               <b>MariaDB</b>
    #            </p>
    #           <p>Possible values are <code>audit</code>, <code>error</code>, <code>general</code>, and <code>slowquery</code>.</p>
    #           <p>
    #               <b>Microsoft SQL Server</b>
    #            </p>
    #           <p>Possible values are <code>agent</code> and <code>error</code>.</p>
    #           <p>
    #               <b>MySQL</b>
    #            </p>
    #           <p>Possible values are <code>audit</code>, <code>error</code>, <code>general</code>, and <code>slowquery</code>.</p>
    #           <p>
    #               <b>Oracle</b>
    #            </p>
    #           <p>Possible values are <code>alert</code>, <code>audit</code>, <code>listener</code>, <code>trace</code>, and
    #               <code>oemagent</code>.</p>
    #           <p>
    #               <b>PostgreSQL</b>
    #            </p>
    #           <p>Possible values are <code>postgresql</code> and <code>upgrade</code>.</p>
    #
    # @option params [Array<ProcessorFeature>] :processor_features
    #   <p>The number of CPU cores and the number of threads per core for the DB instance class of the DB instance.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :deletion_protection
    #   <p>A value that indicates whether the DB instance has deletion protection enabled.
    #               The database can't be deleted when deletion protection is enabled. By default,
    #               deletion protection isn't enabled. For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_DeleteInstance.html">
    #                   Deleting a DB Instance</a>.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. You can enable or disable deletion protection for the DB cluster.
    #               For more information, see <code>CreateDBCluster</code>. DB instances in a DB
    #               cluster can be deleted even when deletion protection is enabled for the DB cluster.</p>
    #
    # @option params [Integer] :max_allocated_storage
    #   <p>The upper limit in gibibytes (GiB) to which Amazon RDS can automatically scale the storage of the DB instance.</p>
    #           <p>For more information about this setting, including limitations that apply to it, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIOPS.StorageTypes.html#USER_PIOPS.Autoscaling">
    #                   Managing capacity automatically with Amazon RDS storage autoscaling</a>
    #               in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :enable_customer_owned_ip
    #   <p>A value that indicates whether to enable a customer-owned IP address (CoIP) for an RDS
    #               on Outposts DB instance.</p>
    #           <p>A <i>CoIP</i> provides local or external connectivity to resources in
    #               your Outpost subnets through your on-premises network. For some use cases, a CoIP can
    #               provide lower latency for connections to the DB instance from outside of its virtual
    #               private cloud (VPC) on your local network.</p>
    #           <p>For more information about RDS on Outposts, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-on-outposts.html">Working with Amazon RDS on Amazon Web Services Outposts</a>
    #               in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>For more information about CoIPs, see <a href="https://docs.aws.amazon.com/outposts/latest/userguide/outposts-networking-components.html#ip-addressing">Customer-owned IP addresses</a>
    #               in the <i>Amazon Web Services Outposts User Guide</i>.</p>
    #
    # @option params [String] :custom_iam_instance_profile
    #   <p>The instance profile associated with the underlying Amazon EC2 instance of an
    #               RDS Custom DB instance. The instance profile must meet the following requirements:</p>
    #           <ul>
    #               <li>
    #                   <p>The profile must exist in your account.</p>
    #               </li>
    #               <li>
    #                   <p>The profile must have an IAM role that Amazon EC2 has permissions to assume.</p>
    #               </li>
    #               <li>
    #                   <p>The instance profile name and the associated IAM role name must start with the prefix <code>AWSRDSCustom</code>.</p>
    #               </li>
    #            </ul>
    #           <p>For the list of permissions required for the IAM role, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/custom-setup-orcl.html#custom-setup-orcl.iam-vpc">
    #                   Configure IAM and your VPC</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting is required for RDS Custom.</p>
    #
    # @option params [String] :backup_target
    #   <p>Specifies where automated backups and manual snapshots are stored.</p>
    #           <p>Possible values are <code>outposts</code> (Amazon Web Services Outposts) and <code>region</code> (Amazon Web Services Region). The default is <code>region</code>.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-on-outposts.html">Working
    #               with Amazon RDS on Amazon Web Services Outposts</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @option params [String] :network_type
    #   <p>The network type of the DB instance.</p>
    #           <p>Valid values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>IPV4</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>DUAL</code>
    #                  </p>
    #               </li>
    #            </ul>
    #           <p>The network type is determined by the <code>DBSubnetGroup</code> specified for the DB instance.
    #               A <code>DBSubnetGroup</code> can support only the IPv4 protocol or the IPv4 and the IPv6
    #               protocols (<code>DUAL</code>).</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.WorkingWithRDSInstanceinaVPC.html">
    #               Working with a DB instance in a VPC</a> in the
    #               <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @return [Types::CreateDBInstanceOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.create_db_instance(
    #     db_name: 'DBName',
    #     db_instance_identifier: 'DBInstanceIdentifier', # required
    #     allocated_storage: 1,
    #     db_instance_class: 'DBInstanceClass', # required
    #     engine: 'Engine', # required
    #     master_username: 'MasterUsername',
    #     master_user_password: 'MasterUserPassword',
    #     db_security_groups: [
    #       'member'
    #     ],
    #     vpc_security_group_ids: [
    #       'member'
    #     ],
    #     availability_zone: 'AvailabilityZone',
    #     db_subnet_group_name: 'DBSubnetGroupName',
    #     preferred_maintenance_window: 'PreferredMaintenanceWindow',
    #     db_parameter_group_name: 'DBParameterGroupName',
    #     backup_retention_period: 1,
    #     preferred_backup_window: 'PreferredBackupWindow',
    #     port: 1,
    #     multi_az: false,
    #     engine_version: 'EngineVersion',
    #     auto_minor_version_upgrade: false,
    #     license_model: 'LicenseModel',
    #     iops: 1,
    #     option_group_name: 'OptionGroupName',
    #     character_set_name: 'CharacterSetName',
    #     nchar_character_set_name: 'NcharCharacterSetName',
    #     publicly_accessible: false,
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ],
    #     db_cluster_identifier: 'DBClusterIdentifier',
    #     storage_type: 'StorageType',
    #     tde_credential_arn: 'TdeCredentialArn',
    #     tde_credential_password: 'TdeCredentialPassword',
    #     storage_encrypted: false,
    #     kms_key_id: 'KmsKeyId',
    #     domain: 'Domain',
    #     copy_tags_to_snapshot: false,
    #     monitoring_interval: 1,
    #     monitoring_role_arn: 'MonitoringRoleArn',
    #     domain_iam_role_name: 'DomainIAMRoleName',
    #     promotion_tier: 1,
    #     timezone: 'Timezone',
    #     enable_iam_database_authentication: false,
    #     enable_performance_insights: false,
    #     performance_insights_kms_key_id: 'PerformanceInsightsKMSKeyId',
    #     performance_insights_retention_period: 1,
    #     enable_cloudwatch_logs_exports: [
    #       'member'
    #     ],
    #     processor_features: [
    #       {
    #         name: 'Name',
    #         value: 'Value'
    #       }
    #     ],
    #     deletion_protection: false,
    #     max_allocated_storage: 1,
    #     enable_customer_owned_ip: false,
    #     custom_iam_instance_profile: 'CustomIamInstanceProfile',
    #     backup_target: 'BackupTarget',
    #     network_type: 'NetworkType'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CreateDBInstanceOutput
    #   resp.data.db_instance #=> Types::DBInstance
    #   resp.data.db_instance.db_instance_identifier #=> String
    #   resp.data.db_instance.db_instance_class #=> String
    #   resp.data.db_instance.engine #=> String
    #   resp.data.db_instance.db_instance_status #=> String
    #   resp.data.db_instance.automatic_restart_time #=> Time
    #   resp.data.db_instance.master_username #=> String
    #   resp.data.db_instance.db_name #=> String
    #   resp.data.db_instance.endpoint #=> Types::Endpoint
    #   resp.data.db_instance.endpoint.address #=> String
    #   resp.data.db_instance.endpoint.port #=> Integer
    #   resp.data.db_instance.endpoint.hosted_zone_id #=> String
    #   resp.data.db_instance.allocated_storage #=> Integer
    #   resp.data.db_instance.instance_create_time #=> Time
    #   resp.data.db_instance.preferred_backup_window #=> String
    #   resp.data.db_instance.backup_retention_period #=> Integer
    #   resp.data.db_instance.db_security_groups #=> Array<DBSecurityGroupMembership>
    #   resp.data.db_instance.db_security_groups[0] #=> Types::DBSecurityGroupMembership
    #   resp.data.db_instance.db_security_groups[0].db_security_group_name #=> String
    #   resp.data.db_instance.db_security_groups[0].status #=> String
    #   resp.data.db_instance.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_instance.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_instance.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_instance.vpc_security_groups[0].status #=> String
    #   resp.data.db_instance.db_parameter_groups #=> Array<DBParameterGroupStatus>
    #   resp.data.db_instance.db_parameter_groups[0] #=> Types::DBParameterGroupStatus
    #   resp.data.db_instance.db_parameter_groups[0].db_parameter_group_name #=> String
    #   resp.data.db_instance.db_parameter_groups[0].parameter_apply_status #=> String
    #   resp.data.db_instance.availability_zone #=> String
    #   resp.data.db_instance.db_subnet_group #=> Types::DBSubnetGroup
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_name #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_description #=> String
    #   resp.data.db_instance.db_subnet_group.vpc_id #=> String
    #   resp.data.db_instance.db_subnet_group.subnet_group_status #=> String
    #   resp.data.db_instance.db_subnet_group.subnets #=> Array<Subnet>
    #   resp.data.db_instance.db_subnet_group.subnets[0] #=> Types::Subnet
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_identifier #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone #=> Types::AvailabilityZone
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone.name #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost #=> Types::Outpost
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost.arn #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_status #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_arn #=> String
    #   resp.data.db_instance.db_subnet_group.supported_network_types #=> Array<String>
    #   resp.data.db_instance.db_subnet_group.supported_network_types[0] #=> String
    #   resp.data.db_instance.preferred_maintenance_window #=> String
    #   resp.data.db_instance.pending_modified_values #=> Types::PendingModifiedValues
    #   resp.data.db_instance.pending_modified_values.db_instance_class #=> String
    #   resp.data.db_instance.pending_modified_values.allocated_storage #=> Integer
    #   resp.data.db_instance.pending_modified_values.master_user_password #=> String
    #   resp.data.db_instance.pending_modified_values.port #=> Integer
    #   resp.data.db_instance.pending_modified_values.backup_retention_period #=> Integer
    #   resp.data.db_instance.pending_modified_values.multi_az #=> Boolean
    #   resp.data.db_instance.pending_modified_values.engine_version #=> String
    #   resp.data.db_instance.pending_modified_values.license_model #=> String
    #   resp.data.db_instance.pending_modified_values.iops #=> Integer
    #   resp.data.db_instance.pending_modified_values.db_instance_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.storage_type #=> String
    #   resp.data.db_instance.pending_modified_values.ca_certificate_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.db_subnet_group_name #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable[0] #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.pending_modified_values.processor_features[0] #=> Types::ProcessorFeature
    #   resp.data.db_instance.pending_modified_values.processor_features[0].name #=> String
    #   resp.data.db_instance.pending_modified_values.processor_features[0].value #=> String
    #   resp.data.db_instance.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.pending_modified_values.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.pending_modified_values.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.latest_restorable_time #=> Time
    #   resp.data.db_instance.multi_az #=> Boolean
    #   resp.data.db_instance.engine_version #=> String
    #   resp.data.db_instance.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_instance.read_replica_source_db_instance_identifier #=> String
    #   resp.data.db_instance.read_replica_db_instance_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_instance_identifiers[0] #=> String
    #   resp.data.db_instance.read_replica_db_cluster_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_cluster_identifiers[0] #=> String
    #   resp.data.db_instance.replica_mode #=> String, one of ["open-read-only", "mounted"]
    #   resp.data.db_instance.license_model #=> String
    #   resp.data.db_instance.iops #=> Integer
    #   resp.data.db_instance.option_group_memberships #=> Array<OptionGroupMembership>
    #   resp.data.db_instance.option_group_memberships[0] #=> Types::OptionGroupMembership
    #   resp.data.db_instance.option_group_memberships[0].option_group_name #=> String
    #   resp.data.db_instance.option_group_memberships[0].status #=> String
    #   resp.data.db_instance.character_set_name #=> String
    #   resp.data.db_instance.nchar_character_set_name #=> String
    #   resp.data.db_instance.secondary_availability_zone #=> String
    #   resp.data.db_instance.publicly_accessible #=> Boolean
    #   resp.data.db_instance.status_infos #=> Array<DBInstanceStatusInfo>
    #   resp.data.db_instance.status_infos[0] #=> Types::DBInstanceStatusInfo
    #   resp.data.db_instance.status_infos[0].status_type #=> String
    #   resp.data.db_instance.status_infos[0].normal #=> Boolean
    #   resp.data.db_instance.status_infos[0].status #=> String
    #   resp.data.db_instance.status_infos[0].message #=> String
    #   resp.data.db_instance.storage_type #=> String
    #   resp.data.db_instance.tde_credential_arn #=> String
    #   resp.data.db_instance.db_instance_port #=> Integer
    #   resp.data.db_instance.db_cluster_identifier #=> String
    #   resp.data.db_instance.storage_encrypted #=> Boolean
    #   resp.data.db_instance.kms_key_id #=> String
    #   resp.data.db_instance.dbi_resource_id #=> String
    #   resp.data.db_instance.ca_certificate_identifier #=> String
    #   resp.data.db_instance.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_instance.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_instance.domain_memberships[0].domain #=> String
    #   resp.data.db_instance.domain_memberships[0].status #=> String
    #   resp.data.db_instance.domain_memberships[0].fqdn #=> String
    #   resp.data.db_instance.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_instance.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_instance.monitoring_interval #=> Integer
    #   resp.data.db_instance.enhanced_monitoring_resource_arn #=> String
    #   resp.data.db_instance.monitoring_role_arn #=> String
    #   resp.data.db_instance.promotion_tier #=> Integer
    #   resp.data.db_instance.db_instance_arn #=> String
    #   resp.data.db_instance.timezone #=> String
    #   resp.data.db_instance.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_kms_key_id #=> String
    #   resp.data.db_instance.performance_insights_retention_period #=> Integer
    #   resp.data.db_instance.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_instance.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.deletion_protection #=> Boolean
    #   resp.data.db_instance.associated_roles #=> Array<DBInstanceRole>
    #   resp.data.db_instance.associated_roles[0] #=> Types::DBInstanceRole
    #   resp.data.db_instance.associated_roles[0].role_arn #=> String
    #   resp.data.db_instance.associated_roles[0].feature_name #=> String
    #   resp.data.db_instance.associated_roles[0].status #=> String
    #   resp.data.db_instance.listener_endpoint #=> Types::Endpoint
    #   resp.data.db_instance.max_allocated_storage #=> Integer
    #   resp.data.db_instance.tag_list #=> Array<Tag>
    #   resp.data.db_instance.tag_list[0] #=> Types::Tag
    #   resp.data.db_instance.tag_list[0].key #=> String
    #   resp.data.db_instance.tag_list[0].value #=> String
    #   resp.data.db_instance.db_instance_automated_backups_replications #=> Array<DBInstanceAutomatedBackupsReplication>
    #   resp.data.db_instance.db_instance_automated_backups_replications[0] #=> Types::DBInstanceAutomatedBackupsReplication
    #   resp.data.db_instance.db_instance_automated_backups_replications[0].db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance.customer_owned_ip_enabled #=> Boolean
    #   resp.data.db_instance.aws_backup_recovery_point_arn #=> String
    #   resp.data.db_instance.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_instance.activity_stream_kms_key_id #=> String
    #   resp.data.db_instance.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_instance.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_instance.activity_stream_engine_native_audit_fields_included #=> Boolean
    #   resp.data.db_instance.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.custom_iam_instance_profile #=> String
    #   resp.data.db_instance.backup_target #=> String
    #   resp.data.db_instance.network_type #=> String
    #
    def create_db_instance(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CreateDBInstanceInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CreateDBInstanceInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CreateDBInstance
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::DBSubnetGroupDoesNotCoverEnoughAZs, Errors::DBSubnetGroupNotFoundFault, Errors::KMSKeyNotAccessibleFault, Errors::InstanceQuotaExceededFault, Errors::OptionGroupNotFoundFault, Errors::InvalidVPCNetworkStateFault, Errors::StorageQuotaExceededFault, Errors::InvalidSubnet, Errors::DBInstanceAlreadyExistsFault, Errors::InsufficientDBInstanceCapacityFault, Errors::NetworkTypeNotSupported, Errors::DBSecurityGroupNotFoundFault, Errors::DomainNotFoundFault, Errors::ProvisionedIopsNotAvailableInAZFault, Errors::InvalidDBClusterStateFault, Errors::AuthorizationNotFoundFault, Errors::StorageTypeNotSupportedFault, Errors::DBParameterGroupNotFoundFault, Errors::BackupPolicyNotFoundFault]),
        data_parser: Parsers::CreateDBInstance
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CreateDBInstance,
        stubs: @stubs,
        params_class: Params::CreateDBInstanceOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :create_db_instance
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates a new DB instance that acts as a read replica for an existing source DB
    #             instance. You can create a read replica for a DB instance running MySQL, MariaDB,
    #             Oracle, PostgreSQL, or SQL Server. For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html">Working with Read
    #                 Replicas</a> in the <i>Amazon RDS User Guide</i>.</p>
    #         <p>Amazon Aurora doesn't support this action. Call the <code>CreateDBInstance</code>
    #             action to create a DB instance for an Aurora DB cluster.</p>
    #         <p>All read replica DB instances are created with backups disabled. All other DB
    #             instance attributes (including DB security groups and DB parameter groups) are inherited
    #             from the source DB instance, except as specified.</p>
    #         <important>
    #             <p>Your source DB instance must have backup retention enabled.</p>
    #         </important>
    #
    # @param [Hash] params
    #   See {Types::CreateDBInstanceReadReplicaInput}.
    #
    # @option params [String] :db_instance_identifier
    #   <p>The DB instance identifier of the read replica. This identifier is the unique key
    #               that identifies a DB instance. This parameter is stored as a lowercase string.</p>
    #
    # @option params [String] :source_db_instance_identifier
    #   <p>The identifier of the DB instance that will act as the source for the read replica.
    #               Each DB instance can have up to five read replicas.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be the identifier of an existing MySQL, MariaDB, Oracle, PostgreSQL, or SQL Server DB
    #                       instance.</p>
    #               </li>
    #               <li>
    #                   <p>Can specify a DB instance that is a MySQL read replica only if the source is running MySQL
    #                       5.6 or later.</p>
    #               </li>
    #               <li>
    #                   <p>For the limitations of Oracle read replicas, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/oracle-read-replicas.html">Read Replica Limitations with Oracle</a> in the
    #                     <i>Amazon RDS User Guide</i>.</p>
    #               </li>
    #               <li>
    #                   <p>For the limitations of SQL Server read replicas, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/SQLServer.ReadReplicas.Limitations.html">Read Replica
    #                           Limitations with Microsoft SQL Server</a> in the <i>Amazon RDS User Guide</i>.</p>
    #               </li>
    #               <li>
    #                   <p>Can specify a PostgreSQL DB instance only if the source is running PostgreSQL 9.3.5 or
    #                       later (9.4.7 and higher for cross-Region replication).</p>
    #               </li>
    #               <li>
    #                   <p>The specified DB instance must have automatic backups enabled, that is, its backup
    #                       retention period must be greater than 0.</p>
    #               </li>
    #               <li>
    #                   <p>If the source DB instance is in the same Amazon Web Services Region as the read replica, specify a valid DB
    #                       instance identifier.</p>
    #               </li>
    #               <li>
    #                   <p>If the source DB instance is in a different Amazon Web Services Region from the read replica, specify a valid DB instance ARN.
    #                For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.ARN.html#USER_Tagging.ARN.Constructing">Constructing an ARN for Amazon RDS</a>
    #                in the <i>Amazon RDS User Guide</i>. This doesn't apply to SQL Server or RDS Custom, which don't support
    #                cross-Region replicas.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :db_instance_class
    #   <p>The compute and memory capacity of the read replica, for example
    #                   db.m4.large. Not all DB instance classes are available in all Amazon Web Services
    #               Regions, or for all database engines. For the full list of DB instance classes, and
    #               availability for your engine, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html">DB Instance
    #                   Class</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>Default: Inherits from the source DB instance.</p>
    #
    # @option params [String] :availability_zone
    #   <p>The Availability Zone (AZ) where the read replica will be created.</p>
    #           <p>Default: A random, system-chosen Availability Zone in the endpoint's Amazon Web Services Region.</p>
    #           <p>Example: <code>us-east-1d</code>
    #            </p>
    #
    # @option params [Integer] :port
    #   <p>The port number that the DB instance uses for connections.</p>
    #           <p>Default: Inherits from the source DB instance</p>
    #           <p>Valid Values: <code>1150-65535</code>
    #            </p>
    #
    # @option params [Boolean] :multi_az
    #   <p>A value that indicates whether the read replica is in a Multi-AZ deployment.</p>
    #           <p>You can create a read replica as a Multi-AZ DB instance. RDS creates a standby of
    #               your replica in another Availability Zone for failover support for the replica. Creating
    #               your read replica as a Multi-AZ DB instance is independent of whether the source
    #               database is a Multi-AZ DB instance.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :auto_minor_version_upgrade
    #   <p>A value that indicates whether minor engine upgrades are applied automatically to the
    #               read replica during the maintenance window.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Default: Inherits from the source DB instance</p>
    #
    # @option params [Integer] :iops
    #   <p>The amount of Provisioned IOPS (input/output operations per second) to be initially allocated for the DB instance.</p>
    #
    # @option params [String] :option_group_name
    #   <p>The option group the DB instance is associated with. If omitted, the option group associated with the source instance is used.</p>
    #           <note>
    #               <p>For SQL Server, you must use the option group associated with the source
    #                   instance.</p>
    #           </note>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :db_parameter_group_name
    #   <p>The name of the DB parameter group to associate with this DB instance.</p>
    #           <p>If you do not specify a value for <code>DBParameterGroupName</code>, then Amazon RDS
    #               uses the <code>DBParameterGroup</code> of source DB instance for a same Region read
    #               replica, or the default <code>DBParameterGroup</code> for the specified DB engine for a
    #               cross-Region read replica.</p>
    #           <p>Specifying a parameter group for this operation is only supported for Oracle DB instances. It
    #           isn't supported for RDS Custom.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be 1 to 255 letters, numbers, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #            </ul>
    #
    # @option params [Boolean] :publicly_accessible
    #   <p>A value that indicates whether the DB instance is publicly accessible.</p>
    #           <p>When the DB cluster is publicly accessible, its Domain Name System (DNS) endpoint
    #             resolves to the private IP address from within the DB cluster's virtual private cloud
    #             (VPC). It resolves to the public IP address from outside of the DB cluster's VPC. Access
    #             to the DB cluster is ultimately controlled by the security group it uses. That public
    #             access isn't permitted if the security group assigned to the DB cluster doesn't permit
    #             it.</p>
    #           <p>When the DB instance isn't publicly accessible, it is an internal DB instance with a DNS name that resolves to a private IP address.</p>
    #           <p>For more information, see <a>CreateDBInstance</a>.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>A list of tags.
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.html">Tagging Amazon RDS Resources</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @option params [String] :db_subnet_group_name
    #   <p>Specifies a DB subnet group for the DB instance. The new DB instance is created in the VPC associated with the DB subnet group. If no DB subnet group is specified, then the new DB instance isn't created in a VPC.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Can only be specified if the source DB instance identifier specifies a DB instance in another Amazon Web Services Region.</p>
    #               </li>
    #               <li>
    #                   <p>If supplied, must match the name of an existing DBSubnetGroup.</p>
    #               </li>
    #               <li>
    #                   <p>The specified DB subnet group must be in the same Amazon Web Services Region in which the operation is running.</p>
    #               </li>
    #               <li>
    #                   <p>All read replicas in one Amazon Web Services Region that are created from the same source DB
    #                       instance must either:></p>
    #                   <ul>
    #                     <li>
    #                           <p>Specify DB subnet groups from the same VPC. All these read replicas are created in the same
    #                               VPC.</p>
    #                       </li>
    #                     <li>
    #                           <p>Not specify a DB subnet group. All these read replicas are created outside of any
    #                               VPC.</p>
    #                       </li>
    #                  </ul>
    #               </li>
    #            </ul>
    #           <p>Example: <code>mydbsubnetgroup</code>
    #            </p>
    #
    # @option params [Array<String>] :vpc_security_group_ids
    #   <p>A list of Amazon EC2 VPC security groups to associate with the read replica.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Default: The default EC2 VPC security group for the DB subnet group's VPC.</p>
    #
    # @option params [String] :storage_type
    #   <p>Specifies the storage type to be associated with the read replica.</p>
    #           <p>Valid values: <code>standard | gp2 | io1</code>
    #            </p>
    #           <p>If you specify <code>io1</code>, you must also include a value for the
    #               <code>Iops</code> parameter.</p>
    #           <p>Default: <code>io1</code> if the <code>Iops</code> parameter
    #               is specified, otherwise <code>gp2</code>
    #            </p>
    #
    # @option params [Boolean] :copy_tags_to_snapshot
    #   <p>A value that indicates whether to copy all tags from the read replica to snapshots of
    #               the read replica. By default, tags are not copied.</p>
    #
    # @option params [Integer] :monitoring_interval
    #   <p>The interval, in seconds, between points when Enhanced Monitoring metrics are
    #               collected for the read replica. To disable collecting Enhanced Monitoring metrics,
    #               specify 0. The default is 0.</p>
    #           <p>If <code>MonitoringRoleArn</code> is specified, then you must also set <code>MonitoringInterval</code>
    #         to a value other than 0.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Valid Values: <code>0, 1, 5, 10, 15, 30, 60</code>
    #            </p>
    #
    # @option params [String] :monitoring_role_arn
    #   <p>The ARN for the IAM role that permits RDS to send enhanced monitoring metrics to Amazon CloudWatch Logs. For
    #         example, <code>arn:aws:iam:123456789012:role/emaccess</code>. For information on creating a monitoring role,
    #         go to <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.html#USER_Monitoring.OS.IAMRole">To
    #             create an IAM role for Amazon RDS Enhanced Monitoring</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>If <code>MonitoringInterval</code> is set to a value other than 0, then you must
    #             supply a <code>MonitoringRoleArn</code> value.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :kms_key_id
    #   <p>The Amazon Web Services KMS key identifier for an encrypted read replica.</p>
    #           <p>The Amazon Web Services KMS key identifier is the key ARN, key ID, alias ARN, or alias name for the KMS key.</p>
    #           <p>If you create an encrypted read replica in the same Amazon Web Services Region as the source DB
    #               instance, then do not specify a value for this parameter. A read replica in the same Amazon Web Services Region
    #               is always encrypted with the same KMS key as the source DB instance.</p>
    #           <p>If you create an encrypted read replica in a different Amazon Web Services Region, then you must
    #               specify a KMS key identifier for the destination Amazon Web Services Region. KMS keys are specific to
    #               the Amazon Web Services Region that they are created in, and you can't use KMS keys from one
    #               Amazon Web Services Region in another Amazon Web Services Region.</p>
    #           <p>You can't create an encrypted read replica from an unencrypted DB instance.</p>
    #           <p>This setting doesn't apply to RDS Custom, which uses the same KMS key as the primary
    #               replica.</p>
    #
    # @option params [String] :pre_signed_url
    #   <p>The URL that contains a Signature Version 4 signed request for the <code>CreateDBInstanceReadReplica</code> API action
    #               in the source Amazon Web Services Region that contains the source DB instance.</p>
    #           <p>You must specify this parameter when you create an encrypted read replica from
    #               another Amazon Web Services Region by using the Amazon RDS API. Don't specify
    #                   <code>PreSignedUrl</code> when you are creating an encrypted read replica in the
    #               same Amazon Web Services Region.</p>
    #           <p>The presigned URL must be a valid request for the <code>CreateDBInstanceReadReplica</code> API action
    #               that can be executed in the source Amazon Web Services Region that contains the encrypted source DB instance.
    #               The presigned URL request must contain the following parameter values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>DestinationRegion</code> - The Amazon Web Services Region that the encrypted read
    #                       replica is created in. This Amazon Web Services Region is the same one where the
    #                           <code>CreateDBInstanceReadReplica</code> action is called that contains this presigned URL.</p>
    #                   <p>For example, if you create an encrypted DB instance in the us-west-1 Amazon Web Services Region,
    #                       from a source DB instance in the us-east-2 Amazon Web Services Region,
    #                       then you call the <code>CreateDBInstanceReadReplica</code> action in
    #                       the us-east-1 Amazon Web Services Region and provide a presigned URL that contains a call to the
    #                       <code>CreateDBInstanceReadReplica</code> action in the us-west-2 Amazon Web Services Region. For this
    #                       example, the <code>DestinationRegion</code> in the presigned URL must be set to
    #                       the us-east-1 Amazon Web Services Region.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>KmsKeyId</code> - The Amazon Web Services KMS key identifier for the key to use to
    #                       encrypt the read replica in the destination Amazon Web Services Region. This is the same
    #                       identifier for both the <code>CreateDBInstanceReadReplica</code> action that is
    #                       called in the destination Amazon Web Services Region, and the action contained in the presigned
    #                       URL.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>SourceDBInstanceIdentifier</code> - The DB instance identifier for
    #                       the encrypted DB instance to be replicated. This identifier must be in the
    #                       Amazon Resource Name (ARN) format for the source Amazon Web Services Region. For example, if you
    #                       are creating an encrypted read replica from a DB instance in the us-west-2 Amazon Web Services
    #                       Region, then your <code>SourceDBInstanceIdentifier</code> looks like the
    #                       following example:
    #                           <code>arn:aws:rds:us-west-2:123456789012:instance:mysql-instance1-20161115</code>.</p>
    #               </li>
    #            </ul>
    #           <p>To learn how to generate a Signature Version 4 signed request, see
    #               <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html">Authenticating Requests: Using Query Parameters (Amazon Web Services Signature Version 4)</a> and
    #               <a href="https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html">Signature Version 4 Signing Process</a>.</p>
    #           <note>
    #               <p>If you are using an Amazon Web Services SDK tool or the CLI, you can specify
    #                       <code>SourceRegion</code> (or <code>--source-region</code> for the CLI)
    #                   instead of specifying <code>PreSignedUrl</code> manually. Specifying
    #                       <code>SourceRegion</code> autogenerates a presigned URL that is a valid request
    #                   for the operation that can be executed in the source Amazon Web Services Region.</p>
    #               <p>
    #                  <code>SourceRegion</code> isn't supported for SQL Server, because SQL Server on Amazon RDS
    #                   doesn't support cross-Region read replicas.</p>
    #           </note>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :enable_iam_database_authentication
    #   <p>A value that indicates whether to enable mapping of Amazon Web Services Identity and Access Management
    #               (IAM) accounts to database accounts. By default, mapping isn't enabled.</p>
    #           <p>For more information about IAM database authentication, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.html">
    #                 IAM Database Authentication for MySQL and PostgreSQL</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :enable_performance_insights
    #   <p>A value that indicates whether to enable Performance Insights for the read replica.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PerfInsights.html">Using
    #               Amazon Performance Insights</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :performance_insights_kms_key_id
    #   <p>The Amazon Web Services KMS key identifier for encryption of Performance Insights data.</p>
    #           <p>The Amazon Web Services KMS key identifier is the key ARN, key ID, alias ARN, or alias name for the KMS key.</p>
    #           <p>If you do not specify a value for <code>PerformanceInsightsKMSKeyId</code>, then Amazon RDS
    #               uses your default KMS key. There is a default KMS key for your Amazon Web Services account.
    #               Your Amazon Web Services account has a different default KMS key for each Amazon Web Services Region.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Integer] :performance_insights_retention_period
    #   <p>The amount of time, in days, to retain Performance Insights data. Valid values are 7 or 731 (2 years).</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Array<String>] :enable_cloudwatch_logs_exports
    #   <p>The list of logs that the new DB instance is to export to CloudWatch Logs. The values
    #               in the list depend on the DB engine being used. For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.html#USER_LogAccess.Procedural.UploadtoCloudWatch">Publishing
    #                   Database Logs to Amazon CloudWatch Logs </a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Array<ProcessorFeature>] :processor_features
    #   <p>The number of CPU cores and the number of threads per core for the DB instance class of the DB instance.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :use_default_processor_features
    #   <p>A value that indicates whether the DB instance class of the DB instance uses its default
    #               processor features.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :deletion_protection
    #   <p>A value that indicates whether the DB instance has deletion protection enabled.
    #               The database can't be deleted when deletion protection is enabled. By default,
    #               deletion protection isn't enabled. For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_DeleteInstance.html">
    #                   Deleting a DB Instance</a>.</p>
    #
    # @option params [String] :domain
    #   <p>The Active Directory directory ID to create the DB instance in. Currently, only MySQL, Microsoft SQL
    #               Server, Oracle, and PostgreSQL DB instances can be created in an Active Directory Domain.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/kerberos-authentication.html">
    #               Kerberos Authentication</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :domain_iam_role_name
    #   <p>Specify the name of the IAM role to be used when making API calls to the Directory Service.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :replica_mode
    #   <p>The open mode of the replica database: mounted or read-only.</p>
    #           <note>
    #               <p>This parameter is only supported for Oracle DB instances.</p>
    #           </note>
    #           <p>Mounted DB replicas are included in Oracle Database Enterprise Edition. The main use case for
    #               mounted replicas is cross-Region disaster recovery. The primary database doesn't use Active
    #               Data Guard to transmit information to the mounted replica. Because it doesn't accept
    #               user connections, a mounted replica can't serve a read-only workload.</p>
    #           <p>You can create a combination of mounted and read-only DB replicas for the same primary DB instance.
    #               For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/oracle-read-replicas.html">Working with Oracle Read Replicas for Amazon RDS</a>
    #               in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>For RDS Custom, you must specify this parameter and set it to <code>mounted</code>. The value won't be set by default.
    #               After replica creation, you can manage the open mode manually.</p>
    #
    # @option params [Integer] :max_allocated_storage
    #   <p>The upper limit in gibibytes (GiB) to which Amazon RDS can automatically scale the storage of the DB instance.</p>
    #           <p>For more information about this setting, including limitations that apply to it, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIOPS.StorageTypes.html#USER_PIOPS.Autoscaling">
    #                   Managing capacity automatically with Amazon RDS storage autoscaling</a>
    #               in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @option params [String] :custom_iam_instance_profile
    #   <p>The instance profile associated with the underlying Amazon EC2 instance of an
    #               RDS Custom DB instance. The instance profile must meet the following requirements:</p>
    #           <ul>
    #               <li>
    #                   <p>The profile must exist in your account.</p>
    #               </li>
    #               <li>
    #                   <p>The profile must have an IAM role that Amazon EC2 has permissions to assume.</p>
    #               </li>
    #               <li>
    #                   <p>The instance profile name and the associated IAM role name must start with the prefix <code>AWSRDSCustom</code>.</p>
    #               </li>
    #            </ul>
    #           <p>For the list of permissions required for the IAM role, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/custom-setup-orcl.html#custom-setup-orcl.iam-vpc">
    #                   Configure IAM and your VPC</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting is required for RDS Custom.</p>
    #
    # @option params [String] :network_type
    #   <p>The network type of the DB instance.</p>
    #           <p>Valid values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>IPV4</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>DUAL</code>
    #                  </p>
    #               </li>
    #            </ul>
    #           <p>The network type is determined by the <code>DBSubnetGroup</code> specified for read replica.
    #               A <code>DBSubnetGroup</code> can support only the IPv4 protocol or the IPv4 and the IPv6
    #               protocols (<code>DUAL</code>).</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.WorkingWithRDSInstanceinaVPC.html">
    #               Working with a DB instance in a VPC</a> in the
    #               <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @return [Types::CreateDBInstanceReadReplicaOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.create_db_instance_read_replica(
    #     db_instance_identifier: 'DBInstanceIdentifier', # required
    #     source_db_instance_identifier: 'SourceDBInstanceIdentifier', # required
    #     db_instance_class: 'DBInstanceClass',
    #     availability_zone: 'AvailabilityZone',
    #     port: 1,
    #     multi_az: false,
    #     auto_minor_version_upgrade: false,
    #     iops: 1,
    #     option_group_name: 'OptionGroupName',
    #     db_parameter_group_name: 'DBParameterGroupName',
    #     publicly_accessible: false,
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ],
    #     db_subnet_group_name: 'DBSubnetGroupName',
    #     vpc_security_group_ids: [
    #       'member'
    #     ],
    #     storage_type: 'StorageType',
    #     copy_tags_to_snapshot: false,
    #     monitoring_interval: 1,
    #     monitoring_role_arn: 'MonitoringRoleArn',
    #     kms_key_id: 'KmsKeyId',
    #     pre_signed_url: 'PreSignedUrl',
    #     enable_iam_database_authentication: false,
    #     enable_performance_insights: false,
    #     performance_insights_kms_key_id: 'PerformanceInsightsKMSKeyId',
    #     performance_insights_retention_period: 1,
    #     enable_cloudwatch_logs_exports: [
    #       'member'
    #     ],
    #     processor_features: [
    #       {
    #         name: 'Name',
    #         value: 'Value'
    #       }
    #     ],
    #     use_default_processor_features: false,
    #     deletion_protection: false,
    #     domain: 'Domain',
    #     domain_iam_role_name: 'DomainIAMRoleName',
    #     replica_mode: 'open-read-only', # accepts ["open-read-only", "mounted"]
    #     max_allocated_storage: 1,
    #     custom_iam_instance_profile: 'CustomIamInstanceProfile',
    #     network_type: 'NetworkType'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CreateDBInstanceReadReplicaOutput
    #   resp.data.db_instance #=> Types::DBInstance
    #   resp.data.db_instance.db_instance_identifier #=> String
    #   resp.data.db_instance.db_instance_class #=> String
    #   resp.data.db_instance.engine #=> String
    #   resp.data.db_instance.db_instance_status #=> String
    #   resp.data.db_instance.automatic_restart_time #=> Time
    #   resp.data.db_instance.master_username #=> String
    #   resp.data.db_instance.db_name #=> String
    #   resp.data.db_instance.endpoint #=> Types::Endpoint
    #   resp.data.db_instance.endpoint.address #=> String
    #   resp.data.db_instance.endpoint.port #=> Integer
    #   resp.data.db_instance.endpoint.hosted_zone_id #=> String
    #   resp.data.db_instance.allocated_storage #=> Integer
    #   resp.data.db_instance.instance_create_time #=> Time
    #   resp.data.db_instance.preferred_backup_window #=> String
    #   resp.data.db_instance.backup_retention_period #=> Integer
    #   resp.data.db_instance.db_security_groups #=> Array<DBSecurityGroupMembership>
    #   resp.data.db_instance.db_security_groups[0] #=> Types::DBSecurityGroupMembership
    #   resp.data.db_instance.db_security_groups[0].db_security_group_name #=> String
    #   resp.data.db_instance.db_security_groups[0].status #=> String
    #   resp.data.db_instance.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_instance.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_instance.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_instance.vpc_security_groups[0].status #=> String
    #   resp.data.db_instance.db_parameter_groups #=> Array<DBParameterGroupStatus>
    #   resp.data.db_instance.db_parameter_groups[0] #=> Types::DBParameterGroupStatus
    #   resp.data.db_instance.db_parameter_groups[0].db_parameter_group_name #=> String
    #   resp.data.db_instance.db_parameter_groups[0].parameter_apply_status #=> String
    #   resp.data.db_instance.availability_zone #=> String
    #   resp.data.db_instance.db_subnet_group #=> Types::DBSubnetGroup
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_name #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_description #=> String
    #   resp.data.db_instance.db_subnet_group.vpc_id #=> String
    #   resp.data.db_instance.db_subnet_group.subnet_group_status #=> String
    #   resp.data.db_instance.db_subnet_group.subnets #=> Array<Subnet>
    #   resp.data.db_instance.db_subnet_group.subnets[0] #=> Types::Subnet
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_identifier #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone #=> Types::AvailabilityZone
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone.name #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost #=> Types::Outpost
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost.arn #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_status #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_arn #=> String
    #   resp.data.db_instance.db_subnet_group.supported_network_types #=> Array<String>
    #   resp.data.db_instance.db_subnet_group.supported_network_types[0] #=> String
    #   resp.data.db_instance.preferred_maintenance_window #=> String
    #   resp.data.db_instance.pending_modified_values #=> Types::PendingModifiedValues
    #   resp.data.db_instance.pending_modified_values.db_instance_class #=> String
    #   resp.data.db_instance.pending_modified_values.allocated_storage #=> Integer
    #   resp.data.db_instance.pending_modified_values.master_user_password #=> String
    #   resp.data.db_instance.pending_modified_values.port #=> Integer
    #   resp.data.db_instance.pending_modified_values.backup_retention_period #=> Integer
    #   resp.data.db_instance.pending_modified_values.multi_az #=> Boolean
    #   resp.data.db_instance.pending_modified_values.engine_version #=> String
    #   resp.data.db_instance.pending_modified_values.license_model #=> String
    #   resp.data.db_instance.pending_modified_values.iops #=> Integer
    #   resp.data.db_instance.pending_modified_values.db_instance_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.storage_type #=> String
    #   resp.data.db_instance.pending_modified_values.ca_certificate_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.db_subnet_group_name #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable[0] #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.pending_modified_values.processor_features[0] #=> Types::ProcessorFeature
    #   resp.data.db_instance.pending_modified_values.processor_features[0].name #=> String
    #   resp.data.db_instance.pending_modified_values.processor_features[0].value #=> String
    #   resp.data.db_instance.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.pending_modified_values.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.pending_modified_values.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.latest_restorable_time #=> Time
    #   resp.data.db_instance.multi_az #=> Boolean
    #   resp.data.db_instance.engine_version #=> String
    #   resp.data.db_instance.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_instance.read_replica_source_db_instance_identifier #=> String
    #   resp.data.db_instance.read_replica_db_instance_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_instance_identifiers[0] #=> String
    #   resp.data.db_instance.read_replica_db_cluster_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_cluster_identifiers[0] #=> String
    #   resp.data.db_instance.replica_mode #=> String, one of ["open-read-only", "mounted"]
    #   resp.data.db_instance.license_model #=> String
    #   resp.data.db_instance.iops #=> Integer
    #   resp.data.db_instance.option_group_memberships #=> Array<OptionGroupMembership>
    #   resp.data.db_instance.option_group_memberships[0] #=> Types::OptionGroupMembership
    #   resp.data.db_instance.option_group_memberships[0].option_group_name #=> String
    #   resp.data.db_instance.option_group_memberships[0].status #=> String
    #   resp.data.db_instance.character_set_name #=> String
    #   resp.data.db_instance.nchar_character_set_name #=> String
    #   resp.data.db_instance.secondary_availability_zone #=> String
    #   resp.data.db_instance.publicly_accessible #=> Boolean
    #   resp.data.db_instance.status_infos #=> Array<DBInstanceStatusInfo>
    #   resp.data.db_instance.status_infos[0] #=> Types::DBInstanceStatusInfo
    #   resp.data.db_instance.status_infos[0].status_type #=> String
    #   resp.data.db_instance.status_infos[0].normal #=> Boolean
    #   resp.data.db_instance.status_infos[0].status #=> String
    #   resp.data.db_instance.status_infos[0].message #=> String
    #   resp.data.db_instance.storage_type #=> String
    #   resp.data.db_instance.tde_credential_arn #=> String
    #   resp.data.db_instance.db_instance_port #=> Integer
    #   resp.data.db_instance.db_cluster_identifier #=> String
    #   resp.data.db_instance.storage_encrypted #=> Boolean
    #   resp.data.db_instance.kms_key_id #=> String
    #   resp.data.db_instance.dbi_resource_id #=> String
    #   resp.data.db_instance.ca_certificate_identifier #=> String
    #   resp.data.db_instance.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_instance.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_instance.domain_memberships[0].domain #=> String
    #   resp.data.db_instance.domain_memberships[0].status #=> String
    #   resp.data.db_instance.domain_memberships[0].fqdn #=> String
    #   resp.data.db_instance.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_instance.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_instance.monitoring_interval #=> Integer
    #   resp.data.db_instance.enhanced_monitoring_resource_arn #=> String
    #   resp.data.db_instance.monitoring_role_arn #=> String
    #   resp.data.db_instance.promotion_tier #=> Integer
    #   resp.data.db_instance.db_instance_arn #=> String
    #   resp.data.db_instance.timezone #=> String
    #   resp.data.db_instance.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_kms_key_id #=> String
    #   resp.data.db_instance.performance_insights_retention_period #=> Integer
    #   resp.data.db_instance.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_instance.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.deletion_protection #=> Boolean
    #   resp.data.db_instance.associated_roles #=> Array<DBInstanceRole>
    #   resp.data.db_instance.associated_roles[0] #=> Types::DBInstanceRole
    #   resp.data.db_instance.associated_roles[0].role_arn #=> String
    #   resp.data.db_instance.associated_roles[0].feature_name #=> String
    #   resp.data.db_instance.associated_roles[0].status #=> String
    #   resp.data.db_instance.listener_endpoint #=> Types::Endpoint
    #   resp.data.db_instance.max_allocated_storage #=> Integer
    #   resp.data.db_instance.tag_list #=> Array<Tag>
    #   resp.data.db_instance.tag_list[0] #=> Types::Tag
    #   resp.data.db_instance.tag_list[0].key #=> String
    #   resp.data.db_instance.tag_list[0].value #=> String
    #   resp.data.db_instance.db_instance_automated_backups_replications #=> Array<DBInstanceAutomatedBackupsReplication>
    #   resp.data.db_instance.db_instance_automated_backups_replications[0] #=> Types::DBInstanceAutomatedBackupsReplication
    #   resp.data.db_instance.db_instance_automated_backups_replications[0].db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance.customer_owned_ip_enabled #=> Boolean
    #   resp.data.db_instance.aws_backup_recovery_point_arn #=> String
    #   resp.data.db_instance.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_instance.activity_stream_kms_key_id #=> String
    #   resp.data.db_instance.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_instance.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_instance.activity_stream_engine_native_audit_fields_included #=> Boolean
    #   resp.data.db_instance.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.custom_iam_instance_profile #=> String
    #   resp.data.db_instance.backup_target #=> String
    #   resp.data.db_instance.network_type #=> String
    #
    def create_db_instance_read_replica(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CreateDBInstanceReadReplicaInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CreateDBInstanceReadReplicaInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CreateDBInstanceReadReplica
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBSubnetGroupDoesNotCoverEnoughAZs, Errors::DBSubnetGroupNotFoundFault, Errors::KMSKeyNotAccessibleFault, Errors::InstanceQuotaExceededFault, Errors::InvalidDBSubnetGroupFault, Errors::OptionGroupNotFoundFault, Errors::DBSubnetGroupNotAllowedFault, Errors::InvalidVPCNetworkStateFault, Errors::StorageQuotaExceededFault, Errors::InvalidSubnet, Errors::DBInstanceAlreadyExistsFault, Errors::InvalidDBInstanceStateFault, Errors::InsufficientDBInstanceCapacityFault, Errors::NetworkTypeNotSupported, Errors::DBInstanceNotFoundFault, Errors::DBSecurityGroupNotFoundFault, Errors::DomainNotFoundFault, Errors::ProvisionedIopsNotAvailableInAZFault, Errors::StorageTypeNotSupportedFault, Errors::DBParameterGroupNotFoundFault]),
        data_parser: Parsers::CreateDBInstanceReadReplica
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CreateDBInstanceReadReplica,
        stubs: @stubs,
        params_class: Params::CreateDBInstanceReadReplicaOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :create_db_instance_read_replica
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates a new DB parameter group.</p>
    #         <p>A DB parameter group is initially created with the default parameters for the
    #             database engine used by the DB instance. To provide custom values for any of the
    #             parameters, you must modify the group after creating it using
    #             <code>ModifyDBParameterGroup</code>. Once you've created a DB parameter group, you need to
    #             associate it with your DB instance using <code>ModifyDBInstance</code>. When you associate
    #             a new DB parameter group with a running DB instance, you need to reboot the DB
    #             instance without failover for the new DB parameter group and associated settings to take effect.</p>
    #         <p>This command doesn't apply to RDS Custom.</p>
    #         <important>
    #             <p>After you create a DB parameter group, you should wait at least 5 minutes
    #                 before creating your first DB instance that uses that DB parameter group as the default parameter
    #                 group. This allows Amazon RDS to fully complete the create action before the parameter
    #                 group is used as the default for a new DB instance. This is especially important for parameters
    #                 that are critical when creating the default database for a DB instance, such as the character set
    #                 for the default database defined by the <code>character_set_database</code> parameter. You can use the
    #                 <i>Parameter Groups</i> option of the <a href="https://console.aws.amazon.com/rds/">Amazon RDS console</a> or the
    #                 <i>DescribeDBParameters</i> command to verify
    #                 that your DB parameter group has been created or modified.</p>
    #         </important>
    #
    # @param [Hash] params
    #   See {Types::CreateDBParameterGroupInput}.
    #
    # @option params [String] :db_parameter_group_name
    #   <p>The name of the DB parameter group.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be 1 to 255 letters, numbers, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #            </ul>
    #           <note>
    #               <p>This value is stored as a lowercase string.</p>
    #           </note>
    #
    # @option params [String] :db_parameter_group_family
    #   <p>The DB parameter group family name. A DB parameter group can be associated with one and only one DB parameter group family, and can be applied only to a DB instance running a database engine and engine version compatible with that DB parameter group family.</p>
    #           <p>To list all of the available parameter group families for a DB engine, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --query "DBEngineVersions[].DBParameterGroupFamily" --engine <engine></code>
    #            </p>
    #           <p>For example, to list all of the available parameter group families for the MySQL DB engine, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --query "DBEngineVersions[].DBParameterGroupFamily" --engine mysql</code>
    #            </p>
    #           <note>
    #               <p>The output contains duplicates.</p>
    #           </note>
    #           <p>The following are the valid DB engine values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>aurora</code> (for MySQL 5.6-compatible Aurora)</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-mysql</code> (for MySQL 5.7-compatible and MySQL 8.0-compatible Aurora)</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-postgresql</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mariadb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mysql</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>postgres</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-se</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ex</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-web</code>
    #                  </p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :description
    #   <p>The description for the DB parameter group.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>Tags to assign to the DB parameter group.</p>
    #
    # @return [Types::CreateDBParameterGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.create_db_parameter_group(
    #     db_parameter_group_name: 'DBParameterGroupName', # required
    #     db_parameter_group_family: 'DBParameterGroupFamily', # required
    #     description: 'Description', # required
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CreateDBParameterGroupOutput
    #   resp.data.db_parameter_group #=> Types::DBParameterGroup
    #   resp.data.db_parameter_group.db_parameter_group_name #=> String
    #   resp.data.db_parameter_group.db_parameter_group_family #=> String
    #   resp.data.db_parameter_group.description #=> String
    #   resp.data.db_parameter_group.db_parameter_group_arn #=> String
    #
    def create_db_parameter_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CreateDBParameterGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CreateDBParameterGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CreateDBParameterGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBParameterGroupAlreadyExistsFault, Errors::DBParameterGroupQuotaExceededFault]),
        data_parser: Parsers::CreateDBParameterGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CreateDBParameterGroup,
        stubs: @stubs,
        params_class: Params::CreateDBParameterGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :create_db_parameter_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates a new DB proxy.</p>
    #
    # @param [Hash] params
    #   See {Types::CreateDBProxyInput}.
    #
    # @option params [String] :db_proxy_name
    #   <p>The identifier for the proxy. This name must be unique for all proxies owned by your Amazon Web Services account in the specified Amazon Web Services Region. An identifier must begin with a letter and must contain only ASCII letters, digits, and hyphens; it can't end with a hyphen or contain two consecutive hyphens.</p>
    #
    # @option params [String] :engine_family
    #   <p>The kinds of databases that the proxy can connect to.
    #             This value determines which database network protocol the proxy recognizes when it interprets
    #           network traffic to and from the database.
    #           The engine family applies to MySQL and PostgreSQL for both RDS and Aurora.</p>
    #
    # @option params [Array<UserAuthConfig>] :auth
    #   <p>The authorization mechanism that the proxy uses.</p>
    #
    # @option params [String] :role_arn
    #   <p>The Amazon Resource Name (ARN) of the IAM role that the proxy uses to access secrets in Amazon Web Services Secrets Manager.</p>
    #
    # @option params [Array<String>] :vpc_subnet_ids
    #   <p>One or more VPC subnet IDs to associate with the new proxy.</p>
    #
    # @option params [Array<String>] :vpc_security_group_ids
    #   <p>One or more VPC security group IDs to associate with the new proxy.</p>
    #
    # @option params [Boolean] :require_tls
    #   <p>A Boolean parameter that specifies whether Transport Layer Security (TLS) encryption is required for connections to the proxy.
    #           By enabling this setting, you can enforce encrypted TLS connections to the proxy.</p>
    #
    # @option params [Integer] :idle_client_timeout
    #   <p>The number of seconds that a connection to the proxy can be inactive before the proxy disconnects it. You can set this
    #           value higher or lower than the connection timeout limit for the associated database.</p>
    #
    # @option params [Boolean] :debug_logging
    #   <p>Whether the proxy includes detailed information about SQL statements in its logs.
    #           This information helps you to debug issues involving SQL behavior or the performance
    #           and scalability of the proxy connections. The debug information includes the text of
    #           SQL statements that you submit through the proxy. Thus, only enable this setting
    #           when needed for debugging, and only when you have security measures in place to
    #           safeguard any sensitive information that appears in the logs.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>An optional set of key-value pairs to associate arbitrary data of your choosing with the proxy.</p>
    #
    # @return [Types::CreateDBProxyOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.create_db_proxy(
    #     db_proxy_name: 'DBProxyName', # required
    #     engine_family: 'MYSQL', # required - accepts ["MYSQL", "POSTGRESQL"]
    #     auth: [
    #       {
    #         description: 'Description',
    #         user_name: 'UserName',
    #         auth_scheme: 'SECRETS', # accepts ["SECRETS"]
    #         secret_arn: 'SecretArn',
    #         iam_auth: 'DISABLED' # accepts ["DISABLED", "REQUIRED"]
    #       }
    #     ], # required
    #     role_arn: 'RoleArn', # required
    #     vpc_subnet_ids: [
    #       'member'
    #     ], # required
    #     require_tls: false,
    #     idle_client_timeout: 1,
    #     debug_logging: false,
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CreateDBProxyOutput
    #   resp.data.db_proxy #=> Types::DBProxy
    #   resp.data.db_proxy.db_proxy_name #=> String
    #   resp.data.db_proxy.db_proxy_arn #=> String
    #   resp.data.db_proxy.status #=> String, one of ["available", "modifying", "incompatible-network", "insufficient-resource-limits", "creating", "deleting", "suspended", "suspending", "reactivating"]
    #   resp.data.db_proxy.engine_family #=> String
    #   resp.data.db_proxy.vpc_id #=> String
    #   resp.data.db_proxy.vpc_security_group_ids #=> Array<String>
    #   resp.data.db_proxy.vpc_security_group_ids[0] #=> String
    #   resp.data.db_proxy.vpc_subnet_ids #=> Array<String>
    #   resp.data.db_proxy.auth #=> Array<UserAuthConfigInfo>
    #   resp.data.db_proxy.auth[0] #=> Types::UserAuthConfigInfo
    #   resp.data.db_proxy.auth[0].description #=> String
    #   resp.data.db_proxy.auth[0].user_name #=> String
    #   resp.data.db_proxy.auth[0].auth_scheme #=> String, one of ["SECRETS"]
    #   resp.data.db_proxy.auth[0].secret_arn #=> String
    #   resp.data.db_proxy.auth[0].iam_auth #=> String, one of ["DISABLED", "REQUIRED"]
    #   resp.data.db_proxy.role_arn #=> String
    #   resp.data.db_proxy.endpoint #=> String
    #   resp.data.db_proxy.require_tls #=> Boolean
    #   resp.data.db_proxy.idle_client_timeout #=> Integer
    #   resp.data.db_proxy.debug_logging #=> Boolean
    #   resp.data.db_proxy.created_date #=> Time
    #   resp.data.db_proxy.updated_date #=> Time
    #
    def create_db_proxy(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CreateDBProxyInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CreateDBProxyInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CreateDBProxy
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBProxyQuotaExceededFault, Errors::DBProxyAlreadyExistsFault, Errors::InvalidSubnet]),
        data_parser: Parsers::CreateDBProxy
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CreateDBProxy,
        stubs: @stubs,
        params_class: Params::CreateDBProxyOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :create_db_proxy
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates a <code>DBProxyEndpoint</code>. Only applies to proxies that are associated with Aurora DB clusters.
    #         You can use DB proxy endpoints to specify read/write or read-only access to the DB cluster. You can also use
    #         DB proxy endpoints to access a DB proxy through a different VPC than the proxy's default VPC.</p>
    #
    # @param [Hash] params
    #   See {Types::CreateDBProxyEndpointInput}.
    #
    # @option params [String] :db_proxy_name
    #   <p>The name of the DB proxy associated with the DB proxy endpoint that you create.</p>
    #
    # @option params [String] :db_proxy_endpoint_name
    #   <p>The name of the DB proxy endpoint to create.</p>
    #
    # @option params [Array<String>] :vpc_subnet_ids
    #   <p>The VPC subnet IDs for the DB proxy endpoint that you create. You can specify a
    #           different set of subnet IDs than for the original DB proxy.</p>
    #
    # @option params [Array<String>] :vpc_security_group_ids
    #   <p>The VPC security group IDs for the DB proxy endpoint that you create. You can
    #           specify a different set of security group IDs than for the original DB proxy.
    #           The default is the default security group for the VPC.</p>
    #
    # @option params [String] :target_role
    #   <p>A value that indicates whether the DB proxy endpoint can be used for read/write
    #           or read-only operations. The default is <code>READ_WRITE</code>.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>A list of tags.
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.html">Tagging Amazon RDS Resources</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @return [Types::CreateDBProxyEndpointOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.create_db_proxy_endpoint(
    #     db_proxy_name: 'DBProxyName', # required
    #     db_proxy_endpoint_name: 'DBProxyEndpointName', # required
    #     vpc_subnet_ids: [
    #       'member'
    #     ], # required
    #     target_role: 'READ_WRITE', # accepts ["READ_WRITE", "READ_ONLY"]
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CreateDBProxyEndpointOutput
    #   resp.data.db_proxy_endpoint #=> Types::DBProxyEndpoint
    #   resp.data.db_proxy_endpoint.db_proxy_endpoint_name #=> String
    #   resp.data.db_proxy_endpoint.db_proxy_endpoint_arn #=> String
    #   resp.data.db_proxy_endpoint.db_proxy_name #=> String
    #   resp.data.db_proxy_endpoint.status #=> String, one of ["available", "modifying", "incompatible-network", "insufficient-resource-limits", "creating", "deleting"]
    #   resp.data.db_proxy_endpoint.vpc_id #=> String
    #   resp.data.db_proxy_endpoint.vpc_security_group_ids #=> Array<String>
    #   resp.data.db_proxy_endpoint.vpc_security_group_ids[0] #=> String
    #   resp.data.db_proxy_endpoint.vpc_subnet_ids #=> Array<String>
    #   resp.data.db_proxy_endpoint.endpoint #=> String
    #   resp.data.db_proxy_endpoint.created_date #=> Time
    #   resp.data.db_proxy_endpoint.target_role #=> String, one of ["READ_WRITE", "READ_ONLY"]
    #   resp.data.db_proxy_endpoint.is_default #=> Boolean
    #
    def create_db_proxy_endpoint(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CreateDBProxyEndpointInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CreateDBProxyEndpointInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CreateDBProxyEndpoint
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBProxyEndpointAlreadyExistsFault, Errors::DBProxyNotFoundFault, Errors::DBProxyEndpointQuotaExceededFault, Errors::InvalidSubnet, Errors::InvalidDBProxyStateFault]),
        data_parser: Parsers::CreateDBProxyEndpoint
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CreateDBProxyEndpoint,
        stubs: @stubs,
        params_class: Params::CreateDBProxyEndpointOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :create_db_proxy_endpoint
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates a new DB security group. DB security groups control access to a DB instance.</p>
    #         <note>
    #             <p>A DB security group controls access to EC2-Classic DB instances that are not in a VPC.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::CreateDBSecurityGroupInput}.
    #
    # @option params [String] :db_security_group_name
    #   <p>The name for the DB security group. This value is stored as a lowercase string.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be 1 to 255 letters, numbers, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #               <li>
    #                   <p>Must not be "Default"</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>mysecuritygroup</code>
    #            </p>
    #
    # @option params [String] :db_security_group_description
    #   <p>The description for the DB security group.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>Tags to assign to the DB security group.</p>
    #
    # @return [Types::CreateDBSecurityGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.create_db_security_group(
    #     db_security_group_name: 'DBSecurityGroupName', # required
    #     db_security_group_description: 'DBSecurityGroupDescription', # required
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CreateDBSecurityGroupOutput
    #   resp.data.db_security_group #=> Types::DBSecurityGroup
    #   resp.data.db_security_group.owner_id #=> String
    #   resp.data.db_security_group.db_security_group_name #=> String
    #   resp.data.db_security_group.db_security_group_description #=> String
    #   resp.data.db_security_group.vpc_id #=> String
    #   resp.data.db_security_group.ec2_security_groups #=> Array<EC2SecurityGroup>
    #   resp.data.db_security_group.ec2_security_groups[0] #=> Types::EC2SecurityGroup
    #   resp.data.db_security_group.ec2_security_groups[0].status #=> String
    #   resp.data.db_security_group.ec2_security_groups[0].ec2_security_group_name #=> String
    #   resp.data.db_security_group.ec2_security_groups[0].ec2_security_group_id #=> String
    #   resp.data.db_security_group.ec2_security_groups[0].ec2_security_group_owner_id #=> String
    #   resp.data.db_security_group.ip_ranges #=> Array<IPRange>
    #   resp.data.db_security_group.ip_ranges[0] #=> Types::IPRange
    #   resp.data.db_security_group.ip_ranges[0].status #=> String
    #   resp.data.db_security_group.ip_ranges[0].cidrip #=> String
    #   resp.data.db_security_group.db_security_group_arn #=> String
    #
    def create_db_security_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CreateDBSecurityGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CreateDBSecurityGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CreateDBSecurityGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBSecurityGroupNotSupportedFault, Errors::DBSecurityGroupAlreadyExistsFault, Errors::DBSecurityGroupQuotaExceededFault]),
        data_parser: Parsers::CreateDBSecurityGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CreateDBSecurityGroup,
        stubs: @stubs,
        params_class: Params::CreateDBSecurityGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :create_db_security_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates a snapshot of a DB instance. The source DB instance must be in the <code>available</code> or
    #                 <code>storage-optimization</code> state.</p>
    #
    # @param [Hash] params
    #   See {Types::CreateDBSnapshotInput}.
    #
    # @option params [String] :db_snapshot_identifier
    #   <p>The identifier for the DB snapshot.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Can't be null, empty, or blank</p>
    #               </li>
    #               <li>
    #                   <p>Must contain from 1 to 255 letters, numbers, or hyphens</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-snapshot-id</code>
    #            </p>
    #
    # @option params [String] :db_instance_identifier
    #   <p>The identifier of the DB instance that you want to create the snapshot of.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the identifier of an existing DBInstance.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Array<Tag>] :tags
    #   <p>A list of tags.
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.html">Tagging Amazon RDS Resources</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @return [Types::CreateDBSnapshotOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.create_db_snapshot(
    #     db_snapshot_identifier: 'DBSnapshotIdentifier', # required
    #     db_instance_identifier: 'DBInstanceIdentifier', # required
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CreateDBSnapshotOutput
    #   resp.data.db_snapshot #=> Types::DBSnapshot
    #   resp.data.db_snapshot.db_snapshot_identifier #=> String
    #   resp.data.db_snapshot.db_instance_identifier #=> String
    #   resp.data.db_snapshot.snapshot_create_time #=> Time
    #   resp.data.db_snapshot.engine #=> String
    #   resp.data.db_snapshot.allocated_storage #=> Integer
    #   resp.data.db_snapshot.status #=> String
    #   resp.data.db_snapshot.port #=> Integer
    #   resp.data.db_snapshot.availability_zone #=> String
    #   resp.data.db_snapshot.vpc_id #=> String
    #   resp.data.db_snapshot.instance_create_time #=> Time
    #   resp.data.db_snapshot.master_username #=> String
    #   resp.data.db_snapshot.engine_version #=> String
    #   resp.data.db_snapshot.license_model #=> String
    #   resp.data.db_snapshot.snapshot_type #=> String
    #   resp.data.db_snapshot.iops #=> Integer
    #   resp.data.db_snapshot.option_group_name #=> String
    #   resp.data.db_snapshot.percent_progress #=> Integer
    #   resp.data.db_snapshot.source_region #=> String
    #   resp.data.db_snapshot.source_db_snapshot_identifier #=> String
    #   resp.data.db_snapshot.storage_type #=> String
    #   resp.data.db_snapshot.tde_credential_arn #=> String
    #   resp.data.db_snapshot.encrypted #=> Boolean
    #   resp.data.db_snapshot.kms_key_id #=> String
    #   resp.data.db_snapshot.db_snapshot_arn #=> String
    #   resp.data.db_snapshot.timezone #=> String
    #   resp.data.db_snapshot.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_snapshot.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_snapshot.processor_features[0] #=> Types::ProcessorFeature
    #   resp.data.db_snapshot.processor_features[0].name #=> String
    #   resp.data.db_snapshot.processor_features[0].value #=> String
    #   resp.data.db_snapshot.dbi_resource_id #=> String
    #   resp.data.db_snapshot.tag_list #=> Array<Tag>
    #   resp.data.db_snapshot.tag_list[0] #=> Types::Tag
    #   resp.data.db_snapshot.tag_list[0].key #=> String
    #   resp.data.db_snapshot.tag_list[0].value #=> String
    #   resp.data.db_snapshot.original_snapshot_create_time #=> Time
    #   resp.data.db_snapshot.snapshot_target #=> String
    #
    def create_db_snapshot(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CreateDBSnapshotInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CreateDBSnapshotInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CreateDBSnapshot
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBInstanceNotFoundFault, Errors::SnapshotQuotaExceededFault, Errors::DBSnapshotAlreadyExistsFault, Errors::InvalidDBInstanceStateFault]),
        data_parser: Parsers::CreateDBSnapshot
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CreateDBSnapshot,
        stubs: @stubs,
        params_class: Params::CreateDBSnapshotOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :create_db_snapshot
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates a new DB subnet group. DB subnet groups must contain at least one subnet in at least two AZs in the Amazon Web Services Region.</p>
    #
    # @param [Hash] params
    #   See {Types::CreateDBSubnetGroupInput}.
    #
    # @option params [String] :db_subnet_group_name
    #   <p>The name for the DB subnet group. This value is stored as a lowercase string.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain no more than 255 letters, numbers, periods, underscores, spaces, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>Must not be default.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>mydbsubnetgroup</code>
    #            </p>
    #
    # @option params [String] :db_subnet_group_description
    #   <p>The description for the DB subnet group.</p>
    #
    # @option params [Array<String>] :subnet_ids
    #   <p>The EC2 Subnet IDs for the DB subnet group.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>Tags to assign to the DB subnet group.</p>
    #
    # @return [Types::CreateDBSubnetGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.create_db_subnet_group(
    #     db_subnet_group_name: 'DBSubnetGroupName', # required
    #     db_subnet_group_description: 'DBSubnetGroupDescription', # required
    #     subnet_ids: [
    #       'member'
    #     ], # required
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CreateDBSubnetGroupOutput
    #   resp.data.db_subnet_group #=> Types::DBSubnetGroup
    #   resp.data.db_subnet_group.db_subnet_group_name #=> String
    #   resp.data.db_subnet_group.db_subnet_group_description #=> String
    #   resp.data.db_subnet_group.vpc_id #=> String
    #   resp.data.db_subnet_group.subnet_group_status #=> String
    #   resp.data.db_subnet_group.subnets #=> Array<Subnet>
    #   resp.data.db_subnet_group.subnets[0] #=> Types::Subnet
    #   resp.data.db_subnet_group.subnets[0].subnet_identifier #=> String
    #   resp.data.db_subnet_group.subnets[0].subnet_availability_zone #=> Types::AvailabilityZone
    #   resp.data.db_subnet_group.subnets[0].subnet_availability_zone.name #=> String
    #   resp.data.db_subnet_group.subnets[0].subnet_outpost #=> Types::Outpost
    #   resp.data.db_subnet_group.subnets[0].subnet_outpost.arn #=> String
    #   resp.data.db_subnet_group.subnets[0].subnet_status #=> String
    #   resp.data.db_subnet_group.db_subnet_group_arn #=> String
    #   resp.data.db_subnet_group.supported_network_types #=> Array<String>
    #   resp.data.db_subnet_group.supported_network_types[0] #=> String
    #
    def create_db_subnet_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CreateDBSubnetGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CreateDBSubnetGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CreateDBSubnetGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBSubnetGroupDoesNotCoverEnoughAZs, Errors::DBSubnetGroupQuotaExceededFault, Errors::DBSubnetQuotaExceededFault, Errors::DBSubnetGroupAlreadyExistsFault, Errors::InvalidSubnet]),
        data_parser: Parsers::CreateDBSubnetGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CreateDBSubnetGroup,
        stubs: @stubs,
        params_class: Params::CreateDBSubnetGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :create_db_subnet_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates an RDS event notification subscription. This action requires a topic Amazon
    #             Resource Name (ARN) created by either the RDS console, the SNS console, or the SNS API.
    #             To obtain an ARN with SNS, you must create a topic in Amazon SNS and subscribe to the
    #             topic. The ARN is displayed in the SNS console.</p>
    #         <p>You can specify the type of source (<code>SourceType</code>) that you want to be
    #             notified of and provide a list of RDS sources (<code>SourceIds</code>) that triggers the
    #             events. You can also provide a list of event categories (<code>EventCategories</code>)
    #             for events that you want to be notified of. For example, you can specify
    #                 <code>SourceType</code> = <code>db-instance</code>, <code>SourceIds</code> =
    #                 <code>mydbinstance1</code>, <code>mydbinstance2</code> and
    #                 <code>EventCategories</code> = <code>Availability</code>,
    #             <code>Backup</code>.</p>
    #         <p>If you specify both the <code>SourceType</code> and <code>SourceIds</code>, such as <code>SourceType</code> = <code>db-instance</code>
    #           and <code>SourceIds</code> = <code>myDBInstance1</code>, you are notified of all the <code>db-instance</code> events for
    #           the specified source. If you specify a <code>SourceType</code> but do not specify <code>SourceIds</code>,
    #           you receive notice of the events for that source type for all your RDS sources. If you
    #           don't specify either the SourceType or the <code>SourceIds</code>, you are notified of events
    #           generated from all RDS sources belonging to your customer account.</p>
    #         <note>
    #             <p>RDS event notification is only available for unencrypted SNS topics. If you specify an
    #               encrypted SNS topic, event notifications aren't sent for the topic.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::CreateEventSubscriptionInput}.
    #
    # @option params [String] :subscription_name
    #   <p>The name of the subscription.</p>
    #           <p>Constraints: The name must be less than 255 characters.</p>
    #
    # @option params [String] :sns_topic_arn
    #   <p>The Amazon Resource Name (ARN) of the SNS topic created for event notification. The ARN is created by Amazon SNS when you create a topic and subscribe to it.</p>
    #
    # @option params [String] :source_type
    #   <p>The type of source that is generating the events. For example, if you want to be
    #               notified of events generated by a DB instance, you set this parameter to
    #                   <code>db-instance</code>. For RDS Proxy events, specify <code>db-proxy</code>. If this value isn't specified, all events are
    #               returned.</p>
    #           <p>Valid values: <code>db-instance</code> | <code>db-cluster</code> | <code>db-parameter-group</code> | <code>db-security-group</code> | <code>db-snapshot</code> | <code>db-cluster-snapshot</code> | <code>db-proxy</code>
    #            </p>
    #
    # @option params [Array<String>] :event_categories
    #   <p>A list of event categories for a particular source type (<code>SourceType</code>)
    #               that you want to subscribe to. You can see a list of the categories for a given source type in the "Amazon RDS event categories and event messages" section of the <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.Messages.html">
    #                   <i>Amazon RDS User Guide</i>
    #               </a> or the
    #                   <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_Events.Messages.html">
    #                   <i>Amazon Aurora User Guide</i>
    #               </a>.
    #                   You can also see this list by using the <code>DescribeEventCategories</code> operation.</p>
    #
    # @option params [Array<String>] :source_ids
    #   <p>The list of identifiers of the event sources for which events are returned. If not specified, then all sources are included in the response.
    #             An identifier must begin with a letter and must contain only ASCII letters, digits, and hyphens. It can't end with a hyphen or contain two consecutive hyphens.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If <code>SourceIds</code> are supplied, <code>SourceType</code> must also be provided.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is a DB instance, a <code>DBInstanceIdentifier</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is a DB cluster, a <code>DBClusterIdentifier</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is a DB parameter group, a <code>DBParameterGroupName</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is a DB security group, a <code>DBSecurityGroupName</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is a DB snapshot, a <code>DBSnapshotIdentifier</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is a DB cluster snapshot, a <code>DBClusterSnapshotIdentifier</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is an RDS Proxy, a <code>DBProxyName</code> value must be supplied.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Boolean] :enabled
    #   <p>A value that indicates whether to activate the subscription. If the event notification subscription isn't activated, the subscription is created but not active.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>A list of tags.
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.html">Tagging Amazon RDS Resources</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @return [Types::CreateEventSubscriptionOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.create_event_subscription(
    #     subscription_name: 'SubscriptionName', # required
    #     sns_topic_arn: 'SnsTopicArn', # required
    #     source_type: 'SourceType',
    #     event_categories: [
    #       'member'
    #     ],
    #     source_ids: [
    #       'member'
    #     ],
    #     enabled: false,
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CreateEventSubscriptionOutput
    #   resp.data.event_subscription #=> Types::EventSubscription
    #   resp.data.event_subscription.customer_aws_id #=> String
    #   resp.data.event_subscription.cust_subscription_id #=> String
    #   resp.data.event_subscription.sns_topic_arn #=> String
    #   resp.data.event_subscription.status #=> String
    #   resp.data.event_subscription.subscription_creation_time #=> String
    #   resp.data.event_subscription.source_type #=> String
    #   resp.data.event_subscription.source_ids_list #=> Array<String>
    #   resp.data.event_subscription.source_ids_list[0] #=> String
    #   resp.data.event_subscription.event_categories_list #=> Array<String>
    #   resp.data.event_subscription.event_categories_list[0] #=> String
    #   resp.data.event_subscription.enabled #=> Boolean
    #   resp.data.event_subscription.event_subscription_arn #=> String
    #
    def create_event_subscription(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CreateEventSubscriptionInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CreateEventSubscriptionInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CreateEventSubscription
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::SNSInvalidTopicFault, Errors::SubscriptionCategoryNotFoundFault, Errors::SourceNotFoundFault, Errors::SNSNoAuthorizationFault, Errors::SNSTopicArnNotFoundFault, Errors::SubscriptionAlreadyExistFault, Errors::EventSubscriptionQuotaExceededFault]),
        data_parser: Parsers::CreateEventSubscription
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CreateEventSubscription,
        stubs: @stubs,
        params_class: Params::CreateEventSubscriptionOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :create_event_subscription
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates an Aurora global database
    #         spread across multiple Amazon Web Services Regions. The global database
    #         contains a single primary cluster with read-write capability,
    #         and a read-only secondary cluster that receives
    #         data from the primary cluster through high-speed replication
    #         performed by the Aurora storage subsystem.</p>
    #         <p>You can create a global database that is initially empty, and then
    #         add a primary cluster and a secondary cluster to it.
    #         Or you can specify an existing Aurora cluster during the create operation,
    #         and this cluster becomes the primary cluster of the global database.</p>
    #         <note>
    #             <p>This action only applies to Aurora DB clusters.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::CreateGlobalClusterInput}.
    #
    # @option params [String] :global_cluster_identifier
    #   <p>The cluster identifier of the new global database cluster.</p>
    #
    # @option params [String] :source_db_cluster_identifier
    #   <p>The Amazon Resource Name (ARN) to use as the primary cluster of the global database.
    #           This parameter is optional.</p>
    #
    # @option params [String] :engine
    #   <p>The name of the database engine to be used for this DB cluster.</p>
    #
    # @option params [String] :engine_version
    #   <p>The engine version of the Aurora global database.</p>
    #
    # @option params [Boolean] :deletion_protection
    #   <p>The deletion protection setting for the new global database.
    #           The global database can't be deleted when deletion protection is enabled.</p>
    #
    # @option params [String] :database_name
    #   <p>The name for your database of up to 64 alpha-numeric characters. If you do not provide a name, Amazon
    #           Aurora will not create a database in the global database cluster you are creating.</p>
    #
    # @option params [Boolean] :storage_encrypted
    #   <p>The storage encryption setting for the new global database cluster.</p>
    #
    # @return [Types::CreateGlobalClusterOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.create_global_cluster(
    #     global_cluster_identifier: 'GlobalClusterIdentifier',
    #     source_db_cluster_identifier: 'SourceDBClusterIdentifier',
    #     engine: 'Engine',
    #     engine_version: 'EngineVersion',
    #     deletion_protection: false,
    #     database_name: 'DatabaseName',
    #     storage_encrypted: false
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CreateGlobalClusterOutput
    #   resp.data.global_cluster #=> Types::GlobalCluster
    #   resp.data.global_cluster.global_cluster_identifier #=> String
    #   resp.data.global_cluster.global_cluster_resource_id #=> String
    #   resp.data.global_cluster.global_cluster_arn #=> String
    #   resp.data.global_cluster.status #=> String
    #   resp.data.global_cluster.engine #=> String
    #   resp.data.global_cluster.engine_version #=> String
    #   resp.data.global_cluster.database_name #=> String
    #   resp.data.global_cluster.storage_encrypted #=> Boolean
    #   resp.data.global_cluster.deletion_protection #=> Boolean
    #   resp.data.global_cluster.global_cluster_members #=> Array<GlobalClusterMember>
    #   resp.data.global_cluster.global_cluster_members[0] #=> Types::GlobalClusterMember
    #   resp.data.global_cluster.global_cluster_members[0].db_cluster_arn #=> String
    #   resp.data.global_cluster.global_cluster_members[0].readers #=> Array<String>
    #   resp.data.global_cluster.global_cluster_members[0].readers[0] #=> String
    #   resp.data.global_cluster.global_cluster_members[0].is_writer #=> Boolean
    #   resp.data.global_cluster.global_cluster_members[0].global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.global_cluster.failover_state #=> Types::FailoverState
    #   resp.data.global_cluster.failover_state.status #=> String, one of ["pending", "failing-over", "cancelling"]
    #   resp.data.global_cluster.failover_state.from_db_cluster_arn #=> String
    #   resp.data.global_cluster.failover_state.to_db_cluster_arn #=> String
    #
    def create_global_cluster(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CreateGlobalClusterInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CreateGlobalClusterInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CreateGlobalCluster
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::GlobalClusterQuotaExceededFault, Errors::InvalidDBClusterStateFault, Errors::GlobalClusterAlreadyExistsFault]),
        data_parser: Parsers::CreateGlobalCluster
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CreateGlobalCluster,
        stubs: @stubs,
        params_class: Params::CreateGlobalClusterOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :create_global_cluster
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates a new option group. You can create up to 20 option groups.</p>
    #         <p>This command doesn't apply to RDS Custom.</p>
    #
    # @param [Hash] params
    #   See {Types::CreateOptionGroupInput}.
    #
    # @option params [String] :option_group_name
    #   <p>Specifies the name of the option group to be created.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be 1 to 255 letters, numbers, or hyphens</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>myoptiongroup</code>
    #            </p>
    #
    # @option params [String] :engine_name
    #   <p>Specifies the name of the engine that this option group should be associated with.</p>
    #           <p>Valid Values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>mariadb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mysql</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>postgres</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-se</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ex</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-web</code>
    #                  </p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :major_engine_version
    #   <p>Specifies the major version of the engine that this option group should be associated with.</p>
    #
    # @option params [String] :option_group_description
    #   <p>The description of the option group.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>Tags to assign to the option group.</p>
    #
    # @return [Types::CreateOptionGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.create_option_group(
    #     option_group_name: 'OptionGroupName', # required
    #     engine_name: 'EngineName', # required
    #     major_engine_version: 'MajorEngineVersion', # required
    #     option_group_description: 'OptionGroupDescription', # required
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::CreateOptionGroupOutput
    #   resp.data.option_group #=> Types::OptionGroup
    #   resp.data.option_group.option_group_name #=> String
    #   resp.data.option_group.option_group_description #=> String
    #   resp.data.option_group.engine_name #=> String
    #   resp.data.option_group.major_engine_version #=> String
    #   resp.data.option_group.options #=> Array<Option>
    #   resp.data.option_group.options[0] #=> Types::Option
    #   resp.data.option_group.options[0].option_name #=> String
    #   resp.data.option_group.options[0].option_description #=> String
    #   resp.data.option_group.options[0].persistent #=> Boolean
    #   resp.data.option_group.options[0].permanent #=> Boolean
    #   resp.data.option_group.options[0].port #=> Integer
    #   resp.data.option_group.options[0].option_version #=> String
    #   resp.data.option_group.options[0].option_settings #=> Array<OptionSetting>
    #   resp.data.option_group.options[0].option_settings[0] #=> Types::OptionSetting
    #   resp.data.option_group.options[0].option_settings[0].name #=> String
    #   resp.data.option_group.options[0].option_settings[0].value #=> String
    #   resp.data.option_group.options[0].option_settings[0].default_value #=> String
    #   resp.data.option_group.options[0].option_settings[0].description #=> String
    #   resp.data.option_group.options[0].option_settings[0].apply_type #=> String
    #   resp.data.option_group.options[0].option_settings[0].data_type #=> String
    #   resp.data.option_group.options[0].option_settings[0].allowed_values #=> String
    #   resp.data.option_group.options[0].option_settings[0].is_modifiable #=> Boolean
    #   resp.data.option_group.options[0].option_settings[0].is_collection #=> Boolean
    #   resp.data.option_group.options[0].db_security_group_memberships #=> Array<DBSecurityGroupMembership>
    #   resp.data.option_group.options[0].db_security_group_memberships[0] #=> Types::DBSecurityGroupMembership
    #   resp.data.option_group.options[0].db_security_group_memberships[0].db_security_group_name #=> String
    #   resp.data.option_group.options[0].db_security_group_memberships[0].status #=> String
    #   resp.data.option_group.options[0].vpc_security_group_memberships #=> Array<VpcSecurityGroupMembership>
    #   resp.data.option_group.options[0].vpc_security_group_memberships[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.option_group.options[0].vpc_security_group_memberships[0].vpc_security_group_id #=> String
    #   resp.data.option_group.options[0].vpc_security_group_memberships[0].status #=> String
    #   resp.data.option_group.allows_vpc_and_non_vpc_instance_memberships #=> Boolean
    #   resp.data.option_group.vpc_id #=> String
    #   resp.data.option_group.option_group_arn #=> String
    #
    def create_option_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::CreateOptionGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::CreateOptionGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::CreateOptionGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::OptionGroupAlreadyExistsFault, Errors::OptionGroupQuotaExceededFault]),
        data_parser: Parsers::CreateOptionGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::CreateOptionGroup,
        stubs: @stubs,
        params_class: Params::CreateOptionGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :create_option_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Deletes a custom engine version. To run this command, make sure you meet the following prerequisites:</p>
    #         <ul>
    #             <li>
    #                 <p>The CEV must not be the default for RDS Custom. If it is, change the default
    #                 before running this command.</p>
    #             </li>
    #             <li>
    #                 <p>The CEV must not be associated with an RDS Custom DB instance, RDS Custom instance snapshot,
    #                 or automated backup of your RDS Custom instance.</p>
    #             </li>
    #          </ul>
    #         <p>Typically, deletion takes a few minutes.</p>
    #         <note>
    #             <p>The MediaImport service that imports files from Amazon S3 to create CEVs isn't integrated with
    #             Amazon Web Services CloudTrail. If you turn on data logging for Amazon RDS in CloudTrail, calls to the
    #             <code>DeleteCustomDbEngineVersion</code> event aren't logged. However, you might see calls from the
    #             API gateway that accesses your Amazon S3 bucket. These calls originate from the MediaImport service for
    #             the <code>DeleteCustomDbEngineVersion</code> event.</p>
    #         </note>
    #         <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/custom-cev.html#custom-cev.delete">
    #             Deleting a CEV</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::DeleteCustomDBEngineVersionInput}.
    #
    # @option params [String] :engine
    #   <p>The database engine. The only supported engine is <code>custom-oracle-ee</code>.</p>
    #
    # @option params [String] :engine_version
    #   <p>The custom engine version (CEV) for your DB instance. This option is required for
    #               RDS Custom, but optional for Amazon RDS. The combination of <code>Engine</code> and
    #               <code>EngineVersion</code> is unique per customer per Amazon Web Services Region.</p>
    #
    # @return [Types::DeleteCustomDBEngineVersionOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.delete_custom_db_engine_version(
    #     engine: 'Engine', # required
    #     engine_version: 'EngineVersion' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DeleteCustomDBEngineVersionOutput
    #   resp.data.engine #=> String
    #   resp.data.engine_version #=> String
    #   resp.data.db_parameter_group_family #=> String
    #   resp.data.db_engine_description #=> String
    #   resp.data.db_engine_version_description #=> String
    #   resp.data.default_character_set #=> Types::CharacterSet
    #   resp.data.default_character_set.character_set_name #=> String
    #   resp.data.default_character_set.character_set_description #=> String
    #   resp.data.supported_character_sets #=> Array<CharacterSet>
    #   resp.data.supported_nchar_character_sets #=> Array<CharacterSet>
    #   resp.data.valid_upgrade_target #=> Array<UpgradeTarget>
    #   resp.data.valid_upgrade_target[0] #=> Types::UpgradeTarget
    #   resp.data.valid_upgrade_target[0].engine #=> String
    #   resp.data.valid_upgrade_target[0].engine_version #=> String
    #   resp.data.valid_upgrade_target[0].description #=> String
    #   resp.data.valid_upgrade_target[0].auto_upgrade #=> Boolean
    #   resp.data.valid_upgrade_target[0].is_major_version_upgrade #=> Boolean
    #   resp.data.valid_upgrade_target[0].supported_engine_modes #=> Array<String>
    #   resp.data.valid_upgrade_target[0].supported_engine_modes[0] #=> String
    #   resp.data.valid_upgrade_target[0].supports_parallel_query #=> Boolean
    #   resp.data.valid_upgrade_target[0].supports_global_databases #=> Boolean
    #   resp.data.valid_upgrade_target[0].supports_babelfish #=> Boolean
    #   resp.data.supported_timezones #=> Array<Timezone>
    #   resp.data.supported_timezones[0] #=> Types::Timezone
    #   resp.data.supported_timezones[0].timezone_name #=> String
    #   resp.data.exportable_log_types #=> Array<String>
    #   resp.data.exportable_log_types[0] #=> String
    #   resp.data.supports_log_exports_to_cloudwatch_logs #=> Boolean
    #   resp.data.supports_read_replica #=> Boolean
    #   resp.data.supported_engine_modes #=> Array<String>
    #   resp.data.supported_feature_names #=> Array<String>
    #   resp.data.supported_feature_names[0] #=> String
    #   resp.data.status #=> String
    #   resp.data.supports_parallel_query #=> Boolean
    #   resp.data.supports_global_databases #=> Boolean
    #   resp.data.major_engine_version #=> String
    #   resp.data.database_installation_files_s3_bucket_name #=> String
    #   resp.data.database_installation_files_s3_prefix #=> String
    #   resp.data.db_engine_version_arn #=> String
    #   resp.data.kms_key_id #=> String
    #   resp.data.create_time #=> Time
    #   resp.data.tag_list #=> Array<Tag>
    #   resp.data.tag_list[0] #=> Types::Tag
    #   resp.data.tag_list[0].key #=> String
    #   resp.data.tag_list[0].value #=> String
    #   resp.data.supports_babelfish #=> Boolean
    #
    def delete_custom_db_engine_version(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DeleteCustomDBEngineVersionInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DeleteCustomDBEngineVersionInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DeleteCustomDBEngineVersion
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidCustomDBEngineVersionStateFault, Errors::CustomDBEngineVersionNotFoundFault]),
        data_parser: Parsers::DeleteCustomDBEngineVersion
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DeleteCustomDBEngineVersion,
        stubs: @stubs,
        params_class: Params::DeleteCustomDBEngineVersionOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :delete_custom_db_engine_version
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>The DeleteDBCluster action deletes a previously provisioned DB cluster.
    #           When you delete a DB cluster, all automated backups for that DB cluster are deleted and can't be recovered.
    #           Manual DB cluster snapshots of the specified DB cluster are not deleted.</p>
    #         <p>For more information on Amazon Aurora, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #               What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #               Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::DeleteDBClusterInput}.
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The DB cluster identifier for the DB cluster to be deleted. This parameter isn't case-sensitive.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match an existing DBClusterIdentifier.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Boolean] :skip_final_snapshot
    #   <p>A value that indicates whether to skip the creation of a final DB cluster snapshot before the DB cluster is deleted.
    #             If skip is specified, no DB cluster snapshot is created. If skip isn't specified, a DB cluster snapshot
    #             is created before the DB cluster is deleted. By default, skip isn't specified, and the DB cluster snapshot is created.
    #             By default, this parameter is disabled.</p>
    #           <note>
    #               <p>You must specify a <code>FinalDBSnapshotIdentifier</code> parameter if <code>SkipFinalSnapshot</code> is disabled.</p>
    #           </note>
    #
    # @option params [String] :final_db_snapshot_identifier
    #   <p>The DB cluster snapshot identifier of the new DB cluster snapshot created when <code>SkipFinalSnapshot</code>
    #         is disabled.</p>
    #           <note>
    #               <p>Specifying this parameter and also skipping the creation of a final DB cluster snapshot
    #             with the <code>SkipFinalShapshot</code> parameter results in an error.</p>
    #           </note>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be 1 to 255 letters, numbers, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #            </ul>
    #
    # @return [Types::DeleteDBClusterOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.delete_db_cluster(
    #     db_cluster_identifier: 'DBClusterIdentifier', # required
    #     skip_final_snapshot: false,
    #     final_db_snapshot_identifier: 'FinalDBSnapshotIdentifier'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DeleteDBClusterOutput
    #   resp.data.db_cluster #=> Types::DBCluster
    #   resp.data.db_cluster.allocated_storage #=> Integer
    #   resp.data.db_cluster.availability_zones #=> Array<String>
    #   resp.data.db_cluster.availability_zones[0] #=> String
    #   resp.data.db_cluster.backup_retention_period #=> Integer
    #   resp.data.db_cluster.character_set_name #=> String
    #   resp.data.db_cluster.database_name #=> String
    #   resp.data.db_cluster.db_cluster_identifier #=> String
    #   resp.data.db_cluster.db_cluster_parameter_group #=> String
    #   resp.data.db_cluster.db_subnet_group #=> String
    #   resp.data.db_cluster.status #=> String
    #   resp.data.db_cluster.automatic_restart_time #=> Time
    #   resp.data.db_cluster.percent_progress #=> String
    #   resp.data.db_cluster.earliest_restorable_time #=> Time
    #   resp.data.db_cluster.endpoint #=> String
    #   resp.data.db_cluster.reader_endpoint #=> String
    #   resp.data.db_cluster.custom_endpoints #=> Array<String>
    #   resp.data.db_cluster.custom_endpoints[0] #=> String
    #   resp.data.db_cluster.multi_az #=> Boolean
    #   resp.data.db_cluster.engine #=> String
    #   resp.data.db_cluster.engine_version #=> String
    #   resp.data.db_cluster.latest_restorable_time #=> Time
    #   resp.data.db_cluster.port #=> Integer
    #   resp.data.db_cluster.master_username #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships #=> Array<DBClusterOptionGroupStatus>
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0] #=> Types::DBClusterOptionGroupStatus
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].db_cluster_option_group_name #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].status #=> String
    #   resp.data.db_cluster.preferred_backup_window #=> String
    #   resp.data.db_cluster.preferred_maintenance_window #=> String
    #   resp.data.db_cluster.replication_source_identifier #=> String
    #   resp.data.db_cluster.read_replica_identifiers #=> Array<String>
    #   resp.data.db_cluster.read_replica_identifiers[0] #=> String
    #   resp.data.db_cluster.db_cluster_members #=> Array<DBClusterMember>
    #   resp.data.db_cluster.db_cluster_members[0] #=> Types::DBClusterMember
    #   resp.data.db_cluster.db_cluster_members[0].db_instance_identifier #=> String
    #   resp.data.db_cluster.db_cluster_members[0].is_cluster_writer #=> Boolean
    #   resp.data.db_cluster.db_cluster_members[0].db_cluster_parameter_group_status #=> String
    #   resp.data.db_cluster.db_cluster_members[0].promotion_tier #=> Integer
    #   resp.data.db_cluster.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_cluster.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_cluster.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_cluster.vpc_security_groups[0].status #=> String
    #   resp.data.db_cluster.hosted_zone_id #=> String
    #   resp.data.db_cluster.storage_encrypted #=> Boolean
    #   resp.data.db_cluster.kms_key_id #=> String
    #   resp.data.db_cluster.db_cluster_resource_id #=> String
    #   resp.data.db_cluster.db_cluster_arn #=> String
    #   resp.data.db_cluster.associated_roles #=> Array<DBClusterRole>
    #   resp.data.db_cluster.associated_roles[0] #=> Types::DBClusterRole
    #   resp.data.db_cluster.associated_roles[0].role_arn #=> String
    #   resp.data.db_cluster.associated_roles[0].status #=> String
    #   resp.data.db_cluster.associated_roles[0].feature_name #=> String
    #   resp.data.db_cluster.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.clone_group_id #=> String
    #   resp.data.db_cluster.cluster_create_time #=> Time
    #   resp.data.db_cluster.earliest_backtrack_time #=> Time
    #   resp.data.db_cluster.backtrack_window #=> Integer
    #   resp.data.db_cluster.backtrack_consumed_change_records #=> Integer
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports[0] #=> String
    #   resp.data.db_cluster.capacity #=> Integer
    #   resp.data.db_cluster.engine_mode #=> String
    #   resp.data.db_cluster.scaling_configuration_info #=> Types::ScalingConfigurationInfo
    #   resp.data.db_cluster.scaling_configuration_info.min_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.max_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.auto_pause #=> Boolean
    #   resp.data.db_cluster.scaling_configuration_info.seconds_until_auto_pause #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.timeout_action #=> String
    #   resp.data.db_cluster.scaling_configuration_info.seconds_before_timeout #=> Integer
    #   resp.data.db_cluster.deletion_protection #=> Boolean
    #   resp.data.db_cluster.http_endpoint_enabled #=> Boolean
    #   resp.data.db_cluster.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_cluster.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_cluster.activity_stream_kms_key_id #=> String
    #   resp.data.db_cluster.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_cluster.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_cluster.cross_account_clone #=> Boolean
    #   resp.data.db_cluster.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_cluster.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_cluster.domain_memberships[0].domain #=> String
    #   resp.data.db_cluster.domain_memberships[0].status #=> String
    #   resp.data.db_cluster.domain_memberships[0].fqdn #=> String
    #   resp.data.db_cluster.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_cluster.tag_list #=> Array<Tag>
    #   resp.data.db_cluster.tag_list[0] #=> Types::Tag
    #   resp.data.db_cluster.tag_list[0].key #=> String
    #   resp.data.db_cluster.tag_list[0].value #=> String
    #   resp.data.db_cluster.global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.db_cluster.global_write_forwarding_requested #=> Boolean
    #   resp.data.db_cluster.pending_modified_values #=> Types::ClusterPendingModifiedValues
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.db_cluster_identifier #=> String
    #   resp.data.db_cluster.pending_modified_values.master_user_password #=> String
    #   resp.data.db_cluster.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.pending_modified_values.engine_version #=> String
    #   resp.data.db_cluster.db_cluster_instance_class #=> String
    #   resp.data.db_cluster.storage_type #=> String
    #   resp.data.db_cluster.iops #=> Integer
    #   resp.data.db_cluster.publicly_accessible #=> Boolean
    #   resp.data.db_cluster.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_cluster.monitoring_interval #=> Integer
    #   resp.data.db_cluster.monitoring_role_arn #=> String
    #   resp.data.db_cluster.performance_insights_enabled #=> Boolean
    #   resp.data.db_cluster.performance_insights_kms_key_id #=> String
    #   resp.data.db_cluster.performance_insights_retention_period #=> Integer
    #   resp.data.db_cluster.serverless_v2_scaling_configuration #=> Types::ServerlessV2ScalingConfigurationInfo
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.min_capacity #=> Float
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.max_capacity #=> Float
    #
    def delete_db_cluster(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DeleteDBClusterInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DeleteDBClusterInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DeleteDBCluster
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidDBClusterSnapshotStateFault, Errors::DBClusterNotFoundFault, Errors::SnapshotQuotaExceededFault, Errors::DBClusterSnapshotAlreadyExistsFault, Errors::InvalidDBClusterStateFault]),
        data_parser: Parsers::DeleteDBCluster
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DeleteDBCluster,
        stubs: @stubs,
        params_class: Params::DeleteDBClusterOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :delete_db_cluster
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Deletes a custom endpoint and removes it from an Amazon Aurora DB cluster.</p>
    #         <note>
    #             <p>This action only applies to Aurora DB clusters.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::DeleteDBClusterEndpointInput}.
    #
    # @option params [String] :db_cluster_endpoint_identifier
    #   <p>The identifier associated with the custom endpoint. This parameter is stored as a lowercase string.</p>
    #
    # @return [Types::DeleteDBClusterEndpointOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.delete_db_cluster_endpoint(
    #     db_cluster_endpoint_identifier: 'DBClusterEndpointIdentifier' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DeleteDBClusterEndpointOutput
    #   resp.data.db_cluster_endpoint_identifier #=> String
    #   resp.data.db_cluster_identifier #=> String
    #   resp.data.db_cluster_endpoint_resource_identifier #=> String
    #   resp.data.endpoint #=> String
    #   resp.data.status #=> String
    #   resp.data.endpoint_type #=> String
    #   resp.data.custom_endpoint_type #=> String
    #   resp.data.static_members #=> Array<String>
    #   resp.data.static_members[0] #=> String
    #   resp.data.excluded_members #=> Array<String>
    #   resp.data.db_cluster_endpoint_arn #=> String
    #
    def delete_db_cluster_endpoint(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DeleteDBClusterEndpointInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DeleteDBClusterEndpointInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DeleteDBClusterEndpoint
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterEndpointNotFoundFault, Errors::InvalidDBClusterStateFault, Errors::InvalidDBClusterEndpointStateFault]),
        data_parser: Parsers::DeleteDBClusterEndpoint
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DeleteDBClusterEndpoint,
        stubs: @stubs,
        params_class: Params::DeleteDBClusterEndpointOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :delete_db_cluster_endpoint
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Deletes a specified DB cluster parameter group. The DB cluster parameter group to be deleted can't be associated with any DB clusters.</p>
    #         <p>For more information on Amazon Aurora, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #               What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #               Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::DeleteDBClusterParameterGroupInput}.
    #
    # @option params [String] :db_cluster_parameter_group_name
    #   <p>The name of the DB cluster parameter group.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be the name of an existing DB cluster parameter group.</p>
    #               </li>
    #               <li>
    #                   <p>You can't delete a default DB cluster parameter group.</p>
    #               </li>
    #               <li>
    #                   <p>Can't be associated with any DB clusters.</p>
    #               </li>
    #            </ul>
    #
    # @return [Types::DeleteDBClusterParameterGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.delete_db_cluster_parameter_group(
    #     db_cluster_parameter_group_name: 'DBClusterParameterGroupName' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DeleteDBClusterParameterGroupOutput
    #
    def delete_db_cluster_parameter_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DeleteDBClusterParameterGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DeleteDBClusterParameterGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DeleteDBClusterParameterGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidDBParameterGroupStateFault, Errors::DBParameterGroupNotFoundFault]),
        data_parser: Parsers::DeleteDBClusterParameterGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DeleteDBClusterParameterGroup,
        stubs: @stubs,
        params_class: Params::DeleteDBClusterParameterGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :delete_db_cluster_parameter_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Deletes a DB cluster snapshot. If the snapshot is being copied, the copy operation is terminated.</p>
    #         <note>
    #             <p>The DB cluster snapshot must be in the <code>available</code> state to be
    #             deleted.</p>
    #         </note>
    #         <p>For more information on Amazon Aurora, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #               What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #               Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::DeleteDBClusterSnapshotInput}.
    #
    # @option params [String] :db_cluster_snapshot_identifier
    #   <p>The identifier of the DB cluster snapshot to delete.</p>
    #           <p>Constraints: Must be the name of an existing DB cluster snapshot in the <code>available</code> state.</p>
    #
    # @return [Types::DeleteDBClusterSnapshotOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.delete_db_cluster_snapshot(
    #     db_cluster_snapshot_identifier: 'DBClusterSnapshotIdentifier' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DeleteDBClusterSnapshotOutput
    #   resp.data.db_cluster_snapshot #=> Types::DBClusterSnapshot
    #   resp.data.db_cluster_snapshot.availability_zones #=> Array<String>
    #   resp.data.db_cluster_snapshot.availability_zones[0] #=> String
    #   resp.data.db_cluster_snapshot.db_cluster_snapshot_identifier #=> String
    #   resp.data.db_cluster_snapshot.db_cluster_identifier #=> String
    #   resp.data.db_cluster_snapshot.snapshot_create_time #=> Time
    #   resp.data.db_cluster_snapshot.engine #=> String
    #   resp.data.db_cluster_snapshot.engine_mode #=> String
    #   resp.data.db_cluster_snapshot.allocated_storage #=> Integer
    #   resp.data.db_cluster_snapshot.status #=> String
    #   resp.data.db_cluster_snapshot.port #=> Integer
    #   resp.data.db_cluster_snapshot.vpc_id #=> String
    #   resp.data.db_cluster_snapshot.cluster_create_time #=> Time
    #   resp.data.db_cluster_snapshot.master_username #=> String
    #   resp.data.db_cluster_snapshot.engine_version #=> String
    #   resp.data.db_cluster_snapshot.license_model #=> String
    #   resp.data.db_cluster_snapshot.snapshot_type #=> String
    #   resp.data.db_cluster_snapshot.percent_progress #=> Integer
    #   resp.data.db_cluster_snapshot.storage_encrypted #=> Boolean
    #   resp.data.db_cluster_snapshot.kms_key_id #=> String
    #   resp.data.db_cluster_snapshot.db_cluster_snapshot_arn #=> String
    #   resp.data.db_cluster_snapshot.source_db_cluster_snapshot_arn #=> String
    #   resp.data.db_cluster_snapshot.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster_snapshot.tag_list #=> Array<Tag>
    #   resp.data.db_cluster_snapshot.tag_list[0] #=> Types::Tag
    #   resp.data.db_cluster_snapshot.tag_list[0].key #=> String
    #   resp.data.db_cluster_snapshot.tag_list[0].value #=> String
    #
    def delete_db_cluster_snapshot(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DeleteDBClusterSnapshotInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DeleteDBClusterSnapshotInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DeleteDBClusterSnapshot
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidDBClusterSnapshotStateFault, Errors::DBClusterSnapshotNotFoundFault]),
        data_parser: Parsers::DeleteDBClusterSnapshot
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DeleteDBClusterSnapshot,
        stubs: @stubs,
        params_class: Params::DeleteDBClusterSnapshotOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :delete_db_cluster_snapshot
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>The DeleteDBInstance action deletes a previously provisioned DB instance.
    #           When you delete a DB instance, all automated backups for that instance are deleted and can't be recovered.
    #           Manual DB snapshots of the DB instance to be deleted by <code>DeleteDBInstance</code> are not deleted.</p>
    #         <p>If you request a final DB snapshot
    #         the status of the Amazon RDS DB instance is <code>deleting</code> until the DB snapshot is created. The API action <code>DescribeDBInstance</code>
    #         is used to monitor the status of this operation. The action can't be canceled or reverted once submitted.</p>
    #         <p>When a DB instance is in a failure state and has a status of <code>failed</code>, <code>incompatible-restore</code>,
    #           or <code>incompatible-network</code>, you can only delete it when you skip creation of the final snapshot with the <code>SkipFinalSnapshot</code> parameter.</p>
    #         <p>If the specified DB instance is part of an Amazon Aurora DB cluster, you can't delete the DB instance if both of the following
    #       conditions are true:</p>
    #         <ul>
    #             <li>
    #                 <p>The DB cluster is a read replica of another Amazon Aurora DB cluster.</p>
    #             </li>
    #             <li>
    #                 <p>The DB instance is the only instance in the DB cluster.</p>
    #             </li>
    #          </ul>
    #         <p>To delete a DB instance in this case, first call the
    #                 <code>PromoteReadReplicaDBCluster</code> API action to promote the DB cluster so
    #             it's no longer a read replica. After the promotion completes, then call the
    #                 <code>DeleteDBInstance</code> API action to delete the final instance in the DB
    #             cluster.</p>
    #
    # @param [Hash] params
    #   See {Types::DeleteDBInstanceInput}.
    #
    # @option params [String] :db_instance_identifier
    #   <p>The DB instance identifier for the DB instance to be deleted. This parameter isn't case-sensitive.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the name of an existing DB instance.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Boolean] :skip_final_snapshot
    #   <p>A value that indicates whether to skip the creation of a final DB snapshot before deleting the instance.
    #             If you enable this parameter, RDS doesn't create a DB snapshot. If you don't enable this parameter,
    #             RDS creates a DB snapshot before the DB instance is deleted. By default, skip isn't enabled,
    #             and the DB snapshot is created.</p>
    #           <note>
    #               <p>If you don't enable this parameter, you must specify the <code>FinalDBSnapshotIdentifier</code> parameter.</p>
    #           </note>
    #           <p>When a DB instance is in a failure state and has a status of <code>failed</code>, <code>incompatible-restore</code>,
    #             or <code>incompatible-network</code>, RDS can delete the instance only if you enable this parameter.</p>
    #           <p>If you delete a read replica or an RDS Custom instance, you must enable this setting.</p>
    #           <p>This setting is required for RDS Custom.</p>
    #
    # @option params [String] :final_db_snapshot_identifier
    #   <p>The <code>DBSnapshotIdentifier</code> of the new <code>DBSnapshot</code> created when the <code>SkipFinalSnapshot</code>
    #           parameter is disabled.</p>
    #           <note>
    #               <p>If you enable this parameter and also enable SkipFinalShapshot, the command results in an error.</p>
    #           </note>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be 1 to 255 letters or numbers.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>Can't be specified when deleting a read replica.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Boolean] :delete_automated_backups
    #   <p>A value that indicates whether to remove automated backups immediately after the DB
    #               instance is deleted. This parameter isn't case-sensitive. The default is to remove
    #               automated backups immediately after the DB instance is deleted.</p>
    #
    # @return [Types::DeleteDBInstanceOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.delete_db_instance(
    #     db_instance_identifier: 'DBInstanceIdentifier', # required
    #     skip_final_snapshot: false,
    #     final_db_snapshot_identifier: 'FinalDBSnapshotIdentifier',
    #     delete_automated_backups: false
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DeleteDBInstanceOutput
    #   resp.data.db_instance #=> Types::DBInstance
    #   resp.data.db_instance.db_instance_identifier #=> String
    #   resp.data.db_instance.db_instance_class #=> String
    #   resp.data.db_instance.engine #=> String
    #   resp.data.db_instance.db_instance_status #=> String
    #   resp.data.db_instance.automatic_restart_time #=> Time
    #   resp.data.db_instance.master_username #=> String
    #   resp.data.db_instance.db_name #=> String
    #   resp.data.db_instance.endpoint #=> Types::Endpoint
    #   resp.data.db_instance.endpoint.address #=> String
    #   resp.data.db_instance.endpoint.port #=> Integer
    #   resp.data.db_instance.endpoint.hosted_zone_id #=> String
    #   resp.data.db_instance.allocated_storage #=> Integer
    #   resp.data.db_instance.instance_create_time #=> Time
    #   resp.data.db_instance.preferred_backup_window #=> String
    #   resp.data.db_instance.backup_retention_period #=> Integer
    #   resp.data.db_instance.db_security_groups #=> Array<DBSecurityGroupMembership>
    #   resp.data.db_instance.db_security_groups[0] #=> Types::DBSecurityGroupMembership
    #   resp.data.db_instance.db_security_groups[0].db_security_group_name #=> String
    #   resp.data.db_instance.db_security_groups[0].status #=> String
    #   resp.data.db_instance.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_instance.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_instance.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_instance.vpc_security_groups[0].status #=> String
    #   resp.data.db_instance.db_parameter_groups #=> Array<DBParameterGroupStatus>
    #   resp.data.db_instance.db_parameter_groups[0] #=> Types::DBParameterGroupStatus
    #   resp.data.db_instance.db_parameter_groups[0].db_parameter_group_name #=> String
    #   resp.data.db_instance.db_parameter_groups[0].parameter_apply_status #=> String
    #   resp.data.db_instance.availability_zone #=> String
    #   resp.data.db_instance.db_subnet_group #=> Types::DBSubnetGroup
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_name #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_description #=> String
    #   resp.data.db_instance.db_subnet_group.vpc_id #=> String
    #   resp.data.db_instance.db_subnet_group.subnet_group_status #=> String
    #   resp.data.db_instance.db_subnet_group.subnets #=> Array<Subnet>
    #   resp.data.db_instance.db_subnet_group.subnets[0] #=> Types::Subnet
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_identifier #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone #=> Types::AvailabilityZone
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone.name #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost #=> Types::Outpost
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost.arn #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_status #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_arn #=> String
    #   resp.data.db_instance.db_subnet_group.supported_network_types #=> Array<String>
    #   resp.data.db_instance.db_subnet_group.supported_network_types[0] #=> String
    #   resp.data.db_instance.preferred_maintenance_window #=> String
    #   resp.data.db_instance.pending_modified_values #=> Types::PendingModifiedValues
    #   resp.data.db_instance.pending_modified_values.db_instance_class #=> String
    #   resp.data.db_instance.pending_modified_values.allocated_storage #=> Integer
    #   resp.data.db_instance.pending_modified_values.master_user_password #=> String
    #   resp.data.db_instance.pending_modified_values.port #=> Integer
    #   resp.data.db_instance.pending_modified_values.backup_retention_period #=> Integer
    #   resp.data.db_instance.pending_modified_values.multi_az #=> Boolean
    #   resp.data.db_instance.pending_modified_values.engine_version #=> String
    #   resp.data.db_instance.pending_modified_values.license_model #=> String
    #   resp.data.db_instance.pending_modified_values.iops #=> Integer
    #   resp.data.db_instance.pending_modified_values.db_instance_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.storage_type #=> String
    #   resp.data.db_instance.pending_modified_values.ca_certificate_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.db_subnet_group_name #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable[0] #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.pending_modified_values.processor_features[0] #=> Types::ProcessorFeature
    #   resp.data.db_instance.pending_modified_values.processor_features[0].name #=> String
    #   resp.data.db_instance.pending_modified_values.processor_features[0].value #=> String
    #   resp.data.db_instance.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.pending_modified_values.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.pending_modified_values.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.latest_restorable_time #=> Time
    #   resp.data.db_instance.multi_az #=> Boolean
    #   resp.data.db_instance.engine_version #=> String
    #   resp.data.db_instance.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_instance.read_replica_source_db_instance_identifier #=> String
    #   resp.data.db_instance.read_replica_db_instance_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_instance_identifiers[0] #=> String
    #   resp.data.db_instance.read_replica_db_cluster_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_cluster_identifiers[0] #=> String
    #   resp.data.db_instance.replica_mode #=> String, one of ["open-read-only", "mounted"]
    #   resp.data.db_instance.license_model #=> String
    #   resp.data.db_instance.iops #=> Integer
    #   resp.data.db_instance.option_group_memberships #=> Array<OptionGroupMembership>
    #   resp.data.db_instance.option_group_memberships[0] #=> Types::OptionGroupMembership
    #   resp.data.db_instance.option_group_memberships[0].option_group_name #=> String
    #   resp.data.db_instance.option_group_memberships[0].status #=> String
    #   resp.data.db_instance.character_set_name #=> String
    #   resp.data.db_instance.nchar_character_set_name #=> String
    #   resp.data.db_instance.secondary_availability_zone #=> String
    #   resp.data.db_instance.publicly_accessible #=> Boolean
    #   resp.data.db_instance.status_infos #=> Array<DBInstanceStatusInfo>
    #   resp.data.db_instance.status_infos[0] #=> Types::DBInstanceStatusInfo
    #   resp.data.db_instance.status_infos[0].status_type #=> String
    #   resp.data.db_instance.status_infos[0].normal #=> Boolean
    #   resp.data.db_instance.status_infos[0].status #=> String
    #   resp.data.db_instance.status_infos[0].message #=> String
    #   resp.data.db_instance.storage_type #=> String
    #   resp.data.db_instance.tde_credential_arn #=> String
    #   resp.data.db_instance.db_instance_port #=> Integer
    #   resp.data.db_instance.db_cluster_identifier #=> String
    #   resp.data.db_instance.storage_encrypted #=> Boolean
    #   resp.data.db_instance.kms_key_id #=> String
    #   resp.data.db_instance.dbi_resource_id #=> String
    #   resp.data.db_instance.ca_certificate_identifier #=> String
    #   resp.data.db_instance.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_instance.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_instance.domain_memberships[0].domain #=> String
    #   resp.data.db_instance.domain_memberships[0].status #=> String
    #   resp.data.db_instance.domain_memberships[0].fqdn #=> String
    #   resp.data.db_instance.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_instance.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_instance.monitoring_interval #=> Integer
    #   resp.data.db_instance.enhanced_monitoring_resource_arn #=> String
    #   resp.data.db_instance.monitoring_role_arn #=> String
    #   resp.data.db_instance.promotion_tier #=> Integer
    #   resp.data.db_instance.db_instance_arn #=> String
    #   resp.data.db_instance.timezone #=> String
    #   resp.data.db_instance.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_kms_key_id #=> String
    #   resp.data.db_instance.performance_insights_retention_period #=> Integer
    #   resp.data.db_instance.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_instance.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.deletion_protection #=> Boolean
    #   resp.data.db_instance.associated_roles #=> Array<DBInstanceRole>
    #   resp.data.db_instance.associated_roles[0] #=> Types::DBInstanceRole
    #   resp.data.db_instance.associated_roles[0].role_arn #=> String
    #   resp.data.db_instance.associated_roles[0].feature_name #=> String
    #   resp.data.db_instance.associated_roles[0].status #=> String
    #   resp.data.db_instance.listener_endpoint #=> Types::Endpoint
    #   resp.data.db_instance.max_allocated_storage #=> Integer
    #   resp.data.db_instance.tag_list #=> Array<Tag>
    #   resp.data.db_instance.tag_list[0] #=> Types::Tag
    #   resp.data.db_instance.tag_list[0].key #=> String
    #   resp.data.db_instance.tag_list[0].value #=> String
    #   resp.data.db_instance.db_instance_automated_backups_replications #=> Array<DBInstanceAutomatedBackupsReplication>
    #   resp.data.db_instance.db_instance_automated_backups_replications[0] #=> Types::DBInstanceAutomatedBackupsReplication
    #   resp.data.db_instance.db_instance_automated_backups_replications[0].db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance.customer_owned_ip_enabled #=> Boolean
    #   resp.data.db_instance.aws_backup_recovery_point_arn #=> String
    #   resp.data.db_instance.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_instance.activity_stream_kms_key_id #=> String
    #   resp.data.db_instance.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_instance.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_instance.activity_stream_engine_native_audit_fields_included #=> Boolean
    #   resp.data.db_instance.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.custom_iam_instance_profile #=> String
    #   resp.data.db_instance.backup_target #=> String
    #   resp.data.db_instance.network_type #=> String
    #
    def delete_db_instance(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DeleteDBInstanceInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DeleteDBInstanceInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DeleteDBInstance
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBInstanceNotFoundFault, Errors::SnapshotQuotaExceededFault, Errors::DBInstanceAutomatedBackupQuotaExceededFault, Errors::InvalidDBClusterStateFault, Errors::DBSnapshotAlreadyExistsFault, Errors::InvalidDBInstanceStateFault]),
        data_parser: Parsers::DeleteDBInstance
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DeleteDBInstance,
        stubs: @stubs,
        params_class: Params::DeleteDBInstanceOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :delete_db_instance
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Deletes automated backups using the <code>DbiResourceId</code> value of the source DB instance or the Amazon Resource Name (ARN) of the automated backups.</p>
    #
    # @param [Hash] params
    #   See {Types::DeleteDBInstanceAutomatedBackupInput}.
    #
    # @option params [String] :dbi_resource_id
    #   <p>The identifier for the source DB instance, which can't be changed and which is unique to an Amazon Web Services Region.</p>
    #
    # @option params [String] :db_instance_automated_backups_arn
    #   <p>The Amazon Resource Name (ARN) of the automated backups to delete, for example,
    #               <code>arn:aws:rds:us-east-1:123456789012:auto-backup:ab-L2IJCEXJP7XQ7HOJ4SIEXAMPLE</code>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @return [Types::DeleteDBInstanceAutomatedBackupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.delete_db_instance_automated_backup(
    #     dbi_resource_id: 'DbiResourceId',
    #     db_instance_automated_backups_arn: 'DBInstanceAutomatedBackupsArn'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DeleteDBInstanceAutomatedBackupOutput
    #   resp.data.db_instance_automated_backup #=> Types::DBInstanceAutomatedBackup
    #   resp.data.db_instance_automated_backup.db_instance_arn #=> String
    #   resp.data.db_instance_automated_backup.dbi_resource_id #=> String
    #   resp.data.db_instance_automated_backup.region #=> String
    #   resp.data.db_instance_automated_backup.db_instance_identifier #=> String
    #   resp.data.db_instance_automated_backup.restore_window #=> Types::RestoreWindow
    #   resp.data.db_instance_automated_backup.restore_window.earliest_time #=> Time
    #   resp.data.db_instance_automated_backup.restore_window.latest_time #=> Time
    #   resp.data.db_instance_automated_backup.allocated_storage #=> Integer
    #   resp.data.db_instance_automated_backup.status #=> String
    #   resp.data.db_instance_automated_backup.port #=> Integer
    #   resp.data.db_instance_automated_backup.availability_zone #=> String
    #   resp.data.db_instance_automated_backup.vpc_id #=> String
    #   resp.data.db_instance_automated_backup.instance_create_time #=> Time
    #   resp.data.db_instance_automated_backup.master_username #=> String
    #   resp.data.db_instance_automated_backup.engine #=> String
    #   resp.data.db_instance_automated_backup.engine_version #=> String
    #   resp.data.db_instance_automated_backup.license_model #=> String
    #   resp.data.db_instance_automated_backup.iops #=> Integer
    #   resp.data.db_instance_automated_backup.option_group_name #=> String
    #   resp.data.db_instance_automated_backup.tde_credential_arn #=> String
    #   resp.data.db_instance_automated_backup.encrypted #=> Boolean
    #   resp.data.db_instance_automated_backup.storage_type #=> String
    #   resp.data.db_instance_automated_backup.kms_key_id #=> String
    #   resp.data.db_instance_automated_backup.timezone #=> String
    #   resp.data.db_instance_automated_backup.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance_automated_backup.backup_retention_period #=> Integer
    #   resp.data.db_instance_automated_backup.db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance_automated_backup.db_instance_automated_backups_replications #=> Array<DBInstanceAutomatedBackupsReplication>
    #   resp.data.db_instance_automated_backup.db_instance_automated_backups_replications[0] #=> Types::DBInstanceAutomatedBackupsReplication
    #   resp.data.db_instance_automated_backup.db_instance_automated_backups_replications[0].db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance_automated_backup.backup_target #=> String
    #
    def delete_db_instance_automated_backup(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DeleteDBInstanceAutomatedBackupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DeleteDBInstanceAutomatedBackupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DeleteDBInstanceAutomatedBackup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBInstanceAutomatedBackupNotFoundFault, Errors::InvalidDBInstanceAutomatedBackupStateFault]),
        data_parser: Parsers::DeleteDBInstanceAutomatedBackup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DeleteDBInstanceAutomatedBackup,
        stubs: @stubs,
        params_class: Params::DeleteDBInstanceAutomatedBackupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :delete_db_instance_automated_backup
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Deletes a specified DB parameter group. The DB parameter group to be deleted can't be associated with any DB instances.</p>
    #
    # @param [Hash] params
    #   See {Types::DeleteDBParameterGroupInput}.
    #
    # @option params [String] :db_parameter_group_name
    #   <p>The name of the DB parameter group.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be the name of an existing DB parameter group</p>
    #               </li>
    #               <li>
    #                   <p>You can't delete a default DB parameter group</p>
    #               </li>
    #               <li>
    #                   <p>Can't be associated with any DB instances</p>
    #               </li>
    #            </ul>
    #
    # @return [Types::DeleteDBParameterGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.delete_db_parameter_group(
    #     db_parameter_group_name: 'DBParameterGroupName' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DeleteDBParameterGroupOutput
    #
    def delete_db_parameter_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DeleteDBParameterGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DeleteDBParameterGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DeleteDBParameterGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidDBParameterGroupStateFault, Errors::DBParameterGroupNotFoundFault]),
        data_parser: Parsers::DeleteDBParameterGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DeleteDBParameterGroup,
        stubs: @stubs,
        params_class: Params::DeleteDBParameterGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :delete_db_parameter_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Deletes an existing DB proxy.</p>
    #
    # @param [Hash] params
    #   See {Types::DeleteDBProxyInput}.
    #
    # @option params [String] :db_proxy_name
    #   <p>The name of the DB proxy to delete.</p>
    #
    # @return [Types::DeleteDBProxyOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.delete_db_proxy(
    #     db_proxy_name: 'DBProxyName' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DeleteDBProxyOutput
    #   resp.data.db_proxy #=> Types::DBProxy
    #   resp.data.db_proxy.db_proxy_name #=> String
    #   resp.data.db_proxy.db_proxy_arn #=> String
    #   resp.data.db_proxy.status #=> String, one of ["available", "modifying", "incompatible-network", "insufficient-resource-limits", "creating", "deleting", "suspended", "suspending", "reactivating"]
    #   resp.data.db_proxy.engine_family #=> String
    #   resp.data.db_proxy.vpc_id #=> String
    #   resp.data.db_proxy.vpc_security_group_ids #=> Array<String>
    #   resp.data.db_proxy.vpc_security_group_ids[0] #=> String
    #   resp.data.db_proxy.vpc_subnet_ids #=> Array<String>
    #   resp.data.db_proxy.auth #=> Array<UserAuthConfigInfo>
    #   resp.data.db_proxy.auth[0] #=> Types::UserAuthConfigInfo
    #   resp.data.db_proxy.auth[0].description #=> String
    #   resp.data.db_proxy.auth[0].user_name #=> String
    #   resp.data.db_proxy.auth[0].auth_scheme #=> String, one of ["SECRETS"]
    #   resp.data.db_proxy.auth[0].secret_arn #=> String
    #   resp.data.db_proxy.auth[0].iam_auth #=> String, one of ["DISABLED", "REQUIRED"]
    #   resp.data.db_proxy.role_arn #=> String
    #   resp.data.db_proxy.endpoint #=> String
    #   resp.data.db_proxy.require_tls #=> Boolean
    #   resp.data.db_proxy.idle_client_timeout #=> Integer
    #   resp.data.db_proxy.debug_logging #=> Boolean
    #   resp.data.db_proxy.created_date #=> Time
    #   resp.data.db_proxy.updated_date #=> Time
    #
    def delete_db_proxy(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DeleteDBProxyInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DeleteDBProxyInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DeleteDBProxy
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBProxyNotFoundFault, Errors::InvalidDBProxyStateFault]),
        data_parser: Parsers::DeleteDBProxy
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DeleteDBProxy,
        stubs: @stubs,
        params_class: Params::DeleteDBProxyOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :delete_db_proxy
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Deletes a <code>DBProxyEndpoint</code>. Doing so removes the ability to access the DB proxy using the
    #         endpoint that you defined. The endpoint that you delete might have provided capabilities such as read/write
    #         or read-only operations, or using a different VPC than the DB proxy's default VPC.</p>
    #
    # @param [Hash] params
    #   See {Types::DeleteDBProxyEndpointInput}.
    #
    # @option params [String] :db_proxy_endpoint_name
    #   <p>The name of the DB proxy endpoint to delete.</p>
    #
    # @return [Types::DeleteDBProxyEndpointOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.delete_db_proxy_endpoint(
    #     db_proxy_endpoint_name: 'DBProxyEndpointName' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DeleteDBProxyEndpointOutput
    #   resp.data.db_proxy_endpoint #=> Types::DBProxyEndpoint
    #   resp.data.db_proxy_endpoint.db_proxy_endpoint_name #=> String
    #   resp.data.db_proxy_endpoint.db_proxy_endpoint_arn #=> String
    #   resp.data.db_proxy_endpoint.db_proxy_name #=> String
    #   resp.data.db_proxy_endpoint.status #=> String, one of ["available", "modifying", "incompatible-network", "insufficient-resource-limits", "creating", "deleting"]
    #   resp.data.db_proxy_endpoint.vpc_id #=> String
    #   resp.data.db_proxy_endpoint.vpc_security_group_ids #=> Array<String>
    #   resp.data.db_proxy_endpoint.vpc_security_group_ids[0] #=> String
    #   resp.data.db_proxy_endpoint.vpc_subnet_ids #=> Array<String>
    #   resp.data.db_proxy_endpoint.endpoint #=> String
    #   resp.data.db_proxy_endpoint.created_date #=> Time
    #   resp.data.db_proxy_endpoint.target_role #=> String, one of ["READ_WRITE", "READ_ONLY"]
    #   resp.data.db_proxy_endpoint.is_default #=> Boolean
    #
    def delete_db_proxy_endpoint(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DeleteDBProxyEndpointInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DeleteDBProxyEndpointInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DeleteDBProxyEndpoint
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidDBProxyEndpointStateFault, Errors::DBProxyEndpointNotFoundFault]),
        data_parser: Parsers::DeleteDBProxyEndpoint
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DeleteDBProxyEndpoint,
        stubs: @stubs,
        params_class: Params::DeleteDBProxyEndpointOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :delete_db_proxy_endpoint
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Deletes a DB security group.</p>
    #         <note>
    #             <p>The specified DB security group must not be associated with any DB instances.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::DeleteDBSecurityGroupInput}.
    #
    # @option params [String] :db_security_group_name
    #   <p>The name of the DB security group to delete.</p>
    #           <note>
    #               <p>You can't delete the default DB security group.</p>
    #           </note>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be 1 to 255 letters, numbers, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #               <li>
    #                   <p>Must not be "Default"</p>
    #               </li>
    #            </ul>
    #
    # @return [Types::DeleteDBSecurityGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.delete_db_security_group(
    #     db_security_group_name: 'DBSecurityGroupName' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DeleteDBSecurityGroupOutput
    #
    def delete_db_security_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DeleteDBSecurityGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DeleteDBSecurityGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DeleteDBSecurityGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBSecurityGroupNotFoundFault, Errors::InvalidDBSecurityGroupStateFault]),
        data_parser: Parsers::DeleteDBSecurityGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DeleteDBSecurityGroup,
        stubs: @stubs,
        params_class: Params::DeleteDBSecurityGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :delete_db_security_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Deletes a DB snapshot. If the snapshot is being copied, the copy operation is
    #             terminated.</p>
    #         <note>
    #             <p>The DB snapshot must be in the <code>available</code> state to be deleted.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::DeleteDBSnapshotInput}.
    #
    # @option params [String] :db_snapshot_identifier
    #   <p>The DB snapshot identifier.</p>
    #           <p>Constraints: Must be the name of an existing DB snapshot in the <code>available</code> state.</p>
    #
    # @return [Types::DeleteDBSnapshotOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.delete_db_snapshot(
    #     db_snapshot_identifier: 'DBSnapshotIdentifier' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DeleteDBSnapshotOutput
    #   resp.data.db_snapshot #=> Types::DBSnapshot
    #   resp.data.db_snapshot.db_snapshot_identifier #=> String
    #   resp.data.db_snapshot.db_instance_identifier #=> String
    #   resp.data.db_snapshot.snapshot_create_time #=> Time
    #   resp.data.db_snapshot.engine #=> String
    #   resp.data.db_snapshot.allocated_storage #=> Integer
    #   resp.data.db_snapshot.status #=> String
    #   resp.data.db_snapshot.port #=> Integer
    #   resp.data.db_snapshot.availability_zone #=> String
    #   resp.data.db_snapshot.vpc_id #=> String
    #   resp.data.db_snapshot.instance_create_time #=> Time
    #   resp.data.db_snapshot.master_username #=> String
    #   resp.data.db_snapshot.engine_version #=> String
    #   resp.data.db_snapshot.license_model #=> String
    #   resp.data.db_snapshot.snapshot_type #=> String
    #   resp.data.db_snapshot.iops #=> Integer
    #   resp.data.db_snapshot.option_group_name #=> String
    #   resp.data.db_snapshot.percent_progress #=> Integer
    #   resp.data.db_snapshot.source_region #=> String
    #   resp.data.db_snapshot.source_db_snapshot_identifier #=> String
    #   resp.data.db_snapshot.storage_type #=> String
    #   resp.data.db_snapshot.tde_credential_arn #=> String
    #   resp.data.db_snapshot.encrypted #=> Boolean
    #   resp.data.db_snapshot.kms_key_id #=> String
    #   resp.data.db_snapshot.db_snapshot_arn #=> String
    #   resp.data.db_snapshot.timezone #=> String
    #   resp.data.db_snapshot.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_snapshot.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_snapshot.processor_features[0] #=> Types::ProcessorFeature
    #   resp.data.db_snapshot.processor_features[0].name #=> String
    #   resp.data.db_snapshot.processor_features[0].value #=> String
    #   resp.data.db_snapshot.dbi_resource_id #=> String
    #   resp.data.db_snapshot.tag_list #=> Array<Tag>
    #   resp.data.db_snapshot.tag_list[0] #=> Types::Tag
    #   resp.data.db_snapshot.tag_list[0].key #=> String
    #   resp.data.db_snapshot.tag_list[0].value #=> String
    #   resp.data.db_snapshot.original_snapshot_create_time #=> Time
    #   resp.data.db_snapshot.snapshot_target #=> String
    #
    def delete_db_snapshot(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DeleteDBSnapshotInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DeleteDBSnapshotInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DeleteDBSnapshot
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidDBSnapshotStateFault, Errors::DBSnapshotNotFoundFault]),
        data_parser: Parsers::DeleteDBSnapshot
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DeleteDBSnapshot,
        stubs: @stubs,
        params_class: Params::DeleteDBSnapshotOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :delete_db_snapshot
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Deletes a DB subnet group.</p>
    #         <note>
    #             <p>The specified database subnet group must not be associated with any DB instances.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::DeleteDBSubnetGroupInput}.
    #
    # @option params [String] :db_subnet_group_name
    #   <p>The name of the database subnet group to delete.</p>
    #           <note>
    #               <p>You can't delete the default subnet group.</p>
    #           </note>
    #           <p>Constraints: Must match the name of an existing DBSubnetGroup. Must not be default.</p>
    #           <p>Example: <code>mydbsubnetgroup</code>
    #            </p>
    #
    # @return [Types::DeleteDBSubnetGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.delete_db_subnet_group(
    #     db_subnet_group_name: 'DBSubnetGroupName' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DeleteDBSubnetGroupOutput
    #
    def delete_db_subnet_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DeleteDBSubnetGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DeleteDBSubnetGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DeleteDBSubnetGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidDBSubnetStateFault, Errors::InvalidDBSubnetGroupStateFault, Errors::DBSubnetGroupNotFoundFault]),
        data_parser: Parsers::DeleteDBSubnetGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DeleteDBSubnetGroup,
        stubs: @stubs,
        params_class: Params::DeleteDBSubnetGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :delete_db_subnet_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Deletes an RDS event notification subscription.</p>
    #
    # @param [Hash] params
    #   See {Types::DeleteEventSubscriptionInput}.
    #
    # @option params [String] :subscription_name
    #   <p>The name of the RDS event notification subscription you want to delete.</p>
    #
    # @return [Types::DeleteEventSubscriptionOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.delete_event_subscription(
    #     subscription_name: 'SubscriptionName' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DeleteEventSubscriptionOutput
    #   resp.data.event_subscription #=> Types::EventSubscription
    #   resp.data.event_subscription.customer_aws_id #=> String
    #   resp.data.event_subscription.cust_subscription_id #=> String
    #   resp.data.event_subscription.sns_topic_arn #=> String
    #   resp.data.event_subscription.status #=> String
    #   resp.data.event_subscription.subscription_creation_time #=> String
    #   resp.data.event_subscription.source_type #=> String
    #   resp.data.event_subscription.source_ids_list #=> Array<String>
    #   resp.data.event_subscription.source_ids_list[0] #=> String
    #   resp.data.event_subscription.event_categories_list #=> Array<String>
    #   resp.data.event_subscription.event_categories_list[0] #=> String
    #   resp.data.event_subscription.enabled #=> Boolean
    #   resp.data.event_subscription.event_subscription_arn #=> String
    #
    def delete_event_subscription(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DeleteEventSubscriptionInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DeleteEventSubscriptionInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DeleteEventSubscription
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidEventSubscriptionStateFault, Errors::SubscriptionNotFoundFault]),
        data_parser: Parsers::DeleteEventSubscription
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DeleteEventSubscription,
        stubs: @stubs,
        params_class: Params::DeleteEventSubscriptionOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :delete_event_subscription
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Deletes a global database cluster. The primary and secondary clusters must already be detached or
    #         destroyed first.</p>
    #         <note>
    #             <p>This action only applies to Aurora DB clusters.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::DeleteGlobalClusterInput}.
    #
    # @option params [String] :global_cluster_identifier
    #   <p>The cluster identifier of the global database cluster being deleted.</p>
    #
    # @return [Types::DeleteGlobalClusterOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.delete_global_cluster(
    #     global_cluster_identifier: 'GlobalClusterIdentifier' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DeleteGlobalClusterOutput
    #   resp.data.global_cluster #=> Types::GlobalCluster
    #   resp.data.global_cluster.global_cluster_identifier #=> String
    #   resp.data.global_cluster.global_cluster_resource_id #=> String
    #   resp.data.global_cluster.global_cluster_arn #=> String
    #   resp.data.global_cluster.status #=> String
    #   resp.data.global_cluster.engine #=> String
    #   resp.data.global_cluster.engine_version #=> String
    #   resp.data.global_cluster.database_name #=> String
    #   resp.data.global_cluster.storage_encrypted #=> Boolean
    #   resp.data.global_cluster.deletion_protection #=> Boolean
    #   resp.data.global_cluster.global_cluster_members #=> Array<GlobalClusterMember>
    #   resp.data.global_cluster.global_cluster_members[0] #=> Types::GlobalClusterMember
    #   resp.data.global_cluster.global_cluster_members[0].db_cluster_arn #=> String
    #   resp.data.global_cluster.global_cluster_members[0].readers #=> Array<String>
    #   resp.data.global_cluster.global_cluster_members[0].readers[0] #=> String
    #   resp.data.global_cluster.global_cluster_members[0].is_writer #=> Boolean
    #   resp.data.global_cluster.global_cluster_members[0].global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.global_cluster.failover_state #=> Types::FailoverState
    #   resp.data.global_cluster.failover_state.status #=> String, one of ["pending", "failing-over", "cancelling"]
    #   resp.data.global_cluster.failover_state.from_db_cluster_arn #=> String
    #   resp.data.global_cluster.failover_state.to_db_cluster_arn #=> String
    #
    def delete_global_cluster(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DeleteGlobalClusterInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DeleteGlobalClusterInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DeleteGlobalCluster
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::GlobalClusterNotFoundFault, Errors::InvalidGlobalClusterStateFault]),
        data_parser: Parsers::DeleteGlobalCluster
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DeleteGlobalCluster,
        stubs: @stubs,
        params_class: Params::DeleteGlobalClusterOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :delete_global_cluster
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Deletes an existing option group.</p>
    #
    # @param [Hash] params
    #   See {Types::DeleteOptionGroupInput}.
    #
    # @option params [String] :option_group_name
    #   <p>The name of the option group to be deleted.</p>
    #           <note>
    #               <p>You can't delete default option groups.</p>
    #           </note>
    #
    # @return [Types::DeleteOptionGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.delete_option_group(
    #     option_group_name: 'OptionGroupName' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DeleteOptionGroupOutput
    #
    def delete_option_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DeleteOptionGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DeleteOptionGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DeleteOptionGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidOptionGroupStateFault, Errors::OptionGroupNotFoundFault]),
        data_parser: Parsers::DeleteOptionGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DeleteOptionGroup,
        stubs: @stubs,
        params_class: Params::DeleteOptionGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :delete_option_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Remove the association between one or more <code>DBProxyTarget</code> data structures and a <code>DBProxyTargetGroup</code>.</p>
    #
    # @param [Hash] params
    #   See {Types::DeregisterDBProxyTargetsInput}.
    #
    # @option params [String] :db_proxy_name
    #   <p>The identifier of the <code>DBProxy</code> that is associated with the <code>DBProxyTargetGroup</code>.</p>
    #
    # @option params [String] :target_group_name
    #   <p>The identifier of the <code>DBProxyTargetGroup</code>.</p>
    #
    # @option params [Array<String>] :db_instance_identifiers
    #   <p>One or more DB instance identifiers.</p>
    #
    # @option params [Array<String>] :db_cluster_identifiers
    #   <p>One or more DB cluster identifiers.</p>
    #
    # @return [Types::DeregisterDBProxyTargetsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.deregister_db_proxy_targets(
    #     db_proxy_name: 'DBProxyName', # required
    #     target_group_name: 'TargetGroupName',
    #     db_instance_identifiers: [
    #       'member'
    #     ],
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DeregisterDBProxyTargetsOutput
    #
    def deregister_db_proxy_targets(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DeregisterDBProxyTargetsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DeregisterDBProxyTargetsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DeregisterDBProxyTargets
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBProxyTargetGroupNotFoundFault, Errors::DBProxyNotFoundFault, Errors::DBProxyTargetNotFoundFault, Errors::InvalidDBProxyStateFault]),
        data_parser: Parsers::DeregisterDBProxyTargets
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DeregisterDBProxyTargets,
        stubs: @stubs,
        params_class: Params::DeregisterDBProxyTargetsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :deregister_db_proxy_targets
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Lists all of the attributes for a customer account. The attributes include Amazon RDS quotas for the account, such as the number of DB instances allowed. The description for a quota includes the quota name, current usage toward that quota, and the quota's maximum value.</p>
    #         <p>This command doesn't take any parameters.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeAccountAttributesInput}.
    #
    # @return [Types::DescribeAccountAttributesOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_account_attributes()
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeAccountAttributesOutput
    #   resp.data.account_quotas #=> Array<AccountQuota>
    #   resp.data.account_quotas[0] #=> Types::AccountQuota
    #   resp.data.account_quotas[0].account_quota_name #=> String
    #   resp.data.account_quotas[0].used #=> Integer
    #   resp.data.account_quotas[0].max #=> Integer
    #
    def describe_account_attributes(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeAccountAttributesInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeAccountAttributesInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeAccountAttributes
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: []),
        data_parser: Parsers::DescribeAccountAttributes
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeAccountAttributes,
        stubs: @stubs,
        params_class: Params::DescribeAccountAttributesOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_account_attributes
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Lists the set of CA certificates provided by Amazon RDS for this Amazon Web Services account.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeCertificatesInput}.
    #
    # @option params [String] :certificate_identifier
    #   <p>The user-supplied certificate identifier. If this parameter is specified, information for only the identified certificate is returned. This parameter isn't case-sensitive.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match an existing CertificateIdentifier.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #           If more records exist than the specified <code>MaxRecords</code> value,
    #           a pagination token called a marker is included in the response so you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #           <code>DescribeCertificates</code> request.
    #           If this parameter is specified, the response includes
    #           only records beyond the marker,
    #           up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeCertificatesOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_certificates(
    #     certificate_identifier: 'CertificateIdentifier',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeCertificatesOutput
    #   resp.data.certificates #=> Array<Certificate>
    #   resp.data.certificates[0] #=> Types::Certificate
    #   resp.data.certificates[0].certificate_identifier #=> String
    #   resp.data.certificates[0].certificate_type #=> String
    #   resp.data.certificates[0].thumbprint #=> String
    #   resp.data.certificates[0].valid_from #=> Time
    #   resp.data.certificates[0].valid_till #=> Time
    #   resp.data.certificates[0].certificate_arn #=> String
    #   resp.data.certificates[0].customer_override #=> Boolean
    #   resp.data.certificates[0].customer_override_valid_till #=> Time
    #   resp.data.marker #=> String
    #
    def describe_certificates(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeCertificatesInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeCertificatesInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeCertificates
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::CertificateNotFoundFault]),
        data_parser: Parsers::DescribeCertificates
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeCertificates,
        stubs: @stubs,
        params_class: Params::DescribeCertificatesOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_certificates
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns information about backtracks for a DB cluster.</p>
    #         <p>For more information on Amazon Aurora, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #                 What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <note>
    #             <p>This action only applies to Aurora MySQL DB clusters.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBClusterBacktracksInput}.
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The DB cluster identifier of the DB cluster to be described. This parameter is
    #               stored as a lowercase string.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain from 1 to 63 alphanumeric characters or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens.</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-cluster1</code>
    #            </p>
    #
    # @option params [String] :backtrack_identifier
    #   <p>If specified, this value is the backtrack identifier of the backtrack to be
    #               described.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain a valid universally unique identifier (UUID). For more
    #                       information about UUIDs, see <a href="http://www.ietf.org/rfc/rfc4122.txt">A Universally Unique Identifier
    #                           (UUID) URN Namespace</a>.</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>123e4567-e89b-12d3-a456-426655440000</code>
    #            </p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>A filter that specifies one or more DB clusters to describe. Supported filters
    #               include the following:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>db-cluster-backtrack-id</code> - Accepts backtrack identifiers. The
    #                       results list includes information about only the backtracks identified by these
    #                       identifiers.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>db-cluster-backtrack-status</code> - Accepts any of the following backtrack status values:</p>
    #                   <ul>
    #                     <li>
    #                           <p>
    #                           <code>applying</code>
    #                        </p>
    #                       </li>
    #                     <li>
    #                           <p>
    #                           <code>completed</code>
    #                        </p>
    #                       </li>
    #                     <li>
    #                           <p>
    #                           <code>failed</code>
    #                        </p>
    #                       </li>
    #                     <li>
    #                           <p>
    #                           <code>pending</code>
    #                        </p>
    #                       </li>
    #                  </ul>
    #                   <p>The results list includes information about only the backtracks identified
    #                       by these values.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #               If more records exist than the specified <code>MaxRecords</code> value,
    #               a pagination token called a marker is included in the response so you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #               <code>DescribeDBClusterBacktracks</code> request.
    #               If this parameter is specified, the response includes
    #               only records beyond the marker,
    #               up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeDBClusterBacktracksOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_cluster_backtracks(
    #     db_cluster_identifier: 'DBClusterIdentifier', # required
    #     backtrack_identifier: 'BacktrackIdentifier',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBClusterBacktracksOutput
    #   resp.data.marker #=> String
    #   resp.data.db_cluster_backtracks #=> Array<DBClusterBacktrack>
    #   resp.data.db_cluster_backtracks[0] #=> Types::DBClusterBacktrack
    #   resp.data.db_cluster_backtracks[0].db_cluster_identifier #=> String
    #   resp.data.db_cluster_backtracks[0].backtrack_identifier #=> String
    #   resp.data.db_cluster_backtracks[0].backtrack_to #=> Time
    #   resp.data.db_cluster_backtracks[0].backtracked_from #=> Time
    #   resp.data.db_cluster_backtracks[0].backtrack_request_creation_time #=> Time
    #   resp.data.db_cluster_backtracks[0].status #=> String
    #
    def describe_db_cluster_backtracks(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBClusterBacktracksInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBClusterBacktracksInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBClusterBacktracks
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::DBClusterBacktrackNotFoundFault]),
        data_parser: Parsers::DescribeDBClusterBacktracks
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBClusterBacktracks,
        stubs: @stubs,
        params_class: Params::DescribeDBClusterBacktracksOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_cluster_backtracks
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns information about endpoints for an Amazon Aurora DB cluster.</p>
    #         <note>
    #             <p>This action only applies to Aurora DB clusters.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBClusterEndpointsInput}.
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The DB cluster identifier of the DB cluster associated with the endpoint. This parameter is
    #               stored as a lowercase string.</p>
    #
    # @option params [String] :db_cluster_endpoint_identifier
    #   <p>The identifier of the endpoint to describe. This parameter is stored as a lowercase string.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>A set of name-value pairs that define which endpoints to include in the output.
    #          The filters are specified as name-value pairs, in the format
    #          <code>Name=<i>endpoint_type</i>,Values=<i>endpoint_type1</i>,<i>endpoint_type2</i>,...</code>.
    #          <code>Name</code> can be one of: <code>db-cluster-endpoint-type</code>, <code>db-cluster-endpoint-custom-type</code>, <code>db-cluster-endpoint-id</code>, <code>db-cluster-endpoint-status</code>.
    #            <code>Values</code> for the <code> db-cluster-endpoint-type</code> filter can be one or more of: <code>reader</code>, <code>writer</code>, <code>custom</code>.
    #          <code>Values</code> for the <code>db-cluster-endpoint-custom-type</code> filter can be one or more of: <code>reader</code>, <code>any</code>.
    #          <code>Values</code> for the <code>db-cluster-endpoint-status</code> filter can be one or more of: <code>available</code>, <code>creating</code>, <code>deleting</code>, <code>inactive</code>, <code>modifying</code>.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #               If more records exist than the specified <code>MaxRecords</code> value,
    #               a pagination token called a marker is included in the response so you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #               <code>DescribeDBClusterEndpoints</code> request.
    #               If this parameter is specified, the response includes
    #               only records beyond the marker,
    #               up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeDBClusterEndpointsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_cluster_endpoints(
    #     db_cluster_identifier: 'DBClusterIdentifier',
    #     db_cluster_endpoint_identifier: 'DBClusterEndpointIdentifier',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBClusterEndpointsOutput
    #   resp.data.marker #=> String
    #   resp.data.db_cluster_endpoints #=> Array<DBClusterEndpoint>
    #   resp.data.db_cluster_endpoints[0] #=> Types::DBClusterEndpoint
    #   resp.data.db_cluster_endpoints[0].db_cluster_endpoint_identifier #=> String
    #   resp.data.db_cluster_endpoints[0].db_cluster_identifier #=> String
    #   resp.data.db_cluster_endpoints[0].db_cluster_endpoint_resource_identifier #=> String
    #   resp.data.db_cluster_endpoints[0].endpoint #=> String
    #   resp.data.db_cluster_endpoints[0].status #=> String
    #   resp.data.db_cluster_endpoints[0].endpoint_type #=> String
    #   resp.data.db_cluster_endpoints[0].custom_endpoint_type #=> String
    #   resp.data.db_cluster_endpoints[0].static_members #=> Array<String>
    #   resp.data.db_cluster_endpoints[0].static_members[0] #=> String
    #   resp.data.db_cluster_endpoints[0].excluded_members #=> Array<String>
    #   resp.data.db_cluster_endpoints[0].db_cluster_endpoint_arn #=> String
    #
    def describe_db_cluster_endpoints(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBClusterEndpointsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBClusterEndpointsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBClusterEndpoints
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault]),
        data_parser: Parsers::DescribeDBClusterEndpoints
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBClusterEndpoints,
        stubs: @stubs,
        params_class: Params::DescribeDBClusterEndpointsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_cluster_endpoints
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns a list of <code>DBClusterParameterGroup</code> descriptions. If a
    #             <code>DBClusterParameterGroupName</code> parameter is specified,
    #             the list will contain only the description of the specified DB cluster parameter group.</p>
    #         <p>For more information on Amazon Aurora, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #               What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #               Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBClusterParameterGroupsInput}.
    #
    # @option params [String] :db_cluster_parameter_group_name
    #   <p>The name of a specific DB cluster parameter group to return details for.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match the name of an existing DBClusterParameterGroup.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #           If more records exist than the specified <code>MaxRecords</code> value,
    #             a pagination token called a marker is included in the response so you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #           <code>DescribeDBClusterParameterGroups</code> request.
    #           If this parameter is specified, the response includes
    #           only records beyond the marker,
    #           up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeDBClusterParameterGroupsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_cluster_parameter_groups(
    #     db_cluster_parameter_group_name: 'DBClusterParameterGroupName',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBClusterParameterGroupsOutput
    #   resp.data.marker #=> String
    #   resp.data.db_cluster_parameter_groups #=> Array<DBClusterParameterGroup>
    #   resp.data.db_cluster_parameter_groups[0] #=> Types::DBClusterParameterGroup
    #   resp.data.db_cluster_parameter_groups[0].db_cluster_parameter_group_name #=> String
    #   resp.data.db_cluster_parameter_groups[0].db_parameter_group_family #=> String
    #   resp.data.db_cluster_parameter_groups[0].description #=> String
    #   resp.data.db_cluster_parameter_groups[0].db_cluster_parameter_group_arn #=> String
    #
    def describe_db_cluster_parameter_groups(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBClusterParameterGroupsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBClusterParameterGroupsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBClusterParameterGroups
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBParameterGroupNotFoundFault]),
        data_parser: Parsers::DescribeDBClusterParameterGroups
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBClusterParameterGroups,
        stubs: @stubs,
        params_class: Params::DescribeDBClusterParameterGroupsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_cluster_parameter_groups
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns the detailed parameter list for a particular DB cluster parameter group.</p>
    #         <p>For more information on Amazon Aurora, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #               What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #               Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBClusterParametersInput}.
    #
    # @option params [String] :db_cluster_parameter_group_name
    #   <p>The name of a specific DB cluster parameter group to return parameter details for.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match the name of an existing DBClusterParameterGroup.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :source
    #   <p>A value that indicates to return only parameters for a specific source.
    #         Parameter sources can be <code>engine</code>, <code>service</code>,
    #         or <code>customer</code>.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #         If more records exist than the specified <code>MaxRecords</code> value,
    #             a pagination token called a marker is included in the response so you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #         <code>DescribeDBClusterParameters</code> request.
    #         If this parameter is specified, the response includes
    #         only records beyond the marker,
    #         up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeDBClusterParametersOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_cluster_parameters(
    #     db_cluster_parameter_group_name: 'DBClusterParameterGroupName', # required
    #     source: 'Source',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBClusterParametersOutput
    #   resp.data.parameters #=> Array<Parameter>
    #   resp.data.parameters[0] #=> Types::Parameter
    #   resp.data.parameters[0].parameter_name #=> String
    #   resp.data.parameters[0].parameter_value #=> String
    #   resp.data.parameters[0].description #=> String
    #   resp.data.parameters[0].source #=> String
    #   resp.data.parameters[0].apply_type #=> String
    #   resp.data.parameters[0].data_type #=> String
    #   resp.data.parameters[0].allowed_values #=> String
    #   resp.data.parameters[0].is_modifiable #=> Boolean
    #   resp.data.parameters[0].minimum_engine_version #=> String
    #   resp.data.parameters[0].apply_method #=> String, one of ["immediate", "pending-reboot"]
    #   resp.data.parameters[0].supported_engine_modes #=> Array<String>
    #   resp.data.parameters[0].supported_engine_modes[0] #=> String
    #   resp.data.marker #=> String
    #
    def describe_db_cluster_parameters(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBClusterParametersInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBClusterParametersInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBClusterParameters
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBParameterGroupNotFoundFault]),
        data_parser: Parsers::DescribeDBClusterParameters
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBClusterParameters,
        stubs: @stubs,
        params_class: Params::DescribeDBClusterParametersOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_cluster_parameters
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns a list of DB cluster snapshot attribute names and values for a manual DB cluster snapshot.</p>
    #         <p>When sharing snapshots with other Amazon Web Services accounts, <code>DescribeDBClusterSnapshotAttributes</code>
    #             returns the <code>restore</code> attribute and a list of IDs for the Amazon Web Services accounts that are
    #             authorized to copy or restore the manual DB cluster snapshot. If <code>all</code> is included in the list of
    #             values for the <code>restore</code> attribute, then the manual DB cluster snapshot is public and
    #             can be copied or restored by all Amazon Web Services accounts.</p>
    #         <p>To add or remove access for an Amazon Web Services account to copy or restore a manual DB cluster snapshot, or to make the
    #             manual DB cluster snapshot public or private, use the <code>ModifyDBClusterSnapshotAttribute</code> API action.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBClusterSnapshotAttributesInput}.
    #
    # @option params [String] :db_cluster_snapshot_identifier
    #   <p>The identifier for the DB cluster snapshot to describe the attributes for.</p>
    #
    # @return [Types::DescribeDBClusterSnapshotAttributesOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_cluster_snapshot_attributes(
    #     db_cluster_snapshot_identifier: 'DBClusterSnapshotIdentifier' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBClusterSnapshotAttributesOutput
    #   resp.data.db_cluster_snapshot_attributes_result #=> Types::DBClusterSnapshotAttributesResult
    #   resp.data.db_cluster_snapshot_attributes_result.db_cluster_snapshot_identifier #=> String
    #   resp.data.db_cluster_snapshot_attributes_result.db_cluster_snapshot_attributes #=> Array<DBClusterSnapshotAttribute>
    #   resp.data.db_cluster_snapshot_attributes_result.db_cluster_snapshot_attributes[0] #=> Types::DBClusterSnapshotAttribute
    #   resp.data.db_cluster_snapshot_attributes_result.db_cluster_snapshot_attributes[0].attribute_name #=> String
    #   resp.data.db_cluster_snapshot_attributes_result.db_cluster_snapshot_attributes[0].attribute_values #=> Array<String>
    #   resp.data.db_cluster_snapshot_attributes_result.db_cluster_snapshot_attributes[0].attribute_values[0] #=> String
    #
    def describe_db_cluster_snapshot_attributes(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBClusterSnapshotAttributesInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBClusterSnapshotAttributesInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBClusterSnapshotAttributes
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterSnapshotNotFoundFault]),
        data_parser: Parsers::DescribeDBClusterSnapshotAttributes
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBClusterSnapshotAttributes,
        stubs: @stubs,
        params_class: Params::DescribeDBClusterSnapshotAttributesOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_cluster_snapshot_attributes
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns information about DB cluster snapshots. This API action supports pagination.</p>
    #         <p>For more information on Amazon Aurora DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #               What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #               Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBClusterSnapshotsInput}.
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The ID of the DB cluster to retrieve the list of DB cluster snapshots for.
    #               This parameter can't be used in conjunction with the
    #               <code>DBClusterSnapshotIdentifier</code> parameter.
    #               This parameter isn't case-sensitive.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match the identifier of an existing DBCluster.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :db_cluster_snapshot_identifier
    #   <p>A specific DB cluster snapshot identifier to describe.
    #               This parameter can't be used in conjunction with the
    #               <code>DBClusterIdentifier</code> parameter.
    #               This value is stored as a lowercase string.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match the identifier of an existing DBClusterSnapshot.</p>
    #               </li>
    #               <li>
    #                   <p>If this identifier is for an automated snapshot, the <code>SnapshotType</code> parameter must also be specified.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :snapshot_type
    #   <p>The type of DB cluster snapshots to be returned. You can specify one of the following values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>automated</code> - Return all DB cluster snapshots that have been automatically taken by
    #                 Amazon RDS for my Amazon Web Services account.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>manual</code> - Return all DB cluster snapshots that have been taken by my Amazon Web Services account.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>shared</code> - Return all manual DB cluster snapshots that have been shared to my Amazon Web Services account.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>public</code> - Return all DB cluster snapshots that have been marked as public.</p>
    #               </li>
    #            </ul>
    #           <p>If you don't specify a <code>SnapshotType</code> value, then both automated and manual DB cluster snapshots are
    #             returned. You can include shared DB cluster snapshots with these results by enabling the <code>IncludeShared</code>
    #             parameter. You can include public DB cluster snapshots with these results by enabling the
    #             <code>IncludePublic</code> parameter.</p>
    #           <p>The <code>IncludeShared</code> and <code>IncludePublic</code> parameters don't apply for <code>SnapshotType</code> values
    #             of <code>manual</code> or <code>automated</code>. The <code>IncludePublic</code> parameter doesn't apply when <code>SnapshotType</code> is
    #             set to <code>shared</code>. The <code>IncludeShared</code> parameter doesn't apply when <code>SnapshotType</code> is set to
    #             <code>public</code>.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>A filter that specifies one or more DB cluster snapshots to describe.</p>
    #           <p>Supported filters:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>db-cluster-id</code> - Accepts DB cluster identifiers and DB
    #                 cluster Amazon Resource Names (ARNs).</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>db-cluster-snapshot-id</code> - Accepts DB cluster snapshot identifiers.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>snapshot-type</code> - Accepts types of DB cluster snapshots.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>engine</code> - Accepts names of database engines.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #               If more records exist than the specified <code>MaxRecords</code> value,
    #             a pagination token called a marker is included in the response so you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #               <code>DescribeDBClusterSnapshots</code> request.
    #               If this parameter is specified, the response includes
    #               only records beyond the marker,
    #               up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @option params [Boolean] :include_shared
    #   <p>A value that indicates whether to include shared manual DB cluster snapshots
    #               from other Amazon Web Services accounts that this Amazon Web Services account has been given
    #               permission to copy or restore. By default, these snapshots are not included.</p>
    #           <p>You can give an Amazon Web Services account permission to restore a manual DB cluster snapshot from
    #               another Amazon Web Services account by the <code>ModifyDBClusterSnapshotAttribute</code> API action.</p>
    #
    # @option params [Boolean] :include_public
    #   <p>A value that indicates whether to include manual DB cluster snapshots that are public and can be copied
    #               or restored by any Amazon Web Services account. By default, the public snapshots are not included.</p>
    #           <p>You can share a manual DB cluster snapshot  as public by using the <a>ModifyDBClusterSnapshotAttribute</a> API action.</p>
    #
    # @return [Types::DescribeDBClusterSnapshotsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_cluster_snapshots(
    #     db_cluster_identifier: 'DBClusterIdentifier',
    #     db_cluster_snapshot_identifier: 'DBClusterSnapshotIdentifier',
    #     snapshot_type: 'SnapshotType',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker',
    #     include_shared: false,
    #     include_public: false
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBClusterSnapshotsOutput
    #   resp.data.marker #=> String
    #   resp.data.db_cluster_snapshots #=> Array<DBClusterSnapshot>
    #   resp.data.db_cluster_snapshots[0] #=> Types::DBClusterSnapshot
    #   resp.data.db_cluster_snapshots[0].availability_zones #=> Array<String>
    #   resp.data.db_cluster_snapshots[0].availability_zones[0] #=> String
    #   resp.data.db_cluster_snapshots[0].db_cluster_snapshot_identifier #=> String
    #   resp.data.db_cluster_snapshots[0].db_cluster_identifier #=> String
    #   resp.data.db_cluster_snapshots[0].snapshot_create_time #=> Time
    #   resp.data.db_cluster_snapshots[0].engine #=> String
    #   resp.data.db_cluster_snapshots[0].engine_mode #=> String
    #   resp.data.db_cluster_snapshots[0].allocated_storage #=> Integer
    #   resp.data.db_cluster_snapshots[0].status #=> String
    #   resp.data.db_cluster_snapshots[0].port #=> Integer
    #   resp.data.db_cluster_snapshots[0].vpc_id #=> String
    #   resp.data.db_cluster_snapshots[0].cluster_create_time #=> Time
    #   resp.data.db_cluster_snapshots[0].master_username #=> String
    #   resp.data.db_cluster_snapshots[0].engine_version #=> String
    #   resp.data.db_cluster_snapshots[0].license_model #=> String
    #   resp.data.db_cluster_snapshots[0].snapshot_type #=> String
    #   resp.data.db_cluster_snapshots[0].percent_progress #=> Integer
    #   resp.data.db_cluster_snapshots[0].storage_encrypted #=> Boolean
    #   resp.data.db_cluster_snapshots[0].kms_key_id #=> String
    #   resp.data.db_cluster_snapshots[0].db_cluster_snapshot_arn #=> String
    #   resp.data.db_cluster_snapshots[0].source_db_cluster_snapshot_arn #=> String
    #   resp.data.db_cluster_snapshots[0].iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster_snapshots[0].tag_list #=> Array<Tag>
    #   resp.data.db_cluster_snapshots[0].tag_list[0] #=> Types::Tag
    #   resp.data.db_cluster_snapshots[0].tag_list[0].key #=> String
    #   resp.data.db_cluster_snapshots[0].tag_list[0].value #=> String
    #
    def describe_db_cluster_snapshots(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBClusterSnapshotsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBClusterSnapshotsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBClusterSnapshots
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterSnapshotNotFoundFault]),
        data_parser: Parsers::DescribeDBClusterSnapshots
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBClusterSnapshots,
        stubs: @stubs,
        params_class: Params::DescribeDBClusterSnapshotsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_cluster_snapshots
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns information about Amazon Aurora DB clusters and Multi-AZ DB clusters. This API supports pagination.</p>
    #         <p>For more information on Amazon Aurora DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #               What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #               Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide</i>.</p>
    #         <p>This operation can also return information for Amazon Neptune DB instances and Amazon DocumentDB instances.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBClustersInput}.
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The user-supplied DB cluster identifier. If this parameter is specified, information from only the specific DB cluster is returned. This parameter isn't case-sensitive.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match an existing DBClusterIdentifier.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Array<Filter>] :filters
    #   <p>A filter that specifies one or more DB clusters to describe.</p>
    #           <p>Supported filters:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>clone-group-id</code> - Accepts clone group identifiers.
    #                 The results list only includes information about
    #                 the DB clusters associated with these clone groups.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>db-cluster-id</code> - Accepts DB cluster identifiers and DB
    #                 cluster Amazon Resource Names (ARNs). The results list only includes information about
    #                 the DB clusters identified by these ARNs.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>domain</code> - Accepts Active Directory directory IDs.
    #                 The results list only includes information about
    #                 the DB clusters associated with these domains.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>engine</code> - Accepts engine names.
    #                 The results list only includes information about
    #                 the DB clusters for these engines.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #               If more records exist than the specified <code>MaxRecords</code> value,
    #             a pagination token called a marker is included in the response so you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #               <code>DescribeDBClusters</code> request.
    #               If this parameter is specified, the response includes
    #               only records beyond the marker,
    #               up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @option params [Boolean] :include_shared
    #   <p>Optional Boolean parameter that specifies whether the output includes information about clusters
    #             shared from other Amazon Web Services accounts.</p>
    #
    # @return [Types::DescribeDBClustersOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_clusters(
    #     db_cluster_identifier: 'DBClusterIdentifier',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker',
    #     include_shared: false
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBClustersOutput
    #   resp.data.marker #=> String
    #   resp.data.db_clusters #=> Array<DBCluster>
    #   resp.data.db_clusters[0] #=> Types::DBCluster
    #   resp.data.db_clusters[0].allocated_storage #=> Integer
    #   resp.data.db_clusters[0].availability_zones #=> Array<String>
    #   resp.data.db_clusters[0].availability_zones[0] #=> String
    #   resp.data.db_clusters[0].backup_retention_period #=> Integer
    #   resp.data.db_clusters[0].character_set_name #=> String
    #   resp.data.db_clusters[0].database_name #=> String
    #   resp.data.db_clusters[0].db_cluster_identifier #=> String
    #   resp.data.db_clusters[0].db_cluster_parameter_group #=> String
    #   resp.data.db_clusters[0].db_subnet_group #=> String
    #   resp.data.db_clusters[0].status #=> String
    #   resp.data.db_clusters[0].automatic_restart_time #=> Time
    #   resp.data.db_clusters[0].percent_progress #=> String
    #   resp.data.db_clusters[0].earliest_restorable_time #=> Time
    #   resp.data.db_clusters[0].endpoint #=> String
    #   resp.data.db_clusters[0].reader_endpoint #=> String
    #   resp.data.db_clusters[0].custom_endpoints #=> Array<String>
    #   resp.data.db_clusters[0].custom_endpoints[0] #=> String
    #   resp.data.db_clusters[0].multi_az #=> Boolean
    #   resp.data.db_clusters[0].engine #=> String
    #   resp.data.db_clusters[0].engine_version #=> String
    #   resp.data.db_clusters[0].latest_restorable_time #=> Time
    #   resp.data.db_clusters[0].port #=> Integer
    #   resp.data.db_clusters[0].master_username #=> String
    #   resp.data.db_clusters[0].db_cluster_option_group_memberships #=> Array<DBClusterOptionGroupStatus>
    #   resp.data.db_clusters[0].db_cluster_option_group_memberships[0] #=> Types::DBClusterOptionGroupStatus
    #   resp.data.db_clusters[0].db_cluster_option_group_memberships[0].db_cluster_option_group_name #=> String
    #   resp.data.db_clusters[0].db_cluster_option_group_memberships[0].status #=> String
    #   resp.data.db_clusters[0].preferred_backup_window #=> String
    #   resp.data.db_clusters[0].preferred_maintenance_window #=> String
    #   resp.data.db_clusters[0].replication_source_identifier #=> String
    #   resp.data.db_clusters[0].read_replica_identifiers #=> Array<String>
    #   resp.data.db_clusters[0].read_replica_identifiers[0] #=> String
    #   resp.data.db_clusters[0].db_cluster_members #=> Array<DBClusterMember>
    #   resp.data.db_clusters[0].db_cluster_members[0] #=> Types::DBClusterMember
    #   resp.data.db_clusters[0].db_cluster_members[0].db_instance_identifier #=> String
    #   resp.data.db_clusters[0].db_cluster_members[0].is_cluster_writer #=> Boolean
    #   resp.data.db_clusters[0].db_cluster_members[0].db_cluster_parameter_group_status #=> String
    #   resp.data.db_clusters[0].db_cluster_members[0].promotion_tier #=> Integer
    #   resp.data.db_clusters[0].vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_clusters[0].vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_clusters[0].vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_clusters[0].vpc_security_groups[0].status #=> String
    #   resp.data.db_clusters[0].hosted_zone_id #=> String
    #   resp.data.db_clusters[0].storage_encrypted #=> Boolean
    #   resp.data.db_clusters[0].kms_key_id #=> String
    #   resp.data.db_clusters[0].db_cluster_resource_id #=> String
    #   resp.data.db_clusters[0].db_cluster_arn #=> String
    #   resp.data.db_clusters[0].associated_roles #=> Array<DBClusterRole>
    #   resp.data.db_clusters[0].associated_roles[0] #=> Types::DBClusterRole
    #   resp.data.db_clusters[0].associated_roles[0].role_arn #=> String
    #   resp.data.db_clusters[0].associated_roles[0].status #=> String
    #   resp.data.db_clusters[0].associated_roles[0].feature_name #=> String
    #   resp.data.db_clusters[0].iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_clusters[0].clone_group_id #=> String
    #   resp.data.db_clusters[0].cluster_create_time #=> Time
    #   resp.data.db_clusters[0].earliest_backtrack_time #=> Time
    #   resp.data.db_clusters[0].backtrack_window #=> Integer
    #   resp.data.db_clusters[0].backtrack_consumed_change_records #=> Integer
    #   resp.data.db_clusters[0].enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_clusters[0].enabled_cloudwatch_logs_exports[0] #=> String
    #   resp.data.db_clusters[0].capacity #=> Integer
    #   resp.data.db_clusters[0].engine_mode #=> String
    #   resp.data.db_clusters[0].scaling_configuration_info #=> Types::ScalingConfigurationInfo
    #   resp.data.db_clusters[0].scaling_configuration_info.min_capacity #=> Integer
    #   resp.data.db_clusters[0].scaling_configuration_info.max_capacity #=> Integer
    #   resp.data.db_clusters[0].scaling_configuration_info.auto_pause #=> Boolean
    #   resp.data.db_clusters[0].scaling_configuration_info.seconds_until_auto_pause #=> Integer
    #   resp.data.db_clusters[0].scaling_configuration_info.timeout_action #=> String
    #   resp.data.db_clusters[0].scaling_configuration_info.seconds_before_timeout #=> Integer
    #   resp.data.db_clusters[0].deletion_protection #=> Boolean
    #   resp.data.db_clusters[0].http_endpoint_enabled #=> Boolean
    #   resp.data.db_clusters[0].activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_clusters[0].activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_clusters[0].activity_stream_kms_key_id #=> String
    #   resp.data.db_clusters[0].activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_clusters[0].copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_clusters[0].cross_account_clone #=> Boolean
    #   resp.data.db_clusters[0].domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_clusters[0].domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_clusters[0].domain_memberships[0].domain #=> String
    #   resp.data.db_clusters[0].domain_memberships[0].status #=> String
    #   resp.data.db_clusters[0].domain_memberships[0].fqdn #=> String
    #   resp.data.db_clusters[0].domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_clusters[0].tag_list #=> Array<Tag>
    #   resp.data.db_clusters[0].tag_list[0] #=> Types::Tag
    #   resp.data.db_clusters[0].tag_list[0].key #=> String
    #   resp.data.db_clusters[0].tag_list[0].value #=> String
    #   resp.data.db_clusters[0].global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.db_clusters[0].global_write_forwarding_requested #=> Boolean
    #   resp.data.db_clusters[0].pending_modified_values #=> Types::ClusterPendingModifiedValues
    #   resp.data.db_clusters[0].pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_clusters[0].pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_clusters[0].pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_clusters[0].pending_modified_values.db_cluster_identifier #=> String
    #   resp.data.db_clusters[0].pending_modified_values.master_user_password #=> String
    #   resp.data.db_clusters[0].pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_clusters[0].pending_modified_values.engine_version #=> String
    #   resp.data.db_clusters[0].db_cluster_instance_class #=> String
    #   resp.data.db_clusters[0].storage_type #=> String
    #   resp.data.db_clusters[0].iops #=> Integer
    #   resp.data.db_clusters[0].publicly_accessible #=> Boolean
    #   resp.data.db_clusters[0].auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_clusters[0].monitoring_interval #=> Integer
    #   resp.data.db_clusters[0].monitoring_role_arn #=> String
    #   resp.data.db_clusters[0].performance_insights_enabled #=> Boolean
    #   resp.data.db_clusters[0].performance_insights_kms_key_id #=> String
    #   resp.data.db_clusters[0].performance_insights_retention_period #=> Integer
    #   resp.data.db_clusters[0].serverless_v2_scaling_configuration #=> Types::ServerlessV2ScalingConfigurationInfo
    #   resp.data.db_clusters[0].serverless_v2_scaling_configuration.min_capacity #=> Float
    #   resp.data.db_clusters[0].serverless_v2_scaling_configuration.max_capacity #=> Float
    #
    def describe_db_clusters(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBClustersInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBClustersInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBClusters
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault]),
        data_parser: Parsers::DescribeDBClusters
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBClusters,
        stubs: @stubs,
        params_class: Params::DescribeDBClustersOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_clusters
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns a list of the available DB engines.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBEngineVersionsInput}.
    #
    # @option params [String] :engine
    #   <p>The database engine to return.</p>
    #           <p>Valid Values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>aurora</code> (for MySQL 5.6-compatible Aurora)</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-mysql</code> (for MySQL 5.7-compatible and MySQL 8.0-compatible Aurora)</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-postgresql</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mariadb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mysql</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>postgres</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-se</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ex</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-web</code>
    #                  </p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :engine_version
    #   <p>The database engine version to return.</p>
    #           <p>Example: <code>5.1.49</code>
    #            </p>
    #
    # @option params [String] :db_parameter_group_family
    #   <p>The name of a specific DB parameter group family to return details for.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match an existing DBParameterGroupFamily.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Array<Filter>] :filters
    #   <p>A filter that specifies one or more DB engine versions to describe.</p>
    #           <p>Supported filters:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>db-parameter-group-family</code> - Accepts parameter groups family names.
    #                     The results list only includes information about
    #                     the DB engine versions for these parameter group families.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>engine</code> - Accepts engine names.
    #                     The results list only includes information about
    #                     the DB engine versions for these engines.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>engine-mode</code> - Accepts DB engine modes.
    #                     The results list only includes information about
    #                     the DB engine versions for these engine modes. Valid
    #                     DB engine modes are the following:</p>
    #                   <ul>
    #                     <li>
    #                           <p>
    #                           <code>global</code>
    #                        </p>
    #                       </li>
    #                     <li>
    #                           <p>
    #                           <code>multimaster</code>
    #                        </p>
    #                       </li>
    #                     <li>
    #                           <p>
    #                           <code>parallelquery</code>
    #                        </p>
    #                       </li>
    #                     <li>
    #                           <p>
    #                           <code>provisioned</code>
    #                        </p>
    #                       </li>
    #                     <li>
    #                           <p>
    #                           <code>serverless</code>
    #                        </p>
    #                       </li>
    #                  </ul>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>engine-version</code> - Accepts engine versions.
    #                     The results list only includes information about
    #                     the DB engine versions for these engine versions.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>status</code> - Accepts engine version statuses.
    #                     The results list only includes information about
    #                     the DB engine versions for these statuses. Valid statuses
    #                     are the following:</p>
    #                   <ul>
    #                     <li>
    #                           <p>
    #                           <code>available</code>
    #                        </p>
    #                       </li>
    #                     <li>
    #                           <p>
    #                           <code>deprecated</code>
    #                        </p>
    #                       </li>
    #                  </ul>
    #               </li>
    #            </ul>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #       If more than the <code>MaxRecords</code> value is available, a pagination token called a marker is
    #       included in the response so you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous request.
    #           If this parameter is specified, the response includes
    #           only records beyond the marker,
    #           up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @option params [Boolean] :default_only
    #   <p>A value that indicates whether only the default version of the specified engine or engine and major version combination is returned.</p>
    #
    # @option params [Boolean] :list_supported_character_sets
    #   <p>A value that indicates whether to list the supported character sets for each engine version.</p>
    #           <p>If this parameter is enabled and the requested engine supports the <code>CharacterSetName</code> parameter for
    #                   <code>CreateDBInstance</code>, the response includes a list of supported character sets for each engine
    #               version.</p>
    #           <p>For RDS Custom, the default is not to list supported character sets. If you set <code>ListSupportedCharacterSets</code>
    #             to <code>true</code>, RDS Custom returns no results.</p>
    #
    # @option params [Boolean] :list_supported_timezones
    #   <p>A value that indicates whether to list the supported time zones for each engine version.</p>
    #           <p>If this parameter is enabled and the requested engine supports the <code>TimeZone</code> parameter for <code>CreateDBInstance</code>,
    #               the response includes a list of supported time zones for each engine version.</p>
    #           <p>For RDS Custom, the default is not to list supported time zones. If you set <code>ListSupportedTimezones</code>
    #               to <code>true</code>, RDS Custom returns no results.</p>
    #
    # @option params [Boolean] :include_all
    #   <p>A value that indicates whether to include engine versions that aren't available in the list. The default is to list only available engine versions.</p>
    #
    # @return [Types::DescribeDBEngineVersionsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_engine_versions(
    #     engine: 'Engine',
    #     engine_version: 'EngineVersion',
    #     db_parameter_group_family: 'DBParameterGroupFamily',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker',
    #     default_only: false,
    #     list_supported_character_sets: false,
    #     list_supported_timezones: false,
    #     include_all: false
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBEngineVersionsOutput
    #   resp.data.marker #=> String
    #   resp.data.db_engine_versions #=> Array<DBEngineVersion>
    #   resp.data.db_engine_versions[0] #=> Types::DBEngineVersion
    #   resp.data.db_engine_versions[0].engine #=> String
    #   resp.data.db_engine_versions[0].engine_version #=> String
    #   resp.data.db_engine_versions[0].db_parameter_group_family #=> String
    #   resp.data.db_engine_versions[0].db_engine_description #=> String
    #   resp.data.db_engine_versions[0].db_engine_version_description #=> String
    #   resp.data.db_engine_versions[0].default_character_set #=> Types::CharacterSet
    #   resp.data.db_engine_versions[0].default_character_set.character_set_name #=> String
    #   resp.data.db_engine_versions[0].default_character_set.character_set_description #=> String
    #   resp.data.db_engine_versions[0].supported_character_sets #=> Array<CharacterSet>
    #   resp.data.db_engine_versions[0].supported_nchar_character_sets #=> Array<CharacterSet>
    #   resp.data.db_engine_versions[0].valid_upgrade_target #=> Array<UpgradeTarget>
    #   resp.data.db_engine_versions[0].valid_upgrade_target[0] #=> Types::UpgradeTarget
    #   resp.data.db_engine_versions[0].valid_upgrade_target[0].engine #=> String
    #   resp.data.db_engine_versions[0].valid_upgrade_target[0].engine_version #=> String
    #   resp.data.db_engine_versions[0].valid_upgrade_target[0].description #=> String
    #   resp.data.db_engine_versions[0].valid_upgrade_target[0].auto_upgrade #=> Boolean
    #   resp.data.db_engine_versions[0].valid_upgrade_target[0].is_major_version_upgrade #=> Boolean
    #   resp.data.db_engine_versions[0].valid_upgrade_target[0].supported_engine_modes #=> Array<String>
    #   resp.data.db_engine_versions[0].valid_upgrade_target[0].supported_engine_modes[0] #=> String
    #   resp.data.db_engine_versions[0].valid_upgrade_target[0].supports_parallel_query #=> Boolean
    #   resp.data.db_engine_versions[0].valid_upgrade_target[0].supports_global_databases #=> Boolean
    #   resp.data.db_engine_versions[0].valid_upgrade_target[0].supports_babelfish #=> Boolean
    #   resp.data.db_engine_versions[0].supported_timezones #=> Array<Timezone>
    #   resp.data.db_engine_versions[0].supported_timezones[0] #=> Types::Timezone
    #   resp.data.db_engine_versions[0].supported_timezones[0].timezone_name #=> String
    #   resp.data.db_engine_versions[0].exportable_log_types #=> Array<String>
    #   resp.data.db_engine_versions[0].exportable_log_types[0] #=> String
    #   resp.data.db_engine_versions[0].supports_log_exports_to_cloudwatch_logs #=> Boolean
    #   resp.data.db_engine_versions[0].supports_read_replica #=> Boolean
    #   resp.data.db_engine_versions[0].supported_engine_modes #=> Array<String>
    #   resp.data.db_engine_versions[0].supported_feature_names #=> Array<String>
    #   resp.data.db_engine_versions[0].supported_feature_names[0] #=> String
    #   resp.data.db_engine_versions[0].status #=> String
    #   resp.data.db_engine_versions[0].supports_parallel_query #=> Boolean
    #   resp.data.db_engine_versions[0].supports_global_databases #=> Boolean
    #   resp.data.db_engine_versions[0].major_engine_version #=> String
    #   resp.data.db_engine_versions[0].database_installation_files_s3_bucket_name #=> String
    #   resp.data.db_engine_versions[0].database_installation_files_s3_prefix #=> String
    #   resp.data.db_engine_versions[0].db_engine_version_arn #=> String
    #   resp.data.db_engine_versions[0].kms_key_id #=> String
    #   resp.data.db_engine_versions[0].create_time #=> Time
    #   resp.data.db_engine_versions[0].tag_list #=> Array<Tag>
    #   resp.data.db_engine_versions[0].tag_list[0] #=> Types::Tag
    #   resp.data.db_engine_versions[0].tag_list[0].key #=> String
    #   resp.data.db_engine_versions[0].tag_list[0].value #=> String
    #   resp.data.db_engine_versions[0].supports_babelfish #=> Boolean
    #
    def describe_db_engine_versions(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBEngineVersionsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBEngineVersionsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBEngineVersions
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: []),
        data_parser: Parsers::DescribeDBEngineVersions
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBEngineVersions,
        stubs: @stubs,
        params_class: Params::DescribeDBEngineVersionsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_engine_versions
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Displays backups for both current and deleted
    #             instances. For example, use this operation to
    #             find details about automated backups for previously deleted instances. Current instances
    #             with retention periods greater than zero (0) are returned for both the
    #             <code>DescribeDBInstanceAutomatedBackups</code> and
    #             <code>DescribeDBInstances</code> operations.</p>
    #         <p>All parameters are optional.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBInstanceAutomatedBackupsInput}.
    #
    # @option params [String] :dbi_resource_id
    #   <p>The resource ID of the DB instance that is the source of
    #               the automated backup. This parameter isn't case-sensitive.</p>
    #
    # @option params [String] :db_instance_identifier
    #   <p>(Optional) The user-supplied instance identifier. If this parameter is specified, it must
    #               match the identifier of an existing DB instance. It returns information from the
    #               specific DB instance' automated backup. This parameter isn't case-sensitive.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>A filter that specifies which resources to return based on status.</p>
    #           <p>Supported filters are the following:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>status</code>
    #                  </p>
    #                   <ul>
    #                     <li>
    #                           <p>
    #                           <code>active</code> - automated backups for current instances</p>
    #                       </li>
    #                     <li>
    #                           <p>
    #                           <code>retained</code> - automated backups for deleted instances and after backup replication is stopped</p>
    #                       </li>
    #                     <li>
    #                           <p>
    #                           <code>creating</code> - automated backups that are waiting for the first automated snapshot to be available</p>
    #                       </li>
    #                  </ul>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>db-instance-id</code> - Accepts DB instance identifiers and Amazon Resource Names (ARNs).
    #                   The results list includes only information about the DB instance automated backups identified by these ARNs.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>dbi-resource-id</code> - Accepts DB resource identifiers and Amazon Resource Names (ARNs).
    #                   The results list includes only information about the DB instance resources identified by these ARNs.</p>
    #               </li>
    #            </ul>
    #           <p>Returns all resources by default. The status for each resource is specified in the response.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response. If more records exist than the specified
    #               <code>MaxRecords</code> value, a pagination token called a marker is included in the response so that
    #               you can retrieve the remaining results.</p>
    #
    # @option params [String] :marker
    #   <p>The pagination token provided in the previous request. If this parameter is specified the response
    #               includes only records beyond the marker, up to <code>MaxRecords</code>.</p>
    #
    # @option params [String] :db_instance_automated_backups_arn
    #   <p>The Amazon Resource Name (ARN) of the replicated automated backups, for example,
    #               <code>arn:aws:rds:us-east-1:123456789012:auto-backup:ab-L2IJCEXJP7XQ7HOJ4SIEXAMPLE</code>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @return [Types::DescribeDBInstanceAutomatedBackupsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_instance_automated_backups(
    #     dbi_resource_id: 'DbiResourceId',
    #     db_instance_identifier: 'DBInstanceIdentifier',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker',
    #     db_instance_automated_backups_arn: 'DBInstanceAutomatedBackupsArn'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBInstanceAutomatedBackupsOutput
    #   resp.data.marker #=> String
    #   resp.data.db_instance_automated_backups #=> Array<DBInstanceAutomatedBackup>
    #   resp.data.db_instance_automated_backups[0] #=> Types::DBInstanceAutomatedBackup
    #   resp.data.db_instance_automated_backups[0].db_instance_arn #=> String
    #   resp.data.db_instance_automated_backups[0].dbi_resource_id #=> String
    #   resp.data.db_instance_automated_backups[0].region #=> String
    #   resp.data.db_instance_automated_backups[0].db_instance_identifier #=> String
    #   resp.data.db_instance_automated_backups[0].restore_window #=> Types::RestoreWindow
    #   resp.data.db_instance_automated_backups[0].restore_window.earliest_time #=> Time
    #   resp.data.db_instance_automated_backups[0].restore_window.latest_time #=> Time
    #   resp.data.db_instance_automated_backups[0].allocated_storage #=> Integer
    #   resp.data.db_instance_automated_backups[0].status #=> String
    #   resp.data.db_instance_automated_backups[0].port #=> Integer
    #   resp.data.db_instance_automated_backups[0].availability_zone #=> String
    #   resp.data.db_instance_automated_backups[0].vpc_id #=> String
    #   resp.data.db_instance_automated_backups[0].instance_create_time #=> Time
    #   resp.data.db_instance_automated_backups[0].master_username #=> String
    #   resp.data.db_instance_automated_backups[0].engine #=> String
    #   resp.data.db_instance_automated_backups[0].engine_version #=> String
    #   resp.data.db_instance_automated_backups[0].license_model #=> String
    #   resp.data.db_instance_automated_backups[0].iops #=> Integer
    #   resp.data.db_instance_automated_backups[0].option_group_name #=> String
    #   resp.data.db_instance_automated_backups[0].tde_credential_arn #=> String
    #   resp.data.db_instance_automated_backups[0].encrypted #=> Boolean
    #   resp.data.db_instance_automated_backups[0].storage_type #=> String
    #   resp.data.db_instance_automated_backups[0].kms_key_id #=> String
    #   resp.data.db_instance_automated_backups[0].timezone #=> String
    #   resp.data.db_instance_automated_backups[0].iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance_automated_backups[0].backup_retention_period #=> Integer
    #   resp.data.db_instance_automated_backups[0].db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance_automated_backups[0].db_instance_automated_backups_replications #=> Array<DBInstanceAutomatedBackupsReplication>
    #   resp.data.db_instance_automated_backups[0].db_instance_automated_backups_replications[0] #=> Types::DBInstanceAutomatedBackupsReplication
    #   resp.data.db_instance_automated_backups[0].db_instance_automated_backups_replications[0].db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance_automated_backups[0].backup_target #=> String
    #
    def describe_db_instance_automated_backups(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBInstanceAutomatedBackupsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBInstanceAutomatedBackupsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBInstanceAutomatedBackups
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBInstanceAutomatedBackupNotFoundFault]),
        data_parser: Parsers::DescribeDBInstanceAutomatedBackups
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBInstanceAutomatedBackups,
        stubs: @stubs,
        params_class: Params::DescribeDBInstanceAutomatedBackupsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_instance_automated_backups
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns information about provisioned RDS instances. This API supports pagination.</p>
    #         <note>
    #             <p>This operation can also return information for Amazon Neptune DB instances and Amazon DocumentDB instances.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBInstancesInput}.
    #
    # @option params [String] :db_instance_identifier
    #   <p>The user-supplied instance identifier. If this parameter is specified, information from only the specific DB instance is returned. This parameter isn't case-sensitive.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match the identifier of an existing DBInstance.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Array<Filter>] :filters
    #   <p>A filter that specifies one or more DB instances to describe.</p>
    #           <p>Supported filters:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>db-cluster-id</code> - Accepts DB cluster identifiers and DB
    #                 cluster Amazon Resource Names (ARNs). The results list only includes information about
    #                 the DB instances associated with the DB clusters identified by these ARNs.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>db-instance-id</code> - Accepts DB instance identifiers and DB
    #                 instance Amazon Resource Names (ARNs). The results list only includes information about
    #                 the DB instances identified by these ARNs.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>dbi-resource-id</code> - Accepts DB instance resource identifiers. The results list will
    #                 only include information about the DB instances identified by these DB instance resource identifiers.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>domain</code> - Accepts Active Directory directory IDs. The results list only includes
    #                 information about the DB instances associated with these domains.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>engine</code> - Accepts engine names. The results list only includes information
    #                 about the DB instances for these engines.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #           If more records exist than the specified <code>MaxRecords</code> value,
    #           a pagination token called a marker is included in the response so that
    #           you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #           <code>DescribeDBInstances</code> request.
    #           If this parameter is specified, the response includes
    #           only records beyond the marker,
    #           up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeDBInstancesOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_instances(
    #     db_instance_identifier: 'DBInstanceIdentifier',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBInstancesOutput
    #   resp.data.marker #=> String
    #   resp.data.db_instances #=> Array<DBInstance>
    #   resp.data.db_instances[0] #=> Types::DBInstance
    #   resp.data.db_instances[0].db_instance_identifier #=> String
    #   resp.data.db_instances[0].db_instance_class #=> String
    #   resp.data.db_instances[0].engine #=> String
    #   resp.data.db_instances[0].db_instance_status #=> String
    #   resp.data.db_instances[0].automatic_restart_time #=> Time
    #   resp.data.db_instances[0].master_username #=> String
    #   resp.data.db_instances[0].db_name #=> String
    #   resp.data.db_instances[0].endpoint #=> Types::Endpoint
    #   resp.data.db_instances[0].endpoint.address #=> String
    #   resp.data.db_instances[0].endpoint.port #=> Integer
    #   resp.data.db_instances[0].endpoint.hosted_zone_id #=> String
    #   resp.data.db_instances[0].allocated_storage #=> Integer
    #   resp.data.db_instances[0].instance_create_time #=> Time
    #   resp.data.db_instances[0].preferred_backup_window #=> String
    #   resp.data.db_instances[0].backup_retention_period #=> Integer
    #   resp.data.db_instances[0].db_security_groups #=> Array<DBSecurityGroupMembership>
    #   resp.data.db_instances[0].db_security_groups[0] #=> Types::DBSecurityGroupMembership
    #   resp.data.db_instances[0].db_security_groups[0].db_security_group_name #=> String
    #   resp.data.db_instances[0].db_security_groups[0].status #=> String
    #   resp.data.db_instances[0].vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_instances[0].vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_instances[0].vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_instances[0].vpc_security_groups[0].status #=> String
    #   resp.data.db_instances[0].db_parameter_groups #=> Array<DBParameterGroupStatus>
    #   resp.data.db_instances[0].db_parameter_groups[0] #=> Types::DBParameterGroupStatus
    #   resp.data.db_instances[0].db_parameter_groups[0].db_parameter_group_name #=> String
    #   resp.data.db_instances[0].db_parameter_groups[0].parameter_apply_status #=> String
    #   resp.data.db_instances[0].availability_zone #=> String
    #   resp.data.db_instances[0].db_subnet_group #=> Types::DBSubnetGroup
    #   resp.data.db_instances[0].db_subnet_group.db_subnet_group_name #=> String
    #   resp.data.db_instances[0].db_subnet_group.db_subnet_group_description #=> String
    #   resp.data.db_instances[0].db_subnet_group.vpc_id #=> String
    #   resp.data.db_instances[0].db_subnet_group.subnet_group_status #=> String
    #   resp.data.db_instances[0].db_subnet_group.subnets #=> Array<Subnet>
    #   resp.data.db_instances[0].db_subnet_group.subnets[0] #=> Types::Subnet
    #   resp.data.db_instances[0].db_subnet_group.subnets[0].subnet_identifier #=> String
    #   resp.data.db_instances[0].db_subnet_group.subnets[0].subnet_availability_zone #=> Types::AvailabilityZone
    #   resp.data.db_instances[0].db_subnet_group.subnets[0].subnet_availability_zone.name #=> String
    #   resp.data.db_instances[0].db_subnet_group.subnets[0].subnet_outpost #=> Types::Outpost
    #   resp.data.db_instances[0].db_subnet_group.subnets[0].subnet_outpost.arn #=> String
    #   resp.data.db_instances[0].db_subnet_group.subnets[0].subnet_status #=> String
    #   resp.data.db_instances[0].db_subnet_group.db_subnet_group_arn #=> String
    #   resp.data.db_instances[0].db_subnet_group.supported_network_types #=> Array<String>
    #   resp.data.db_instances[0].db_subnet_group.supported_network_types[0] #=> String
    #   resp.data.db_instances[0].preferred_maintenance_window #=> String
    #   resp.data.db_instances[0].pending_modified_values #=> Types::PendingModifiedValues
    #   resp.data.db_instances[0].pending_modified_values.db_instance_class #=> String
    #   resp.data.db_instances[0].pending_modified_values.allocated_storage #=> Integer
    #   resp.data.db_instances[0].pending_modified_values.master_user_password #=> String
    #   resp.data.db_instances[0].pending_modified_values.port #=> Integer
    #   resp.data.db_instances[0].pending_modified_values.backup_retention_period #=> Integer
    #   resp.data.db_instances[0].pending_modified_values.multi_az #=> Boolean
    #   resp.data.db_instances[0].pending_modified_values.engine_version #=> String
    #   resp.data.db_instances[0].pending_modified_values.license_model #=> String
    #   resp.data.db_instances[0].pending_modified_values.iops #=> Integer
    #   resp.data.db_instances[0].pending_modified_values.db_instance_identifier #=> String
    #   resp.data.db_instances[0].pending_modified_values.storage_type #=> String
    #   resp.data.db_instances[0].pending_modified_values.ca_certificate_identifier #=> String
    #   resp.data.db_instances[0].pending_modified_values.db_subnet_group_name #=> String
    #   resp.data.db_instances[0].pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_instances[0].pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_instances[0].pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable[0] #=> String
    #   resp.data.db_instances[0].pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_instances[0].pending_modified_values.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instances[0].pending_modified_values.processor_features[0] #=> Types::ProcessorFeature
    #   resp.data.db_instances[0].pending_modified_values.processor_features[0].name #=> String
    #   resp.data.db_instances[0].pending_modified_values.processor_features[0].value #=> String
    #   resp.data.db_instances[0].pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instances[0].pending_modified_values.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instances[0].pending_modified_values.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instances[0].latest_restorable_time #=> Time
    #   resp.data.db_instances[0].multi_az #=> Boolean
    #   resp.data.db_instances[0].engine_version #=> String
    #   resp.data.db_instances[0].auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_instances[0].read_replica_source_db_instance_identifier #=> String
    #   resp.data.db_instances[0].read_replica_db_instance_identifiers #=> Array<String>
    #   resp.data.db_instances[0].read_replica_db_instance_identifiers[0] #=> String
    #   resp.data.db_instances[0].read_replica_db_cluster_identifiers #=> Array<String>
    #   resp.data.db_instances[0].read_replica_db_cluster_identifiers[0] #=> String
    #   resp.data.db_instances[0].replica_mode #=> String, one of ["open-read-only", "mounted"]
    #   resp.data.db_instances[0].license_model #=> String
    #   resp.data.db_instances[0].iops #=> Integer
    #   resp.data.db_instances[0].option_group_memberships #=> Array<OptionGroupMembership>
    #   resp.data.db_instances[0].option_group_memberships[0] #=> Types::OptionGroupMembership
    #   resp.data.db_instances[0].option_group_memberships[0].option_group_name #=> String
    #   resp.data.db_instances[0].option_group_memberships[0].status #=> String
    #   resp.data.db_instances[0].character_set_name #=> String
    #   resp.data.db_instances[0].nchar_character_set_name #=> String
    #   resp.data.db_instances[0].secondary_availability_zone #=> String
    #   resp.data.db_instances[0].publicly_accessible #=> Boolean
    #   resp.data.db_instances[0].status_infos #=> Array<DBInstanceStatusInfo>
    #   resp.data.db_instances[0].status_infos[0] #=> Types::DBInstanceStatusInfo
    #   resp.data.db_instances[0].status_infos[0].status_type #=> String
    #   resp.data.db_instances[0].status_infos[0].normal #=> Boolean
    #   resp.data.db_instances[0].status_infos[0].status #=> String
    #   resp.data.db_instances[0].status_infos[0].message #=> String
    #   resp.data.db_instances[0].storage_type #=> String
    #   resp.data.db_instances[0].tde_credential_arn #=> String
    #   resp.data.db_instances[0].db_instance_port #=> Integer
    #   resp.data.db_instances[0].db_cluster_identifier #=> String
    #   resp.data.db_instances[0].storage_encrypted #=> Boolean
    #   resp.data.db_instances[0].kms_key_id #=> String
    #   resp.data.db_instances[0].dbi_resource_id #=> String
    #   resp.data.db_instances[0].ca_certificate_identifier #=> String
    #   resp.data.db_instances[0].domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_instances[0].domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_instances[0].domain_memberships[0].domain #=> String
    #   resp.data.db_instances[0].domain_memberships[0].status #=> String
    #   resp.data.db_instances[0].domain_memberships[0].fqdn #=> String
    #   resp.data.db_instances[0].domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_instances[0].copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_instances[0].monitoring_interval #=> Integer
    #   resp.data.db_instances[0].enhanced_monitoring_resource_arn #=> String
    #   resp.data.db_instances[0].monitoring_role_arn #=> String
    #   resp.data.db_instances[0].promotion_tier #=> Integer
    #   resp.data.db_instances[0].db_instance_arn #=> String
    #   resp.data.db_instances[0].timezone #=> String
    #   resp.data.db_instances[0].iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instances[0].performance_insights_enabled #=> Boolean
    #   resp.data.db_instances[0].performance_insights_kms_key_id #=> String
    #   resp.data.db_instances[0].performance_insights_retention_period #=> Integer
    #   resp.data.db_instances[0].enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_instances[0].processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instances[0].deletion_protection #=> Boolean
    #   resp.data.db_instances[0].associated_roles #=> Array<DBInstanceRole>
    #   resp.data.db_instances[0].associated_roles[0] #=> Types::DBInstanceRole
    #   resp.data.db_instances[0].associated_roles[0].role_arn #=> String
    #   resp.data.db_instances[0].associated_roles[0].feature_name #=> String
    #   resp.data.db_instances[0].associated_roles[0].status #=> String
    #   resp.data.db_instances[0].listener_endpoint #=> Types::Endpoint
    #   resp.data.db_instances[0].max_allocated_storage #=> Integer
    #   resp.data.db_instances[0].tag_list #=> Array<Tag>
    #   resp.data.db_instances[0].tag_list[0] #=> Types::Tag
    #   resp.data.db_instances[0].tag_list[0].key #=> String
    #   resp.data.db_instances[0].tag_list[0].value #=> String
    #   resp.data.db_instances[0].db_instance_automated_backups_replications #=> Array<DBInstanceAutomatedBackupsReplication>
    #   resp.data.db_instances[0].db_instance_automated_backups_replications[0] #=> Types::DBInstanceAutomatedBackupsReplication
    #   resp.data.db_instances[0].db_instance_automated_backups_replications[0].db_instance_automated_backups_arn #=> String
    #   resp.data.db_instances[0].customer_owned_ip_enabled #=> Boolean
    #   resp.data.db_instances[0].aws_backup_recovery_point_arn #=> String
    #   resp.data.db_instances[0].activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_instances[0].activity_stream_kms_key_id #=> String
    #   resp.data.db_instances[0].activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_instances[0].activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_instances[0].activity_stream_engine_native_audit_fields_included #=> Boolean
    #   resp.data.db_instances[0].automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instances[0].resume_full_automation_mode_time #=> Time
    #   resp.data.db_instances[0].custom_iam_instance_profile #=> String
    #   resp.data.db_instances[0].backup_target #=> String
    #   resp.data.db_instances[0].network_type #=> String
    #
    def describe_db_instances(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBInstancesInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBInstancesInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBInstances
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBInstanceNotFoundFault]),
        data_parser: Parsers::DescribeDBInstances
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBInstances,
        stubs: @stubs,
        params_class: Params::DescribeDBInstancesOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_instances
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns a list of DB log files for the DB instance.</p>
    #         <p>This command doesn't apply to RDS Custom.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBLogFilesInput}.
    #
    # @option params [String] :db_instance_identifier
    #   <p>The customer-assigned name of the DB instance that contains the log files you want to list.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the identifier of an existing DBInstance.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :filename_contains
    #   <p>Filters the available log files for log file names that contain the specified string.</p>
    #
    # @option params [Integer] :file_last_written
    #   <p>Filters the available log files for files written since the specified date, in POSIX timestamp format with milliseconds.</p>
    #
    # @option params [Integer] :file_size
    #   <p>Filters the available log files for files larger than the specified size.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response. If more records exist than the specified MaxRecords value, a pagination token called a marker is included in the response so you can retrieve the remaining results.</p>
    #
    # @option params [String] :marker
    #   <p>The pagination token provided in the previous request. If this parameter is specified the response includes only records beyond the marker, up to MaxRecords.</p>
    #
    # @return [Types::DescribeDBLogFilesOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_log_files(
    #     db_instance_identifier: 'DBInstanceIdentifier', # required
    #     filename_contains: 'FilenameContains',
    #     file_last_written: 1,
    #     file_size: 1,
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBLogFilesOutput
    #   resp.data.describe_db_log_files #=> Array<DescribeDBLogFilesDetails>
    #   resp.data.describe_db_log_files[0] #=> Types::DescribeDBLogFilesDetails
    #   resp.data.describe_db_log_files[0].log_file_name #=> String
    #   resp.data.describe_db_log_files[0].last_written #=> Integer
    #   resp.data.describe_db_log_files[0].size #=> Integer
    #   resp.data.marker #=> String
    #
    def describe_db_log_files(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBLogFilesInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBLogFilesInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBLogFiles
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBInstanceNotFoundFault]),
        data_parser: Parsers::DescribeDBLogFiles
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBLogFiles,
        stubs: @stubs,
        params_class: Params::DescribeDBLogFilesOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_log_files
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns a list of <code>DBParameterGroup</code> descriptions. If a <code>DBParameterGroupName</code> is specified,
    #             the list will contain only the description of the specified DB parameter group.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBParameterGroupsInput}.
    #
    # @option params [String] :db_parameter_group_name
    #   <p>The name of a specific DB parameter group to return details for.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match the name of an existing DBClusterParameterGroup.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #           If more records exist than the specified <code>MaxRecords</code> value,
    #               a pagination token called a marker is included in the response so that
    #           you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #           <code>DescribeDBParameterGroups</code> request.
    #               If this parameter is specified, the response includes
    #           only records beyond the marker,
    #           up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeDBParameterGroupsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_parameter_groups(
    #     db_parameter_group_name: 'DBParameterGroupName',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBParameterGroupsOutput
    #   resp.data.marker #=> String
    #   resp.data.db_parameter_groups #=> Array<DBParameterGroup>
    #   resp.data.db_parameter_groups[0] #=> Types::DBParameterGroup
    #   resp.data.db_parameter_groups[0].db_parameter_group_name #=> String
    #   resp.data.db_parameter_groups[0].db_parameter_group_family #=> String
    #   resp.data.db_parameter_groups[0].description #=> String
    #   resp.data.db_parameter_groups[0].db_parameter_group_arn #=> String
    #
    def describe_db_parameter_groups(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBParameterGroupsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBParameterGroupsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBParameterGroups
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBParameterGroupNotFoundFault]),
        data_parser: Parsers::DescribeDBParameterGroups
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBParameterGroups,
        stubs: @stubs,
        params_class: Params::DescribeDBParameterGroupsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_parameter_groups
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns the detailed parameter list for a particular DB parameter group.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBParametersInput}.
    #
    # @option params [String] :db_parameter_group_name
    #   <p>The name of a specific DB parameter group to return details for.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match the name of an existing DBParameterGroup.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :source
    #   <p>The parameter types to return.</p>
    #           <p>Default: All parameter types returned</p>
    #           <p>Valid Values: <code>user | system | engine-default</code>
    #            </p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #           If more records exist than the specified <code>MaxRecords</code> value,
    #               a pagination token called a marker is included in the response so that
    #           you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #           <code>DescribeDBParameters</code> request.
    #               If this parameter is specified, the response includes
    #           only records beyond the marker,
    #           up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeDBParametersOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_parameters(
    #     db_parameter_group_name: 'DBParameterGroupName', # required
    #     source: 'Source',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBParametersOutput
    #   resp.data.parameters #=> Array<Parameter>
    #   resp.data.parameters[0] #=> Types::Parameter
    #   resp.data.parameters[0].parameter_name #=> String
    #   resp.data.parameters[0].parameter_value #=> String
    #   resp.data.parameters[0].description #=> String
    #   resp.data.parameters[0].source #=> String
    #   resp.data.parameters[0].apply_type #=> String
    #   resp.data.parameters[0].data_type #=> String
    #   resp.data.parameters[0].allowed_values #=> String
    #   resp.data.parameters[0].is_modifiable #=> Boolean
    #   resp.data.parameters[0].minimum_engine_version #=> String
    #   resp.data.parameters[0].apply_method #=> String, one of ["immediate", "pending-reboot"]
    #   resp.data.parameters[0].supported_engine_modes #=> Array<String>
    #   resp.data.parameters[0].supported_engine_modes[0] #=> String
    #   resp.data.marker #=> String
    #
    def describe_db_parameters(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBParametersInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBParametersInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBParameters
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBParameterGroupNotFoundFault]),
        data_parser: Parsers::DescribeDBParameters
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBParameters,
        stubs: @stubs,
        params_class: Params::DescribeDBParametersOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_parameters
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns information about DB proxies.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBProxiesInput}.
    #
    # @option params [String] :db_proxy_name
    #   <p>The name of the DB proxy. If you omit this parameter,
    #           the output includes information about all DB proxies owned by
    #           your Amazon Web Services account ID.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter is not currently supported.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous request.
    #           If this parameter is specified, the response includes only records beyond the marker,
    #           up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response. If more records exist
    #             than the specified <code>MaxRecords</code> value, a pagination token called a marker is
    #             included in the response so that the remaining results can be retrieved.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @return [Types::DescribeDBProxiesOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_proxies(
    #     db_proxy_name: 'DBProxyName',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     marker: 'Marker',
    #     max_records: 1
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBProxiesOutput
    #   resp.data.db_proxies #=> Array<DBProxy>
    #   resp.data.db_proxies[0] #=> Types::DBProxy
    #   resp.data.db_proxies[0].db_proxy_name #=> String
    #   resp.data.db_proxies[0].db_proxy_arn #=> String
    #   resp.data.db_proxies[0].status #=> String, one of ["available", "modifying", "incompatible-network", "insufficient-resource-limits", "creating", "deleting", "suspended", "suspending", "reactivating"]
    #   resp.data.db_proxies[0].engine_family #=> String
    #   resp.data.db_proxies[0].vpc_id #=> String
    #   resp.data.db_proxies[0].vpc_security_group_ids #=> Array<String>
    #   resp.data.db_proxies[0].vpc_security_group_ids[0] #=> String
    #   resp.data.db_proxies[0].vpc_subnet_ids #=> Array<String>
    #   resp.data.db_proxies[0].auth #=> Array<UserAuthConfigInfo>
    #   resp.data.db_proxies[0].auth[0] #=> Types::UserAuthConfigInfo
    #   resp.data.db_proxies[0].auth[0].description #=> String
    #   resp.data.db_proxies[0].auth[0].user_name #=> String
    #   resp.data.db_proxies[0].auth[0].auth_scheme #=> String, one of ["SECRETS"]
    #   resp.data.db_proxies[0].auth[0].secret_arn #=> String
    #   resp.data.db_proxies[0].auth[0].iam_auth #=> String, one of ["DISABLED", "REQUIRED"]
    #   resp.data.db_proxies[0].role_arn #=> String
    #   resp.data.db_proxies[0].endpoint #=> String
    #   resp.data.db_proxies[0].require_tls #=> Boolean
    #   resp.data.db_proxies[0].idle_client_timeout #=> Integer
    #   resp.data.db_proxies[0].debug_logging #=> Boolean
    #   resp.data.db_proxies[0].created_date #=> Time
    #   resp.data.db_proxies[0].updated_date #=> Time
    #   resp.data.marker #=> String
    #
    def describe_db_proxies(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBProxiesInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBProxiesInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBProxies
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBProxyNotFoundFault]),
        data_parser: Parsers::DescribeDBProxies
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBProxies,
        stubs: @stubs,
        params_class: Params::DescribeDBProxiesOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_proxies
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns information about DB proxy endpoints.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBProxyEndpointsInput}.
    #
    # @option params [String] :db_proxy_name
    #   <p>The name of the DB proxy whose endpoints you want to describe. If you omit
    #           this parameter, the output includes information about all DB proxy endpoints
    #           associated with all your DB proxies.</p>
    #
    # @option params [String] :db_proxy_endpoint_name
    #   <p>The name of a DB proxy endpoint to describe. If you omit this parameter,
    #           the output includes information about all DB proxy endpoints associated with
    #           the specified proxy.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter is not currently supported.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous request.
    #           If this parameter is specified, the response includes only records beyond the marker,
    #           up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response. If more records exist
    #             than the specified <code>MaxRecords</code> value, a pagination token called a marker is
    #             included in the response so that the remaining results can be retrieved.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @return [Types::DescribeDBProxyEndpointsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_proxy_endpoints(
    #     db_proxy_name: 'DBProxyName',
    #     db_proxy_endpoint_name: 'DBProxyEndpointName',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     marker: 'Marker',
    #     max_records: 1
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBProxyEndpointsOutput
    #   resp.data.db_proxy_endpoints #=> Array<DBProxyEndpoint>
    #   resp.data.db_proxy_endpoints[0] #=> Types::DBProxyEndpoint
    #   resp.data.db_proxy_endpoints[0].db_proxy_endpoint_name #=> String
    #   resp.data.db_proxy_endpoints[0].db_proxy_endpoint_arn #=> String
    #   resp.data.db_proxy_endpoints[0].db_proxy_name #=> String
    #   resp.data.db_proxy_endpoints[0].status #=> String, one of ["available", "modifying", "incompatible-network", "insufficient-resource-limits", "creating", "deleting"]
    #   resp.data.db_proxy_endpoints[0].vpc_id #=> String
    #   resp.data.db_proxy_endpoints[0].vpc_security_group_ids #=> Array<String>
    #   resp.data.db_proxy_endpoints[0].vpc_security_group_ids[0] #=> String
    #   resp.data.db_proxy_endpoints[0].vpc_subnet_ids #=> Array<String>
    #   resp.data.db_proxy_endpoints[0].endpoint #=> String
    #   resp.data.db_proxy_endpoints[0].created_date #=> Time
    #   resp.data.db_proxy_endpoints[0].target_role #=> String, one of ["READ_WRITE", "READ_ONLY"]
    #   resp.data.db_proxy_endpoints[0].is_default #=> Boolean
    #   resp.data.marker #=> String
    #
    def describe_db_proxy_endpoints(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBProxyEndpointsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBProxyEndpointsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBProxyEndpoints
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBProxyNotFoundFault, Errors::DBProxyEndpointNotFoundFault]),
        data_parser: Parsers::DescribeDBProxyEndpoints
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBProxyEndpoints,
        stubs: @stubs,
        params_class: Params::DescribeDBProxyEndpointsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_proxy_endpoints
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns information about DB proxy target groups, represented by <code>DBProxyTargetGroup</code> data structures.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBProxyTargetGroupsInput}.
    #
    # @option params [String] :db_proxy_name
    #   <p>The identifier of the <code>DBProxy</code> associated with the target group.</p>
    #
    # @option params [String] :target_group_name
    #   <p>The identifier of the <code>DBProxyTargetGroup</code> to describe.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter is not currently supported.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous request.
    #           If this parameter is specified, the response includes only records beyond the marker,
    #           up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #           If more records exist than the specified <code>MaxRecords</code> value,
    #           a pagination token called a marker is included in the response so that the remaining
    #           results can be retrieved.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @return [Types::DescribeDBProxyTargetGroupsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_proxy_target_groups(
    #     db_proxy_name: 'DBProxyName', # required
    #     target_group_name: 'TargetGroupName',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     marker: 'Marker',
    #     max_records: 1
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBProxyTargetGroupsOutput
    #   resp.data.target_groups #=> Array<DBProxyTargetGroup>
    #   resp.data.target_groups[0] #=> Types::DBProxyTargetGroup
    #   resp.data.target_groups[0].db_proxy_name #=> String
    #   resp.data.target_groups[0].target_group_name #=> String
    #   resp.data.target_groups[0].target_group_arn #=> String
    #   resp.data.target_groups[0].is_default #=> Boolean
    #   resp.data.target_groups[0].status #=> String
    #   resp.data.target_groups[0].connection_pool_config #=> Types::ConnectionPoolConfigurationInfo
    #   resp.data.target_groups[0].connection_pool_config.max_connections_percent #=> Integer
    #   resp.data.target_groups[0].connection_pool_config.max_idle_connections_percent #=> Integer
    #   resp.data.target_groups[0].connection_pool_config.connection_borrow_timeout #=> Integer
    #   resp.data.target_groups[0].connection_pool_config.session_pinning_filters #=> Array<String>
    #   resp.data.target_groups[0].connection_pool_config.session_pinning_filters[0] #=> String
    #   resp.data.target_groups[0].connection_pool_config.init_query #=> String
    #   resp.data.target_groups[0].created_date #=> Time
    #   resp.data.target_groups[0].updated_date #=> Time
    #   resp.data.marker #=> String
    #
    def describe_db_proxy_target_groups(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBProxyTargetGroupsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBProxyTargetGroupsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBProxyTargetGroups
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBProxyTargetGroupNotFoundFault, Errors::DBProxyNotFoundFault, Errors::InvalidDBProxyStateFault]),
        data_parser: Parsers::DescribeDBProxyTargetGroups
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBProxyTargetGroups,
        stubs: @stubs,
        params_class: Params::DescribeDBProxyTargetGroupsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_proxy_target_groups
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns information about <code>DBProxyTarget</code> objects. This API supports pagination.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBProxyTargetsInput}.
    #
    # @option params [String] :db_proxy_name
    #   <p>The identifier of the <code>DBProxyTarget</code> to describe.</p>
    #
    # @option params [String] :target_group_name
    #   <p>The identifier of the <code>DBProxyTargetGroup</code> to describe.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter is not currently supported.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous request.
    #           If this parameter is specified, the response includes only records beyond the marker,
    #           up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #           If more records exist than the specified <code>MaxRecords</code> value,
    #           a pagination token called a marker is included in the response so that the remaining
    #           results can be retrieved.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @return [Types::DescribeDBProxyTargetsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_proxy_targets(
    #     db_proxy_name: 'DBProxyName', # required
    #     target_group_name: 'TargetGroupName',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     marker: 'Marker',
    #     max_records: 1
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBProxyTargetsOutput
    #   resp.data.targets #=> Array<DBProxyTarget>
    #   resp.data.targets[0] #=> Types::DBProxyTarget
    #   resp.data.targets[0].target_arn #=> String
    #   resp.data.targets[0].endpoint #=> String
    #   resp.data.targets[0].tracked_cluster_id #=> String
    #   resp.data.targets[0].rds_resource_id #=> String
    #   resp.data.targets[0].port #=> Integer
    #   resp.data.targets[0].type #=> String, one of ["RDS_INSTANCE", "RDS_SERVERLESS_ENDPOINT", "TRACKED_CLUSTER"]
    #   resp.data.targets[0].role #=> String, one of ["READ_WRITE", "READ_ONLY", "UNKNOWN"]
    #   resp.data.targets[0].target_health #=> Types::TargetHealth
    #   resp.data.targets[0].target_health.state #=> String, one of ["REGISTERING", "AVAILABLE", "UNAVAILABLE"]
    #   resp.data.targets[0].target_health.reason #=> String, one of ["UNREACHABLE", "CONNECTION_FAILED", "AUTH_FAILURE", "PENDING_PROXY_CAPACITY", "INVALID_REPLICATION_STATE"]
    #   resp.data.targets[0].target_health.description #=> String
    #   resp.data.marker #=> String
    #
    def describe_db_proxy_targets(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBProxyTargetsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBProxyTargetsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBProxyTargets
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBProxyTargetGroupNotFoundFault, Errors::DBProxyNotFoundFault, Errors::DBProxyTargetNotFoundFault, Errors::InvalidDBProxyStateFault]),
        data_parser: Parsers::DescribeDBProxyTargets
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBProxyTargets,
        stubs: @stubs,
        params_class: Params::DescribeDBProxyTargetsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_proxy_targets
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns a list of <code>DBSecurityGroup</code> descriptions. If a <code>DBSecurityGroupName</code> is specified,
    #             the list will contain only the descriptions of the specified DB security group.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBSecurityGroupsInput}.
    #
    # @option params [String] :db_security_group_name
    #   <p>The name of the DB security group to return details for.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #           If more records exist than the specified <code>MaxRecords</code> value,
    #           a pagination token called a marker is included in the response so that
    #           you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #           <code>DescribeDBSecurityGroups</code> request.
    #           If this parameter is specified, the response includes
    #           only records beyond the marker,
    #           up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeDBSecurityGroupsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_security_groups(
    #     db_security_group_name: 'DBSecurityGroupName',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBSecurityGroupsOutput
    #   resp.data.marker #=> String
    #   resp.data.db_security_groups #=> Array<DBSecurityGroup>
    #   resp.data.db_security_groups[0] #=> Types::DBSecurityGroup
    #   resp.data.db_security_groups[0].owner_id #=> String
    #   resp.data.db_security_groups[0].db_security_group_name #=> String
    #   resp.data.db_security_groups[0].db_security_group_description #=> String
    #   resp.data.db_security_groups[0].vpc_id #=> String
    #   resp.data.db_security_groups[0].ec2_security_groups #=> Array<EC2SecurityGroup>
    #   resp.data.db_security_groups[0].ec2_security_groups[0] #=> Types::EC2SecurityGroup
    #   resp.data.db_security_groups[0].ec2_security_groups[0].status #=> String
    #   resp.data.db_security_groups[0].ec2_security_groups[0].ec2_security_group_name #=> String
    #   resp.data.db_security_groups[0].ec2_security_groups[0].ec2_security_group_id #=> String
    #   resp.data.db_security_groups[0].ec2_security_groups[0].ec2_security_group_owner_id #=> String
    #   resp.data.db_security_groups[0].ip_ranges #=> Array<IPRange>
    #   resp.data.db_security_groups[0].ip_ranges[0] #=> Types::IPRange
    #   resp.data.db_security_groups[0].ip_ranges[0].status #=> String
    #   resp.data.db_security_groups[0].ip_ranges[0].cidrip #=> String
    #   resp.data.db_security_groups[0].db_security_group_arn #=> String
    #
    def describe_db_security_groups(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBSecurityGroupsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBSecurityGroupsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBSecurityGroups
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBSecurityGroupNotFoundFault]),
        data_parser: Parsers::DescribeDBSecurityGroups
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBSecurityGroups,
        stubs: @stubs,
        params_class: Params::DescribeDBSecurityGroupsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_security_groups
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns a list of DB snapshot attribute names and values for a manual DB snapshot.</p>
    #         <p>When sharing snapshots with other Amazon Web Services accounts, <code>DescribeDBSnapshotAttributes</code>
    #       returns the <code>restore</code> attribute and a list of IDs for the Amazon Web Services accounts that are
    #       authorized to copy or restore the manual DB snapshot. If <code>all</code> is included in the list of
    #       values for the <code>restore</code> attribute, then the manual DB snapshot is public and
    #       can be copied or restored by all Amazon Web Services accounts.</p>
    #         <p>To add or remove access for an Amazon Web Services account to copy or restore a manual DB snapshot, or to make the
    #       manual DB snapshot public or private, use the <code>ModifyDBSnapshotAttribute</code> API action.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBSnapshotAttributesInput}.
    #
    # @option params [String] :db_snapshot_identifier
    #   <p>The identifier for the DB snapshot to describe the attributes for.</p>
    #
    # @return [Types::DescribeDBSnapshotAttributesOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_snapshot_attributes(
    #     db_snapshot_identifier: 'DBSnapshotIdentifier' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBSnapshotAttributesOutput
    #   resp.data.db_snapshot_attributes_result #=> Types::DBSnapshotAttributesResult
    #   resp.data.db_snapshot_attributes_result.db_snapshot_identifier #=> String
    #   resp.data.db_snapshot_attributes_result.db_snapshot_attributes #=> Array<DBSnapshotAttribute>
    #   resp.data.db_snapshot_attributes_result.db_snapshot_attributes[0] #=> Types::DBSnapshotAttribute
    #   resp.data.db_snapshot_attributes_result.db_snapshot_attributes[0].attribute_name #=> String
    #   resp.data.db_snapshot_attributes_result.db_snapshot_attributes[0].attribute_values #=> Array<String>
    #   resp.data.db_snapshot_attributes_result.db_snapshot_attributes[0].attribute_values[0] #=> String
    #
    def describe_db_snapshot_attributes(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBSnapshotAttributesInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBSnapshotAttributesInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBSnapshotAttributes
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBSnapshotNotFoundFault]),
        data_parser: Parsers::DescribeDBSnapshotAttributes
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBSnapshotAttributes,
        stubs: @stubs,
        params_class: Params::DescribeDBSnapshotAttributesOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_snapshot_attributes
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns information about DB snapshots. This API action supports pagination.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBSnapshotsInput}.
    #
    # @option params [String] :db_instance_identifier
    #   <p>The ID of the DB instance to retrieve the list of DB snapshots for.
    #           This parameter can't be used in conjunction with <code>DBSnapshotIdentifier</code>.
    #           This parameter isn't case-sensitive.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match the identifier of an existing DBInstance.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :db_snapshot_identifier
    #   <p>A specific DB snapshot identifier to describe. This parameter can't be used in conjunction with <code>DBInstanceIdentifier</code>.
    #               This value is stored as a lowercase string.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match the identifier of an existing DBSnapshot.</p>
    #               </li>
    #               <li>
    #                   <p>If this identifier is for an automated snapshot, the <code>SnapshotType</code> parameter must also be specified.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :snapshot_type
    #   <p>The type of snapshots to be returned. You can specify one of the following values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>automated</code> - Return all DB snapshots that have been automatically taken by
    #         Amazon RDS for my Amazon Web Services account.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>manual</code> - Return all DB snapshots that have been taken by my Amazon Web Services account.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>shared</code> - Return all manual DB snapshots that have been shared to my Amazon Web Services account.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>public</code> - Return all DB snapshots that have been marked as public.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>awsbackup</code> - Return the DB snapshots managed by the Amazon Web Services Backup service.</p>
    #                   <p>For information about Amazon Web Services Backup, see the
    #                     <a href="https://docs.aws.amazon.com/aws-backup/latest/devguide/whatisbackup.html">
    #                           <i>Amazon Web Services Backup Developer Guide.</i>
    #                       </a>
    #                  </p>
    #                   <p>The <code>awsbackup</code> type does not apply to Aurora.</p>
    #               </li>
    #            </ul>
    #           <p>If you don't specify a <code>SnapshotType</code> value, then both automated and manual snapshots are
    #         returned. Shared and public DB snapshots are not included in the returned results by default.
    #         You can include shared snapshots with these results by enabling the <code>IncludeShared</code>
    #         parameter. You can include public snapshots with these results by enabling the
    #         <code>IncludePublic</code> parameter.</p>
    #           <p>The <code>IncludeShared</code> and <code>IncludePublic</code> parameters don't apply for <code>SnapshotType</code> values
    #         of <code>manual</code> or <code>automated</code>. The <code>IncludePublic</code> parameter doesn't apply when <code>SnapshotType</code> is
    #         set to <code>shared</code>. The <code>IncludeShared</code> parameter doesn't apply when <code>SnapshotType</code> is set to
    #         <code>public</code>.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>A filter that specifies one or more DB snapshots to describe.</p>
    #           <p>Supported filters:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>db-instance-id</code> - Accepts DB instance identifiers and DB
    #                 instance Amazon Resource Names (ARNs).</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>db-snapshot-id</code> - Accepts DB snapshot identifiers.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>dbi-resource-id</code> - Accepts identifiers of source DB instances.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>snapshot-type</code> - Accepts types of DB snapshots.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>engine</code> - Accepts names of database engines.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #           If more records exist than the specified <code>MaxRecords</code> value,
    #           a pagination token called a marker is included in the response so that
    #           you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #           <code>DescribeDBSnapshots</code> request.
    #               If this parameter is specified, the response includes
    #           only records beyond the marker,
    #           up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @option params [Boolean] :include_shared
    #   <p>A value that indicates whether to include shared manual DB cluster snapshots
    #             from other Amazon Web Services accounts that this Amazon Web Services account has been given
    #             permission to copy or restore. By default, these snapshots are not included.</p>
    #           <p>You can give an Amazon Web Services account permission to restore a manual DB snapshot from
    #       another Amazon Web Services account by using the <code>ModifyDBSnapshotAttribute</code> API action.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :include_public
    #   <p>A value that indicates whether to include manual DB cluster snapshots that are public and can be copied
    #             or restored by any Amazon Web Services account. By default, the public snapshots are not included.</p>
    #           <p>You can share a manual DB snapshot as public by using the <a>ModifyDBSnapshotAttribute</a> API.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :dbi_resource_id
    #   <p>A specific DB resource ID to describe.</p>
    #
    # @return [Types::DescribeDBSnapshotsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_snapshots(
    #     db_instance_identifier: 'DBInstanceIdentifier',
    #     db_snapshot_identifier: 'DBSnapshotIdentifier',
    #     snapshot_type: 'SnapshotType',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker',
    #     include_shared: false,
    #     include_public: false,
    #     dbi_resource_id: 'DbiResourceId'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBSnapshotsOutput
    #   resp.data.marker #=> String
    #   resp.data.db_snapshots #=> Array<DBSnapshot>
    #   resp.data.db_snapshots[0] #=> Types::DBSnapshot
    #   resp.data.db_snapshots[0].db_snapshot_identifier #=> String
    #   resp.data.db_snapshots[0].db_instance_identifier #=> String
    #   resp.data.db_snapshots[0].snapshot_create_time #=> Time
    #   resp.data.db_snapshots[0].engine #=> String
    #   resp.data.db_snapshots[0].allocated_storage #=> Integer
    #   resp.data.db_snapshots[0].status #=> String
    #   resp.data.db_snapshots[0].port #=> Integer
    #   resp.data.db_snapshots[0].availability_zone #=> String
    #   resp.data.db_snapshots[0].vpc_id #=> String
    #   resp.data.db_snapshots[0].instance_create_time #=> Time
    #   resp.data.db_snapshots[0].master_username #=> String
    #   resp.data.db_snapshots[0].engine_version #=> String
    #   resp.data.db_snapshots[0].license_model #=> String
    #   resp.data.db_snapshots[0].snapshot_type #=> String
    #   resp.data.db_snapshots[0].iops #=> Integer
    #   resp.data.db_snapshots[0].option_group_name #=> String
    #   resp.data.db_snapshots[0].percent_progress #=> Integer
    #   resp.data.db_snapshots[0].source_region #=> String
    #   resp.data.db_snapshots[0].source_db_snapshot_identifier #=> String
    #   resp.data.db_snapshots[0].storage_type #=> String
    #   resp.data.db_snapshots[0].tde_credential_arn #=> String
    #   resp.data.db_snapshots[0].encrypted #=> Boolean
    #   resp.data.db_snapshots[0].kms_key_id #=> String
    #   resp.data.db_snapshots[0].db_snapshot_arn #=> String
    #   resp.data.db_snapshots[0].timezone #=> String
    #   resp.data.db_snapshots[0].iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_snapshots[0].processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_snapshots[0].processor_features[0] #=> Types::ProcessorFeature
    #   resp.data.db_snapshots[0].processor_features[0].name #=> String
    #   resp.data.db_snapshots[0].processor_features[0].value #=> String
    #   resp.data.db_snapshots[0].dbi_resource_id #=> String
    #   resp.data.db_snapshots[0].tag_list #=> Array<Tag>
    #   resp.data.db_snapshots[0].tag_list[0] #=> Types::Tag
    #   resp.data.db_snapshots[0].tag_list[0].key #=> String
    #   resp.data.db_snapshots[0].tag_list[0].value #=> String
    #   resp.data.db_snapshots[0].original_snapshot_create_time #=> Time
    #   resp.data.db_snapshots[0].snapshot_target #=> String
    #
    def describe_db_snapshots(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBSnapshotsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBSnapshotsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBSnapshots
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBSnapshotNotFoundFault]),
        data_parser: Parsers::DescribeDBSnapshots
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBSnapshots,
        stubs: @stubs,
        params_class: Params::DescribeDBSnapshotsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_snapshots
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns a list of DBSubnetGroup descriptions. If a DBSubnetGroupName is specified, the list will contain only the descriptions of the specified DBSubnetGroup.</p>
    #         <p>For an overview of CIDR ranges, go to the
    #             <a href="http://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing">Wikipedia Tutorial</a>.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeDBSubnetGroupsInput}.
    #
    # @option params [String] :db_subnet_group_name
    #   <p>The name of the DB subnet group to return details for.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #           If more records exist than the specified <code>MaxRecords</code> value,
    #           a pagination token called a marker is included in the response so that
    #           you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous DescribeDBSubnetGroups request.
    #               If this parameter is specified, the response includes
    #               only records beyond the marker,
    #               up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeDBSubnetGroupsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_db_subnet_groups(
    #     db_subnet_group_name: 'DBSubnetGroupName',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeDBSubnetGroupsOutput
    #   resp.data.marker #=> String
    #   resp.data.db_subnet_groups #=> Array<DBSubnetGroup>
    #   resp.data.db_subnet_groups[0] #=> Types::DBSubnetGroup
    #   resp.data.db_subnet_groups[0].db_subnet_group_name #=> String
    #   resp.data.db_subnet_groups[0].db_subnet_group_description #=> String
    #   resp.data.db_subnet_groups[0].vpc_id #=> String
    #   resp.data.db_subnet_groups[0].subnet_group_status #=> String
    #   resp.data.db_subnet_groups[0].subnets #=> Array<Subnet>
    #   resp.data.db_subnet_groups[0].subnets[0] #=> Types::Subnet
    #   resp.data.db_subnet_groups[0].subnets[0].subnet_identifier #=> String
    #   resp.data.db_subnet_groups[0].subnets[0].subnet_availability_zone #=> Types::AvailabilityZone
    #   resp.data.db_subnet_groups[0].subnets[0].subnet_availability_zone.name #=> String
    #   resp.data.db_subnet_groups[0].subnets[0].subnet_outpost #=> Types::Outpost
    #   resp.data.db_subnet_groups[0].subnets[0].subnet_outpost.arn #=> String
    #   resp.data.db_subnet_groups[0].subnets[0].subnet_status #=> String
    #   resp.data.db_subnet_groups[0].db_subnet_group_arn #=> String
    #   resp.data.db_subnet_groups[0].supported_network_types #=> Array<String>
    #   resp.data.db_subnet_groups[0].supported_network_types[0] #=> String
    #
    def describe_db_subnet_groups(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeDBSubnetGroupsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeDBSubnetGroupsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeDBSubnetGroups
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBSubnetGroupNotFoundFault]),
        data_parser: Parsers::DescribeDBSubnetGroups
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeDBSubnetGroups,
        stubs: @stubs,
        params_class: Params::DescribeDBSubnetGroupsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_db_subnet_groups
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns the default engine and system parameter information for the cluster database engine.</p>
    #         <p>For more information on Amazon Aurora, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #               What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeEngineDefaultClusterParametersInput}.
    #
    # @option params [String] :db_parameter_group_family
    #   <p>The name of the DB cluster parameter group family to return engine parameter information for.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #         If more records exist than the specified <code>MaxRecords</code> value,
    #             a pagination token called a marker is included in the response so you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #         <code>DescribeEngineDefaultClusterParameters</code> request.
    #         If this parameter is specified, the response includes
    #         only records beyond the marker,
    #         up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeEngineDefaultClusterParametersOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_engine_default_cluster_parameters(
    #     db_parameter_group_family: 'DBParameterGroupFamily', # required
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeEngineDefaultClusterParametersOutput
    #   resp.data.engine_defaults #=> Types::EngineDefaults
    #   resp.data.engine_defaults.db_parameter_group_family #=> String
    #   resp.data.engine_defaults.marker #=> String
    #   resp.data.engine_defaults.parameters #=> Array<Parameter>
    #   resp.data.engine_defaults.parameters[0] #=> Types::Parameter
    #   resp.data.engine_defaults.parameters[0].parameter_name #=> String
    #   resp.data.engine_defaults.parameters[0].parameter_value #=> String
    #   resp.data.engine_defaults.parameters[0].description #=> String
    #   resp.data.engine_defaults.parameters[0].source #=> String
    #   resp.data.engine_defaults.parameters[0].apply_type #=> String
    #   resp.data.engine_defaults.parameters[0].data_type #=> String
    #   resp.data.engine_defaults.parameters[0].allowed_values #=> String
    #   resp.data.engine_defaults.parameters[0].is_modifiable #=> Boolean
    #   resp.data.engine_defaults.parameters[0].minimum_engine_version #=> String
    #   resp.data.engine_defaults.parameters[0].apply_method #=> String, one of ["immediate", "pending-reboot"]
    #   resp.data.engine_defaults.parameters[0].supported_engine_modes #=> Array<String>
    #   resp.data.engine_defaults.parameters[0].supported_engine_modes[0] #=> String
    #
    def describe_engine_default_cluster_parameters(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeEngineDefaultClusterParametersInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeEngineDefaultClusterParametersInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeEngineDefaultClusterParameters
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: []),
        data_parser: Parsers::DescribeEngineDefaultClusterParameters
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeEngineDefaultClusterParameters,
        stubs: @stubs,
        params_class: Params::DescribeEngineDefaultClusterParametersOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_engine_default_cluster_parameters
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns the default engine and system parameter information for the specified database engine.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeEngineDefaultParametersInput}.
    #
    # @option params [String] :db_parameter_group_family
    #   <p>The name of the DB parameter group family.</p>
    #           <p>Valid Values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>aurora5.6</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-mysql5.7</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-mysql8.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-postgresql10</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-postgresql11</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-postgresql12</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-postgresql13</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mariadb10.2</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mariadb10.3</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mariadb10.4</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mariadb10.5</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mariadb10.6</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mysql5.7</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mysql8.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>postgres10</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>postgres11</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>postgres12</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>postgres13</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>postgres14</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ee-11.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ee-12.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ee-13.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ee-14.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ee-15.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ex-11.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ex-12.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ex-13.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ex-14.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ex-15.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-se-11.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-se-12.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-se-13.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-se-14.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-se-15.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-web-11.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-web-12.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-web-13.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-web-14.0</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-web-15.0</code>
    #                  </p>
    #               </li>
    #            </ul>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #           If more records exist than the specified <code>MaxRecords</code> value,
    #             a pagination token called a marker is included in the response so you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #           <code>DescribeEngineDefaultParameters</code> request.
    #               If this parameter is specified, the response includes
    #           only records beyond the marker,
    #           up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeEngineDefaultParametersOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_engine_default_parameters(
    #     db_parameter_group_family: 'DBParameterGroupFamily', # required
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeEngineDefaultParametersOutput
    #   resp.data.engine_defaults #=> Types::EngineDefaults
    #   resp.data.engine_defaults.db_parameter_group_family #=> String
    #   resp.data.engine_defaults.marker #=> String
    #   resp.data.engine_defaults.parameters #=> Array<Parameter>
    #   resp.data.engine_defaults.parameters[0] #=> Types::Parameter
    #   resp.data.engine_defaults.parameters[0].parameter_name #=> String
    #   resp.data.engine_defaults.parameters[0].parameter_value #=> String
    #   resp.data.engine_defaults.parameters[0].description #=> String
    #   resp.data.engine_defaults.parameters[0].source #=> String
    #   resp.data.engine_defaults.parameters[0].apply_type #=> String
    #   resp.data.engine_defaults.parameters[0].data_type #=> String
    #   resp.data.engine_defaults.parameters[0].allowed_values #=> String
    #   resp.data.engine_defaults.parameters[0].is_modifiable #=> Boolean
    #   resp.data.engine_defaults.parameters[0].minimum_engine_version #=> String
    #   resp.data.engine_defaults.parameters[0].apply_method #=> String, one of ["immediate", "pending-reboot"]
    #   resp.data.engine_defaults.parameters[0].supported_engine_modes #=> Array<String>
    #   resp.data.engine_defaults.parameters[0].supported_engine_modes[0] #=> String
    #
    def describe_engine_default_parameters(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeEngineDefaultParametersInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeEngineDefaultParametersInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeEngineDefaultParameters
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: []),
        data_parser: Parsers::DescribeEngineDefaultParameters
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeEngineDefaultParameters,
        stubs: @stubs,
        params_class: Params::DescribeEngineDefaultParametersOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_engine_default_parameters
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Displays a list of categories for all event source types, or, if specified, for a specified source type.
    #             You can also see this list in the "Amazon RDS event categories and event messages" section of the <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.Messages.html">
    #                 <i>Amazon RDS User Guide</i>
    #             </a> or the
    #                 <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_Events.Messages.html">
    #                 <i>Amazon Aurora User Guide</i>
    #             </a>.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeEventCategoriesInput}.
    #
    # @option params [String] :source_type
    #   <p>The type of source that is generating the events. For RDS Proxy events, specify <code>db-proxy</code>.</p>
    #           <p>Valid values: <code>db-instance</code> | <code>db-cluster</code> | <code>db-parameter-group</code> | <code>db-security-group</code> | <code>db-snapshot</code> | <code>db-cluster-snapshot</code> | <code>db-proxy</code>
    #            </p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @return [Types::DescribeEventCategoriesOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_event_categories(
    #     source_type: 'SourceType',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeEventCategoriesOutput
    #   resp.data.event_categories_map_list #=> Array<EventCategoriesMap>
    #   resp.data.event_categories_map_list[0] #=> Types::EventCategoriesMap
    #   resp.data.event_categories_map_list[0].source_type #=> String
    #   resp.data.event_categories_map_list[0].event_categories #=> Array<String>
    #   resp.data.event_categories_map_list[0].event_categories[0] #=> String
    #
    def describe_event_categories(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeEventCategoriesInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeEventCategoriesInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeEventCategories
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: []),
        data_parser: Parsers::DescribeEventCategories
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeEventCategories,
        stubs: @stubs,
        params_class: Params::DescribeEventCategoriesOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_event_categories
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Lists all the subscription descriptions for a customer account. The description for a subscription includes
    #           <code>SubscriptionName</code>, <code>SNSTopicARN</code>, <code>CustomerID</code>, <code>SourceType</code>, <code>SourceID</code>, <code>CreationTime</code>, and <code>Status</code>.</p>
    #         <p>If you specify a <code>SubscriptionName</code>, lists the description for that subscription.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeEventSubscriptionsInput}.
    #
    # @option params [String] :subscription_name
    #   <p>The name of the RDS event notification subscription you want to describe.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #               If more records exist than the specified <code>MaxRecords</code> value,
    #               a pagination token called a marker is included in the response so that
    #               you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #               DescribeOrderableDBInstanceOptions request.
    #               If this parameter is specified, the response includes
    #               only records beyond the marker,
    #               up to the value specified by <code>MaxRecords</code> .</p>
    #
    # @return [Types::DescribeEventSubscriptionsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_event_subscriptions(
    #     subscription_name: 'SubscriptionName',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeEventSubscriptionsOutput
    #   resp.data.marker #=> String
    #   resp.data.event_subscriptions_list #=> Array<EventSubscription>
    #   resp.data.event_subscriptions_list[0] #=> Types::EventSubscription
    #   resp.data.event_subscriptions_list[0].customer_aws_id #=> String
    #   resp.data.event_subscriptions_list[0].cust_subscription_id #=> String
    #   resp.data.event_subscriptions_list[0].sns_topic_arn #=> String
    #   resp.data.event_subscriptions_list[0].status #=> String
    #   resp.data.event_subscriptions_list[0].subscription_creation_time #=> String
    #   resp.data.event_subscriptions_list[0].source_type #=> String
    #   resp.data.event_subscriptions_list[0].source_ids_list #=> Array<String>
    #   resp.data.event_subscriptions_list[0].source_ids_list[0] #=> String
    #   resp.data.event_subscriptions_list[0].event_categories_list #=> Array<String>
    #   resp.data.event_subscriptions_list[0].event_categories_list[0] #=> String
    #   resp.data.event_subscriptions_list[0].enabled #=> Boolean
    #   resp.data.event_subscriptions_list[0].event_subscription_arn #=> String
    #
    def describe_event_subscriptions(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeEventSubscriptionsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeEventSubscriptionsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeEventSubscriptions
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::SubscriptionNotFoundFault]),
        data_parser: Parsers::DescribeEventSubscriptions
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeEventSubscriptions,
        stubs: @stubs,
        params_class: Params::DescribeEventSubscriptionsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_event_subscriptions
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns events related to DB instances, DB clusters, DB parameter groups, DB security groups, DB snapshots, DB cluster snapshots, and RDS Proxies for the past 14 days.
    #           Events specific to a particular DB instance, DB cluster, DB parameter group, DB security group, DB snapshot, DB cluster snapshot group, or RDS Proxy can be
    #           obtained by providing the name as a parameter.</p>
    #         <note>
    #             <p>By default, RDS returns events that were generated in the past hour.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::DescribeEventsInput}.
    #
    # @option params [String] :source_identifier
    #   <p>The identifier of the event source for which events are returned. If not specified, then all sources are included in the response.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If <code>SourceIdentifier</code> is supplied, <code>SourceType</code> must also be provided.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is a DB instance, a <code>DBInstanceIdentifier</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is a DB cluster, a <code>DBClusterIdentifier</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is a DB parameter group, a <code>DBParameterGroupName</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is a DB security group, a <code>DBSecurityGroupName</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is a DB snapshot, a <code>DBSnapshotIdentifier</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is a DB cluster snapshot, a <code>DBClusterSnapshotIdentifier</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>If the source type is an RDS Proxy, a <code>DBProxyName</code> value must be supplied.</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :source_type
    #   <p>The event source to retrieve events for. If no value is specified, all events are returned.</p>
    #
    # @option params [Time] :start_time
    #   <p>The beginning of the time interval to retrieve events for,
    #           specified in ISO 8601 format. For more information about ISO 8601,
    #           go to the <a href="http://en.wikipedia.org/wiki/ISO_8601">ISO8601 Wikipedia page.</a>
    #            </p>
    #           <p>Example: 2009-07-08T18:00Z</p>
    #
    # @option params [Time] :end_time
    #   <p>The end of the time interval for which to retrieve events,
    #           specified in ISO 8601 format. For more information about ISO 8601,
    #           go to the <a href="http://en.wikipedia.org/wiki/ISO_8601">ISO8601 Wikipedia page.</a>
    #            </p>
    #           <p>Example: 2009-07-08T18:00Z</p>
    #
    # @option params [Integer] :duration
    #   <p>The number of minutes to retrieve events for.</p>
    #           <p>Default: 60</p>
    #
    # @option params [Array<String>] :event_categories
    #   <p>A list of event categories that trigger notifications for a event notification subscription.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #           If more records exist than the specified <code>MaxRecords</code> value,
    #               a pagination token called a marker is included in the response so that
    #           you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #           DescribeEvents request.
    #           If this parameter is specified, the response includes
    #           only records beyond the marker,
    #           up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeEventsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_events(
    #     source_identifier: 'SourceIdentifier',
    #     source_type: 'db-instance', # accepts ["db-instance", "db-parameter-group", "db-security-group", "db-snapshot", "db-cluster", "db-cluster-snapshot", "custom-engine-version", "db-proxy"]
    #     start_time: Time.now,
    #     end_time: Time.now,
    #     duration: 1,
    #     event_categories: [
    #       'member'
    #     ],
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeEventsOutput
    #   resp.data.marker #=> String
    #   resp.data.events #=> Array<Event>
    #   resp.data.events[0] #=> Types::Event
    #   resp.data.events[0].source_identifier #=> String
    #   resp.data.events[0].source_type #=> String, one of ["db-instance", "db-parameter-group", "db-security-group", "db-snapshot", "db-cluster", "db-cluster-snapshot", "custom-engine-version", "db-proxy"]
    #   resp.data.events[0].message #=> String
    #   resp.data.events[0].event_categories #=> Array<String>
    #   resp.data.events[0].event_categories[0] #=> String
    #   resp.data.events[0].date #=> Time
    #   resp.data.events[0].source_arn #=> String
    #
    def describe_events(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeEventsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeEventsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeEvents
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: []),
        data_parser: Parsers::DescribeEvents
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeEvents,
        stubs: @stubs,
        params_class: Params::DescribeEventsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_events
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns information about a snapshot export to Amazon S3. This API operation supports
    #             pagination.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeExportTasksInput}.
    #
    # @option params [String] :export_task_identifier
    #   <p>The identifier of the snapshot export task to be described.</p>
    #
    # @option params [String] :source_arn
    #   <p>The Amazon Resource Name (ARN) of the snapshot exported to Amazon S3.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>Filters specify one or more snapshot exports to describe. The filters are specified as name-value pairs that define what to
    #               include in the output. Filter names and values are case-sensitive.</p>
    #           <p>Supported filters include the following:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>export-task-identifier</code> - An identifier for the snapshot export task.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>s3-bucket</code> - The Amazon S3 bucket the snapshot is exported to.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>source-arn</code> - The Amazon Resource Name (ARN) of the snapshot exported to Amazon S3</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>status</code> - The status of the export task. Must be lowercase. Valid statuses are the following:</p>
    #                   <ul>
    #                     <li>
    #                           <p>
    #                           <code>canceled</code>
    #                        </p>
    #                       </li>
    #                     <li>
    #                           <p>
    #                           <code>canceling</code>
    #                        </p>
    #                       </li>
    #                     <li>
    #                           <p>
    #                           <code>complete</code>
    #                        </p>
    #                       </li>
    #                     <li>
    #                           <p>
    #                           <code>failed</code>
    #                        </p>
    #                       </li>
    #                     <li>
    #                           <p>
    #                           <code>in_progress</code>
    #                        </p>
    #                       </li>
    #                     <li>
    #                           <p>
    #                           <code>starting</code>
    #                        </p>
    #                       </li>
    #                  </ul>
    #               </li>
    #            </ul>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous <code>DescribeExportTasks</code> request.
    #               If you specify this parameter, the response includes only records beyond the marker,
    #               up to the value specified by the <code>MaxRecords</code> parameter.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response. If more records exist than the
    #               specified value, a pagination token called a marker is included in the response.
    #               You can use the marker in a later <code>DescribeExportTasks</code> request
    #               to retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @return [Types::DescribeExportTasksOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_export_tasks(
    #     export_task_identifier: 'ExportTaskIdentifier',
    #     source_arn: 'SourceArn',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     marker: 'Marker',
    #     max_records: 1
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeExportTasksOutput
    #   resp.data.marker #=> String
    #   resp.data.export_tasks #=> Array<ExportTask>
    #   resp.data.export_tasks[0] #=> Types::ExportTask
    #   resp.data.export_tasks[0].export_task_identifier #=> String
    #   resp.data.export_tasks[0].source_arn #=> String
    #   resp.data.export_tasks[0].export_only #=> Array<String>
    #   resp.data.export_tasks[0].export_only[0] #=> String
    #   resp.data.export_tasks[0].snapshot_time #=> Time
    #   resp.data.export_tasks[0].task_start_time #=> Time
    #   resp.data.export_tasks[0].task_end_time #=> Time
    #   resp.data.export_tasks[0].s3_bucket #=> String
    #   resp.data.export_tasks[0].s3_prefix #=> String
    #   resp.data.export_tasks[0].iam_role_arn #=> String
    #   resp.data.export_tasks[0].kms_key_id #=> String
    #   resp.data.export_tasks[0].status #=> String
    #   resp.data.export_tasks[0].percent_progress #=> Integer
    #   resp.data.export_tasks[0].total_extracted_data_in_gb #=> Integer
    #   resp.data.export_tasks[0].failure_cause #=> String
    #   resp.data.export_tasks[0].warning_message #=> String
    #
    def describe_export_tasks(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeExportTasksInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeExportTasksInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeExportTasks
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::ExportTaskNotFoundFault]),
        data_parser: Parsers::DescribeExportTasks
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeExportTasks,
        stubs: @stubs,
        params_class: Params::DescribeExportTasksOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_export_tasks
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns information about Aurora global database clusters. This API supports pagination.</p>
    #         <p>For more information on Amazon Aurora, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html"> What is Amazon Aurora?</a> in the
    #         <i>Amazon Aurora User Guide</i>.</p>
    #         <note>
    #             <p>This action only applies to Aurora DB clusters.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::DescribeGlobalClustersInput}.
    #
    # @option params [String] :global_cluster_identifier
    #   <p>The user-supplied DB cluster identifier. If this parameter is specified, information from only the specific DB cluster is returned. This parameter isn't case-sensitive.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match an existing DBClusterIdentifier.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response. If more records exist than the specified
    #           <code>MaxRecords</code> value, a pagination token called a marker is included in the response so that
    #          you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous <code>DescribeGlobalClusters</code> request. If
    #           this parameter is specified, the response includes only records beyond the marker, up to the value
    #           specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeGlobalClustersOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_global_clusters(
    #     global_cluster_identifier: 'GlobalClusterIdentifier',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeGlobalClustersOutput
    #   resp.data.marker #=> String
    #   resp.data.global_clusters #=> Array<GlobalCluster>
    #   resp.data.global_clusters[0] #=> Types::GlobalCluster
    #   resp.data.global_clusters[0].global_cluster_identifier #=> String
    #   resp.data.global_clusters[0].global_cluster_resource_id #=> String
    #   resp.data.global_clusters[0].global_cluster_arn #=> String
    #   resp.data.global_clusters[0].status #=> String
    #   resp.data.global_clusters[0].engine #=> String
    #   resp.data.global_clusters[0].engine_version #=> String
    #   resp.data.global_clusters[0].database_name #=> String
    #   resp.data.global_clusters[0].storage_encrypted #=> Boolean
    #   resp.data.global_clusters[0].deletion_protection #=> Boolean
    #   resp.data.global_clusters[0].global_cluster_members #=> Array<GlobalClusterMember>
    #   resp.data.global_clusters[0].global_cluster_members[0] #=> Types::GlobalClusterMember
    #   resp.data.global_clusters[0].global_cluster_members[0].db_cluster_arn #=> String
    #   resp.data.global_clusters[0].global_cluster_members[0].readers #=> Array<String>
    #   resp.data.global_clusters[0].global_cluster_members[0].readers[0] #=> String
    #   resp.data.global_clusters[0].global_cluster_members[0].is_writer #=> Boolean
    #   resp.data.global_clusters[0].global_cluster_members[0].global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.global_clusters[0].failover_state #=> Types::FailoverState
    #   resp.data.global_clusters[0].failover_state.status #=> String, one of ["pending", "failing-over", "cancelling"]
    #   resp.data.global_clusters[0].failover_state.from_db_cluster_arn #=> String
    #   resp.data.global_clusters[0].failover_state.to_db_cluster_arn #=> String
    #
    def describe_global_clusters(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeGlobalClustersInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeGlobalClustersInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeGlobalClusters
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::GlobalClusterNotFoundFault]),
        data_parser: Parsers::DescribeGlobalClusters
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeGlobalClusters,
        stubs: @stubs,
        params_class: Params::DescribeGlobalClustersOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_global_clusters
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Describes all available options.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeOptionGroupOptionsInput}.
    #
    # @option params [String] :engine_name
    #   <p>A required parameter. Options available for the given engine name are described.</p>
    #           <p>Valid Values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>mariadb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mysql</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>postgres</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-se</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ex</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-web</code>
    #                  </p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :major_engine_version
    #   <p>If specified, filters the results to include only options for the specified major engine version.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #               If more records exist than the specified <code>MaxRecords</code> value,
    #               a pagination token called a marker is included in the response so that
    #               you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous request.
    #               If this parameter is specified, the response includes
    #               only records beyond the marker,
    #               up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeOptionGroupOptionsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_option_group_options(
    #     engine_name: 'EngineName', # required
    #     major_engine_version: 'MajorEngineVersion',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeOptionGroupOptionsOutput
    #   resp.data.option_group_options #=> Array<OptionGroupOption>
    #   resp.data.option_group_options[0] #=> Types::OptionGroupOption
    #   resp.data.option_group_options[0].name #=> String
    #   resp.data.option_group_options[0].description #=> String
    #   resp.data.option_group_options[0].engine_name #=> String
    #   resp.data.option_group_options[0].major_engine_version #=> String
    #   resp.data.option_group_options[0].minimum_required_minor_engine_version #=> String
    #   resp.data.option_group_options[0].port_required #=> Boolean
    #   resp.data.option_group_options[0].default_port #=> Integer
    #   resp.data.option_group_options[0].options_depended_on #=> Array<String>
    #   resp.data.option_group_options[0].options_depended_on[0] #=> String
    #   resp.data.option_group_options[0].options_conflicts_with #=> Array<String>
    #   resp.data.option_group_options[0].options_conflicts_with[0] #=> String
    #   resp.data.option_group_options[0].persistent #=> Boolean
    #   resp.data.option_group_options[0].permanent #=> Boolean
    #   resp.data.option_group_options[0].requires_auto_minor_engine_version_upgrade #=> Boolean
    #   resp.data.option_group_options[0].vpc_only #=> Boolean
    #   resp.data.option_group_options[0].supports_option_version_downgrade #=> Boolean
    #   resp.data.option_group_options[0].option_group_option_settings #=> Array<OptionGroupOptionSetting>
    #   resp.data.option_group_options[0].option_group_option_settings[0] #=> Types::OptionGroupOptionSetting
    #   resp.data.option_group_options[0].option_group_option_settings[0].setting_name #=> String
    #   resp.data.option_group_options[0].option_group_option_settings[0].setting_description #=> String
    #   resp.data.option_group_options[0].option_group_option_settings[0].default_value #=> String
    #   resp.data.option_group_options[0].option_group_option_settings[0].apply_type #=> String
    #   resp.data.option_group_options[0].option_group_option_settings[0].allowed_values #=> String
    #   resp.data.option_group_options[0].option_group_option_settings[0].is_modifiable #=> Boolean
    #   resp.data.option_group_options[0].option_group_option_settings[0].is_required #=> Boolean
    #   resp.data.option_group_options[0].option_group_option_settings[0].minimum_engine_version_per_allowed_value #=> Array<MinimumEngineVersionPerAllowedValue>
    #   resp.data.option_group_options[0].option_group_option_settings[0].minimum_engine_version_per_allowed_value[0] #=> Types::MinimumEngineVersionPerAllowedValue
    #   resp.data.option_group_options[0].option_group_option_settings[0].minimum_engine_version_per_allowed_value[0].allowed_value #=> String
    #   resp.data.option_group_options[0].option_group_option_settings[0].minimum_engine_version_per_allowed_value[0].minimum_engine_version #=> String
    #   resp.data.option_group_options[0].option_group_option_versions #=> Array<OptionVersion>
    #   resp.data.option_group_options[0].option_group_option_versions[0] #=> Types::OptionVersion
    #   resp.data.option_group_options[0].option_group_option_versions[0].version #=> String
    #   resp.data.option_group_options[0].option_group_option_versions[0].is_default #=> Boolean
    #   resp.data.marker #=> String
    #
    def describe_option_group_options(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeOptionGroupOptionsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeOptionGroupOptionsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeOptionGroupOptions
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: []),
        data_parser: Parsers::DescribeOptionGroupOptions
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeOptionGroupOptions,
        stubs: @stubs,
        params_class: Params::DescribeOptionGroupOptionsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_option_group_options
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Describes the available option groups.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeOptionGroupsInput}.
    #
    # @option params [String] :option_group_name
    #   <p>The name of the option group to describe. Can't be supplied together with EngineName or MajorEngineVersion.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous DescribeOptionGroups request.
    #               If this parameter is specified, the response includes
    #               only records beyond the marker,
    #               up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #               If more records exist than the specified <code>MaxRecords</code> value,
    #               a pagination token called a marker is included in the response so that
    #               you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :engine_name
    #   <p>Filters the list of option groups to only include groups associated with a specific database engine.</p>
    #           <p>Valid Values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>mariadb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mysql</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>postgres</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-se</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ex</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-web</code>
    #                  </p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :major_engine_version
    #   <p>Filters the list of option groups to only include groups associated with a specific database engine version. If specified, then EngineName must also be specified.</p>
    #
    # @return [Types::DescribeOptionGroupsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_option_groups(
    #     option_group_name: 'OptionGroupName',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     marker: 'Marker',
    #     max_records: 1,
    #     engine_name: 'EngineName',
    #     major_engine_version: 'MajorEngineVersion'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeOptionGroupsOutput
    #   resp.data.option_groups_list #=> Array<OptionGroup>
    #   resp.data.option_groups_list[0] #=> Types::OptionGroup
    #   resp.data.option_groups_list[0].option_group_name #=> String
    #   resp.data.option_groups_list[0].option_group_description #=> String
    #   resp.data.option_groups_list[0].engine_name #=> String
    #   resp.data.option_groups_list[0].major_engine_version #=> String
    #   resp.data.option_groups_list[0].options #=> Array<Option>
    #   resp.data.option_groups_list[0].options[0] #=> Types::Option
    #   resp.data.option_groups_list[0].options[0].option_name #=> String
    #   resp.data.option_groups_list[0].options[0].option_description #=> String
    #   resp.data.option_groups_list[0].options[0].persistent #=> Boolean
    #   resp.data.option_groups_list[0].options[0].permanent #=> Boolean
    #   resp.data.option_groups_list[0].options[0].port #=> Integer
    #   resp.data.option_groups_list[0].options[0].option_version #=> String
    #   resp.data.option_groups_list[0].options[0].option_settings #=> Array<OptionSetting>
    #   resp.data.option_groups_list[0].options[0].option_settings[0] #=> Types::OptionSetting
    #   resp.data.option_groups_list[0].options[0].option_settings[0].name #=> String
    #   resp.data.option_groups_list[0].options[0].option_settings[0].value #=> String
    #   resp.data.option_groups_list[0].options[0].option_settings[0].default_value #=> String
    #   resp.data.option_groups_list[0].options[0].option_settings[0].description #=> String
    #   resp.data.option_groups_list[0].options[0].option_settings[0].apply_type #=> String
    #   resp.data.option_groups_list[0].options[0].option_settings[0].data_type #=> String
    #   resp.data.option_groups_list[0].options[0].option_settings[0].allowed_values #=> String
    #   resp.data.option_groups_list[0].options[0].option_settings[0].is_modifiable #=> Boolean
    #   resp.data.option_groups_list[0].options[0].option_settings[0].is_collection #=> Boolean
    #   resp.data.option_groups_list[0].options[0].db_security_group_memberships #=> Array<DBSecurityGroupMembership>
    #   resp.data.option_groups_list[0].options[0].db_security_group_memberships[0] #=> Types::DBSecurityGroupMembership
    #   resp.data.option_groups_list[0].options[0].db_security_group_memberships[0].db_security_group_name #=> String
    #   resp.data.option_groups_list[0].options[0].db_security_group_memberships[0].status #=> String
    #   resp.data.option_groups_list[0].options[0].vpc_security_group_memberships #=> Array<VpcSecurityGroupMembership>
    #   resp.data.option_groups_list[0].options[0].vpc_security_group_memberships[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.option_groups_list[0].options[0].vpc_security_group_memberships[0].vpc_security_group_id #=> String
    #   resp.data.option_groups_list[0].options[0].vpc_security_group_memberships[0].status #=> String
    #   resp.data.option_groups_list[0].allows_vpc_and_non_vpc_instance_memberships #=> Boolean
    #   resp.data.option_groups_list[0].vpc_id #=> String
    #   resp.data.option_groups_list[0].option_group_arn #=> String
    #   resp.data.marker #=> String
    #
    def describe_option_groups(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeOptionGroupsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeOptionGroupsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeOptionGroups
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::OptionGroupNotFoundFault]),
        data_parser: Parsers::DescribeOptionGroups
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeOptionGroups,
        stubs: @stubs,
        params_class: Params::DescribeOptionGroupsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_option_groups
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns a list of orderable DB instance options for the specified DB engine, DB engine version, and DB instance class.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeOrderableDBInstanceOptionsInput}.
    #
    # @option params [String] :engine
    #   <p>The name of the engine to retrieve DB instance options for.</p>
    #           <p>Valid Values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>aurora</code> (for MySQL 5.6-compatible Aurora)</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-mysql</code> (for MySQL 5.7-compatible and MySQL 8.0-compatible Aurora)</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>aurora-postgresql</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mariadb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mysql</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>postgres</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-se</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ex</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-web</code>
    #                  </p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :engine_version
    #   <p>The engine version filter value. Specify this parameter to show only the available offerings matching the specified engine version.</p>
    #
    # @option params [String] :db_instance_class
    #   <p>The DB instance class filter value. Specify this parameter to show only the available offerings matching the specified DB instance class.</p>
    #
    # @option params [String] :license_model
    #   <p>The license model filter value. Specify this parameter to show only the available offerings
    #             matching the specified license model.</p>
    #           <p>RDS Custom supports only the BYOL licensing model.</p>
    #
    # @option params [String] :availability_zone_group
    #   <p>The Availability Zone group associated with a Local Zone. Specify this parameter to retrieve available offerings for the Local Zones in the group.</p>
    #           <p>Omit this parameter to show the available offerings in the specified Amazon Web Services Region.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :vpc
    #   <p>A value that indicates whether to show only VPC or non-VPC offerings. RDS Custom supports
    #         only VPC offerings.</p>
    #           <p>RDS Custom supports only VPC offerings. If you describe non-VPC offerings for RDS Custom, the output
    #             shows VPC offerings.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #               If more records exist than the specified <code>MaxRecords</code> value,
    #               a pagination token called a marker is included in the response so that
    #               you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #               DescribeOrderableDBInstanceOptions request.
    #               If this parameter is specified, the response includes
    #               only records beyond the marker,
    #               up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeOrderableDBInstanceOptionsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_orderable_db_instance_options(
    #     engine: 'Engine', # required
    #     engine_version: 'EngineVersion',
    #     db_instance_class: 'DBInstanceClass',
    #     license_model: 'LicenseModel',
    #     availability_zone_group: 'AvailabilityZoneGroup',
    #     vpc: false,
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeOrderableDBInstanceOptionsOutput
    #   resp.data.orderable_db_instance_options #=> Array<OrderableDBInstanceOption>
    #   resp.data.orderable_db_instance_options[0] #=> Types::OrderableDBInstanceOption
    #   resp.data.orderable_db_instance_options[0].engine #=> String
    #   resp.data.orderable_db_instance_options[0].engine_version #=> String
    #   resp.data.orderable_db_instance_options[0].db_instance_class #=> String
    #   resp.data.orderable_db_instance_options[0].license_model #=> String
    #   resp.data.orderable_db_instance_options[0].availability_zone_group #=> String
    #   resp.data.orderable_db_instance_options[0].availability_zones #=> Array<AvailabilityZone>
    #   resp.data.orderable_db_instance_options[0].availability_zones[0] #=> Types::AvailabilityZone
    #   resp.data.orderable_db_instance_options[0].availability_zones[0].name #=> String
    #   resp.data.orderable_db_instance_options[0].multi_az_capable #=> Boolean
    #   resp.data.orderable_db_instance_options[0].read_replica_capable #=> Boolean
    #   resp.data.orderable_db_instance_options[0].vpc #=> Boolean
    #   resp.data.orderable_db_instance_options[0].supports_storage_encryption #=> Boolean
    #   resp.data.orderable_db_instance_options[0].storage_type #=> String
    #   resp.data.orderable_db_instance_options[0].supports_iops #=> Boolean
    #   resp.data.orderable_db_instance_options[0].supports_enhanced_monitoring #=> Boolean
    #   resp.data.orderable_db_instance_options[0].supports_iam_database_authentication #=> Boolean
    #   resp.data.orderable_db_instance_options[0].supports_performance_insights #=> Boolean
    #   resp.data.orderable_db_instance_options[0].min_storage_size #=> Integer
    #   resp.data.orderable_db_instance_options[0].max_storage_size #=> Integer
    #   resp.data.orderable_db_instance_options[0].min_iops_per_db_instance #=> Integer
    #   resp.data.orderable_db_instance_options[0].max_iops_per_db_instance #=> Integer
    #   resp.data.orderable_db_instance_options[0].min_iops_per_gib #=> Float
    #   resp.data.orderable_db_instance_options[0].max_iops_per_gib #=> Float
    #   resp.data.orderable_db_instance_options[0].available_processor_features #=> Array<AvailableProcessorFeature>
    #   resp.data.orderable_db_instance_options[0].available_processor_features[0] #=> Types::AvailableProcessorFeature
    #   resp.data.orderable_db_instance_options[0].available_processor_features[0].name #=> String
    #   resp.data.orderable_db_instance_options[0].available_processor_features[0].default_value #=> String
    #   resp.data.orderable_db_instance_options[0].available_processor_features[0].allowed_values #=> String
    #   resp.data.orderable_db_instance_options[0].supported_engine_modes #=> Array<String>
    #   resp.data.orderable_db_instance_options[0].supported_engine_modes[0] #=> String
    #   resp.data.orderable_db_instance_options[0].supports_storage_autoscaling #=> Boolean
    #   resp.data.orderable_db_instance_options[0].supports_kerberos_authentication #=> Boolean
    #   resp.data.orderable_db_instance_options[0].outpost_capable #=> Boolean
    #   resp.data.orderable_db_instance_options[0].supported_activity_stream_modes #=> Array<String>
    #   resp.data.orderable_db_instance_options[0].supported_activity_stream_modes[0] #=> String
    #   resp.data.orderable_db_instance_options[0].supports_global_databases #=> Boolean
    #   resp.data.orderable_db_instance_options[0].supports_clusters #=> Boolean
    #   resp.data.orderable_db_instance_options[0].supported_network_types #=> Array<String>
    #   resp.data.orderable_db_instance_options[0].supported_network_types[0] #=> String
    #   resp.data.marker #=> String
    #
    def describe_orderable_db_instance_options(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeOrderableDBInstanceOptionsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeOrderableDBInstanceOptionsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeOrderableDBInstanceOptions
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: []),
        data_parser: Parsers::DescribeOrderableDBInstanceOptions
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeOrderableDBInstanceOptions,
        stubs: @stubs,
        params_class: Params::DescribeOrderableDBInstanceOptionsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_orderable_db_instance_options
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns a list of resources (for example, DB instances) that have at least one pending maintenance action.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribePendingMaintenanceActionsInput}.
    #
    # @option params [String] :resource_identifier
    #   <p>The ARN of a resource to return pending maintenance actions for.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>A filter that specifies one or more resources to return pending maintenance actions for.</p>
    #           <p>Supported filters:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>db-cluster-id</code> - Accepts DB cluster identifiers and DB
    #                 cluster Amazon Resource Names (ARNs). The results list only includes pending maintenance
    #                 actions for the DB clusters identified by these ARNs.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>db-instance-id</code> - Accepts DB instance identifiers and DB
    #               instance ARNs. The results list only includes pending maintenance
    #               actions for the DB instances identified by these ARNs.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous
    #               <code>DescribePendingMaintenanceActions</code> request.
    #               If this parameter is specified, the response includes
    #               only records beyond the marker,
    #               up to a number of records specified by <code>MaxRecords</code>.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #               If more records exist than the specified <code>MaxRecords</code> value,
    #               a pagination token called a marker is included in the response so that
    #               you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @return [Types::DescribePendingMaintenanceActionsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_pending_maintenance_actions(
    #     resource_identifier: 'ResourceIdentifier',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     marker: 'Marker',
    #     max_records: 1
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribePendingMaintenanceActionsOutput
    #   resp.data.pending_maintenance_actions #=> Array<ResourcePendingMaintenanceActions>
    #   resp.data.pending_maintenance_actions[0] #=> Types::ResourcePendingMaintenanceActions
    #   resp.data.pending_maintenance_actions[0].resource_identifier #=> String
    #   resp.data.pending_maintenance_actions[0].pending_maintenance_action_details #=> Array<PendingMaintenanceAction>
    #   resp.data.pending_maintenance_actions[0].pending_maintenance_action_details[0] #=> Types::PendingMaintenanceAction
    #   resp.data.pending_maintenance_actions[0].pending_maintenance_action_details[0].action #=> String
    #   resp.data.pending_maintenance_actions[0].pending_maintenance_action_details[0].auto_applied_after_date #=> Time
    #   resp.data.pending_maintenance_actions[0].pending_maintenance_action_details[0].forced_apply_date #=> Time
    #   resp.data.pending_maintenance_actions[0].pending_maintenance_action_details[0].opt_in_status #=> String
    #   resp.data.pending_maintenance_actions[0].pending_maintenance_action_details[0].current_apply_date #=> Time
    #   resp.data.pending_maintenance_actions[0].pending_maintenance_action_details[0].description #=> String
    #   resp.data.marker #=> String
    #
    def describe_pending_maintenance_actions(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribePendingMaintenanceActionsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribePendingMaintenanceActionsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribePendingMaintenanceActions
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::ResourceNotFoundFault]),
        data_parser: Parsers::DescribePendingMaintenanceActions
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribePendingMaintenanceActions,
        stubs: @stubs,
        params_class: Params::DescribePendingMaintenanceActionsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_pending_maintenance_actions
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns information about reserved DB instances for this account, or about a specified reserved DB instance.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeReservedDBInstancesInput}.
    #
    # @option params [String] :reserved_db_instance_id
    #   <p>The reserved DB instance identifier filter value. Specify this parameter to show only the reservation that matches the specified reservation ID.</p>
    #
    # @option params [String] :reserved_db_instances_offering_id
    #   <p>The offering identifier filter value. Specify this parameter to show only purchased reservations matching the specified offering identifier.</p>
    #
    # @option params [String] :db_instance_class
    #   <p>The DB instance class filter value. Specify this parameter to show only those reservations matching the specified DB instances class.</p>
    #
    # @option params [String] :duration
    #   <p>The duration filter value, specified in years or seconds. Specify this parameter to show only reservations for this duration.</p>
    #           <p>Valid Values: <code>1 | 3 | 31536000 | 94608000</code>
    #            </p>
    #
    # @option params [String] :product_description
    #   <p>The product description filter value. Specify this parameter to show only those reservations matching the specified product description.</p>
    #
    # @option params [String] :offering_type
    #   <p>The offering type filter value. Specify this parameter to show only the available offerings matching the specified offering type.</p>
    #           <p>Valid Values: <code>"Partial Upfront" | "All Upfront" | "No Upfront" </code>
    #            </p>
    #
    # @option params [Boolean] :multi_az
    #   <p>A value that indicates whether to show only those reservations that support Multi-AZ.</p>
    #
    # @option params [String] :lease_id
    #   <p>The lease identifier filter value. Specify this parameter to show only the reservation that matches the specified lease ID.</p>
    #           <note>
    #               <p>Amazon Web Services Support might request the lease ID for an issue related to a reserved DB instance.</p>
    #           </note>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #       If more than the <code>MaxRecords</code> value is available, a pagination token called a marker is
    #             included in the response so you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous request.
    #           If this parameter is specified, the response includes
    #           only records beyond the marker,
    #           up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeReservedDBInstancesOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_reserved_db_instances(
    #     reserved_db_instance_id: 'ReservedDBInstanceId',
    #     reserved_db_instances_offering_id: 'ReservedDBInstancesOfferingId',
    #     db_instance_class: 'DBInstanceClass',
    #     duration: 'Duration',
    #     product_description: 'ProductDescription',
    #     offering_type: 'OfferingType',
    #     multi_az: false,
    #     lease_id: 'LeaseId',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeReservedDBInstancesOutput
    #   resp.data.marker #=> String
    #   resp.data.reserved_db_instances #=> Array<ReservedDBInstance>
    #   resp.data.reserved_db_instances[0] #=> Types::ReservedDBInstance
    #   resp.data.reserved_db_instances[0].reserved_db_instance_id #=> String
    #   resp.data.reserved_db_instances[0].reserved_db_instances_offering_id #=> String
    #   resp.data.reserved_db_instances[0].db_instance_class #=> String
    #   resp.data.reserved_db_instances[0].start_time #=> Time
    #   resp.data.reserved_db_instances[0].duration #=> Integer
    #   resp.data.reserved_db_instances[0].fixed_price #=> Float
    #   resp.data.reserved_db_instances[0].usage_price #=> Float
    #   resp.data.reserved_db_instances[0].currency_code #=> String
    #   resp.data.reserved_db_instances[0].db_instance_count #=> Integer
    #   resp.data.reserved_db_instances[0].product_description #=> String
    #   resp.data.reserved_db_instances[0].offering_type #=> String
    #   resp.data.reserved_db_instances[0].multi_az #=> Boolean
    #   resp.data.reserved_db_instances[0].state #=> String
    #   resp.data.reserved_db_instances[0].recurring_charges #=> Array<RecurringCharge>
    #   resp.data.reserved_db_instances[0].recurring_charges[0] #=> Types::RecurringCharge
    #   resp.data.reserved_db_instances[0].recurring_charges[0].recurring_charge_amount #=> Float
    #   resp.data.reserved_db_instances[0].recurring_charges[0].recurring_charge_frequency #=> String
    #   resp.data.reserved_db_instances[0].reserved_db_instance_arn #=> String
    #   resp.data.reserved_db_instances[0].lease_id #=> String
    #
    def describe_reserved_db_instances(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeReservedDBInstancesInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeReservedDBInstancesInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeReservedDBInstances
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::ReservedDBInstanceNotFoundFault]),
        data_parser: Parsers::DescribeReservedDBInstances
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeReservedDBInstances,
        stubs: @stubs,
        params_class: Params::DescribeReservedDBInstancesOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_reserved_db_instances
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Lists available reserved DB instance offerings.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeReservedDBInstancesOfferingsInput}.
    #
    # @option params [String] :reserved_db_instances_offering_id
    #   <p>The offering identifier filter value. Specify this parameter to show only the available offering that matches the specified reservation identifier.</p>
    #           <p>Example: <code>438012d3-4052-4cc7-b2e3-8d3372e0e706</code>
    #            </p>
    #
    # @option params [String] :db_instance_class
    #   <p>The DB instance class filter value. Specify this parameter to show only the available offerings matching the specified DB instance class.</p>
    #
    # @option params [String] :duration
    #   <p>Duration filter value, specified in years or seconds. Specify this parameter to show only reservations for this duration.</p>
    #           <p>Valid Values: <code>1 | 3 | 31536000 | 94608000</code>
    #            </p>
    #
    # @option params [String] :product_description
    #   <p>Product description filter value. Specify this parameter to show only the available offerings that contain the specified product description.</p>
    #           <note>
    #               <p>The results show offerings that partially match the filter value.</p>
    #           </note>
    #
    # @option params [String] :offering_type
    #   <p>The offering type filter value. Specify this parameter to show only the available offerings matching the specified offering type.</p>
    #           <p>Valid Values: <code>"Partial Upfront" | "All Upfront" | "No Upfront" </code>
    #            </p>
    #
    # @option params [Boolean] :multi_az
    #   <p>A value that indicates whether to show only those reservations that support Multi-AZ.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response.
    #       If more than the <code>MaxRecords</code> value is available, a pagination token called a marker is
    #       included in the response so you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous request.
    #           If this parameter is specified, the response includes
    #           only records beyond the marker,
    #           up to the value specified by <code>MaxRecords</code>.</p>
    #
    # @return [Types::DescribeReservedDBInstancesOfferingsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_reserved_db_instances_offerings(
    #     reserved_db_instances_offering_id: 'ReservedDBInstancesOfferingId',
    #     db_instance_class: 'DBInstanceClass',
    #     duration: 'Duration',
    #     product_description: 'ProductDescription',
    #     offering_type: 'OfferingType',
    #     multi_az: false,
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ],
    #     max_records: 1,
    #     marker: 'Marker'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeReservedDBInstancesOfferingsOutput
    #   resp.data.marker #=> String
    #   resp.data.reserved_db_instances_offerings #=> Array<ReservedDBInstancesOffering>
    #   resp.data.reserved_db_instances_offerings[0] #=> Types::ReservedDBInstancesOffering
    #   resp.data.reserved_db_instances_offerings[0].reserved_db_instances_offering_id #=> String
    #   resp.data.reserved_db_instances_offerings[0].db_instance_class #=> String
    #   resp.data.reserved_db_instances_offerings[0].duration #=> Integer
    #   resp.data.reserved_db_instances_offerings[0].fixed_price #=> Float
    #   resp.data.reserved_db_instances_offerings[0].usage_price #=> Float
    #   resp.data.reserved_db_instances_offerings[0].currency_code #=> String
    #   resp.data.reserved_db_instances_offerings[0].product_description #=> String
    #   resp.data.reserved_db_instances_offerings[0].offering_type #=> String
    #   resp.data.reserved_db_instances_offerings[0].multi_az #=> Boolean
    #   resp.data.reserved_db_instances_offerings[0].recurring_charges #=> Array<RecurringCharge>
    #   resp.data.reserved_db_instances_offerings[0].recurring_charges[0] #=> Types::RecurringCharge
    #   resp.data.reserved_db_instances_offerings[0].recurring_charges[0].recurring_charge_amount #=> Float
    #   resp.data.reserved_db_instances_offerings[0].recurring_charges[0].recurring_charge_frequency #=> String
    #
    def describe_reserved_db_instances_offerings(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeReservedDBInstancesOfferingsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeReservedDBInstancesOfferingsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeReservedDBInstancesOfferings
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::ReservedDBInstancesOfferingNotFoundFault]),
        data_parser: Parsers::DescribeReservedDBInstancesOfferings
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeReservedDBInstancesOfferings,
        stubs: @stubs,
        params_class: Params::DescribeReservedDBInstancesOfferingsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_reserved_db_instances_offerings
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Returns a list of the source Amazon Web Services Regions where the current Amazon Web Services Region can create a read replica,
    #          copy a DB snapshot from, or replicate automated backups from. This API action supports pagination.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeSourceRegionsInput}.
    #
    # @option params [String] :region_name
    #   <p>The source Amazon Web Services Region name. For example, <code>us-east-1</code>.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must specify a valid Amazon Web Services Region name.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Integer] :max_records
    #   <p>The maximum number of records to include in the response. If more records exist
    #               than the specified <code>MaxRecords</code> value, a pagination token called a marker is
    #               included in the response so you can retrieve the remaining results.</p>
    #           <p>Default: 100</p>
    #           <p>Constraints: Minimum 20, maximum 100.</p>
    #
    # @option params [String] :marker
    #   <p>An optional pagination token provided by a previous <code>DescribeSourceRegions</code> request. If this parameter is specified, the response
    #               includes only records beyond the marker, up to the value specified by
    #               <code>MaxRecords</code>.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @return [Types::DescribeSourceRegionsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_source_regions(
    #     region_name: 'RegionName',
    #     max_records: 1,
    #     marker: 'Marker',
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeSourceRegionsOutput
    #   resp.data.marker #=> String
    #   resp.data.source_regions #=> Array<SourceRegion>
    #   resp.data.source_regions[0] #=> Types::SourceRegion
    #   resp.data.source_regions[0].region_name #=> String
    #   resp.data.source_regions[0].endpoint #=> String
    #   resp.data.source_regions[0].status #=> String
    #   resp.data.source_regions[0].supports_db_instance_automated_backups_replication #=> Boolean
    #
    def describe_source_regions(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeSourceRegionsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeSourceRegionsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeSourceRegions
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: []),
        data_parser: Parsers::DescribeSourceRegions
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeSourceRegions,
        stubs: @stubs,
        params_class: Params::DescribeSourceRegionsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_source_regions
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>You can call <code>DescribeValidDBInstanceModifications</code> to learn what modifications you can make to
    #             your DB instance. You can use this information when you call <code>ModifyDBInstance</code>.</p>
    #         <p>This command doesn't apply to RDS Custom.</p>
    #
    # @param [Hash] params
    #   See {Types::DescribeValidDBInstanceModificationsInput}.
    #
    # @option params [String] :db_instance_identifier
    #   <p>The customer identifier or the ARN of your DB instance.</p>
    #
    # @return [Types::DescribeValidDBInstanceModificationsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.describe_valid_db_instance_modifications(
    #     db_instance_identifier: 'DBInstanceIdentifier' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DescribeValidDBInstanceModificationsOutput
    #   resp.data.valid_db_instance_modifications_message #=> Types::ValidDBInstanceModificationsMessage
    #   resp.data.valid_db_instance_modifications_message.storage #=> Array<ValidStorageOptions>
    #   resp.data.valid_db_instance_modifications_message.storage[0] #=> Types::ValidStorageOptions
    #   resp.data.valid_db_instance_modifications_message.storage[0].storage_type #=> String
    #   resp.data.valid_db_instance_modifications_message.storage[0].storage_size #=> Array<Range>
    #   resp.data.valid_db_instance_modifications_message.storage[0].storage_size[0] #=> Types::Range
    #   resp.data.valid_db_instance_modifications_message.storage[0].storage_size[0].from #=> Integer
    #   resp.data.valid_db_instance_modifications_message.storage[0].storage_size[0].to #=> Integer
    #   resp.data.valid_db_instance_modifications_message.storage[0].storage_size[0].step #=> Integer
    #   resp.data.valid_db_instance_modifications_message.storage[0].provisioned_iops #=> Array<Range>
    #   resp.data.valid_db_instance_modifications_message.storage[0].iops_to_storage_ratio #=> Array<DoubleRange>
    #   resp.data.valid_db_instance_modifications_message.storage[0].iops_to_storage_ratio[0] #=> Types::DoubleRange
    #   resp.data.valid_db_instance_modifications_message.storage[0].iops_to_storage_ratio[0].from #=> Float
    #   resp.data.valid_db_instance_modifications_message.storage[0].iops_to_storage_ratio[0].to #=> Float
    #   resp.data.valid_db_instance_modifications_message.storage[0].supports_storage_autoscaling #=> Boolean
    #   resp.data.valid_db_instance_modifications_message.valid_processor_features #=> Array<AvailableProcessorFeature>
    #   resp.data.valid_db_instance_modifications_message.valid_processor_features[0] #=> Types::AvailableProcessorFeature
    #   resp.data.valid_db_instance_modifications_message.valid_processor_features[0].name #=> String
    #   resp.data.valid_db_instance_modifications_message.valid_processor_features[0].default_value #=> String
    #   resp.data.valid_db_instance_modifications_message.valid_processor_features[0].allowed_values #=> String
    #
    def describe_valid_db_instance_modifications(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DescribeValidDBInstanceModificationsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DescribeValidDBInstanceModificationsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DescribeValidDBInstanceModifications
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBInstanceNotFoundFault, Errors::InvalidDBInstanceStateFault]),
        data_parser: Parsers::DescribeValidDBInstanceModifications
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DescribeValidDBInstanceModifications,
        stubs: @stubs,
        params_class: Params::DescribeValidDBInstanceModificationsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :describe_valid_db_instance_modifications
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Downloads all or a portion of the specified log file, up to 1 MB in size.</p>
    #         <p>This command doesn't apply to RDS Custom.</p>
    #
    # @param [Hash] params
    #   See {Types::DownloadDBLogFilePortionInput}.
    #
    # @option params [String] :db_instance_identifier
    #   <p>The customer-assigned name of the DB instance that contains the log files you want to list.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the identifier of an existing DBInstance.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :log_file_name
    #   <p>The name of the log file to be downloaded.</p>
    #
    # @option params [String] :marker
    #   <p>The pagination token provided in the previous request or "0". If the Marker parameter is specified the response includes only records beyond the marker until the end of the file or up to NumberOfLines.</p>
    #
    # @option params [Integer] :number_of_lines
    #   <p>The number of lines to download. If the number of lines specified results in a file over 1 MB in size, the file is truncated at 1 MB in size.</p>
    #           <p>If the NumberOfLines parameter is specified, then the block of lines returned can be from the beginning
    #               or the end of the log file, depending on the value of the Marker parameter.</p>
    #           <ul>
    #               <li>
    #                   <p>If neither Marker or NumberOfLines are specified, the entire log file is returned up to a
    #                 maximum of 10000 lines, starting with the most recent log entries first.</p>
    #               </li>
    #               <li>
    #                   <p>If
    #                 NumberOfLines is specified and Marker isn't specified, then the most recent lines from the end
    #                       of the log file are returned.</p>
    #               </li>
    #               <li>
    #                   <p>If Marker is specified as "0", then the specified
    #                         number of lines from the beginning of the log file are returned.</p>
    #               </li>
    #               <li>
    #                   <p>You can
    #                           download the log file in blocks of lines by specifying the size of the block using
    #                       the NumberOfLines parameter, and by specifying a value of "0" for the Marker parameter in your
    #                       first request. Include the Marker value returned in the response as the Marker value for the next
    #                       request, continuing until the AdditionalDataPending response element returns false.</p>
    #               </li>
    #            </ul>
    #
    # @return [Types::DownloadDBLogFilePortionOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.download_db_log_file_portion(
    #     db_instance_identifier: 'DBInstanceIdentifier', # required
    #     log_file_name: 'LogFileName', # required
    #     marker: 'Marker',
    #     number_of_lines: 1
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::DownloadDBLogFilePortionOutput
    #   resp.data.log_file_data #=> String
    #   resp.data.marker #=> String
    #   resp.data.additional_data_pending #=> Boolean
    #
    def download_db_log_file_portion(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::DownloadDBLogFilePortionInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::DownloadDBLogFilePortionInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::DownloadDBLogFilePortion
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBInstanceNotFoundFault, Errors::DBLogFileNotFoundFault]),
        data_parser: Parsers::DownloadDBLogFilePortion
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::DownloadDBLogFilePortion,
        stubs: @stubs,
        params_class: Params::DownloadDBLogFilePortionOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :download_db_log_file_portion
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Forces a failover for a DB cluster.</p>
    #         <p>For an Aurora DB cluster, failover for a DB cluster promotes one of the Aurora Replicas (read-only instances)
    #           in the DB cluster to be the primary DB instance (the cluster writer).</p>
    #         <p>For a Multi-AZ DB cluster, failover for a DB cluster promotes one of the readable standby DB instances (read-only instances)
    #           in the DB cluster to be the primary DB instance (the cluster writer).</p>
    #         <p>An Amazon Aurora DB cluster automatically fails over to an Aurora Replica, if one exists,
    #           when the primary DB instance fails. A Multi-AZ DB cluster automatically fails over to a readbable standby
    #           DB instance when the primary DB instance fails.</p>
    #         <p>To simulate a failure of a primary instance for testing, you can force a failover.
    #           Because each instance in a DB cluster has its own endpoint address, make sure to clean up and re-establish any existing
    #           connections that use those endpoint addresses when the failover is complete.</p>
    #         <p>For more information on Amazon Aurora DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #               What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #               Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::FailoverDBClusterInput}.
    #
    # @option params [String] :db_cluster_identifier
    #   <p>A DB cluster identifier to force a failover for. This parameter isn't case-sensitive.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the identifier of an existing DBCluster.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :target_db_instance_identifier
    #   <p>The name of the DB instance to promote to the primary DB instance.</p>
    #           <p>Specify the DB instance identifier for an Aurora Replica or a Multi-AZ readable standby in the DB cluster,
    #           for example <code>mydbcluster-replica1</code>.</p>
    #           <p>This setting isn't supported for RDS for MySQL Multi-AZ DB clusters.</p>
    #
    # @return [Types::FailoverDBClusterOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.failover_db_cluster(
    #     db_cluster_identifier: 'DBClusterIdentifier', # required
    #     target_db_instance_identifier: 'TargetDBInstanceIdentifier'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::FailoverDBClusterOutput
    #   resp.data.db_cluster #=> Types::DBCluster
    #   resp.data.db_cluster.allocated_storage #=> Integer
    #   resp.data.db_cluster.availability_zones #=> Array<String>
    #   resp.data.db_cluster.availability_zones[0] #=> String
    #   resp.data.db_cluster.backup_retention_period #=> Integer
    #   resp.data.db_cluster.character_set_name #=> String
    #   resp.data.db_cluster.database_name #=> String
    #   resp.data.db_cluster.db_cluster_identifier #=> String
    #   resp.data.db_cluster.db_cluster_parameter_group #=> String
    #   resp.data.db_cluster.db_subnet_group #=> String
    #   resp.data.db_cluster.status #=> String
    #   resp.data.db_cluster.automatic_restart_time #=> Time
    #   resp.data.db_cluster.percent_progress #=> String
    #   resp.data.db_cluster.earliest_restorable_time #=> Time
    #   resp.data.db_cluster.endpoint #=> String
    #   resp.data.db_cluster.reader_endpoint #=> String
    #   resp.data.db_cluster.custom_endpoints #=> Array<String>
    #   resp.data.db_cluster.custom_endpoints[0] #=> String
    #   resp.data.db_cluster.multi_az #=> Boolean
    #   resp.data.db_cluster.engine #=> String
    #   resp.data.db_cluster.engine_version #=> String
    #   resp.data.db_cluster.latest_restorable_time #=> Time
    #   resp.data.db_cluster.port #=> Integer
    #   resp.data.db_cluster.master_username #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships #=> Array<DBClusterOptionGroupStatus>
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0] #=> Types::DBClusterOptionGroupStatus
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].db_cluster_option_group_name #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].status #=> String
    #   resp.data.db_cluster.preferred_backup_window #=> String
    #   resp.data.db_cluster.preferred_maintenance_window #=> String
    #   resp.data.db_cluster.replication_source_identifier #=> String
    #   resp.data.db_cluster.read_replica_identifiers #=> Array<String>
    #   resp.data.db_cluster.read_replica_identifiers[0] #=> String
    #   resp.data.db_cluster.db_cluster_members #=> Array<DBClusterMember>
    #   resp.data.db_cluster.db_cluster_members[0] #=> Types::DBClusterMember
    #   resp.data.db_cluster.db_cluster_members[0].db_instance_identifier #=> String
    #   resp.data.db_cluster.db_cluster_members[0].is_cluster_writer #=> Boolean
    #   resp.data.db_cluster.db_cluster_members[0].db_cluster_parameter_group_status #=> String
    #   resp.data.db_cluster.db_cluster_members[0].promotion_tier #=> Integer
    #   resp.data.db_cluster.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_cluster.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_cluster.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_cluster.vpc_security_groups[0].status #=> String
    #   resp.data.db_cluster.hosted_zone_id #=> String
    #   resp.data.db_cluster.storage_encrypted #=> Boolean
    #   resp.data.db_cluster.kms_key_id #=> String
    #   resp.data.db_cluster.db_cluster_resource_id #=> String
    #   resp.data.db_cluster.db_cluster_arn #=> String
    #   resp.data.db_cluster.associated_roles #=> Array<DBClusterRole>
    #   resp.data.db_cluster.associated_roles[0] #=> Types::DBClusterRole
    #   resp.data.db_cluster.associated_roles[0].role_arn #=> String
    #   resp.data.db_cluster.associated_roles[0].status #=> String
    #   resp.data.db_cluster.associated_roles[0].feature_name #=> String
    #   resp.data.db_cluster.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.clone_group_id #=> String
    #   resp.data.db_cluster.cluster_create_time #=> Time
    #   resp.data.db_cluster.earliest_backtrack_time #=> Time
    #   resp.data.db_cluster.backtrack_window #=> Integer
    #   resp.data.db_cluster.backtrack_consumed_change_records #=> Integer
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports[0] #=> String
    #   resp.data.db_cluster.capacity #=> Integer
    #   resp.data.db_cluster.engine_mode #=> String
    #   resp.data.db_cluster.scaling_configuration_info #=> Types::ScalingConfigurationInfo
    #   resp.data.db_cluster.scaling_configuration_info.min_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.max_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.auto_pause #=> Boolean
    #   resp.data.db_cluster.scaling_configuration_info.seconds_until_auto_pause #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.timeout_action #=> String
    #   resp.data.db_cluster.scaling_configuration_info.seconds_before_timeout #=> Integer
    #   resp.data.db_cluster.deletion_protection #=> Boolean
    #   resp.data.db_cluster.http_endpoint_enabled #=> Boolean
    #   resp.data.db_cluster.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_cluster.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_cluster.activity_stream_kms_key_id #=> String
    #   resp.data.db_cluster.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_cluster.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_cluster.cross_account_clone #=> Boolean
    #   resp.data.db_cluster.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_cluster.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_cluster.domain_memberships[0].domain #=> String
    #   resp.data.db_cluster.domain_memberships[0].status #=> String
    #   resp.data.db_cluster.domain_memberships[0].fqdn #=> String
    #   resp.data.db_cluster.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_cluster.tag_list #=> Array<Tag>
    #   resp.data.db_cluster.tag_list[0] #=> Types::Tag
    #   resp.data.db_cluster.tag_list[0].key #=> String
    #   resp.data.db_cluster.tag_list[0].value #=> String
    #   resp.data.db_cluster.global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.db_cluster.global_write_forwarding_requested #=> Boolean
    #   resp.data.db_cluster.pending_modified_values #=> Types::ClusterPendingModifiedValues
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.db_cluster_identifier #=> String
    #   resp.data.db_cluster.pending_modified_values.master_user_password #=> String
    #   resp.data.db_cluster.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.pending_modified_values.engine_version #=> String
    #   resp.data.db_cluster.db_cluster_instance_class #=> String
    #   resp.data.db_cluster.storage_type #=> String
    #   resp.data.db_cluster.iops #=> Integer
    #   resp.data.db_cluster.publicly_accessible #=> Boolean
    #   resp.data.db_cluster.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_cluster.monitoring_interval #=> Integer
    #   resp.data.db_cluster.monitoring_role_arn #=> String
    #   resp.data.db_cluster.performance_insights_enabled #=> Boolean
    #   resp.data.db_cluster.performance_insights_kms_key_id #=> String
    #   resp.data.db_cluster.performance_insights_retention_period #=> Integer
    #   resp.data.db_cluster.serverless_v2_scaling_configuration #=> Types::ServerlessV2ScalingConfigurationInfo
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.min_capacity #=> Float
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.max_capacity #=> Float
    #
    def failover_db_cluster(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::FailoverDBClusterInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::FailoverDBClusterInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::FailoverDBCluster
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::InvalidDBClusterStateFault, Errors::InvalidDBInstanceStateFault]),
        data_parser: Parsers::FailoverDBCluster
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::FailoverDBCluster,
        stubs: @stubs,
        params_class: Params::FailoverDBClusterOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :failover_db_cluster
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Initiates the failover process for an Aurora global database (<a>GlobalCluster</a>).</p>
    #         <p>A failover for an Aurora global database promotes one of secondary read-only DB clusters to be
    #        the primary DB cluster and demotes the primary DB cluster to being a secondary (read-only) DB cluster. In other words,
    #      the role of the current primary DB cluster and the selected (target) DB cluster are switched. The selected
    #      secondary DB cluster assumes full read/write capabilities for the Aurora global database.</p>
    #         <p>For more information about failing over an Amazon Aurora global database, see
    #         <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database-disaster-recovery.html#aurora-global-database-disaster-recovery.managed-failover">Managed planned failover for Amazon Aurora global
    #         databases</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <note>
    #             <p>This action applies to <a>GlobalCluster</a> (Aurora global databases) only. Use this action only on
    #        healthy Aurora global databases with running Aurora DB clusters and no Region-wide outages, to test disaster recovery scenarios or to
    #         reconfigure your Aurora global database topology.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::FailoverGlobalClusterInput}.
    #
    # @option params [String] :global_cluster_identifier
    #   <p>Identifier of the Aurora global database (<a>GlobalCluster</a>)
    #       that should be failed over. The identifier is the unique key assigned by
    #       the user when the Aurora global database was created. In other words,
    #       it's the name of the Aurora global database that you want to fail over.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the identifier of an existing
    #         <a>GlobalCluster</a> (Aurora global database).</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :target_db_cluster_identifier
    #   <p>Identifier of the secondary Aurora DB cluster that you want to promote to primary for the Aurora
    #          global database (<a>GlobalCluster</a>.) Use the Amazon Resource Name (ARN) for the identifier so that
    #          Aurora can locate the cluster in its Amazon Web Services Region.</p>
    #
    # @return [Types::FailoverGlobalClusterOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.failover_global_cluster(
    #     global_cluster_identifier: 'GlobalClusterIdentifier', # required
    #     target_db_cluster_identifier: 'TargetDbClusterIdentifier' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::FailoverGlobalClusterOutput
    #   resp.data.global_cluster #=> Types::GlobalCluster
    #   resp.data.global_cluster.global_cluster_identifier #=> String
    #   resp.data.global_cluster.global_cluster_resource_id #=> String
    #   resp.data.global_cluster.global_cluster_arn #=> String
    #   resp.data.global_cluster.status #=> String
    #   resp.data.global_cluster.engine #=> String
    #   resp.data.global_cluster.engine_version #=> String
    #   resp.data.global_cluster.database_name #=> String
    #   resp.data.global_cluster.storage_encrypted #=> Boolean
    #   resp.data.global_cluster.deletion_protection #=> Boolean
    #   resp.data.global_cluster.global_cluster_members #=> Array<GlobalClusterMember>
    #   resp.data.global_cluster.global_cluster_members[0] #=> Types::GlobalClusterMember
    #   resp.data.global_cluster.global_cluster_members[0].db_cluster_arn #=> String
    #   resp.data.global_cluster.global_cluster_members[0].readers #=> Array<String>
    #   resp.data.global_cluster.global_cluster_members[0].readers[0] #=> String
    #   resp.data.global_cluster.global_cluster_members[0].is_writer #=> Boolean
    #   resp.data.global_cluster.global_cluster_members[0].global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.global_cluster.failover_state #=> Types::FailoverState
    #   resp.data.global_cluster.failover_state.status #=> String, one of ["pending", "failing-over", "cancelling"]
    #   resp.data.global_cluster.failover_state.from_db_cluster_arn #=> String
    #   resp.data.global_cluster.failover_state.to_db_cluster_arn #=> String
    #
    def failover_global_cluster(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::FailoverGlobalClusterInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::FailoverGlobalClusterInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::FailoverGlobalCluster
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::GlobalClusterNotFoundFault, Errors::InvalidGlobalClusterStateFault, Errors::InvalidDBClusterStateFault]),
        data_parser: Parsers::FailoverGlobalCluster
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::FailoverGlobalCluster,
        stubs: @stubs,
        params_class: Params::FailoverGlobalClusterOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :failover_global_cluster
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Lists all tags on an Amazon RDS resource.</p>
    #         <p>For an overview on tagging an Amazon RDS resource,
    #           see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Tagging.html">Tagging Amazon RDS Resources</a>
    #           in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::ListTagsForResourceInput}.
    #
    # @option params [String] :resource_name
    #   <p>The Amazon RDS resource with tags to be listed. This value is an Amazon Resource Name (ARN). For information about
    #               creating an ARN,
    #               see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.ARN.html#USER_Tagging.ARN.Constructing">
    #                   Constructing an ARN for Amazon RDS</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @option params [Array<Filter>] :filters
    #   <p>This parameter isn't currently supported.</p>
    #
    # @return [Types::ListTagsForResourceOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.list_tags_for_resource(
    #     resource_name: 'ResourceName', # required
    #     filters: [
    #       {
    #         name: 'Name', # required
    #         values: [
    #           'member'
    #         ] # required
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ListTagsForResourceOutput
    #   resp.data.tag_list #=> Array<Tag>
    #   resp.data.tag_list[0] #=> Types::Tag
    #   resp.data.tag_list[0].key #=> String
    #   resp.data.tag_list[0].value #=> String
    #
    def list_tags_for_resource(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ListTagsForResourceInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ListTagsForResourceInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ListTagsForResource
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::DBInstanceNotFoundFault, Errors::DBProxyTargetGroupNotFoundFault, Errors::DBProxyNotFoundFault, Errors::DBSnapshotNotFoundFault]),
        data_parser: Parsers::ListTagsForResource
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ListTagsForResource,
        stubs: @stubs,
        params_class: Params::ListTagsForResourceOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :list_tags_for_resource
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Override the system-default Secure Sockets Layer/Transport Layer Security (SSL/TLS)
    #           certificate for Amazon RDS for new DB instances, or remove the override.</p>
    #         <p>By using this operation, you can specify an RDS-approved SSL/TLS certificate for new DB
    #             instances that is different from the default certificate provided by RDS. You can also
    #             use this operation to remove the override, so that new DB instances use the default
    #             certificate provided by RDS.</p>
    #         <p>You might need to override the default certificate in the following situations:</p>
    #         <ul>
    #             <li>
    #                 <p>You already migrated your applications to support the latest certificate authority (CA) certificate, but the new CA certificate is not yet
    #                   the RDS default CA certificate for the specified Amazon Web Services Region.</p>
    #             </li>
    #             <li>
    #                 <p>RDS has already moved to a new default CA certificate for the specified Amazon Web Services
    #                     Region, but you are still in the process of supporting the new CA certificate.
    #                     In this case, you temporarily need additional time to finish your application
    #                     changes.</p>
    #             </li>
    #          </ul>
    #         <p>For more information about rotating your SSL/TLS certificate for RDS DB engines, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.SSL-certificate-rotation.html">
    #               Rotating Your SSL/TLS Certificate</a> in the <i>Amazon RDS User Guide</i>.</p>
    #         <p>For more information about rotating your SSL/TLS certificate for Aurora DB engines, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/UsingWithRDS.SSL-certificate-rotation.html">
    #               Rotating Your SSL/TLS Certificate</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::ModifyCertificatesInput}.
    #
    # @option params [String] :certificate_identifier
    #   <p>The new default certificate identifier to override the current one with.</p>
    #           <p>To determine the valid values, use the <code>describe-certificates</code> CLI
    #               command or the <code>DescribeCertificates</code> API operation.</p>
    #
    # @option params [Boolean] :remove_customer_override
    #   <p>A value that indicates whether to remove the override for the default certificate.
    #               If the override is removed, the default certificate is the system
    #               default.</p>
    #
    # @return [Types::ModifyCertificatesOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_certificates(
    #     certificate_identifier: 'CertificateIdentifier',
    #     remove_customer_override: false
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyCertificatesOutput
    #   resp.data.certificate #=> Types::Certificate
    #   resp.data.certificate.certificate_identifier #=> String
    #   resp.data.certificate.certificate_type #=> String
    #   resp.data.certificate.thumbprint #=> String
    #   resp.data.certificate.valid_from #=> Time
    #   resp.data.certificate.valid_till #=> Time
    #   resp.data.certificate.certificate_arn #=> String
    #   resp.data.certificate.customer_override #=> Boolean
    #   resp.data.certificate.customer_override_valid_till #=> Time
    #
    def modify_certificates(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyCertificatesInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyCertificatesInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyCertificates
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::CertificateNotFoundFault]),
        data_parser: Parsers::ModifyCertificates
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyCertificates,
        stubs: @stubs,
        params_class: Params::ModifyCertificatesOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_certificates
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Set the capacity of an Aurora Serverless v1 DB cluster to a specific value.</p>
    #         <p>Aurora Serverless v1 scales seamlessly based on the workload on the DB cluster. In some cases, the capacity might not scale
    #         fast enough to meet a sudden change in workload, such as a large number of new transactions. Call <code>ModifyCurrentDBClusterCapacity</code>
    #         to set the capacity explicitly.</p>
    #         <p>After this call sets the DB cluster capacity, Aurora Serverless v1 can automatically scale
    #             the DB cluster based on the cooldown period for scaling up and the cooldown period
    #             for scaling down.</p>
    #         <p>For more information about Aurora Serverless v1, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless.html">Using Amazon Aurora Serverless v1</a> in the
    #           <i>Amazon Aurora User Guide</i>.</p>
    #         <important>
    #             <p>If you call <code>ModifyCurrentDBClusterCapacity</code> with the default <code>TimeoutAction</code>, connections that
    #               prevent Aurora Serverless v1 from finding a scaling point might be dropped. For more information about scaling points,
    #               see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless.how-it-works.html#aurora-serverless.how-it-works.auto-scaling">
    #                   Autoscaling for Aurora Serverless v1</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         </important>
    #         <note>
    #             <p>This action only applies to Aurora Serverless v1 DB clusters.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::ModifyCurrentDBClusterCapacityInput}.
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The DB cluster identifier for the cluster being modified. This parameter isn't case-sensitive.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the identifier of an existing DB cluster.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Integer] :capacity
    #   <p>The DB cluster capacity.</p>
    #           <p>When you change the capacity of a paused Aurora Serverless v1 DB cluster, it automatically resumes.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>For Aurora MySQL, valid capacity values are <code>1</code>, <code>2</code>, <code>4</code>, <code>8</code>, <code>16</code>, <code>32</code>, <code>64</code>, <code>128</code>, and <code>256</code>.</p>
    #               </li>
    #               <li>
    #                   <p>For Aurora PostgreSQL, valid capacity values are <code>2</code>, <code>4</code>, <code>8</code>, <code>16</code>, <code>32</code>, <code>64</code>, <code>192</code>, and <code>384</code>.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Integer] :seconds_before_timeout
    #   <p>The amount of time, in seconds, that Aurora Serverless v1 tries to find a scaling point
    #               to perform seamless scaling before enforcing the timeout action. The default is
    #               300.</p>
    #           <p>Specify a value between 10 and 600 seconds.</p>
    #
    # @option params [String] :timeout_action
    #   <p>The action to take when the timeout is reached, either <code>ForceApplyCapacityChange</code> or <code>RollbackCapacityChange</code>.</p>
    #           <p>
    #               <code>ForceApplyCapacityChange</code>, the default, sets the capacity to the specified value as soon as possible.</p>
    #           <p>
    #               <code>RollbackCapacityChange</code> ignores the capacity change if a scaling point isn't found in the timeout period.</p>
    #
    # @return [Types::ModifyCurrentDBClusterCapacityOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_current_db_cluster_capacity(
    #     db_cluster_identifier: 'DBClusterIdentifier', # required
    #     capacity: 1,
    #     seconds_before_timeout: 1,
    #     timeout_action: 'TimeoutAction'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyCurrentDBClusterCapacityOutput
    #   resp.data.db_cluster_identifier #=> String
    #   resp.data.pending_capacity #=> Integer
    #   resp.data.current_capacity #=> Integer
    #   resp.data.seconds_before_timeout #=> Integer
    #   resp.data.timeout_action #=> String
    #
    def modify_current_db_cluster_capacity(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyCurrentDBClusterCapacityInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyCurrentDBClusterCapacityInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyCurrentDBClusterCapacity
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::InvalidDBClusterCapacityFault, Errors::InvalidDBClusterStateFault]),
        data_parser: Parsers::ModifyCurrentDBClusterCapacity
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyCurrentDBClusterCapacity,
        stubs: @stubs,
        params_class: Params::ModifyCurrentDBClusterCapacityOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_current_db_cluster_capacity
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Modifies the status of a custom engine version (CEV). You can find CEVs to modify by calling
    #             <code>DescribeDBEngineVersions</code>.</p>
    #         <note>
    #             <p>The MediaImport service that imports files from Amazon S3 to create CEVs isn't integrated with
    #                 Amazon Web Services CloudTrail. If you turn on data logging for Amazon RDS in CloudTrail, calls to the
    #                 <code>ModifyCustomDbEngineVersion</code> event aren't logged. However, you might see calls from the
    #                 API gateway that accesses your Amazon S3 bucket. These calls originate from the MediaImport service for
    #                 the <code>ModifyCustomDbEngineVersion</code> event.</p>
    #         </note>
    #         <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/custom-cev.html#custom-cev.modify">Modifying CEV status</a>
    #             in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::ModifyCustomDBEngineVersionInput}.
    #
    # @option params [String] :engine
    #   <p>The DB engine. The only supported value is <code>custom-oracle-ee</code>.</p>
    #
    # @option params [String] :engine_version
    #   <p>The custom engine version (CEV) that you want to modify. This option is required for
    #               RDS Custom for Oracle, but optional for Amazon RDS. The combination of <code>Engine</code> and
    #               <code>EngineVersion</code> is unique per customer per Amazon Web Services Region.</p>
    #
    # @option params [String] :description
    #   <p>An optional description of your CEV.</p>
    #
    # @option params [String] :status
    #   <p>The availability status to be assigned to the CEV. Valid values are as follows:</p>
    #           <dl>
    #               <dt>available</dt>
    #               <dd>
    #                       <p>You can use this CEV to create a new RDS Custom DB instance.</p>
    #                   </dd>
    #               <dt>inactive</dt>
    #               <dd>
    #                       <p>You can create a new RDS Custom instance by restoring a DB snapshot with this CEV.
    #                       You can't patch or create new instances with this CEV.</p>
    #                   </dd>
    #            </dl>
    #           <p>You can change any status to any status. A typical reason to change status is to prevent the accidental
    #               use of a CEV, or to make a deprecated CEV eligible for use again. For example, you might change the status
    #               of your CEV from <code>available</code> to <code>inactive</code>, and from <code>inactive</code> back to
    #               <code>available</code>. To change the availability status of the CEV, it must not currently be in use by an
    #               RDS Custom instance, snapshot, or automated backup.</p>
    #
    # @return [Types::ModifyCustomDBEngineVersionOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_custom_db_engine_version(
    #     engine: 'Engine', # required
    #     engine_version: 'EngineVersion', # required
    #     description: 'Description',
    #     status: 'available' # accepts ["available", "inactive", "inactive-except-restore"]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyCustomDBEngineVersionOutput
    #   resp.data.engine #=> String
    #   resp.data.engine_version #=> String
    #   resp.data.db_parameter_group_family #=> String
    #   resp.data.db_engine_description #=> String
    #   resp.data.db_engine_version_description #=> String
    #   resp.data.default_character_set #=> Types::CharacterSet
    #   resp.data.default_character_set.character_set_name #=> String
    #   resp.data.default_character_set.character_set_description #=> String
    #   resp.data.supported_character_sets #=> Array<CharacterSet>
    #   resp.data.supported_nchar_character_sets #=> Array<CharacterSet>
    #   resp.data.valid_upgrade_target #=> Array<UpgradeTarget>
    #   resp.data.valid_upgrade_target[0] #=> Types::UpgradeTarget
    #   resp.data.valid_upgrade_target[0].engine #=> String
    #   resp.data.valid_upgrade_target[0].engine_version #=> String
    #   resp.data.valid_upgrade_target[0].description #=> String
    #   resp.data.valid_upgrade_target[0].auto_upgrade #=> Boolean
    #   resp.data.valid_upgrade_target[0].is_major_version_upgrade #=> Boolean
    #   resp.data.valid_upgrade_target[0].supported_engine_modes #=> Array<String>
    #   resp.data.valid_upgrade_target[0].supported_engine_modes[0] #=> String
    #   resp.data.valid_upgrade_target[0].supports_parallel_query #=> Boolean
    #   resp.data.valid_upgrade_target[0].supports_global_databases #=> Boolean
    #   resp.data.valid_upgrade_target[0].supports_babelfish #=> Boolean
    #   resp.data.supported_timezones #=> Array<Timezone>
    #   resp.data.supported_timezones[0] #=> Types::Timezone
    #   resp.data.supported_timezones[0].timezone_name #=> String
    #   resp.data.exportable_log_types #=> Array<String>
    #   resp.data.exportable_log_types[0] #=> String
    #   resp.data.supports_log_exports_to_cloudwatch_logs #=> Boolean
    #   resp.data.supports_read_replica #=> Boolean
    #   resp.data.supported_engine_modes #=> Array<String>
    #   resp.data.supported_feature_names #=> Array<String>
    #   resp.data.supported_feature_names[0] #=> String
    #   resp.data.status #=> String
    #   resp.data.supports_parallel_query #=> Boolean
    #   resp.data.supports_global_databases #=> Boolean
    #   resp.data.major_engine_version #=> String
    #   resp.data.database_installation_files_s3_bucket_name #=> String
    #   resp.data.database_installation_files_s3_prefix #=> String
    #   resp.data.db_engine_version_arn #=> String
    #   resp.data.kms_key_id #=> String
    #   resp.data.create_time #=> Time
    #   resp.data.tag_list #=> Array<Tag>
    #   resp.data.tag_list[0] #=> Types::Tag
    #   resp.data.tag_list[0].key #=> String
    #   resp.data.tag_list[0].value #=> String
    #   resp.data.supports_babelfish #=> Boolean
    #
    def modify_custom_db_engine_version(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyCustomDBEngineVersionInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyCustomDBEngineVersionInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyCustomDBEngineVersion
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidCustomDBEngineVersionStateFault, Errors::CustomDBEngineVersionNotFoundFault]),
        data_parser: Parsers::ModifyCustomDBEngineVersion
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyCustomDBEngineVersion,
        stubs: @stubs,
        params_class: Params::ModifyCustomDBEngineVersionOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_custom_db_engine_version
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Modify the settings for an Amazon Aurora DB cluster or a Multi-AZ DB cluster.
    #            You can change one or more settings by specifying these parameters and the new values in the
    #            request.</p>
    #         <p>For more information on Amazon Aurora DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #               What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #               Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::ModifyDBClusterInput}.
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The DB cluster identifier for the cluster being modified. This parameter isn't case-sensitive.</p>
    #           <p>Constraints: This identifier must match the identifier of an existing DB
    #               cluster.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :new_db_cluster_identifier
    #   <p>The new DB cluster identifier for the DB cluster when renaming a DB cluster. This value is stored as a lowercase string.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain from 1 to 63 letters, numbers, or hyphens</p>
    #               </li>
    #               <li>
    #                   <p>The first character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-cluster2</code>
    #            </p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [Boolean] :apply_immediately
    #   <p>A value that indicates whether the modifications in this request and
    #         any pending modifications are asynchronously applied
    #         as soon as possible, regardless of the
    #         <code>PreferredMaintenanceWindow</code> setting for the DB cluster.
    #         If this parameter is disabled, changes to the
    #         DB cluster are applied during the next maintenance window.</p>
    #           <p>The <code>ApplyImmediately</code> parameter only affects the <code>EnableIAMDatabaseAuthentication</code>,
    #         <code>MasterUserPassword</code>, and <code>NewDBClusterIdentifier</code> values. If the <code>ApplyImmediately</code>
    #         parameter is disabled, then changes to the <code>EnableIAMDatabaseAuthentication</code>, <code>MasterUserPassword</code>,
    #         and <code>NewDBClusterIdentifier</code> values are applied during the next maintenance window. All other changes are
    #         applied immediately, regardless of the value of the <code>ApplyImmediately</code> parameter.</p>
    #           <p>By default, this parameter is disabled.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Integer] :backup_retention_period
    #   <p>The number of days for which automated backups are retained. Specify a minimum value of 1.</p>
    #           <p>Default: 1</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be a value from 1 to 35</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :db_cluster_parameter_group_name
    #   <p>The name of the DB cluster parameter group to use for the DB cluster.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Array<String>] :vpc_security_group_ids
    #   <p>A list of VPC security groups that the DB cluster will belong to.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Integer] :port
    #   <p>The port number on which the DB cluster accepts connections.</p>
    #           <p>Constraints: Value must be <code>1150-65535</code>
    #            </p>
    #           <p>Default: The same port as the original DB cluster.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [String] :master_user_password
    #   <p>The new password for the master database user. This password can contain any printable ASCII character except "/", """, or "@".</p>
    #           <p>Constraints: Must contain from 8 to 41 characters.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :option_group_name
    #   <p>A value that indicates that the DB cluster should be associated with the specified option group.</p>
    #           <p>DB clusters are associated with a default option group that can't be modified.</p>
    #
    # @option params [String] :preferred_backup_window
    #   <p>The daily time range during which automated backups are created
    #               if automated backups are enabled,
    #               using the <code>BackupRetentionPeriod</code> parameter.</p>
    #           <p>The default is a 30-minute window selected at random from an
    #               8-hour block of time for each Amazon Web Services Region.
    #               To view the time blocks available, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Managing.Backups.html#Aurora.Managing.Backups.BackupWindow">
    #                   Backup window</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be in the format <code>hh24:mi-hh24:mi</code>.</p>
    #               </li>
    #               <li>
    #                   <p>Must be in Universal Coordinated Time (UTC).</p>
    #               </li>
    #               <li>
    #                   <p>Must not conflict with the preferred maintenance window.</p>
    #               </li>
    #               <li>
    #                   <p>Must be at least 30 minutes.</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :preferred_maintenance_window
    #   <p>The weekly time range during which system maintenance can occur, in Universal Coordinated Time (UTC).</p>
    #           <p>Format: <code>ddd:hh24:mi-ddd:hh24:mi</code>
    #            </p>
    #           <p>The default is a 30-minute window selected at random from an
    #               8-hour block of time for each Amazon Web Services Region, occurring on a random day of the
    #               week. To see the time blocks available, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_UpgradeDBInstance.Maintenance.html#AdjustingTheMaintenanceWindow.Aurora">
    #                   Adjusting the Preferred DB Cluster Maintenance Window</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Valid Days: Mon, Tue, Wed, Thu, Fri, Sat, Sun.</p>
    #           <p>Constraints: Minimum 30-minute window.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Boolean] :enable_iam_database_authentication
    #   <p>A value that indicates whether to enable mapping of Amazon Web Services Identity and Access
    #               Management (IAM) accounts to database accounts. By default, mapping isn't
    #               enabled.</p>
    #           <p>For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/UsingWithRDS.IAMDBAuth.html">
    #                   IAM Database Authentication</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [Integer] :backtrack_window
    #   <p>The target backtrack window, in seconds. To disable backtracking, set this value to
    #               0.</p>
    #           <p>Default: 0</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If specified, this value must be set to a number from 0 to 259,200 (72 hours).</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora MySQL DB clusters only</p>
    #
    # @option params [CloudwatchLogsExportConfiguration] :cloudwatch_logs_export_configuration
    #   <p>The configuration setting for the log types to be enabled for export to CloudWatch Logs for a specific DB cluster. The values
    #               in the list depend on the DB engine being used.</p>
    #               <p>
    #               <b>RDS for MySQL</b>
    #            </p>
    #               <p>Possible values are <code>error</code>, <code>general</code>, and <code>slowquery</code>.</p>
    #               <p>
    #               <b>RDS for PostgreSQL</b>
    #            </p>
    #               <p>Possible values are <code>postgresql</code> and <code>upgrade</code>.</p>
    #               <p>
    #               <b>Aurora MySQL</b>
    #            </p>
    #               <p>Possible values are <code>audit</code>, <code>error</code>, <code>general</code>, and <code>slowquery</code>.</p>
    #               <p>
    #               <b>Aurora PostgreSQL</b>
    #            </p>
    #               <p>Possible value is <code>postgresql</code>.</p>
    #               <p>For more information about exporting CloudWatch Logs for Amazon RDS, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.html#USER_LogAccess.Procedural.UploadtoCloudWatch">
    #                   Publishing Database Logs to Amazon CloudWatch Logs</a> in the <i>Amazon RDS User Guide</i>.</p>
    #               <p>For more information about exporting CloudWatch Logs for Amazon Aurora, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_LogAccess.html#USER_LogAccess.Procedural.UploadtoCloudWatch">Publishing Database Logs to Amazon CloudWatch Logs</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :engine_version
    #   <p>The version number of the database engine to which you want to upgrade.
    #               Changing this parameter results in an outage. The change is applied during
    #               the next maintenance window unless <code>ApplyImmediately</code> is enabled.</p>
    #           <p>To list all of the available engine versions for MySQL 5.6-compatible Aurora, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine aurora --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>To list all of the available engine versions for MySQL 5.7-compatible and MySQL 8.0-compatible Aurora, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine aurora-mysql --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>To list all of the available engine versions for Aurora PostgreSQL, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine aurora-postgresql --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>To list all of the available engine versions for RDS for MySQL, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine mysql --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>To list all of the available engine versions for RDS for PostgreSQL, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine postgres --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Boolean] :allow_major_version_upgrade
    #   <p>A value that indicates whether major version upgrades are allowed.</p>
    #           <p>Constraints: You must allow major version upgrades when specifying a value for the
    #                   <code>EngineVersion</code> parameter that is a different major version than the DB
    #               cluster's current version.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [String] :db_instance_parameter_group_name
    #   <p>The name of the DB parameter group to apply to all instances of the DB cluster.</p>
    #           <note>
    #               <p>When you apply a parameter group using the <code>DBInstanceParameterGroupName</code> parameter, the DB
    #             cluster isn't rebooted automatically. Also, parameter changes are applied immediately rather than
    #                during the next maintenance window.</p>
    #           </note>
    #           <p>Default: The existing name setting</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>The DB parameter group must be in the same DB parameter group family as this DB cluster.</p>
    #               </li>
    #               <li>
    #                   <p>The <code>DBInstanceParameterGroupName</code> parameter is valid in combination with the
    #                 <code>AllowMajorVersionUpgrade</code> parameter for a major version upgrade only.</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [String] :domain
    #   <p>The Active Directory directory ID to move the DB cluster to.
    #             Specify <code>none</code> to remove the cluster from its current domain.
    #             The domain must be created prior to this operation.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/kerberos-authentication.html">Kerberos Authentication</a>
    #               in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [String] :domain_iam_role_name
    #   <p>Specify the name of the IAM role to be used when making API calls to the Directory Service.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [ScalingConfiguration] :scaling_configuration
    #   <p>The scaling properties of the DB cluster. You can only modify scaling properties for DB clusters in <code>serverless</code> DB engine mode.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [Boolean] :deletion_protection
    #   <p>A value that indicates whether the DB cluster has deletion protection enabled.
    #               The database can't be deleted when deletion protection is enabled. By default,
    #               deletion protection isn't enabled.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Boolean] :enable_http_endpoint
    #   <p>A value that indicates whether to enable the HTTP endpoint for an Aurora Serverless v1 DB cluster. By default, the HTTP endpoint
    #               is disabled.</p>
    #           <p>When enabled, the HTTP endpoint provides a connectionless web service API for running
    #               SQL queries on the Aurora Serverless v1 DB cluster. You can also query your database
    #               from inside the RDS console with the query editor.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/data-api.html">Using the Data API for Aurora Serverless v1</a> in the
    #               <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [Boolean] :copy_tags_to_snapshot
    #   <p>A value that indicates whether to copy all tags from the DB cluster to snapshots of the DB cluster.
    #               The default is not to copy them.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Boolean] :enable_global_write_forwarding
    #   <p>A value that indicates whether to enable this DB cluster to forward write operations to the primary cluster of an
    #         Aurora global database (<a>GlobalCluster</a>). By default, write operations are not allowed on Aurora DB clusters that
    #         are secondary clusters in an Aurora global database.</p>
    #           <p>You can set this value only on Aurora DB clusters that are members of an Aurora global database. With this parameter
    #         enabled, a secondary cluster can forward writes to the current primary cluster and the resulting changes are replicated back to
    #         this cluster. For the primary DB cluster of an Aurora global database, this value is used immediately if the primary is
    #         demoted by the <a>FailoverGlobalCluster</a> API operation, but it does nothing until then.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [String] :db_cluster_instance_class
    #   <p>The compute and memory capacity of each DB instance in the Multi-AZ DB cluster, for example db.m6g.xlarge.
    #               Not all DB instance classes are available in all Amazon Web Services Regions, or for all database engines.</p>
    #           <p>For the full list of DB instance classes and availability for your engine, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html">
    #           DB Instance Class</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [Integer] :allocated_storage
    #   <p>The amount of storage in gibibytes (GiB) to allocate to each DB instance in the Multi-AZ DB cluster.</p>
    #           <p>Type: Integer</p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [String] :storage_type
    #   <p>Specifies the storage type to be associated with the DB cluster.</p>
    #           <p>Valid values: <code>io1</code>
    #            </p>
    #           <p>When specified, a value for the <code>Iops</code> parameter is required.</p>
    #           <p>Default: <code>io1</code>
    #            </p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [Integer] :iops
    #   <p>The amount of Provisioned IOPS (input/output operations per second) to be initially allocated
    #               for each DB instance in the Multi-AZ DB cluster.</p>
    #           <p>For information about valid Iops values, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html#USER_PIOPS">Amazon RDS Provisioned IOPS Storage to Improve Performance</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>Constraints: Must be a multiple between .5 and 50 of the storage amount for the DB cluster.</p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [Boolean] :auto_minor_version_upgrade
    #   <p>A value that indicates whether minor engine upgrades are applied automatically to the DB cluster during the maintenance window.
    #               By default, minor engine upgrades are applied automatically.</p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [Integer] :monitoring_interval
    #   <p>The interval, in seconds, between points when Enhanced Monitoring metrics are collected for the DB cluster.
    #               To turn off collecting Enhanced Monitoring metrics, specify 0. The default is 0.</p>
    #           <p>If <code>MonitoringRoleArn</code> is specified, also set <code>MonitoringInterval</code>
    #               to a value other than 0.</p>
    #           <p>Valid Values: <code>0, 1, 5, 10, 15, 30, 60</code>
    #            </p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [String] :monitoring_role_arn
    #   <p>The Amazon Resource Name (ARN) for the IAM role that permits RDS to send Enhanced Monitoring metrics to Amazon CloudWatch Logs. An
    #               example is <code>arn:aws:iam:123456789012:role/emaccess</code>. For information on creating a monitoring role,
    #               see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.html#USER_Monitoring.OS.IAMRole">To
    #                   create an IAM role for Amazon RDS Enhanced Monitoring</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>If <code>MonitoringInterval</code> is set to a value other than 0, supply a <code>MonitoringRoleArn</code> value.</p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [Boolean] :enable_performance_insights
    #   <p>A value that indicates whether to turn on Performance Insights for the DB cluster.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PerfInsights.html">
    #               Using Amazon Performance Insights</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [String] :performance_insights_kms_key_id
    #   <p>The Amazon Web Services KMS key identifier for encryption of Performance Insights data.</p>
    #           <p>The Amazon Web Services KMS key identifier is the key ARN, key ID, alias ARN, or alias name for the KMS key.</p>
    #           <p>If you don't specify a value for <code>PerformanceInsightsKMSKeyId</code>, then Amazon RDS
    #               uses your default KMS key. There is a default KMS key for your Amazon Web Services account.
    #               Your Amazon Web Services account has a different default KMS key for each Amazon Web Services Region.</p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [Integer] :performance_insights_retention_period
    #   <p>The amount of time, in days, to retain Performance Insights data. Valid values are 7 or 731 (2 years).</p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [ServerlessV2ScalingConfiguration] :serverless_v2_scaling_configuration
    #   <p>Contains the scaling configuration of an Aurora Serverless v2 DB cluster.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v2.html">Using Amazon Aurora Serverless v2</a> in the
    #               <i>Amazon Aurora User Guide</i>.</p>
    #
    # @return [Types::ModifyDBClusterOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_db_cluster(
    #     db_cluster_identifier: 'DBClusterIdentifier', # required
    #     new_db_cluster_identifier: 'NewDBClusterIdentifier',
    #     apply_immediately: false,
    #     backup_retention_period: 1,
    #     db_cluster_parameter_group_name: 'DBClusterParameterGroupName',
    #     vpc_security_group_ids: [
    #       'member'
    #     ],
    #     port: 1,
    #     master_user_password: 'MasterUserPassword',
    #     option_group_name: 'OptionGroupName',
    #     preferred_backup_window: 'PreferredBackupWindow',
    #     preferred_maintenance_window: 'PreferredMaintenanceWindow',
    #     enable_iam_database_authentication: false,
    #     backtrack_window: 1,
    #     cloudwatch_logs_export_configuration: {
    #       enable_log_types: [
    #         'member'
    #       ],
    #     },
    #     engine_version: 'EngineVersion',
    #     allow_major_version_upgrade: false,
    #     db_instance_parameter_group_name: 'DBInstanceParameterGroupName',
    #     domain: 'Domain',
    #     domain_iam_role_name: 'DomainIAMRoleName',
    #     scaling_configuration: {
    #       min_capacity: 1,
    #       max_capacity: 1,
    #       auto_pause: false,
    #       seconds_until_auto_pause: 1,
    #       timeout_action: 'TimeoutAction',
    #       seconds_before_timeout: 1
    #     },
    #     deletion_protection: false,
    #     enable_http_endpoint: false,
    #     copy_tags_to_snapshot: false,
    #     enable_global_write_forwarding: false,
    #     db_cluster_instance_class: 'DBClusterInstanceClass',
    #     allocated_storage: 1,
    #     storage_type: 'StorageType',
    #     iops: 1,
    #     auto_minor_version_upgrade: false,
    #     monitoring_interval: 1,
    #     monitoring_role_arn: 'MonitoringRoleArn',
    #     enable_performance_insights: false,
    #     performance_insights_kms_key_id: 'PerformanceInsightsKMSKeyId',
    #     performance_insights_retention_period: 1,
    #     serverless_v2_scaling_configuration: {
    #       min_capacity: 1.0,
    #       max_capacity: 1.0
    #     }
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyDBClusterOutput
    #   resp.data.db_cluster #=> Types::DBCluster
    #   resp.data.db_cluster.allocated_storage #=> Integer
    #   resp.data.db_cluster.availability_zones #=> Array<String>
    #   resp.data.db_cluster.availability_zones[0] #=> String
    #   resp.data.db_cluster.backup_retention_period #=> Integer
    #   resp.data.db_cluster.character_set_name #=> String
    #   resp.data.db_cluster.database_name #=> String
    #   resp.data.db_cluster.db_cluster_identifier #=> String
    #   resp.data.db_cluster.db_cluster_parameter_group #=> String
    #   resp.data.db_cluster.db_subnet_group #=> String
    #   resp.data.db_cluster.status #=> String
    #   resp.data.db_cluster.automatic_restart_time #=> Time
    #   resp.data.db_cluster.percent_progress #=> String
    #   resp.data.db_cluster.earliest_restorable_time #=> Time
    #   resp.data.db_cluster.endpoint #=> String
    #   resp.data.db_cluster.reader_endpoint #=> String
    #   resp.data.db_cluster.custom_endpoints #=> Array<String>
    #   resp.data.db_cluster.custom_endpoints[0] #=> String
    #   resp.data.db_cluster.multi_az #=> Boolean
    #   resp.data.db_cluster.engine #=> String
    #   resp.data.db_cluster.engine_version #=> String
    #   resp.data.db_cluster.latest_restorable_time #=> Time
    #   resp.data.db_cluster.port #=> Integer
    #   resp.data.db_cluster.master_username #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships #=> Array<DBClusterOptionGroupStatus>
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0] #=> Types::DBClusterOptionGroupStatus
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].db_cluster_option_group_name #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].status #=> String
    #   resp.data.db_cluster.preferred_backup_window #=> String
    #   resp.data.db_cluster.preferred_maintenance_window #=> String
    #   resp.data.db_cluster.replication_source_identifier #=> String
    #   resp.data.db_cluster.read_replica_identifiers #=> Array<String>
    #   resp.data.db_cluster.read_replica_identifiers[0] #=> String
    #   resp.data.db_cluster.db_cluster_members #=> Array<DBClusterMember>
    #   resp.data.db_cluster.db_cluster_members[0] #=> Types::DBClusterMember
    #   resp.data.db_cluster.db_cluster_members[0].db_instance_identifier #=> String
    #   resp.data.db_cluster.db_cluster_members[0].is_cluster_writer #=> Boolean
    #   resp.data.db_cluster.db_cluster_members[0].db_cluster_parameter_group_status #=> String
    #   resp.data.db_cluster.db_cluster_members[0].promotion_tier #=> Integer
    #   resp.data.db_cluster.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_cluster.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_cluster.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_cluster.vpc_security_groups[0].status #=> String
    #   resp.data.db_cluster.hosted_zone_id #=> String
    #   resp.data.db_cluster.storage_encrypted #=> Boolean
    #   resp.data.db_cluster.kms_key_id #=> String
    #   resp.data.db_cluster.db_cluster_resource_id #=> String
    #   resp.data.db_cluster.db_cluster_arn #=> String
    #   resp.data.db_cluster.associated_roles #=> Array<DBClusterRole>
    #   resp.data.db_cluster.associated_roles[0] #=> Types::DBClusterRole
    #   resp.data.db_cluster.associated_roles[0].role_arn #=> String
    #   resp.data.db_cluster.associated_roles[0].status #=> String
    #   resp.data.db_cluster.associated_roles[0].feature_name #=> String
    #   resp.data.db_cluster.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.clone_group_id #=> String
    #   resp.data.db_cluster.cluster_create_time #=> Time
    #   resp.data.db_cluster.earliest_backtrack_time #=> Time
    #   resp.data.db_cluster.backtrack_window #=> Integer
    #   resp.data.db_cluster.backtrack_consumed_change_records #=> Integer
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports[0] #=> String
    #   resp.data.db_cluster.capacity #=> Integer
    #   resp.data.db_cluster.engine_mode #=> String
    #   resp.data.db_cluster.scaling_configuration_info #=> Types::ScalingConfigurationInfo
    #   resp.data.db_cluster.scaling_configuration_info.min_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.max_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.auto_pause #=> Boolean
    #   resp.data.db_cluster.scaling_configuration_info.seconds_until_auto_pause #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.timeout_action #=> String
    #   resp.data.db_cluster.scaling_configuration_info.seconds_before_timeout #=> Integer
    #   resp.data.db_cluster.deletion_protection #=> Boolean
    #   resp.data.db_cluster.http_endpoint_enabled #=> Boolean
    #   resp.data.db_cluster.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_cluster.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_cluster.activity_stream_kms_key_id #=> String
    #   resp.data.db_cluster.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_cluster.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_cluster.cross_account_clone #=> Boolean
    #   resp.data.db_cluster.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_cluster.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_cluster.domain_memberships[0].domain #=> String
    #   resp.data.db_cluster.domain_memberships[0].status #=> String
    #   resp.data.db_cluster.domain_memberships[0].fqdn #=> String
    #   resp.data.db_cluster.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_cluster.tag_list #=> Array<Tag>
    #   resp.data.db_cluster.tag_list[0] #=> Types::Tag
    #   resp.data.db_cluster.tag_list[0].key #=> String
    #   resp.data.db_cluster.tag_list[0].value #=> String
    #   resp.data.db_cluster.global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.db_cluster.global_write_forwarding_requested #=> Boolean
    #   resp.data.db_cluster.pending_modified_values #=> Types::ClusterPendingModifiedValues
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.db_cluster_identifier #=> String
    #   resp.data.db_cluster.pending_modified_values.master_user_password #=> String
    #   resp.data.db_cluster.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.pending_modified_values.engine_version #=> String
    #   resp.data.db_cluster.db_cluster_instance_class #=> String
    #   resp.data.db_cluster.storage_type #=> String
    #   resp.data.db_cluster.iops #=> Integer
    #   resp.data.db_cluster.publicly_accessible #=> Boolean
    #   resp.data.db_cluster.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_cluster.monitoring_interval #=> Integer
    #   resp.data.db_cluster.monitoring_role_arn #=> String
    #   resp.data.db_cluster.performance_insights_enabled #=> Boolean
    #   resp.data.db_cluster.performance_insights_kms_key_id #=> String
    #   resp.data.db_cluster.performance_insights_retention_period #=> Integer
    #   resp.data.db_cluster.serverless_v2_scaling_configuration #=> Types::ServerlessV2ScalingConfigurationInfo
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.min_capacity #=> Float
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.max_capacity #=> Float
    #
    def modify_db_cluster(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyDBClusterInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyDBClusterInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyDBCluster
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::InvalidDBSubnetGroupStateFault, Errors::DBSubnetGroupNotFoundFault, Errors::DBClusterParameterGroupNotFoundFault, Errors::InvalidDBSecurityGroupStateFault, Errors::InvalidVPCNetworkStateFault, Errors::StorageQuotaExceededFault, Errors::InvalidSubnet, Errors::InvalidDBInstanceStateFault, Errors::DBClusterAlreadyExistsFault, Errors::DomainNotFoundFault, Errors::InvalidDBClusterStateFault]),
        data_parser: Parsers::ModifyDBCluster
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyDBCluster,
        stubs: @stubs,
        params_class: Params::ModifyDBClusterOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_db_cluster
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Modifies the properties of an endpoint in an Amazon Aurora DB cluster.</p>
    #         <note>
    #             <p>This action only applies to Aurora DB clusters.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::ModifyDBClusterEndpointInput}.
    #
    # @option params [String] :db_cluster_endpoint_identifier
    #   <p>The identifier of the endpoint to modify. This parameter is stored as a lowercase string.</p>
    #
    # @option params [String] :endpoint_type
    #   <p>The type of the endpoint. One of: <code>READER</code>, <code>WRITER</code>, <code>ANY</code>.</p>
    #
    # @option params [Array<String>] :static_members
    #   <p>List of DB instance identifiers that are part of the custom endpoint group.</p>
    #
    # @option params [Array<String>] :excluded_members
    #   <p>List of DB instance identifiers that aren't part of the custom endpoint group.
    #          All other eligible instances are reachable through the custom endpoint.
    #          Only relevant if the list of static members is empty.</p>
    #
    # @return [Types::ModifyDBClusterEndpointOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_db_cluster_endpoint(
    #     db_cluster_endpoint_identifier: 'DBClusterEndpointIdentifier', # required
    #     endpoint_type: 'EndpointType',
    #     static_members: [
    #       'member'
    #     ],
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyDBClusterEndpointOutput
    #   resp.data.db_cluster_endpoint_identifier #=> String
    #   resp.data.db_cluster_identifier #=> String
    #   resp.data.db_cluster_endpoint_resource_identifier #=> String
    #   resp.data.endpoint #=> String
    #   resp.data.status #=> String
    #   resp.data.endpoint_type #=> String
    #   resp.data.custom_endpoint_type #=> String
    #   resp.data.static_members #=> Array<String>
    #   resp.data.static_members[0] #=> String
    #   resp.data.excluded_members #=> Array<String>
    #   resp.data.db_cluster_endpoint_arn #=> String
    #
    def modify_db_cluster_endpoint(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyDBClusterEndpointInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyDBClusterEndpointInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyDBClusterEndpoint
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBInstanceNotFoundFault, Errors::DBClusterEndpointNotFoundFault, Errors::InvalidDBClusterStateFault, Errors::InvalidDBClusterEndpointStateFault, Errors::InvalidDBInstanceStateFault]),
        data_parser: Parsers::ModifyDBClusterEndpoint
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyDBClusterEndpoint,
        stubs: @stubs,
        params_class: Params::ModifyDBClusterEndpointOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_db_cluster_endpoint
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Modifies the parameters of a DB cluster parameter group. To modify more than one parameter,
    #             submit a list of the following: <code>ParameterName</code>, <code>ParameterValue</code>,
    #             and <code>ApplyMethod</code>. A maximum of 20
    #             parameters can be modified in a single request.</p>
    #         <important>
    #             <p>After you create a DB cluster parameter group, you should wait at least 5 minutes
    #                 before creating your first DB cluster that uses that DB cluster parameter group as the default parameter
    #                 group. This allows Amazon RDS to fully complete the create action before the parameter
    #                 group is used as the default for a new DB cluster. This is especially important for parameters
    #                 that are critical when creating the default database for a DB cluster, such as the character set
    #                 for the default database defined by the <code>character_set_database</code> parameter. You can use the
    #                 <i>Parameter Groups</i> option of the <a href="https://console.aws.amazon.com/rds/">Amazon RDS console</a> or the
    #                 <code>DescribeDBClusterParameters</code> action to verify
    #                 that your DB cluster parameter group has been created or modified.</p>
    #             <p>If the modified DB cluster parameter group is used by an Aurora Serverless v1 cluster, Aurora
    #                applies the update immediately. The cluster restart might interrupt your workload. In that case,
    #                your application must reopen any connections and retry any transactions that were active
    #                when the parameter changes took effect.</p>
    #         </important>
    #         <p>For more information on Amazon Aurora DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #               What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #               Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide.</i>
    #          </p>
    #
    # @param [Hash] params
    #   See {Types::ModifyDBClusterParameterGroupInput}.
    #
    # @option params [String] :db_cluster_parameter_group_name
    #   <p>The name of the DB cluster parameter group to modify.</p>
    #
    # @option params [Array<Parameter>] :parameters
    #   <p>A list of parameters in the DB cluster parameter group to modify.</p>
    #           <p>Valid Values (for the application method): <code>immediate | pending-reboot</code>
    #            </p>
    #           <note>
    #               <p>You can use the <code>immediate</code> value with dynamic parameters only. You can use the
    #                 <code>pending-reboot</code> value for both dynamic and static parameters.</p>
    #               <p>When the application method is <code>immediate</code>, changes to dynamic parameters are applied immediately
    #             to the DB clusters associated with the parameter group. When the application method is <code>pending-reboot</code>,
    #             changes to dynamic and static parameters are applied after a reboot without failover to the DB clusters associated with the
    #             parameter group.</p>
    #           </note>
    #
    # @return [Types::ModifyDBClusterParameterGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_db_cluster_parameter_group(
    #     db_cluster_parameter_group_name: 'DBClusterParameterGroupName', # required
    #     parameters: [
    #       {
    #         parameter_name: 'ParameterName',
    #         parameter_value: 'ParameterValue',
    #         description: 'Description',
    #         source: 'Source',
    #         apply_type: 'ApplyType',
    #         data_type: 'DataType',
    #         allowed_values: 'AllowedValues',
    #         is_modifiable: false,
    #         minimum_engine_version: 'MinimumEngineVersion',
    #         apply_method: 'immediate', # accepts ["immediate", "pending-reboot"]
    #         supported_engine_modes: [
    #           'member'
    #         ]
    #       }
    #     ] # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyDBClusterParameterGroupOutput
    #   resp.data.db_cluster_parameter_group_name #=> String
    #
    def modify_db_cluster_parameter_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyDBClusterParameterGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyDBClusterParameterGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyDBClusterParameterGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidDBParameterGroupStateFault, Errors::DBParameterGroupNotFoundFault]),
        data_parser: Parsers::ModifyDBClusterParameterGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyDBClusterParameterGroup,
        stubs: @stubs,
        params_class: Params::ModifyDBClusterParameterGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_db_cluster_parameter_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Adds an attribute and values to, or removes an attribute and values from, a manual DB cluster snapshot.</p>
    #         <p>To share a manual DB cluster snapshot with other Amazon Web Services accounts, specify
    #                 <code>restore</code> as the <code>AttributeName</code> and use the
    #                 <code>ValuesToAdd</code> parameter to add a list of IDs of the Amazon Web Services accounts that are
    #             authorized to restore the manual DB cluster snapshot. Use the value <code>all</code> to
    #             make the manual DB cluster snapshot public, which means that it can be copied or
    #             restored by all Amazon Web Services accounts.</p>
    #         <note>
    #             <p>Don't add the <code>all</code> value for any manual DB cluster snapshots
    #                 that contain private information that you don't want available to all Amazon Web Services
    #                 accounts.</p>
    #         </note>
    #         <p>If a manual DB cluster snapshot is encrypted, it can be shared, but only by
    #             specifying a list of authorized Amazon Web Services account IDs for the <code>ValuesToAdd</code>
    #             parameter. You can't use <code>all</code> as a value for that parameter in this
    #             case.</p>
    #         <p>To view which Amazon Web Services accounts have access to copy or restore a manual DB cluster
    #             snapshot, or whether a manual DB cluster snapshot is public or private, use the <a>DescribeDBClusterSnapshotAttributes</a> API action. The accounts are
    #             returned as values for the <code>restore</code> attribute.</p>
    #
    # @param [Hash] params
    #   See {Types::ModifyDBClusterSnapshotAttributeInput}.
    #
    # @option params [String] :db_cluster_snapshot_identifier
    #   <p>The identifier for the DB cluster snapshot to modify the attributes for.</p>
    #
    # @option params [String] :attribute_name
    #   <p>The name of the DB cluster snapshot attribute to modify.</p>
    #           <p>To manage authorization for other Amazon Web Services accounts to copy or restore a manual DB cluster snapshot,
    #               set this value to <code>restore</code>.</p>
    #           <note>
    #               <p>To view the list of attributes available to modify, use the
    #                   <a>DescribeDBClusterSnapshotAttributes</a> API action.</p>
    #           </note>
    #
    # @option params [Array<String>] :values_to_add
    #   <p>A list of DB cluster snapshot attributes to add to the attribute specified by <code>AttributeName</code>.</p>
    #           <p>To authorize other Amazon Web Services accounts to copy or restore a manual DB cluster snapshot, set this list to include one or more Amazon Web Services account
    #               IDs, or <code>all</code> to make the manual DB cluster snapshot restorable by
    #               any Amazon Web Services account. Do not add the <code>all</code> value for any
    #               manual DB cluster snapshots that contain private information that you don't want available
    #               to all Amazon Web Services accounts.</p>
    #
    # @option params [Array<String>] :values_to_remove
    #   <p>A list of DB cluster snapshot attributes to remove from the attribute specified by <code>AttributeName</code>.</p>
    #           <p>To remove authorization for other Amazon Web Services accounts to copy or restore a manual DB cluster snapshot, set this list to include
    #               one or more Amazon Web Services account
    #               identifiers, or <code>all</code> to remove authorization for any Amazon Web Services account to copy or
    #               restore the DB cluster snapshot. If you specify <code>all</code>, an Amazon Web Services account whose account ID is
    #               explicitly added to the <code>restore</code> attribute
    #               can still copy or restore a manual DB cluster snapshot.</p>
    #
    # @return [Types::ModifyDBClusterSnapshotAttributeOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_db_cluster_snapshot_attribute(
    #     db_cluster_snapshot_identifier: 'DBClusterSnapshotIdentifier', # required
    #     attribute_name: 'AttributeName', # required
    #     values_to_add: [
    #       'member'
    #     ],
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyDBClusterSnapshotAttributeOutput
    #   resp.data.db_cluster_snapshot_attributes_result #=> Types::DBClusterSnapshotAttributesResult
    #   resp.data.db_cluster_snapshot_attributes_result.db_cluster_snapshot_identifier #=> String
    #   resp.data.db_cluster_snapshot_attributes_result.db_cluster_snapshot_attributes #=> Array<DBClusterSnapshotAttribute>
    #   resp.data.db_cluster_snapshot_attributes_result.db_cluster_snapshot_attributes[0] #=> Types::DBClusterSnapshotAttribute
    #   resp.data.db_cluster_snapshot_attributes_result.db_cluster_snapshot_attributes[0].attribute_name #=> String
    #   resp.data.db_cluster_snapshot_attributes_result.db_cluster_snapshot_attributes[0].attribute_values #=> Array<String>
    #   resp.data.db_cluster_snapshot_attributes_result.db_cluster_snapshot_attributes[0].attribute_values[0] #=> String
    #
    def modify_db_cluster_snapshot_attribute(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyDBClusterSnapshotAttributeInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyDBClusterSnapshotAttributeInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyDBClusterSnapshotAttribute
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidDBClusterSnapshotStateFault, Errors::SharedSnapshotQuotaExceededFault, Errors::DBClusterSnapshotNotFoundFault]),
        data_parser: Parsers::ModifyDBClusterSnapshotAttribute
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyDBClusterSnapshotAttribute,
        stubs: @stubs,
        params_class: Params::ModifyDBClusterSnapshotAttributeOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_db_cluster_snapshot_attribute
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Modifies settings for a DB instance.
    #           You can change one or more database configuration parameters by specifying these parameters and the new values in the request.
    #             To learn what modifications you can make to your DB instance,
    #             call <code>DescribeValidDBInstanceModifications</code>
    #             before you call <code>ModifyDBInstance</code>.</p>
    #
    # @param [Hash] params
    #   See {Types::ModifyDBInstanceInput}.
    #
    # @option params [String] :db_instance_identifier
    #   <p>The DB instance identifier. This value is stored as a lowercase string.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the identifier of an existing DBInstance.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Integer] :allocated_storage
    #   <p>The new amount of storage in gibibytes (GiB) to allocate for the DB instance.</p>
    #           <p>For MariaDB, MySQL, Oracle, and PostgreSQL,
    #             the value supplied must be at least 10% greater than the current value.
    #             Values that are not at least 10% greater than the existing value are rounded up
    #             so that they are 10% greater than the current value.</p>
    #           <p>For the valid values for allocated storage for each engine,
    #             see <code>CreateDBInstance</code>.</p>
    #
    # @option params [String] :db_instance_class
    #   <p>The new compute and memory capacity of the DB instance, for example db.m4.large.
    #             Not all DB instance classes are available in all Amazon Web Services Regions, or for all database engines.
    #             For the full list of DB instance classes,
    #             and availability for your engine, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html">DB Instance Class</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>If you modify the DB instance class, an outage occurs during the change.
    #           The change is applied during the next maintenance window,
    #           unless <code>ApplyImmediately</code> is enabled for this request.</p>
    #           <p>This setting doesn't apply to RDS Custom for Oracle.</p>
    #           <p>Default: Uses existing setting</p>
    #
    # @option params [String] :db_subnet_group_name
    #   <p>The new DB subnet group for the DB instance.
    #             You can use this parameter to move your DB instance to a different VPC.
    #
    #
    #             If your DB instance isn't in a VPC, you can also use this parameter to move your DB instance into a VPC.
    #             For more information, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.WorkingWithRDSInstanceinaVPC.html#USER_VPC.Non-VPC2VPC">Working with a DB instance in a VPC</a>
    #             in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>Changing the subnet group causes an outage during the change.
    #           The change is applied during the next maintenance window,
    #           unless you enable <code>ApplyImmediately</code>.</p>
    #           <p>This parameter doesn't apply to RDS Custom.</p>
    #           <p>Constraints: If supplied, must match the name of an existing DBSubnetGroup.</p>
    #           <p>Example: <code>mydbsubnetgroup</code>
    #            </p>
    #
    # @option params [Array<String>] :db_security_groups
    #   <p>A list of DB security groups to authorize on this DB instance. Changing this setting doesn't
    #             result in an outage and the change is asynchronously applied as soon as possible.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match existing DBSecurityGroups.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Array<String>] :vpc_security_group_ids
    #   <p>A list of Amazon EC2 VPC security groups to authorize on this DB instance. This change is
    #             asynchronously applied as soon as possible.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. The associated list of EC2 VPC security groups is managed by
    #             the DB cluster. For more information, see <code>ModifyDBCluster</code>.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match existing VpcSecurityGroupIds.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Boolean] :apply_immediately
    #   <p>A value that indicates whether the modifications in this request and any pending modifications are asynchronously applied as soon as possible,
    #             regardless of the <code>PreferredMaintenanceWindow</code> setting for the DB instance. By default, this parameter is disabled.</p>
    #           <p>If this parameter is disabled, changes to the DB instance are applied during the next maintenance window. Some parameter changes can cause an outage
    #           and are applied on the next call to <a>RebootDBInstance</a>, or the next failure reboot. Review the table of parameters in
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.DBInstance.Modifying.html">Modifying a DB Instance</a> in the
    #           <i>Amazon RDS User Guide</i> to see the impact of enabling or disabling <code>ApplyImmediately</code> for each modified parameter and to
    #           determine when the changes are applied.</p>
    #
    # @option params [String] :master_user_password
    #   <p>The new password for the master user. The password can include any printable ASCII
    #             character except "/", """, or "@".</p>
    #           <p>Changing this parameter doesn't result in an outage and the change is asynchronously applied as soon as possible.
    #           Between the time of the request and the completion of the request,
    #           the <code>MasterUserPassword</code> element exists in the
    #             <code>PendingModifiedValues</code> element of the operation response.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. The password for the master user is managed by the DB cluster. For
    #               more information, see <code>ModifyDBCluster</code>.</p>
    #           <p>Default: Uses existing setting</p>
    #           <p>
    #               <b>MariaDB</b>
    #            </p>
    #           <p>Constraints: Must contain from 8 to 41 characters.</p>
    #           <p>
    #               <b>Microsoft SQL Server</b>
    #            </p>
    #           <p>Constraints: Must contain from 8 to 128 characters.</p>
    #           <p>
    #               <b>MySQL</b>
    #            </p>
    #           <p>Constraints: Must contain from 8 to 41 characters.</p>
    #           <p>
    #               <b>Oracle</b>
    #            </p>
    #           <p>Constraints: Must contain from 8 to 30 characters.</p>
    #           <p>
    #               <b>PostgreSQL</b>
    #            </p>
    #           <p>Constraints: Must contain from 8 to 128 characters.</p>
    #           <note>
    #               <p>Amazon RDS API actions never return the password,
    #                 so this action provides a way to regain access to a primary instance user if the password is lost.
    #                 This includes restoring privileges that might have been accidentally revoked.</p>
    #           </note>
    #
    # @option params [String] :db_parameter_group_name
    #   <p>The name of the DB parameter group to apply to the DB instance.</p>
    #           <p>Changing this setting doesn't result in an outage. The parameter group name itself is changed
    #             immediately, but the actual parameter changes are not applied until you reboot the
    #             instance without failover. In this case, the DB instance isn't rebooted automatically, and the
    #             parameter changes aren't applied during the next maintenance window. However, if you modify
    #             dynamic parameters in the newly associated DB parameter group, these changes are applied
    #             immediately without a reboot.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Default: Uses existing setting</p>
    #           <p>Constraints: The DB parameter group must be in the same DB parameter group family as the DB instance.</p>
    #
    # @option params [Integer] :backup_retention_period
    #   <p>The number of days to retain automated backups. Setting this parameter to a positive number enables backups. Setting this parameter to 0 disables automated backups.</p>
    #           <note>
    #               <p>Enabling and disabling backups can result in a brief I/O suspension that lasts from a few seconds to a few minutes, depending on the size and class of your DB instance.</p>
    #           </note>
    #           <p>These changes are applied during the next maintenance window unless the <code>ApplyImmediately</code> parameter is enabled
    #               for this request. If you change the parameter from one non-zero value to another non-zero value, the change is asynchronously
    #               applied as soon as possible.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. The retention period for automated backups is managed by the DB
    #               cluster. For more information, see <code>ModifyDBCluster</code>.</p>
    #           <p>Default: Uses existing setting</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>It must be a value from 0 to 35. It can't be set to 0 if the DB instance is a source to
    #                 read replicas. It can't be set to 0 or 35 for an RDS Custom for Oracle DB instance.</p>
    #               </li>
    #               <li>
    #                   <p>It can be specified for a MySQL read replica only if the source is running MySQL 5.6 or
    #                       later.</p>
    #               </li>
    #               <li>
    #                   <p>It can be specified for a PostgreSQL read replica only if the source is running PostgreSQL
    #                       9.3.5.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :preferred_backup_window
    #   <p>The daily time range during which automated backups are created
    #           if automated backups are enabled,
    #           as determined by the <code>BackupRetentionPeriod</code> parameter.
    #           Changing this parameter doesn't result in an outage and the change is asynchronously applied as soon as possible.
    #           The default is a 30-minute window selected at random from an
    #           8-hour block of time for each Amazon Web Services Region. For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html#USER_WorkingWithAutomatedBackups.BackupWindow">Backup window</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. The daily time range for creating automated backups is managed by
    #               the DB cluster. For more information, see <code>ModifyDBCluster</code>.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be in the format hh24:mi-hh24:mi</p>
    #               </li>
    #               <li>
    #                   <p>Must be in Universal Time Coordinated (UTC)</p>
    #               </li>
    #               <li>
    #                   <p>Must not conflict with the preferred maintenance window</p>
    #               </li>
    #               <li>
    #                   <p>Must be at least 30 minutes</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :preferred_maintenance_window
    #   <p>The weekly time range (in UTC) during which system maintenance can occur, which
    #               might result in an outage. Changing this parameter doesn't result in an outage, except
    #               in the following situation, and the change is asynchronously applied as soon as
    #               possible. If there are pending actions that cause a reboot, and the maintenance window
    #               is changed to include the current time, then changing this parameter will cause a reboot
    #               of the DB instance. If moving this window to the current time, there must be at least 30
    #               minutes between the current time and end of the window to ensure pending changes are
    #               applied.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.Maintenance.html#Concepts.DBMaintenance">Amazon RDS Maintenance Window</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>Default: Uses existing setting</p>
    #           <p>Format: ddd:hh24:mi-ddd:hh24:mi</p>
    #           <p>Valid Days: Mon | Tue | Wed | Thu | Fri | Sat | Sun</p>
    #           <p>Constraints: Must be at least 30 minutes</p>
    #
    # @option params [Boolean] :multi_az
    #   <p>A value that indicates whether the DB instance is a Multi-AZ deployment. Changing this parameter doesn't result
    #             in an outage. The change is applied during the next maintenance window unless the <code>ApplyImmediately</code>
    #             parameter is enabled for this request.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :engine_version
    #   <p>The version number of the database engine to upgrade to.
    #       Changing this parameter results in an outage and the change
    #       is applied during the next maintenance window
    #       unless the <code>ApplyImmediately</code> parameter is enabled for this request.</p>
    #           <p>For major version upgrades, if a nondefault DB parameter group is currently in use, a
    #               new DB parameter group in the DB parameter group family for the new engine version must
    #               be specified. The new DB parameter group can be the default for that DB parameter group
    #               family.</p>
    #           <p>If you specify only a major version, Amazon RDS will update the DB instance to the
    #             default minor version if the current minor version is lower.
    #             For information about valid engine versions, see <code>CreateDBInstance</code>,
    #             or call <code>DescribeDBEngineVersions</code>.</p>
    #           <p>In RDS Custom for Oracle, this parameter is supported for read replicas only if they are in the
    #             <code>PATCH_DB_FAILURE</code> lifecycle.</p>
    #
    # @option params [Boolean] :allow_major_version_upgrade
    #   <p>A value that indicates whether major version upgrades are allowed. Changing this parameter doesn't
    #             result in an outage and the change is asynchronously applied as soon as possible.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Constraints: Major version upgrades must be allowed when specifying a value
    #             for the EngineVersion parameter that is a different major version than the DB instance's current version.</p>
    #
    # @option params [Boolean] :auto_minor_version_upgrade
    #   <p>A value that indicates whether minor version upgrades are applied automatically to the DB instance
    #             during the maintenance window. An outage occurs when all the following conditions are met:</p>
    #           <ul>
    #               <li>
    #                   <p>The automatic upgrade is enabled for the maintenance window.</p>
    #               </li>
    #               <li>
    #                   <p>A newer minor version is available.</p>
    #               </li>
    #               <li>
    #                   <p>RDS has enabled automatic patching for the engine version.</p>
    #               </li>
    #            </ul>
    #           <p>If any of the preceding conditions isn't met, RDS applies the change as soon as possible and
    #         doesn't cause an outage.</p>
    #           <p>For an RDS Custom DB instance, set <code>AutoMinorVersionUpgrade</code>
    #             to <code>false</code>. Otherwise, the operation returns an error.</p>
    #
    # @option params [String] :license_model
    #   <p>The license model for the DB instance.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Valid values: <code>license-included</code> | <code>bring-your-own-license</code> |
    #               <code>general-public-license</code>
    #            </p>
    #
    # @option params [Integer] :iops
    #   <p>The new Provisioned IOPS (I/O operations per second) value for the RDS instance.</p>
    #           <p>Changing this setting doesn't result in an outage and
    #               the change is applied during the next maintenance window
    #               unless the <code>ApplyImmediately</code> parameter is enabled for this request.
    #             If you are migrating from Provisioned IOPS to standard storage, set this value to 0.
    #             The DB instance will require a reboot for the change in storage type to take effect.</p>
    #           <p>If you choose to migrate your DB instance from using standard storage to using
    #               Provisioned IOPS, or from using Provisioned IOPS to using standard storage, the process
    #               can take time. The duration of the migration depends on several factors such as database
    #               load, storage size, storage type (standard or Provisioned IOPS), amount of IOPS
    #               provisioned (if any), and the number of prior scale storage operations. Typical
    #               migration times are under 24 hours, but the process can take up to several days in some
    #               cases. During the migration, the DB instance is available for use, but might experience
    #               performance degradation. While the migration takes place, nightly backups for the
    #               instance are suspended. No other Amazon RDS operations can take place for the instance,
    #               including modifying the instance, rebooting the instance, deleting the instance,
    #               creating a read replica for the instance, and creating a DB snapshot of the instance.</p>
    #           <p>Constraints: For MariaDB, MySQL, Oracle, and PostgreSQL,
    #             the value supplied must be at least 10% greater than the current value.
    #             Values that are not at least 10% greater than the existing value are rounded up so that they are 10% greater than the current value.</p>
    #           <p>Default: Uses existing setting</p>
    #
    # @option params [String] :option_group_name
    #   <p>A value that indicates the DB instance should be associated with the specified option group.</p>
    #           <p>Changing this parameter doesn't result in an outage, with one exception. If the parameter change results
    #             in an option group that enables OEM, it can cause a brief period, lasting less than a second, during which
    #             new connections are rejected but existing connections aren't interrupted.</p>
    #           <p>The change is applied during the next maintenance window unless the <code>ApplyImmediately</code> parameter
    #             is enabled for this request.</p>
    #           <p>Permanent options, such as the TDE option for Oracle Advanced Security TDE, can't be removed
    #             from an option group, and that option group can't be removed from a DB instance after
    #             it is associated with a DB instance.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :new_db_instance_identifier
    #   <p>The new DB instance identifier for the DB instance when renaming a DB instance. When you change the DB instance
    #             identifier, an instance reboot occurs immediately if you enable <code>ApplyImmediately</code>, or will occur
    #             during the next maintenance window if you disable Apply Immediately. This value is stored as a lowercase string.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain from 1 to 63 letters, numbers, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>The first character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens.</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>mydbinstance</code>
    #            </p>
    #
    # @option params [String] :storage_type
    #   <p>Specifies the storage type to be associated with the DB instance.</p>
    #           <p>If you specify Provisioned IOPS (<code>io1</code>),
    #             you must also include a value for the <code>Iops</code> parameter.</p>
    #           <p>If you choose to migrate your DB instance from using standard storage to using
    #               Provisioned IOPS, or from using Provisioned IOPS to using standard storage, the process
    #               can take time. The duration of the migration depends on several factors such as database
    #               load, storage size, storage type (standard or Provisioned IOPS), amount of IOPS
    #               provisioned (if any), and the number of prior scale storage operations. Typical
    #               migration times are under 24 hours, but the process can take up to several days in some
    #               cases. During the migration, the DB instance is available for use, but might experience
    #               performance degradation. While the migration takes place, nightly backups for the
    #               instance are suspended. No other Amazon RDS operations can take place for the instance,
    #               including modifying the instance, rebooting the instance, deleting the instance,
    #               creating a read replica for the instance, and creating a DB snapshot of the instance.</p>
    #           <p>Valid values: <code>standard | gp2 | io1</code>
    #            </p>
    #           <p>Default: <code>io1</code> if the <code>Iops</code> parameter
    #             is specified, otherwise <code>gp2</code>
    #            </p>
    #
    # @option params [String] :tde_credential_arn
    #   <p>The ARN from the key store with which to associate the instance for TDE encryption.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :tde_credential_password
    #   <p>The password for the given ARN from the key store in order to access the device.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :ca_certificate_identifier
    #   <p>Specifies the certificate to associate with the DB instance.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :domain
    #   <p>The Active Directory directory ID to move the DB instance to.
    #             Specify <code>none</code> to remove the instance from its current domain.
    #             You must create the domain before this operation. Currently, you can create only MySQL, Microsoft SQL
    #             Server, Oracle, and PostgreSQL DB instances in an Active Directory Domain.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/kerberos-authentication.html">
    #             Kerberos Authentication</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :copy_tags_to_snapshot
    #   <p>A value that indicates whether to copy all tags from the DB instance to snapshots of the DB instance. By default, tags are not copied.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Not applicable. Copying tags to snapshots is managed by the DB cluster. Setting this
    #             value for an Aurora DB instance has no effect on the DB cluster setting. For more
    #             information, see <code>ModifyDBCluster</code>.</p>
    #
    # @option params [Integer] :monitoring_interval
    #   <p>The interval, in seconds, between points when Enhanced Monitoring metrics are collected
    #             for the DB instance. To disable collecting Enhanced Monitoring metrics, specify 0, which is the default.</p>
    #           <p>If <code>MonitoringRoleArn</code> is specified, set <code>MonitoringInterval</code> to a value other than 0.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Valid Values: <code>0, 1, 5, 10, 15, 30, 60</code>
    #            </p>
    #
    # @option params [Integer] :db_port_number
    #   <p>The port number on which the database accepts connections.</p>
    #           <p>The value of the <code>DBPortNumber</code> parameter must not match any of the port values
    #             specified for options in the option group for the DB instance.</p>
    #           <p>If you change the <code>DBPortNumber</code> value, your database restarts regardless of
    #             the value of the <code>ApplyImmediately</code> parameter.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>
    #               <b>MySQL</b>
    #            </p>
    #           <p>Default: <code>3306</code>
    #            </p>
    #           <p>Valid values: <code>1150-65535</code>
    #            </p>
    #           <p>
    #               <b>MariaDB</b>
    #            </p>
    #           <p>Default: <code>3306</code>
    #            </p>
    #           <p>Valid values: <code>1150-65535</code>
    #            </p>
    #           <p>
    #               <b>PostgreSQL</b>
    #            </p>
    #           <p>Default: <code>5432</code>
    #            </p>
    #           <p>Valid values: <code>1150-65535</code>
    #            </p>
    #           <p>Type: Integer</p>
    #           <p>
    #               <b>Oracle</b>
    #            </p>
    #           <p>Default: <code>1521</code>
    #            </p>
    #           <p>Valid values: <code>1150-65535</code>
    #            </p>
    #           <p>
    #               <b>SQL Server</b>
    #            </p>
    #           <p>Default: <code>1433</code>
    #            </p>
    #           <p>Valid values: <code>1150-65535</code> except <code>1234</code>, <code>1434</code>,
    #                   <code>3260</code>, <code>3343</code>, <code>3389</code>, <code>47001</code>, and
    #                   <code>49152-49156</code>.</p>
    #           <p>
    #               <b>Amazon Aurora</b>
    #            </p>
    #           <p>Default: <code>3306</code>
    #            </p>
    #           <p>Valid values: <code>1150-65535</code>
    #            </p>
    #
    # @option params [Boolean] :publicly_accessible
    #   <p>A value that indicates whether the DB instance is publicly accessible.</p>
    #           <p>When the DB cluster is publicly accessible, its Domain Name System (DNS) endpoint
    #             resolves to the private IP address from within the DB cluster's virtual private cloud
    #             (VPC). It resolves to the public IP address from outside of the DB cluster's VPC. Access
    #             to the DB cluster is ultimately controlled by the security group it uses. That public
    #             access isn't permitted if the security group assigned to the DB cluster doesn't permit
    #             it.</p>
    #           <p>When the DB instance isn't publicly accessible, it is an internal DB instance with a DNS name that resolves to a private IP address.</p>
    #           <p>
    #               <code>PubliclyAccessible</code> only applies to DB instances in a VPC. The DB instance must be part of a
    #             public subnet and <code>PubliclyAccessible</code> must be enabled for it to be publicly accessible.</p>
    #           <p>Changes to the <code>PubliclyAccessible</code> parameter are applied immediately regardless
    #         of the value of the <code>ApplyImmediately</code> parameter.</p>
    #
    # @option params [String] :monitoring_role_arn
    #   <p>The ARN for the IAM role that permits RDS to send enhanced monitoring metrics to Amazon CloudWatch Logs. For
    #         example, <code>arn:aws:iam:123456789012:role/emaccess</code>. For information on creating a monitoring role,
    #         see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.html#USER_Monitoring.OS.IAMRole">To
    #             create an IAM role for Amazon RDS Enhanced Monitoring</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>If <code>MonitoringInterval</code> is set to a value other than 0, supply a <code>MonitoringRoleArn</code>
    #             value.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :domain_iam_role_name
    #   <p>The name of the IAM role to use when making API calls to the Directory Service.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Integer] :promotion_tier
    #   <p>A value that specifies the order in which an Aurora Replica is promoted to the primary instance
    #         after a failure of the existing primary instance. For more information,
    #         see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Managing.Backups.html#Aurora.Managing.FaultTolerance">
    #             Fault Tolerance for an Aurora DB Cluster</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Default: 1</p>
    #           <p>Valid Values: 0 - 15</p>
    #
    # @option params [Boolean] :enable_iam_database_authentication
    #   <p>A value that indicates whether to enable mapping of Amazon Web Services Identity and Access Management
    #               (IAM) accounts to database accounts. By default, mapping isn't enabled.</p>
    #           <p>This setting doesn't apply to Amazon Aurora. Mapping Amazon Web Services IAM accounts to database accounts is managed by the DB
    #             cluster.</p>
    #           <p>For more information about IAM database authentication, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.html">
    #                 IAM Database Authentication for MySQL and PostgreSQL</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :enable_performance_insights
    #   <p>A value that indicates whether to enable Performance Insights for the DB instance.</p>
    #           <p>For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PerfInsights.html">Using Amazon Performance Insights</a> in the <i>Amazon RDS User Guide.</i>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :performance_insights_kms_key_id
    #   <p>The Amazon Web Services KMS key identifier for encryption of Performance Insights data.</p>
    #           <p>The Amazon Web Services KMS key identifier is the key ARN, key ID, alias ARN, or alias name for the KMS key.</p>
    #           <p>If you do not specify a value for <code>PerformanceInsightsKMSKeyId</code>, then Amazon RDS
    #               uses your default KMS key. There is a default KMS key for your Amazon Web Services account.
    #               Your Amazon Web Services account has a different default KMS key for each Amazon Web Services Region.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Integer] :performance_insights_retention_period
    #   <p>The amount of time, in days, to retain Performance Insights data. Valid values are 7 or 731 (2 years).</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [CloudwatchLogsExportConfiguration] :cloudwatch_logs_export_configuration
    #   <p>The configuration setting for the log types to be enabled for export to CloudWatch Logs for a
    #               specific DB instance.</p>
    #           <p>A change to the <code>CloudwatchLogsExportConfiguration</code> parameter is always applied to the DB instance
    #               immediately. Therefore, the <code>ApplyImmediately</code> parameter has no effect.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Array<ProcessorFeature>] :processor_features
    #   <p>The number of CPU cores and the number of threads per core for the DB instance class of the DB instance.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :use_default_processor_features
    #   <p>A value that indicates whether the DB instance class of the DB instance uses its default
    #               processor features.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :deletion_protection
    #   <p>A value that indicates whether the DB instance has deletion protection enabled.
    #               The database can't be deleted when deletion protection is enabled. By default,
    #               deletion protection isn't enabled. For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_DeleteInstance.html">
    #                   Deleting a DB Instance</a>.</p>
    #
    # @option params [Integer] :max_allocated_storage
    #   <p>The upper limit in gibibytes (GiB) to which Amazon RDS can automatically scale the storage of the DB instance.</p>
    #           <p>For more information about this setting, including limitations that apply to it, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIOPS.StorageTypes.html#USER_PIOPS.Autoscaling">
    #                   Managing capacity automatically with Amazon RDS storage autoscaling</a>
    #               in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :certificate_rotation_restart
    #   <p>A value that indicates whether the DB instance is restarted when you rotate your
    #               SSL/TLS certificate.</p>
    #           <p>By default, the DB instance is restarted when you rotate your SSL/TLS certificate. The certificate
    #               is not updated until the DB instance is restarted.</p>
    #           <important>
    #               <p>Set this parameter only if you are <i>not</i> using SSL/TLS to connect to the DB instance.</p>
    #           </important>
    #           <p>If you are using SSL/TLS to connect to the DB instance, follow the appropriate instructions for your
    #               DB engine to rotate your SSL/TLS certificate:</p>
    #           <ul>
    #               <li>
    #                   <p>For more information about rotating your SSL/TLS certificate for RDS DB engines, see
    #                       <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.SSL-certificate-rotation.html">
    #                           Rotating Your SSL/TLS Certificate.</a> in the <i>Amazon RDS User Guide.</i>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>For more information about rotating your SSL/TLS certificate for Aurora DB engines, see
    #                       <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/UsingWithRDS.SSL-certificate-rotation.html">
    #                           Rotating Your SSL/TLS Certificate</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #               </li>
    #            </ul>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :replica_mode
    #   <p>A value that sets the open mode of a replica database to either mounted or read-only.</p>
    #           <note>
    #               <p>Currently, this parameter is only supported for Oracle DB instances.</p>
    #           </note>
    #           <p>Mounted DB replicas are included in Oracle Enterprise Edition. The main use case for
    #               mounted replicas is cross-Region disaster recovery. The primary database doesn't use
    #               Active Data Guard to transmit information to the mounted replica. Because it doesn't
    #               accept user connections, a mounted replica can't serve a read-only workload.
    #               For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/oracle-read-replicas.html">Working with Oracle Read Replicas for Amazon RDS</a>
    #               in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :enable_customer_owned_ip
    #   <p>A value that indicates whether to enable a customer-owned IP address (CoIP) for an RDS on Outposts DB instance.</p>
    #           <p>A <i>CoIP</i> provides local or external connectivity to resources in
    #               your Outpost subnets through your on-premises network. For some use cases, a CoIP can
    #               provide lower latency for connections to the DB instance from outside of its virtual
    #               private cloud (VPC) on your local network.</p>
    #           <p>For more information about RDS on Outposts, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-on-outposts.html">Working with Amazon RDS on Amazon Web Services Outposts</a>
    #               in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>For more information about CoIPs, see <a href="https://docs.aws.amazon.com/outposts/latest/userguide/outposts-networking-components.html#ip-addressing">Customer-owned IP addresses</a>
    #               in the <i>Amazon Web Services Outposts User Guide</i>.</p>
    #
    # @option params [String] :aws_backup_recovery_point_arn
    #   <p>The Amazon Resource Name (ARN) of the recovery point in Amazon Web Services Backup.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :automation_mode
    #   <p>The automation mode of the RDS Custom DB instance: <code>full</code> or <code>all paused</code>.
    #               If <code>full</code>, the DB instance automates monitoring and instance recovery. If
    #               <code>all paused</code>, the instance pauses automation for the duration set by
    #               <code>ResumeFullAutomationModeMinutes</code>.</p>
    #
    # @option params [Integer] :resume_full_automation_mode_minutes
    #   <p>The number of minutes to pause the automation. When the time period ends, RDS Custom resumes
    #               full automation. The minimum value is <code>60</code> (default). The maximum value is <code>1,440</code>.</p>
    #
    # @option params [String] :network_type
    #   <p>The network type of the DB instance.</p>
    #           <p>Valid values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>IPV4</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>DUAL</code>
    #                  </p>
    #               </li>
    #            </ul>
    #           <p>The network type is determined by the <code>DBSubnetGroup</code> specified for the DB instance.
    #               A <code>DBSubnetGroup</code> can support only the IPv4 protocol or the IPv4 and the IPv6
    #               protocols (<code>DUAL</code>).</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.WorkingWithRDSInstanceinaVPC.html">
    #               Working with a DB instance in a VPC</a> in the
    #               <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @return [Types::ModifyDBInstanceOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_db_instance(
    #     db_instance_identifier: 'DBInstanceIdentifier', # required
    #     allocated_storage: 1,
    #     db_instance_class: 'DBInstanceClass',
    #     db_subnet_group_name: 'DBSubnetGroupName',
    #     db_security_groups: [
    #       'member'
    #     ],
    #     vpc_security_group_ids: [
    #       'member'
    #     ],
    #     apply_immediately: false,
    #     master_user_password: 'MasterUserPassword',
    #     db_parameter_group_name: 'DBParameterGroupName',
    #     backup_retention_period: 1,
    #     preferred_backup_window: 'PreferredBackupWindow',
    #     preferred_maintenance_window: 'PreferredMaintenanceWindow',
    #     multi_az: false,
    #     engine_version: 'EngineVersion',
    #     allow_major_version_upgrade: false,
    #     auto_minor_version_upgrade: false,
    #     license_model: 'LicenseModel',
    #     iops: 1,
    #     option_group_name: 'OptionGroupName',
    #     new_db_instance_identifier: 'NewDBInstanceIdentifier',
    #     storage_type: 'StorageType',
    #     tde_credential_arn: 'TdeCredentialArn',
    #     tde_credential_password: 'TdeCredentialPassword',
    #     ca_certificate_identifier: 'CACertificateIdentifier',
    #     domain: 'Domain',
    #     copy_tags_to_snapshot: false,
    #     monitoring_interval: 1,
    #     db_port_number: 1,
    #     publicly_accessible: false,
    #     monitoring_role_arn: 'MonitoringRoleArn',
    #     domain_iam_role_name: 'DomainIAMRoleName',
    #     promotion_tier: 1,
    #     enable_iam_database_authentication: false,
    #     enable_performance_insights: false,
    #     performance_insights_kms_key_id: 'PerformanceInsightsKMSKeyId',
    #     performance_insights_retention_period: 1,
    #     cloudwatch_logs_export_configuration: {
    #       enable_log_types: [
    #         'member'
    #       ],
    #     },
    #     processor_features: [
    #       {
    #         name: 'Name',
    #         value: 'Value'
    #       }
    #     ],
    #     use_default_processor_features: false,
    #     deletion_protection: false,
    #     max_allocated_storage: 1,
    #     certificate_rotation_restart: false,
    #     replica_mode: 'open-read-only', # accepts ["open-read-only", "mounted"]
    #     enable_customer_owned_ip: false,
    #     aws_backup_recovery_point_arn: 'AwsBackupRecoveryPointArn',
    #     automation_mode: 'full', # accepts ["full", "all-paused"]
    #     resume_full_automation_mode_minutes: 1,
    #     network_type: 'NetworkType'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyDBInstanceOutput
    #   resp.data.db_instance #=> Types::DBInstance
    #   resp.data.db_instance.db_instance_identifier #=> String
    #   resp.data.db_instance.db_instance_class #=> String
    #   resp.data.db_instance.engine #=> String
    #   resp.data.db_instance.db_instance_status #=> String
    #   resp.data.db_instance.automatic_restart_time #=> Time
    #   resp.data.db_instance.master_username #=> String
    #   resp.data.db_instance.db_name #=> String
    #   resp.data.db_instance.endpoint #=> Types::Endpoint
    #   resp.data.db_instance.endpoint.address #=> String
    #   resp.data.db_instance.endpoint.port #=> Integer
    #   resp.data.db_instance.endpoint.hosted_zone_id #=> String
    #   resp.data.db_instance.allocated_storage #=> Integer
    #   resp.data.db_instance.instance_create_time #=> Time
    #   resp.data.db_instance.preferred_backup_window #=> String
    #   resp.data.db_instance.backup_retention_period #=> Integer
    #   resp.data.db_instance.db_security_groups #=> Array<DBSecurityGroupMembership>
    #   resp.data.db_instance.db_security_groups[0] #=> Types::DBSecurityGroupMembership
    #   resp.data.db_instance.db_security_groups[0].db_security_group_name #=> String
    #   resp.data.db_instance.db_security_groups[0].status #=> String
    #   resp.data.db_instance.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_instance.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_instance.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_instance.vpc_security_groups[0].status #=> String
    #   resp.data.db_instance.db_parameter_groups #=> Array<DBParameterGroupStatus>
    #   resp.data.db_instance.db_parameter_groups[0] #=> Types::DBParameterGroupStatus
    #   resp.data.db_instance.db_parameter_groups[0].db_parameter_group_name #=> String
    #   resp.data.db_instance.db_parameter_groups[0].parameter_apply_status #=> String
    #   resp.data.db_instance.availability_zone #=> String
    #   resp.data.db_instance.db_subnet_group #=> Types::DBSubnetGroup
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_name #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_description #=> String
    #   resp.data.db_instance.db_subnet_group.vpc_id #=> String
    #   resp.data.db_instance.db_subnet_group.subnet_group_status #=> String
    #   resp.data.db_instance.db_subnet_group.subnets #=> Array<Subnet>
    #   resp.data.db_instance.db_subnet_group.subnets[0] #=> Types::Subnet
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_identifier #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone #=> Types::AvailabilityZone
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone.name #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost #=> Types::Outpost
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost.arn #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_status #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_arn #=> String
    #   resp.data.db_instance.db_subnet_group.supported_network_types #=> Array<String>
    #   resp.data.db_instance.db_subnet_group.supported_network_types[0] #=> String
    #   resp.data.db_instance.preferred_maintenance_window #=> String
    #   resp.data.db_instance.pending_modified_values #=> Types::PendingModifiedValues
    #   resp.data.db_instance.pending_modified_values.db_instance_class #=> String
    #   resp.data.db_instance.pending_modified_values.allocated_storage #=> Integer
    #   resp.data.db_instance.pending_modified_values.master_user_password #=> String
    #   resp.data.db_instance.pending_modified_values.port #=> Integer
    #   resp.data.db_instance.pending_modified_values.backup_retention_period #=> Integer
    #   resp.data.db_instance.pending_modified_values.multi_az #=> Boolean
    #   resp.data.db_instance.pending_modified_values.engine_version #=> String
    #   resp.data.db_instance.pending_modified_values.license_model #=> String
    #   resp.data.db_instance.pending_modified_values.iops #=> Integer
    #   resp.data.db_instance.pending_modified_values.db_instance_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.storage_type #=> String
    #   resp.data.db_instance.pending_modified_values.ca_certificate_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.db_subnet_group_name #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable[0] #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.pending_modified_values.processor_features[0] #=> Types::ProcessorFeature
    #   resp.data.db_instance.pending_modified_values.processor_features[0].name #=> String
    #   resp.data.db_instance.pending_modified_values.processor_features[0].value #=> String
    #   resp.data.db_instance.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.pending_modified_values.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.pending_modified_values.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.latest_restorable_time #=> Time
    #   resp.data.db_instance.multi_az #=> Boolean
    #   resp.data.db_instance.engine_version #=> String
    #   resp.data.db_instance.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_instance.read_replica_source_db_instance_identifier #=> String
    #   resp.data.db_instance.read_replica_db_instance_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_instance_identifiers[0] #=> String
    #   resp.data.db_instance.read_replica_db_cluster_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_cluster_identifiers[0] #=> String
    #   resp.data.db_instance.replica_mode #=> String, one of ["open-read-only", "mounted"]
    #   resp.data.db_instance.license_model #=> String
    #   resp.data.db_instance.iops #=> Integer
    #   resp.data.db_instance.option_group_memberships #=> Array<OptionGroupMembership>
    #   resp.data.db_instance.option_group_memberships[0] #=> Types::OptionGroupMembership
    #   resp.data.db_instance.option_group_memberships[0].option_group_name #=> String
    #   resp.data.db_instance.option_group_memberships[0].status #=> String
    #   resp.data.db_instance.character_set_name #=> String
    #   resp.data.db_instance.nchar_character_set_name #=> String
    #   resp.data.db_instance.secondary_availability_zone #=> String
    #   resp.data.db_instance.publicly_accessible #=> Boolean
    #   resp.data.db_instance.status_infos #=> Array<DBInstanceStatusInfo>
    #   resp.data.db_instance.status_infos[0] #=> Types::DBInstanceStatusInfo
    #   resp.data.db_instance.status_infos[0].status_type #=> String
    #   resp.data.db_instance.status_infos[0].normal #=> Boolean
    #   resp.data.db_instance.status_infos[0].status #=> String
    #   resp.data.db_instance.status_infos[0].message #=> String
    #   resp.data.db_instance.storage_type #=> String
    #   resp.data.db_instance.tde_credential_arn #=> String
    #   resp.data.db_instance.db_instance_port #=> Integer
    #   resp.data.db_instance.db_cluster_identifier #=> String
    #   resp.data.db_instance.storage_encrypted #=> Boolean
    #   resp.data.db_instance.kms_key_id #=> String
    #   resp.data.db_instance.dbi_resource_id #=> String
    #   resp.data.db_instance.ca_certificate_identifier #=> String
    #   resp.data.db_instance.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_instance.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_instance.domain_memberships[0].domain #=> String
    #   resp.data.db_instance.domain_memberships[0].status #=> String
    #   resp.data.db_instance.domain_memberships[0].fqdn #=> String
    #   resp.data.db_instance.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_instance.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_instance.monitoring_interval #=> Integer
    #   resp.data.db_instance.enhanced_monitoring_resource_arn #=> String
    #   resp.data.db_instance.monitoring_role_arn #=> String
    #   resp.data.db_instance.promotion_tier #=> Integer
    #   resp.data.db_instance.db_instance_arn #=> String
    #   resp.data.db_instance.timezone #=> String
    #   resp.data.db_instance.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_kms_key_id #=> String
    #   resp.data.db_instance.performance_insights_retention_period #=> Integer
    #   resp.data.db_instance.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_instance.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.deletion_protection #=> Boolean
    #   resp.data.db_instance.associated_roles #=> Array<DBInstanceRole>
    #   resp.data.db_instance.associated_roles[0] #=> Types::DBInstanceRole
    #   resp.data.db_instance.associated_roles[0].role_arn #=> String
    #   resp.data.db_instance.associated_roles[0].feature_name #=> String
    #   resp.data.db_instance.associated_roles[0].status #=> String
    #   resp.data.db_instance.listener_endpoint #=> Types::Endpoint
    #   resp.data.db_instance.max_allocated_storage #=> Integer
    #   resp.data.db_instance.tag_list #=> Array<Tag>
    #   resp.data.db_instance.tag_list[0] #=> Types::Tag
    #   resp.data.db_instance.tag_list[0].key #=> String
    #   resp.data.db_instance.tag_list[0].value #=> String
    #   resp.data.db_instance.db_instance_automated_backups_replications #=> Array<DBInstanceAutomatedBackupsReplication>
    #   resp.data.db_instance.db_instance_automated_backups_replications[0] #=> Types::DBInstanceAutomatedBackupsReplication
    #   resp.data.db_instance.db_instance_automated_backups_replications[0].db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance.customer_owned_ip_enabled #=> Boolean
    #   resp.data.db_instance.aws_backup_recovery_point_arn #=> String
    #   resp.data.db_instance.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_instance.activity_stream_kms_key_id #=> String
    #   resp.data.db_instance.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_instance.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_instance.activity_stream_engine_native_audit_fields_included #=> Boolean
    #   resp.data.db_instance.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.custom_iam_instance_profile #=> String
    #   resp.data.db_instance.backup_target #=> String
    #   resp.data.db_instance.network_type #=> String
    #
    def modify_db_instance(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyDBInstanceInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyDBInstanceInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyDBInstance
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::KMSKeyNotAccessibleFault, Errors::OptionGroupNotFoundFault, Errors::InvalidDBSecurityGroupStateFault, Errors::InvalidVPCNetworkStateFault, Errors::StorageQuotaExceededFault, Errors::DBInstanceAlreadyExistsFault, Errors::DBUpgradeDependencyFailureFault, Errors::InvalidDBInstanceStateFault, Errors::InsufficientDBInstanceCapacityFault, Errors::CertificateNotFoundFault, Errors::NetworkTypeNotSupported, Errors::DBInstanceNotFoundFault, Errors::DBSecurityGroupNotFoundFault, Errors::DomainNotFoundFault, Errors::ProvisionedIopsNotAvailableInAZFault, Errors::InvalidDBClusterStateFault, Errors::AuthorizationNotFoundFault, Errors::StorageTypeNotSupportedFault, Errors::DBParameterGroupNotFoundFault, Errors::BackupPolicyNotFoundFault]),
        data_parser: Parsers::ModifyDBInstance
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyDBInstance,
        stubs: @stubs,
        params_class: Params::ModifyDBInstanceOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_db_instance
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Modifies the parameters of a DB parameter group. To modify more than one parameter,
    #         submit a list of the following: <code>ParameterName</code>, <code>ParameterValue</code>, and
    #         <code>ApplyMethod</code>. A maximum of 20 parameters can be modified in a single request.</p>
    #         <important>
    #             <p>After you modify a DB parameter group, you should wait at least 5 minutes
    #             before creating your first DB instance that uses that DB parameter group as the default parameter
    #             group. This allows Amazon RDS to fully complete the modify action before the parameter
    #             group is used as the default for a new DB instance. This is especially important for parameters
    #             that are critical when creating the default database for a DB instance, such as the character set
    #             for the default database defined by the <code>character_set_database</code> parameter. You can use the
    #             <i>Parameter Groups</i> option of the <a href="https://console.aws.amazon.com/rds/">Amazon RDS console</a> or the
    #             <i>DescribeDBParameters</i> command to verify
    #             that your DB parameter group has been created or modified.</p>
    #         </important>
    #
    # @param [Hash] params
    #   See {Types::ModifyDBParameterGroupInput}.
    #
    # @option params [String] :db_parameter_group_name
    #   <p>The name of the DB parameter group.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match the name of an existing <code>DBParameterGroup</code>.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Array<Parameter>] :parameters
    #   <p>An array of parameter names, values, and the application methods for the parameter update. At least one parameter name, value, and
    #             application method must be supplied; later arguments are optional. A maximum of 20 parameters can be modified in a single request.</p>
    #           <p>Valid Values (for the application method): <code>immediate | pending-reboot</code>
    #            </p>
    #           <p>You can use the <code>immediate</code> value with dynamic parameters only. You can use the <code>pending-reboot</code> value for both dynamic
    #             and static parameters.</p>
    #           <p>When the application method is <code>immediate</code>, changes to dynamic parameters are applied immediately to the DB instances associated with
    #             the parameter group.</p>
    #           <p>When the application method is <code>pending-reboot</code>, changes to dynamic and static parameters are applied after a reboot without failover
    #             to the DB instances associated with the parameter group.</p>
    #           <note>
    #               <p>You can't use <code>pending-reboot</code> with dynamic parameters on RDS for SQL Server DB instances. Use <code>immediate</code>.</p>
    #           </note>
    #           <p>For more information on modifying DB parameters, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithParamGroups.html">Working
    #             with DB parameter groups</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @return [Types::ModifyDBParameterGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_db_parameter_group(
    #     db_parameter_group_name: 'DBParameterGroupName', # required
    #     parameters: [
    #       {
    #         parameter_name: 'ParameterName',
    #         parameter_value: 'ParameterValue',
    #         description: 'Description',
    #         source: 'Source',
    #         apply_type: 'ApplyType',
    #         data_type: 'DataType',
    #         allowed_values: 'AllowedValues',
    #         is_modifiable: false,
    #         minimum_engine_version: 'MinimumEngineVersion',
    #         apply_method: 'immediate', # accepts ["immediate", "pending-reboot"]
    #         supported_engine_modes: [
    #           'member'
    #         ]
    #       }
    #     ] # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyDBParameterGroupOutput
    #   resp.data.db_parameter_group_name #=> String
    #
    def modify_db_parameter_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyDBParameterGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyDBParameterGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyDBParameterGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidDBParameterGroupStateFault, Errors::DBParameterGroupNotFoundFault]),
        data_parser: Parsers::ModifyDBParameterGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyDBParameterGroup,
        stubs: @stubs,
        params_class: Params::ModifyDBParameterGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_db_parameter_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Changes the settings for an existing DB proxy.</p>
    #
    # @param [Hash] params
    #   See {Types::ModifyDBProxyInput}.
    #
    # @option params [String] :db_proxy_name
    #   <p>The identifier for the <code>DBProxy</code> to modify.</p>
    #
    # @option params [String] :new_db_proxy_name
    #   <p>The new identifier for the <code>DBProxy</code>. An identifier must begin with a letter and must contain only ASCII letters, digits, and hyphens; it can't end with a hyphen or contain two consecutive hyphens.</p>
    #
    # @option params [Array<UserAuthConfig>] :auth
    #   <p>The new authentication settings for the <code>DBProxy</code>.</p>
    #
    # @option params [Boolean] :require_tls
    #   <p>Whether Transport Layer Security (TLS) encryption is required for connections to the proxy.
    #           By enabling this setting, you can enforce encrypted TLS connections to the proxy, even if the associated database doesn't
    #           use TLS.</p>
    #
    # @option params [Integer] :idle_client_timeout
    #   <p>The number of seconds that a connection to the proxy can be inactive before the proxy disconnects it. You can set this
    #           value higher or lower than the connection timeout limit for the associated database.</p>
    #
    # @option params [Boolean] :debug_logging
    #   <p>Whether the proxy includes detailed information about SQL statements in its logs.
    #           This information helps you to debug issues involving SQL behavior or the performance
    #           and scalability of the proxy connections. The debug information includes the text of
    #           SQL statements that you submit through the proxy. Thus, only enable this setting
    #           when needed for debugging, and only when you have security measures in place to
    #           safeguard any sensitive information that appears in the logs.</p>
    #
    # @option params [String] :role_arn
    #   <p>The Amazon Resource Name (ARN) of the IAM role that the proxy uses to access secrets in Amazon Web Services Secrets Manager.</p>
    #
    # @option params [Array<String>] :security_groups
    #   <p>The new list of security groups for the <code>DBProxy</code>.</p>
    #
    # @return [Types::ModifyDBProxyOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_db_proxy(
    #     db_proxy_name: 'DBProxyName', # required
    #     new_db_proxy_name: 'NewDBProxyName',
    #     auth: [
    #       {
    #         description: 'Description',
    #         user_name: 'UserName',
    #         auth_scheme: 'SECRETS', # accepts ["SECRETS"]
    #         secret_arn: 'SecretArn',
    #         iam_auth: 'DISABLED' # accepts ["DISABLED", "REQUIRED"]
    #       }
    #     ],
    #     require_tls: false,
    #     idle_client_timeout: 1,
    #     debug_logging: false,
    #     role_arn: 'RoleArn',
    #     security_groups: [
    #       'member'
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyDBProxyOutput
    #   resp.data.db_proxy #=> Types::DBProxy
    #   resp.data.db_proxy.db_proxy_name #=> String
    #   resp.data.db_proxy.db_proxy_arn #=> String
    #   resp.data.db_proxy.status #=> String, one of ["available", "modifying", "incompatible-network", "insufficient-resource-limits", "creating", "deleting", "suspended", "suspending", "reactivating"]
    #   resp.data.db_proxy.engine_family #=> String
    #   resp.data.db_proxy.vpc_id #=> String
    #   resp.data.db_proxy.vpc_security_group_ids #=> Array<String>
    #   resp.data.db_proxy.vpc_security_group_ids[0] #=> String
    #   resp.data.db_proxy.vpc_subnet_ids #=> Array<String>
    #   resp.data.db_proxy.auth #=> Array<UserAuthConfigInfo>
    #   resp.data.db_proxy.auth[0] #=> Types::UserAuthConfigInfo
    #   resp.data.db_proxy.auth[0].description #=> String
    #   resp.data.db_proxy.auth[0].user_name #=> String
    #   resp.data.db_proxy.auth[0].auth_scheme #=> String, one of ["SECRETS"]
    #   resp.data.db_proxy.auth[0].secret_arn #=> String
    #   resp.data.db_proxy.auth[0].iam_auth #=> String, one of ["DISABLED", "REQUIRED"]
    #   resp.data.db_proxy.role_arn #=> String
    #   resp.data.db_proxy.endpoint #=> String
    #   resp.data.db_proxy.require_tls #=> Boolean
    #   resp.data.db_proxy.idle_client_timeout #=> Integer
    #   resp.data.db_proxy.debug_logging #=> Boolean
    #   resp.data.db_proxy.created_date #=> Time
    #   resp.data.db_proxy.updated_date #=> Time
    #
    def modify_db_proxy(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyDBProxyInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyDBProxyInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyDBProxy
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBProxyNotFoundFault, Errors::DBProxyAlreadyExistsFault, Errors::InvalidDBProxyStateFault]),
        data_parser: Parsers::ModifyDBProxy
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyDBProxy,
        stubs: @stubs,
        params_class: Params::ModifyDBProxyOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_db_proxy
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Changes the settings for an existing DB proxy endpoint.</p>
    #
    # @param [Hash] params
    #   See {Types::ModifyDBProxyEndpointInput}.
    #
    # @option params [String] :db_proxy_endpoint_name
    #   <p>The name of the DB proxy sociated with the DB proxy endpoint that you want to modify.</p>
    #
    # @option params [String] :new_db_proxy_endpoint_name
    #   <p>The new identifier for the <code>DBProxyEndpoint</code>. An identifier must
    #           begin with a letter and must contain only ASCII letters, digits, and hyphens; it
    #           can't end with a hyphen or contain two consecutive hyphens.</p>
    #
    # @option params [Array<String>] :vpc_security_group_ids
    #   <p>The VPC security group IDs for the DB proxy endpoint. When the DB proxy endpoint
    #           uses a different VPC than the original proxy, you also specify a different
    #           set of security group IDs than for the original proxy.</p>
    #
    # @return [Types::ModifyDBProxyEndpointOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_db_proxy_endpoint(
    #     db_proxy_endpoint_name: 'DBProxyEndpointName', # required
    #     new_db_proxy_endpoint_name: 'NewDBProxyEndpointName',
    #     vpc_security_group_ids: [
    #       'member'
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyDBProxyEndpointOutput
    #   resp.data.db_proxy_endpoint #=> Types::DBProxyEndpoint
    #   resp.data.db_proxy_endpoint.db_proxy_endpoint_name #=> String
    #   resp.data.db_proxy_endpoint.db_proxy_endpoint_arn #=> String
    #   resp.data.db_proxy_endpoint.db_proxy_name #=> String
    #   resp.data.db_proxy_endpoint.status #=> String, one of ["available", "modifying", "incompatible-network", "insufficient-resource-limits", "creating", "deleting"]
    #   resp.data.db_proxy_endpoint.vpc_id #=> String
    #   resp.data.db_proxy_endpoint.vpc_security_group_ids #=> Array<String>
    #   resp.data.db_proxy_endpoint.vpc_security_group_ids[0] #=> String
    #   resp.data.db_proxy_endpoint.vpc_subnet_ids #=> Array<String>
    #   resp.data.db_proxy_endpoint.endpoint #=> String
    #   resp.data.db_proxy_endpoint.created_date #=> Time
    #   resp.data.db_proxy_endpoint.target_role #=> String, one of ["READ_WRITE", "READ_ONLY"]
    #   resp.data.db_proxy_endpoint.is_default #=> Boolean
    #
    def modify_db_proxy_endpoint(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyDBProxyEndpointInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyDBProxyEndpointInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyDBProxyEndpoint
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBProxyEndpointAlreadyExistsFault, Errors::InvalidDBProxyEndpointStateFault, Errors::DBProxyEndpointNotFoundFault, Errors::InvalidDBProxyStateFault]),
        data_parser: Parsers::ModifyDBProxyEndpoint
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyDBProxyEndpoint,
        stubs: @stubs,
        params_class: Params::ModifyDBProxyEndpointOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_db_proxy_endpoint
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Modifies the properties of a <code>DBProxyTargetGroup</code>.</p>
    #
    # @param [Hash] params
    #   See {Types::ModifyDBProxyTargetGroupInput}.
    #
    # @option params [String] :target_group_name
    #   <p>The name of the new target group to assign to the proxy.</p>
    #
    # @option params [String] :db_proxy_name
    #   <p>The name of the new proxy to which to assign the target group.</p>
    #
    # @option params [ConnectionPoolConfiguration] :connection_pool_config
    #   <p>The settings that determine the size and behavior of the connection pool for the target group.</p>
    #
    # @option params [String] :new_name
    #   <p>The new name for the modified <code>DBProxyTarget</code>. An identifier must begin with a letter and must contain only ASCII letters, digits, and hyphens; it can't end with a hyphen or contain two consecutive hyphens.</p>
    #
    # @return [Types::ModifyDBProxyTargetGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_db_proxy_target_group(
    #     target_group_name: 'TargetGroupName', # required
    #     db_proxy_name: 'DBProxyName', # required
    #     connection_pool_config: {
    #       max_connections_percent: 1,
    #       max_idle_connections_percent: 1,
    #       connection_borrow_timeout: 1,
    #       session_pinning_filters: [
    #         'member'
    #       ],
    #       init_query: 'InitQuery'
    #     },
    #     new_name: 'NewName'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyDBProxyTargetGroupOutput
    #   resp.data.db_proxy_target_group #=> Types::DBProxyTargetGroup
    #   resp.data.db_proxy_target_group.db_proxy_name #=> String
    #   resp.data.db_proxy_target_group.target_group_name #=> String
    #   resp.data.db_proxy_target_group.target_group_arn #=> String
    #   resp.data.db_proxy_target_group.is_default #=> Boolean
    #   resp.data.db_proxy_target_group.status #=> String
    #   resp.data.db_proxy_target_group.connection_pool_config #=> Types::ConnectionPoolConfigurationInfo
    #   resp.data.db_proxy_target_group.connection_pool_config.max_connections_percent #=> Integer
    #   resp.data.db_proxy_target_group.connection_pool_config.max_idle_connections_percent #=> Integer
    #   resp.data.db_proxy_target_group.connection_pool_config.connection_borrow_timeout #=> Integer
    #   resp.data.db_proxy_target_group.connection_pool_config.session_pinning_filters #=> Array<String>
    #   resp.data.db_proxy_target_group.connection_pool_config.session_pinning_filters[0] #=> String
    #   resp.data.db_proxy_target_group.connection_pool_config.init_query #=> String
    #   resp.data.db_proxy_target_group.created_date #=> Time
    #   resp.data.db_proxy_target_group.updated_date #=> Time
    #
    def modify_db_proxy_target_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyDBProxyTargetGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyDBProxyTargetGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyDBProxyTargetGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBProxyTargetGroupNotFoundFault, Errors::DBProxyNotFoundFault, Errors::InvalidDBProxyStateFault]),
        data_parser: Parsers::ModifyDBProxyTargetGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyDBProxyTargetGroup,
        stubs: @stubs,
        params_class: Params::ModifyDBProxyTargetGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_db_proxy_target_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Updates a manual DB snapshot with a new engine version. The snapshot can be encrypted
    #             or unencrypted, but not shared or public.
    #
    #     </p>
    #         <p>Amazon RDS supports upgrading DB snapshots for MySQL, PostgreSQL, and Oracle. This command
    #           doesn't apply to RDS Custom.</p>
    #
    # @param [Hash] params
    #   See {Types::ModifyDBSnapshotInput}.
    #
    # @option params [String] :db_snapshot_identifier
    #   <p>The identifier of the DB snapshot to modify.</p>
    #
    # @option params [String] :engine_version
    #   <p>The engine version to upgrade the DB snapshot to.</p>
    #           <p>The following are the database engines and engine versions that are available when you upgrade a DB snapshot.</p>
    #           <p>
    #               <b>MySQL</b>
    #            </p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>5.5.46</code> (supported for 5.1 DB snapshots)</p>
    #               </li>
    #            </ul>
    #           <p>
    #               <b>Oracle</b>
    #            </p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>12.1.0.2.v8</code>  (supported for 12.1.0.1 DB snapshots)</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>11.2.0.4.v12</code> (supported for 11.2.0.2 DB snapshots)</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>11.2.0.4.v11</code> (supported for 11.2.0.3 DB snapshots)</p>
    #               </li>
    #            </ul>
    #           <p>
    #               <b>PostgreSQL</b>
    #            </p>
    #           <p>For the list of engine versions that are available for upgrading a DB snapshot, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.PostgreSQL.html#USER_UpgradeDBInstance.PostgreSQL.MajorVersion">
    #                 Upgrading the PostgreSQL DB Engine for Amazon RDS</a>.</p>
    #
    # @option params [String] :option_group_name
    #   <p>The option group to identify with the upgraded DB snapshot.</p>
    #           <p>You can specify this parameter when you upgrade an Oracle DB snapshot.
    #               The same option group considerations apply when upgrading a DB snapshot as when upgrading a DB instance.
    #               For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.Oracle.html#USER_UpgradeDBInstance.Oracle.OGPG.OG">Option group considerations</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @return [Types::ModifyDBSnapshotOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_db_snapshot(
    #     db_snapshot_identifier: 'DBSnapshotIdentifier', # required
    #     engine_version: 'EngineVersion',
    #     option_group_name: 'OptionGroupName'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyDBSnapshotOutput
    #   resp.data.db_snapshot #=> Types::DBSnapshot
    #   resp.data.db_snapshot.db_snapshot_identifier #=> String
    #   resp.data.db_snapshot.db_instance_identifier #=> String
    #   resp.data.db_snapshot.snapshot_create_time #=> Time
    #   resp.data.db_snapshot.engine #=> String
    #   resp.data.db_snapshot.allocated_storage #=> Integer
    #   resp.data.db_snapshot.status #=> String
    #   resp.data.db_snapshot.port #=> Integer
    #   resp.data.db_snapshot.availability_zone #=> String
    #   resp.data.db_snapshot.vpc_id #=> String
    #   resp.data.db_snapshot.instance_create_time #=> Time
    #   resp.data.db_snapshot.master_username #=> String
    #   resp.data.db_snapshot.engine_version #=> String
    #   resp.data.db_snapshot.license_model #=> String
    #   resp.data.db_snapshot.snapshot_type #=> String
    #   resp.data.db_snapshot.iops #=> Integer
    #   resp.data.db_snapshot.option_group_name #=> String
    #   resp.data.db_snapshot.percent_progress #=> Integer
    #   resp.data.db_snapshot.source_region #=> String
    #   resp.data.db_snapshot.source_db_snapshot_identifier #=> String
    #   resp.data.db_snapshot.storage_type #=> String
    #   resp.data.db_snapshot.tde_credential_arn #=> String
    #   resp.data.db_snapshot.encrypted #=> Boolean
    #   resp.data.db_snapshot.kms_key_id #=> String
    #   resp.data.db_snapshot.db_snapshot_arn #=> String
    #   resp.data.db_snapshot.timezone #=> String
    #   resp.data.db_snapshot.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_snapshot.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_snapshot.processor_features[0] #=> Types::ProcessorFeature
    #   resp.data.db_snapshot.processor_features[0].name #=> String
    #   resp.data.db_snapshot.processor_features[0].value #=> String
    #   resp.data.db_snapshot.dbi_resource_id #=> String
    #   resp.data.db_snapshot.tag_list #=> Array<Tag>
    #   resp.data.db_snapshot.tag_list[0] #=> Types::Tag
    #   resp.data.db_snapshot.tag_list[0].key #=> String
    #   resp.data.db_snapshot.tag_list[0].value #=> String
    #   resp.data.db_snapshot.original_snapshot_create_time #=> Time
    #   resp.data.db_snapshot.snapshot_target #=> String
    #
    def modify_db_snapshot(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyDBSnapshotInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyDBSnapshotInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyDBSnapshot
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBSnapshotNotFoundFault]),
        data_parser: Parsers::ModifyDBSnapshot
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyDBSnapshot,
        stubs: @stubs,
        params_class: Params::ModifyDBSnapshotOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_db_snapshot
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Adds an attribute and values to, or removes an attribute and values from, a manual DB snapshot.</p>
    #         <p>To share a manual DB snapshot with other Amazon Web Services accounts, specify <code>restore</code>
    #             as the <code>AttributeName</code> and use the <code>ValuesToAdd</code> parameter to add
    #             a list of IDs of the Amazon Web Services accounts that are authorized to restore the manual DB snapshot.
    #             Uses the value <code>all</code> to make the manual DB snapshot public, which means it
    #             can be copied or restored by all Amazon Web Services accounts.</p>
    #         <note>
    #             <p>Don't add the <code>all</code> value for any manual DB snapshots that
    #                 contain private information that you don't want available to all Amazon Web Services
    #                 accounts.</p>
    #         </note>
    #         <p>If the manual DB snapshot is encrypted, it can be shared, but only by specifying a
    #             list of authorized Amazon Web Services account IDs for the <code>ValuesToAdd</code> parameter. You
    #             can't use <code>all</code> as a value for that parameter in this case.</p>
    #         <p>To view which Amazon Web Services accounts have access to copy or restore a manual DB snapshot, or
    #             whether a manual DB snapshot public or private, use the <a>DescribeDBSnapshotAttributes</a> API action. The accounts are returned as
    #             values for the <code>restore</code> attribute.</p>
    #
    # @param [Hash] params
    #   See {Types::ModifyDBSnapshotAttributeInput}.
    #
    # @option params [String] :db_snapshot_identifier
    #   <p>The identifier for the DB snapshot to modify the attributes for.</p>
    #
    # @option params [String] :attribute_name
    #   <p>The name of the DB snapshot attribute to modify.</p>
    #           <p>To manage authorization for other Amazon Web Services accounts to copy or restore a manual DB snapshot,
    #         set this value to <code>restore</code>.</p>
    #           <note>
    #               <p>To view the list of attributes available to modify, use the
    #                 <a>DescribeDBSnapshotAttributes</a> API action.</p>
    #           </note>
    #
    # @option params [Array<String>] :values_to_add
    #   <p>A list of DB snapshot attributes to add to the attribute specified by <code>AttributeName</code>.</p>
    #           <p>To authorize other Amazon Web Services accounts to copy or restore a manual snapshot, set this list to include one or more Amazon Web Services account
    #         IDs, or <code>all</code> to make the manual DB snapshot restorable by
    #         any Amazon Web Services account. Do not add the <code>all</code> value for any
    #         manual DB snapshots that contain private information that you don't want available
    #         to all Amazon Web Services accounts.</p>
    #
    # @option params [Array<String>] :values_to_remove
    #   <p>A list of DB snapshot attributes to remove from the attribute specified by <code>AttributeName</code>.</p>
    #           <p>To remove authorization for other Amazon Web Services accounts to copy or restore a manual snapshot, set this list to include
    #         one or more Amazon Web Services account
    #         identifiers, or <code>all</code> to remove authorization for any Amazon Web Services account to copy or
    #         restore the DB snapshot. If you specify <code>all</code>, an Amazon Web Services account whose
    #         account ID is explicitly added to the <code>restore</code> attribute
    #         can still copy or restore the manual DB snapshot.</p>
    #
    # @return [Types::ModifyDBSnapshotAttributeOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_db_snapshot_attribute(
    #     db_snapshot_identifier: 'DBSnapshotIdentifier', # required
    #     attribute_name: 'AttributeName', # required
    #     values_to_add: [
    #       'member'
    #     ],
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyDBSnapshotAttributeOutput
    #   resp.data.db_snapshot_attributes_result #=> Types::DBSnapshotAttributesResult
    #   resp.data.db_snapshot_attributes_result.db_snapshot_identifier #=> String
    #   resp.data.db_snapshot_attributes_result.db_snapshot_attributes #=> Array<DBSnapshotAttribute>
    #   resp.data.db_snapshot_attributes_result.db_snapshot_attributes[0] #=> Types::DBSnapshotAttribute
    #   resp.data.db_snapshot_attributes_result.db_snapshot_attributes[0].attribute_name #=> String
    #   resp.data.db_snapshot_attributes_result.db_snapshot_attributes[0].attribute_values #=> Array<String>
    #   resp.data.db_snapshot_attributes_result.db_snapshot_attributes[0].attribute_values[0] #=> String
    #
    def modify_db_snapshot_attribute(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyDBSnapshotAttributeInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyDBSnapshotAttributeInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyDBSnapshotAttribute
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::SharedSnapshotQuotaExceededFault, Errors::InvalidDBSnapshotStateFault, Errors::DBSnapshotNotFoundFault]),
        data_parser: Parsers::ModifyDBSnapshotAttribute
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyDBSnapshotAttribute,
        stubs: @stubs,
        params_class: Params::ModifyDBSnapshotAttributeOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_db_snapshot_attribute
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Modifies an existing DB subnet group. DB subnet groups must contain at least one subnet in at least two AZs in the Amazon Web Services Region.</p>
    #
    # @param [Hash] params
    #   See {Types::ModifyDBSubnetGroupInput}.
    #
    # @option params [String] :db_subnet_group_name
    #   <p>The name for the DB subnet group. This value is stored as a lowercase string.
    #             You can't modify the default subnet group.</p>
    #           <p>Constraints: Must match the name of an existing DBSubnetGroup. Must not be default.</p>
    #           <p>Example: <code>mydbsubnetgroup</code>
    #            </p>
    #
    # @option params [String] :db_subnet_group_description
    #   <p>The description for the DB subnet group.</p>
    #
    # @option params [Array<String>] :subnet_ids
    #   <p>The EC2 subnet IDs for the DB subnet group.</p>
    #
    # @return [Types::ModifyDBSubnetGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_db_subnet_group(
    #     db_subnet_group_name: 'DBSubnetGroupName', # required
    #     db_subnet_group_description: 'DBSubnetGroupDescription',
    #     subnet_ids: [
    #       'member'
    #     ] # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyDBSubnetGroupOutput
    #   resp.data.db_subnet_group #=> Types::DBSubnetGroup
    #   resp.data.db_subnet_group.db_subnet_group_name #=> String
    #   resp.data.db_subnet_group.db_subnet_group_description #=> String
    #   resp.data.db_subnet_group.vpc_id #=> String
    #   resp.data.db_subnet_group.subnet_group_status #=> String
    #   resp.data.db_subnet_group.subnets #=> Array<Subnet>
    #   resp.data.db_subnet_group.subnets[0] #=> Types::Subnet
    #   resp.data.db_subnet_group.subnets[0].subnet_identifier #=> String
    #   resp.data.db_subnet_group.subnets[0].subnet_availability_zone #=> Types::AvailabilityZone
    #   resp.data.db_subnet_group.subnets[0].subnet_availability_zone.name #=> String
    #   resp.data.db_subnet_group.subnets[0].subnet_outpost #=> Types::Outpost
    #   resp.data.db_subnet_group.subnets[0].subnet_outpost.arn #=> String
    #   resp.data.db_subnet_group.subnets[0].subnet_status #=> String
    #   resp.data.db_subnet_group.db_subnet_group_arn #=> String
    #   resp.data.db_subnet_group.supported_network_types #=> Array<String>
    #   resp.data.db_subnet_group.supported_network_types[0] #=> String
    #
    def modify_db_subnet_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyDBSubnetGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyDBSubnetGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyDBSubnetGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBSubnetGroupDoesNotCoverEnoughAZs, Errors::DBSubnetGroupNotFoundFault, Errors::DBSubnetQuotaExceededFault, Errors::SubnetAlreadyInUse, Errors::InvalidSubnet]),
        data_parser: Parsers::ModifyDBSubnetGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyDBSubnetGroup,
        stubs: @stubs,
        params_class: Params::ModifyDBSubnetGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_db_subnet_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Modifies an existing RDS event notification subscription. You can't modify the source identifiers using this call. To change
    #         source identifiers for a subscription, use the <code>AddSourceIdentifierToSubscription</code> and <code>RemoveSourceIdentifierFromSubscription</code> calls.</p>
    #         <p>You can see a list of the event categories for a given source type (<code>SourceType</code>)
    #           in <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.html">Events</a> in the <i>Amazon RDS User Guide</i>
    #             or by using the <code>DescribeEventCategories</code> operation.</p>
    #
    # @param [Hash] params
    #   See {Types::ModifyEventSubscriptionInput}.
    #
    # @option params [String] :subscription_name
    #   <p>The name of the RDS event notification subscription.</p>
    #
    # @option params [String] :sns_topic_arn
    #   <p>The Amazon Resource Name (ARN) of the SNS topic created for event notification. The ARN is created by Amazon SNS when you create a topic and subscribe to it.</p>
    #
    # @option params [String] :source_type
    #   <p>The type of source that is generating the events. For example, if you want to be notified of events generated by a DB instance, you would set this parameter to db-instance. For RDS Proxy events, specify <code>db-proxy</code>. If this value isn't specified, all events are returned.</p>
    #           <p>Valid values: <code>db-instance</code> | <code>db-cluster</code> | <code>db-parameter-group</code> | <code>db-security-group</code> | <code>db-snapshot</code> | <code>db-cluster-snapshot</code> | <code>db-proxy</code>
    #            </p>
    #
    # @option params [Array<String>] :event_categories
    #   <p>A list of event categories for a source type (<code>SourceType</code>) that you want to subscribe to.
    #               You can see a list of the categories for a given source type
    #               in <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.html">Events</a> in the <i>Amazon RDS User Guide</i>
    #               or by using the <code>DescribeEventCategories</code> operation.</p>
    #
    # @option params [Boolean] :enabled
    #   <p>A value that indicates whether to activate the subscription.</p>
    #
    # @return [Types::ModifyEventSubscriptionOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_event_subscription(
    #     subscription_name: 'SubscriptionName', # required
    #     sns_topic_arn: 'SnsTopicArn',
    #     source_type: 'SourceType',
    #     event_categories: [
    #       'member'
    #     ],
    #     enabled: false
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyEventSubscriptionOutput
    #   resp.data.event_subscription #=> Types::EventSubscription
    #   resp.data.event_subscription.customer_aws_id #=> String
    #   resp.data.event_subscription.cust_subscription_id #=> String
    #   resp.data.event_subscription.sns_topic_arn #=> String
    #   resp.data.event_subscription.status #=> String
    #   resp.data.event_subscription.subscription_creation_time #=> String
    #   resp.data.event_subscription.source_type #=> String
    #   resp.data.event_subscription.source_ids_list #=> Array<String>
    #   resp.data.event_subscription.source_ids_list[0] #=> String
    #   resp.data.event_subscription.event_categories_list #=> Array<String>
    #   resp.data.event_subscription.event_categories_list[0] #=> String
    #   resp.data.event_subscription.enabled #=> Boolean
    #   resp.data.event_subscription.event_subscription_arn #=> String
    #
    def modify_event_subscription(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyEventSubscriptionInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyEventSubscriptionInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyEventSubscription
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::SubscriptionNotFoundFault, Errors::SNSInvalidTopicFault, Errors::SubscriptionCategoryNotFoundFault, Errors::SNSNoAuthorizationFault, Errors::SNSTopicArnNotFoundFault, Errors::EventSubscriptionQuotaExceededFault]),
        data_parser: Parsers::ModifyEventSubscription
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyEventSubscription,
        stubs: @stubs,
        params_class: Params::ModifyEventSubscriptionOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_event_subscription
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Modify a setting for an Amazon Aurora global cluster. You can change one or more database configuration
    #         parameters by specifying these parameters and the new values in the request. For more information on
    #         Amazon Aurora, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html"> What is Amazon Aurora?</a> in the
    #         <i>Amazon Aurora User Guide</i>.</p>
    #         <note>
    #             <p>This action only applies to Aurora DB clusters.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::ModifyGlobalClusterInput}.
    #
    # @option params [String] :global_cluster_identifier
    #   <p>The DB cluster identifier for the global cluster being modified. This parameter isn't case-sensitive.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the identifier of an existing global database cluster.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :new_global_cluster_identifier
    #   <p>The new cluster identifier for the global database cluster when modifying a global database cluster.
    #           This value is stored as a lowercase string.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain from 1 to 63 letters, numbers, or hyphens</p>
    #               </li>
    #               <li>
    #                   <p>The first character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-cluster2</code>
    #            </p>
    #
    # @option params [Boolean] :deletion_protection
    #   <p>Indicates if the global database cluster has deletion protection enabled. The global database cluster
    #           can't be deleted when deletion protection is enabled.</p>
    #
    # @option params [String] :engine_version
    #   <p>The version number of the database engine to which you want to upgrade.
    #             Changing this parameter results in an outage. The change is applied during
    #             the next maintenance window unless <code>ApplyImmediately</code> is enabled.</p>
    #           <p>To list all of the available engine versions for <code>aurora</code> (for MySQL 5.6-compatible Aurora), use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine aurora --query '*[]|[?SupportsGlobalDatabases == `true`].[EngineVersion]'</code>
    #            </p>
    #           <p>To list all of the available engine versions for <code>aurora-mysql</code> (for MySQL 5.7-compatible and MySQL 8.0-compatible Aurora), use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine aurora-mysql --query '*[]|[?SupportsGlobalDatabases == `true`].[EngineVersion]'</code>
    #            </p>
    #           <p>To list all of the available engine versions for <code>aurora-postgresql</code>, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine aurora-postgresql --query '*[]|[?SupportsGlobalDatabases == `true`].[EngineVersion]'</code>
    #            </p>
    #
    # @option params [Boolean] :allow_major_version_upgrade
    #   <p>A value that indicates whether major version upgrades are allowed.</p>
    #           <p>Constraints: You must allow major version upgrades when specifying a value for the
    #                   <code>EngineVersion</code> parameter that is a different major version than the DB
    #               cluster's current version.</p>
    #           <p>If you upgrade the major version of a global database, the cluster and DB instance parameter
    #           groups are set to the default parameter groups for the new version. Apply any custom parameter
    #           groups after completing the upgrade.</p>
    #
    # @return [Types::ModifyGlobalClusterOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_global_cluster(
    #     global_cluster_identifier: 'GlobalClusterIdentifier',
    #     new_global_cluster_identifier: 'NewGlobalClusterIdentifier',
    #     deletion_protection: false,
    #     engine_version: 'EngineVersion',
    #     allow_major_version_upgrade: false
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyGlobalClusterOutput
    #   resp.data.global_cluster #=> Types::GlobalCluster
    #   resp.data.global_cluster.global_cluster_identifier #=> String
    #   resp.data.global_cluster.global_cluster_resource_id #=> String
    #   resp.data.global_cluster.global_cluster_arn #=> String
    #   resp.data.global_cluster.status #=> String
    #   resp.data.global_cluster.engine #=> String
    #   resp.data.global_cluster.engine_version #=> String
    #   resp.data.global_cluster.database_name #=> String
    #   resp.data.global_cluster.storage_encrypted #=> Boolean
    #   resp.data.global_cluster.deletion_protection #=> Boolean
    #   resp.data.global_cluster.global_cluster_members #=> Array<GlobalClusterMember>
    #   resp.data.global_cluster.global_cluster_members[0] #=> Types::GlobalClusterMember
    #   resp.data.global_cluster.global_cluster_members[0].db_cluster_arn #=> String
    #   resp.data.global_cluster.global_cluster_members[0].readers #=> Array<String>
    #   resp.data.global_cluster.global_cluster_members[0].readers[0] #=> String
    #   resp.data.global_cluster.global_cluster_members[0].is_writer #=> Boolean
    #   resp.data.global_cluster.global_cluster_members[0].global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.global_cluster.failover_state #=> Types::FailoverState
    #   resp.data.global_cluster.failover_state.status #=> String, one of ["pending", "failing-over", "cancelling"]
    #   resp.data.global_cluster.failover_state.from_db_cluster_arn #=> String
    #   resp.data.global_cluster.failover_state.to_db_cluster_arn #=> String
    #
    def modify_global_cluster(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyGlobalClusterInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyGlobalClusterInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyGlobalCluster
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::GlobalClusterNotFoundFault, Errors::InvalidGlobalClusterStateFault, Errors::InvalidDBClusterStateFault, Errors::InvalidDBInstanceStateFault]),
        data_parser: Parsers::ModifyGlobalCluster
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyGlobalCluster,
        stubs: @stubs,
        params_class: Params::ModifyGlobalClusterOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_global_cluster
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Modifies an existing option group.</p>
    #
    # @param [Hash] params
    #   See {Types::ModifyOptionGroupInput}.
    #
    # @option params [String] :option_group_name
    #   <p>The name of the option group to be modified.</p>
    #           <p>Permanent options, such as the TDE option for Oracle Advanced Security TDE, can't be removed from an option group, and that option group can't be removed from a DB instance once it is associated with a DB instance</p>
    #
    # @option params [Array<OptionConfiguration>] :options_to_include
    #   <p>Options in this list are added to the option group or, if already present, the specified configuration is used to update the existing configuration.</p>
    #
    # @option params [Array<String>] :options_to_remove
    #   <p>Options in this list are removed from the option group.</p>
    #
    # @option params [Boolean] :apply_immediately
    #   <p>A value that indicates whether to apply the change immediately or during the next maintenance window for each instance associated with the option group.</p>
    #
    # @return [Types::ModifyOptionGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.modify_option_group(
    #     option_group_name: 'OptionGroupName', # required
    #     options_to_include: [
    #       {
    #         option_name: 'OptionName', # required
    #         port: 1,
    #         option_version: 'OptionVersion',
    #         db_security_group_memberships: [
    #           'member'
    #         ],
    #         vpc_security_group_memberships: [
    #           'member'
    #         ],
    #         option_settings: [
    #           {
    #             name: 'Name',
    #             value: 'Value',
    #             default_value: 'DefaultValue',
    #             description: 'Description',
    #             apply_type: 'ApplyType',
    #             data_type: 'DataType',
    #             allowed_values: 'AllowedValues',
    #             is_modifiable: false,
    #             is_collection: false
    #           }
    #         ]
    #       }
    #     ],
    #     options_to_remove: [
    #       'member'
    #     ],
    #     apply_immediately: false
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ModifyOptionGroupOutput
    #   resp.data.option_group #=> Types::OptionGroup
    #   resp.data.option_group.option_group_name #=> String
    #   resp.data.option_group.option_group_description #=> String
    #   resp.data.option_group.engine_name #=> String
    #   resp.data.option_group.major_engine_version #=> String
    #   resp.data.option_group.options #=> Array<Option>
    #   resp.data.option_group.options[0] #=> Types::Option
    #   resp.data.option_group.options[0].option_name #=> String
    #   resp.data.option_group.options[0].option_description #=> String
    #   resp.data.option_group.options[0].persistent #=> Boolean
    #   resp.data.option_group.options[0].permanent #=> Boolean
    #   resp.data.option_group.options[0].port #=> Integer
    #   resp.data.option_group.options[0].option_version #=> String
    #   resp.data.option_group.options[0].option_settings #=> Array<OptionSetting>
    #   resp.data.option_group.options[0].option_settings[0] #=> Types::OptionSetting
    #   resp.data.option_group.options[0].option_settings[0].name #=> String
    #   resp.data.option_group.options[0].option_settings[0].value #=> String
    #   resp.data.option_group.options[0].option_settings[0].default_value #=> String
    #   resp.data.option_group.options[0].option_settings[0].description #=> String
    #   resp.data.option_group.options[0].option_settings[0].apply_type #=> String
    #   resp.data.option_group.options[0].option_settings[0].data_type #=> String
    #   resp.data.option_group.options[0].option_settings[0].allowed_values #=> String
    #   resp.data.option_group.options[0].option_settings[0].is_modifiable #=> Boolean
    #   resp.data.option_group.options[0].option_settings[0].is_collection #=> Boolean
    #   resp.data.option_group.options[0].db_security_group_memberships #=> Array<DBSecurityGroupMembership>
    #   resp.data.option_group.options[0].db_security_group_memberships[0] #=> Types::DBSecurityGroupMembership
    #   resp.data.option_group.options[0].db_security_group_memberships[0].db_security_group_name #=> String
    #   resp.data.option_group.options[0].db_security_group_memberships[0].status #=> String
    #   resp.data.option_group.options[0].vpc_security_group_memberships #=> Array<VpcSecurityGroupMembership>
    #   resp.data.option_group.options[0].vpc_security_group_memberships[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.option_group.options[0].vpc_security_group_memberships[0].vpc_security_group_id #=> String
    #   resp.data.option_group.options[0].vpc_security_group_memberships[0].status #=> String
    #   resp.data.option_group.allows_vpc_and_non_vpc_instance_memberships #=> Boolean
    #   resp.data.option_group.vpc_id #=> String
    #   resp.data.option_group.option_group_arn #=> String
    #
    def modify_option_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ModifyOptionGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ModifyOptionGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ModifyOptionGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidOptionGroupStateFault, Errors::OptionGroupNotFoundFault]),
        data_parser: Parsers::ModifyOptionGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ModifyOptionGroup,
        stubs: @stubs,
        params_class: Params::ModifyOptionGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :modify_option_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Promotes a read replica DB instance to a standalone DB instance.</p>
    #         <note>
    #             <ul>
    #                <li>
    #                     <p>Backup duration is a function of the amount of changes to the database since the previous
    #                         backup. If you plan to promote a read replica to a standalone instance, we
    #                         recommend that you enable backups and complete at least one backup prior to
    #                         promotion. In addition, a read replica cannot be promoted to a standalone
    #                         instance when it is in the <code>backing-up</code> status. If you have
    #                         enabled backups on your read replica, configure the automated backup window
    #                         so that daily backups do not interfere with read replica
    #                         promotion.</p>
    #                 </li>
    #                <li>
    #                     <p>This command doesn't apply to Aurora MySQL, Aurora PostgreSQL, or RDS Custom.</p>
    #                 </li>
    #             </ul>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::PromoteReadReplicaInput}.
    #
    # @option params [String] :db_instance_identifier
    #   <p>The DB instance identifier. This value is stored as a lowercase string.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the identifier of an existing read replica DB instance.</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>mydbinstance</code>
    #            </p>
    #
    # @option params [Integer] :backup_retention_period
    #   <p>The number of days for which automated backups are retained. Setting this parameter to a positive number enables backups. Setting this parameter to 0 disables automated backups.</p>
    #           <p>Default: 1</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be a value from 0 to 35.</p>
    #               </li>
    #               <li>
    #                   <p>Can't be set to 0 if the DB instance is a source to read replicas.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :preferred_backup_window
    #   <p>The daily time range during which automated backups are created
    #           if automated backups are enabled,
    #           using the <code>BackupRetentionPeriod</code> parameter.</p>
    #           <p>The default is a 30-minute window selected at random from an
    #               8-hour block of time for each Amazon Web Services Region.
    #               To see the time blocks available, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/AdjustingTheMaintenanceWindow.html">
    #               Adjusting the Preferred Maintenance Window</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be in the format <code>hh24:mi-hh24:mi</code>.</p>
    #               </li>
    #               <li>
    #                   <p>Must be in Universal Coordinated Time (UTC).</p>
    #               </li>
    #               <li>
    #                   <p>Must not conflict with the preferred maintenance window.</p>
    #               </li>
    #               <li>
    #                   <p>Must be at least 30 minutes.</p>
    #               </li>
    #            </ul>
    #
    # @return [Types::PromoteReadReplicaOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.promote_read_replica(
    #     db_instance_identifier: 'DBInstanceIdentifier', # required
    #     backup_retention_period: 1,
    #     preferred_backup_window: 'PreferredBackupWindow'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::PromoteReadReplicaOutput
    #   resp.data.db_instance #=> Types::DBInstance
    #   resp.data.db_instance.db_instance_identifier #=> String
    #   resp.data.db_instance.db_instance_class #=> String
    #   resp.data.db_instance.engine #=> String
    #   resp.data.db_instance.db_instance_status #=> String
    #   resp.data.db_instance.automatic_restart_time #=> Time
    #   resp.data.db_instance.master_username #=> String
    #   resp.data.db_instance.db_name #=> String
    #   resp.data.db_instance.endpoint #=> Types::Endpoint
    #   resp.data.db_instance.endpoint.address #=> String
    #   resp.data.db_instance.endpoint.port #=> Integer
    #   resp.data.db_instance.endpoint.hosted_zone_id #=> String
    #   resp.data.db_instance.allocated_storage #=> Integer
    #   resp.data.db_instance.instance_create_time #=> Time
    #   resp.data.db_instance.preferred_backup_window #=> String
    #   resp.data.db_instance.backup_retention_period #=> Integer
    #   resp.data.db_instance.db_security_groups #=> Array<DBSecurityGroupMembership>
    #   resp.data.db_instance.db_security_groups[0] #=> Types::DBSecurityGroupMembership
    #   resp.data.db_instance.db_security_groups[0].db_security_group_name #=> String
    #   resp.data.db_instance.db_security_groups[0].status #=> String
    #   resp.data.db_instance.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_instance.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_instance.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_instance.vpc_security_groups[0].status #=> String
    #   resp.data.db_instance.db_parameter_groups #=> Array<DBParameterGroupStatus>
    #   resp.data.db_instance.db_parameter_groups[0] #=> Types::DBParameterGroupStatus
    #   resp.data.db_instance.db_parameter_groups[0].db_parameter_group_name #=> String
    #   resp.data.db_instance.db_parameter_groups[0].parameter_apply_status #=> String
    #   resp.data.db_instance.availability_zone #=> String
    #   resp.data.db_instance.db_subnet_group #=> Types::DBSubnetGroup
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_name #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_description #=> String
    #   resp.data.db_instance.db_subnet_group.vpc_id #=> String
    #   resp.data.db_instance.db_subnet_group.subnet_group_status #=> String
    #   resp.data.db_instance.db_subnet_group.subnets #=> Array<Subnet>
    #   resp.data.db_instance.db_subnet_group.subnets[0] #=> Types::Subnet
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_identifier #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone #=> Types::AvailabilityZone
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone.name #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost #=> Types::Outpost
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost.arn #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_status #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_arn #=> String
    #   resp.data.db_instance.db_subnet_group.supported_network_types #=> Array<String>
    #   resp.data.db_instance.db_subnet_group.supported_network_types[0] #=> String
    #   resp.data.db_instance.preferred_maintenance_window #=> String
    #   resp.data.db_instance.pending_modified_values #=> Types::PendingModifiedValues
    #   resp.data.db_instance.pending_modified_values.db_instance_class #=> String
    #   resp.data.db_instance.pending_modified_values.allocated_storage #=> Integer
    #   resp.data.db_instance.pending_modified_values.master_user_password #=> String
    #   resp.data.db_instance.pending_modified_values.port #=> Integer
    #   resp.data.db_instance.pending_modified_values.backup_retention_period #=> Integer
    #   resp.data.db_instance.pending_modified_values.multi_az #=> Boolean
    #   resp.data.db_instance.pending_modified_values.engine_version #=> String
    #   resp.data.db_instance.pending_modified_values.license_model #=> String
    #   resp.data.db_instance.pending_modified_values.iops #=> Integer
    #   resp.data.db_instance.pending_modified_values.db_instance_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.storage_type #=> String
    #   resp.data.db_instance.pending_modified_values.ca_certificate_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.db_subnet_group_name #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable[0] #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.pending_modified_values.processor_features[0] #=> Types::ProcessorFeature
    #   resp.data.db_instance.pending_modified_values.processor_features[0].name #=> String
    #   resp.data.db_instance.pending_modified_values.processor_features[0].value #=> String
    #   resp.data.db_instance.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.pending_modified_values.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.pending_modified_values.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.latest_restorable_time #=> Time
    #   resp.data.db_instance.multi_az #=> Boolean
    #   resp.data.db_instance.engine_version #=> String
    #   resp.data.db_instance.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_instance.read_replica_source_db_instance_identifier #=> String
    #   resp.data.db_instance.read_replica_db_instance_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_instance_identifiers[0] #=> String
    #   resp.data.db_instance.read_replica_db_cluster_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_cluster_identifiers[0] #=> String
    #   resp.data.db_instance.replica_mode #=> String, one of ["open-read-only", "mounted"]
    #   resp.data.db_instance.license_model #=> String
    #   resp.data.db_instance.iops #=> Integer
    #   resp.data.db_instance.option_group_memberships #=> Array<OptionGroupMembership>
    #   resp.data.db_instance.option_group_memberships[0] #=> Types::OptionGroupMembership
    #   resp.data.db_instance.option_group_memberships[0].option_group_name #=> String
    #   resp.data.db_instance.option_group_memberships[0].status #=> String
    #   resp.data.db_instance.character_set_name #=> String
    #   resp.data.db_instance.nchar_character_set_name #=> String
    #   resp.data.db_instance.secondary_availability_zone #=> String
    #   resp.data.db_instance.publicly_accessible #=> Boolean
    #   resp.data.db_instance.status_infos #=> Array<DBInstanceStatusInfo>
    #   resp.data.db_instance.status_infos[0] #=> Types::DBInstanceStatusInfo
    #   resp.data.db_instance.status_infos[0].status_type #=> String
    #   resp.data.db_instance.status_infos[0].normal #=> Boolean
    #   resp.data.db_instance.status_infos[0].status #=> String
    #   resp.data.db_instance.status_infos[0].message #=> String
    #   resp.data.db_instance.storage_type #=> String
    #   resp.data.db_instance.tde_credential_arn #=> String
    #   resp.data.db_instance.db_instance_port #=> Integer
    #   resp.data.db_instance.db_cluster_identifier #=> String
    #   resp.data.db_instance.storage_encrypted #=> Boolean
    #   resp.data.db_instance.kms_key_id #=> String
    #   resp.data.db_instance.dbi_resource_id #=> String
    #   resp.data.db_instance.ca_certificate_identifier #=> String
    #   resp.data.db_instance.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_instance.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_instance.domain_memberships[0].domain #=> String
    #   resp.data.db_instance.domain_memberships[0].status #=> String
    #   resp.data.db_instance.domain_memberships[0].fqdn #=> String
    #   resp.data.db_instance.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_instance.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_instance.monitoring_interval #=> Integer
    #   resp.data.db_instance.enhanced_monitoring_resource_arn #=> String
    #   resp.data.db_instance.monitoring_role_arn #=> String
    #   resp.data.db_instance.promotion_tier #=> Integer
    #   resp.data.db_instance.db_instance_arn #=> String
    #   resp.data.db_instance.timezone #=> String
    #   resp.data.db_instance.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_kms_key_id #=> String
    #   resp.data.db_instance.performance_insights_retention_period #=> Integer
    #   resp.data.db_instance.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_instance.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.deletion_protection #=> Boolean
    #   resp.data.db_instance.associated_roles #=> Array<DBInstanceRole>
    #   resp.data.db_instance.associated_roles[0] #=> Types::DBInstanceRole
    #   resp.data.db_instance.associated_roles[0].role_arn #=> String
    #   resp.data.db_instance.associated_roles[0].feature_name #=> String
    #   resp.data.db_instance.associated_roles[0].status #=> String
    #   resp.data.db_instance.listener_endpoint #=> Types::Endpoint
    #   resp.data.db_instance.max_allocated_storage #=> Integer
    #   resp.data.db_instance.tag_list #=> Array<Tag>
    #   resp.data.db_instance.tag_list[0] #=> Types::Tag
    #   resp.data.db_instance.tag_list[0].key #=> String
    #   resp.data.db_instance.tag_list[0].value #=> String
    #   resp.data.db_instance.db_instance_automated_backups_replications #=> Array<DBInstanceAutomatedBackupsReplication>
    #   resp.data.db_instance.db_instance_automated_backups_replications[0] #=> Types::DBInstanceAutomatedBackupsReplication
    #   resp.data.db_instance.db_instance_automated_backups_replications[0].db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance.customer_owned_ip_enabled #=> Boolean
    #   resp.data.db_instance.aws_backup_recovery_point_arn #=> String
    #   resp.data.db_instance.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_instance.activity_stream_kms_key_id #=> String
    #   resp.data.db_instance.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_instance.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_instance.activity_stream_engine_native_audit_fields_included #=> Boolean
    #   resp.data.db_instance.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.custom_iam_instance_profile #=> String
    #   resp.data.db_instance.backup_target #=> String
    #   resp.data.db_instance.network_type #=> String
    #
    def promote_read_replica(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::PromoteReadReplicaInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::PromoteReadReplicaInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::PromoteReadReplica
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBInstanceNotFoundFault, Errors::InvalidDBInstanceStateFault]),
        data_parser: Parsers::PromoteReadReplica
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::PromoteReadReplica,
        stubs: @stubs,
        params_class: Params::PromoteReadReplicaOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :promote_read_replica
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Promotes a read replica DB cluster to a standalone DB cluster.</p>
    #
    # @param [Hash] params
    #   See {Types::PromoteReadReplicaDBClusterInput}.
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The identifier of the DB cluster read replica to promote. This parameter isn't
    #               case-sensitive.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the identifier of an existing DB cluster read replica.</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-cluster-replica1</code>
    #            </p>
    #
    # @return [Types::PromoteReadReplicaDBClusterOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.promote_read_replica_db_cluster(
    #     db_cluster_identifier: 'DBClusterIdentifier' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::PromoteReadReplicaDBClusterOutput
    #   resp.data.db_cluster #=> Types::DBCluster
    #   resp.data.db_cluster.allocated_storage #=> Integer
    #   resp.data.db_cluster.availability_zones #=> Array<String>
    #   resp.data.db_cluster.availability_zones[0] #=> String
    #   resp.data.db_cluster.backup_retention_period #=> Integer
    #   resp.data.db_cluster.character_set_name #=> String
    #   resp.data.db_cluster.database_name #=> String
    #   resp.data.db_cluster.db_cluster_identifier #=> String
    #   resp.data.db_cluster.db_cluster_parameter_group #=> String
    #   resp.data.db_cluster.db_subnet_group #=> String
    #   resp.data.db_cluster.status #=> String
    #   resp.data.db_cluster.automatic_restart_time #=> Time
    #   resp.data.db_cluster.percent_progress #=> String
    #   resp.data.db_cluster.earliest_restorable_time #=> Time
    #   resp.data.db_cluster.endpoint #=> String
    #   resp.data.db_cluster.reader_endpoint #=> String
    #   resp.data.db_cluster.custom_endpoints #=> Array<String>
    #   resp.data.db_cluster.custom_endpoints[0] #=> String
    #   resp.data.db_cluster.multi_az #=> Boolean
    #   resp.data.db_cluster.engine #=> String
    #   resp.data.db_cluster.engine_version #=> String
    #   resp.data.db_cluster.latest_restorable_time #=> Time
    #   resp.data.db_cluster.port #=> Integer
    #   resp.data.db_cluster.master_username #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships #=> Array<DBClusterOptionGroupStatus>
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0] #=> Types::DBClusterOptionGroupStatus
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].db_cluster_option_group_name #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].status #=> String
    #   resp.data.db_cluster.preferred_backup_window #=> String
    #   resp.data.db_cluster.preferred_maintenance_window #=> String
    #   resp.data.db_cluster.replication_source_identifier #=> String
    #   resp.data.db_cluster.read_replica_identifiers #=> Array<String>
    #   resp.data.db_cluster.read_replica_identifiers[0] #=> String
    #   resp.data.db_cluster.db_cluster_members #=> Array<DBClusterMember>
    #   resp.data.db_cluster.db_cluster_members[0] #=> Types::DBClusterMember
    #   resp.data.db_cluster.db_cluster_members[0].db_instance_identifier #=> String
    #   resp.data.db_cluster.db_cluster_members[0].is_cluster_writer #=> Boolean
    #   resp.data.db_cluster.db_cluster_members[0].db_cluster_parameter_group_status #=> String
    #   resp.data.db_cluster.db_cluster_members[0].promotion_tier #=> Integer
    #   resp.data.db_cluster.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_cluster.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_cluster.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_cluster.vpc_security_groups[0].status #=> String
    #   resp.data.db_cluster.hosted_zone_id #=> String
    #   resp.data.db_cluster.storage_encrypted #=> Boolean
    #   resp.data.db_cluster.kms_key_id #=> String
    #   resp.data.db_cluster.db_cluster_resource_id #=> String
    #   resp.data.db_cluster.db_cluster_arn #=> String
    #   resp.data.db_cluster.associated_roles #=> Array<DBClusterRole>
    #   resp.data.db_cluster.associated_roles[0] #=> Types::DBClusterRole
    #   resp.data.db_cluster.associated_roles[0].role_arn #=> String
    #   resp.data.db_cluster.associated_roles[0].status #=> String
    #   resp.data.db_cluster.associated_roles[0].feature_name #=> String
    #   resp.data.db_cluster.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.clone_group_id #=> String
    #   resp.data.db_cluster.cluster_create_time #=> Time
    #   resp.data.db_cluster.earliest_backtrack_time #=> Time
    #   resp.data.db_cluster.backtrack_window #=> Integer
    #   resp.data.db_cluster.backtrack_consumed_change_records #=> Integer
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports[0] #=> String
    #   resp.data.db_cluster.capacity #=> Integer
    #   resp.data.db_cluster.engine_mode #=> String
    #   resp.data.db_cluster.scaling_configuration_info #=> Types::ScalingConfigurationInfo
    #   resp.data.db_cluster.scaling_configuration_info.min_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.max_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.auto_pause #=> Boolean
    #   resp.data.db_cluster.scaling_configuration_info.seconds_until_auto_pause #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.timeout_action #=> String
    #   resp.data.db_cluster.scaling_configuration_info.seconds_before_timeout #=> Integer
    #   resp.data.db_cluster.deletion_protection #=> Boolean
    #   resp.data.db_cluster.http_endpoint_enabled #=> Boolean
    #   resp.data.db_cluster.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_cluster.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_cluster.activity_stream_kms_key_id #=> String
    #   resp.data.db_cluster.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_cluster.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_cluster.cross_account_clone #=> Boolean
    #   resp.data.db_cluster.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_cluster.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_cluster.domain_memberships[0].domain #=> String
    #   resp.data.db_cluster.domain_memberships[0].status #=> String
    #   resp.data.db_cluster.domain_memberships[0].fqdn #=> String
    #   resp.data.db_cluster.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_cluster.tag_list #=> Array<Tag>
    #   resp.data.db_cluster.tag_list[0] #=> Types::Tag
    #   resp.data.db_cluster.tag_list[0].key #=> String
    #   resp.data.db_cluster.tag_list[0].value #=> String
    #   resp.data.db_cluster.global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.db_cluster.global_write_forwarding_requested #=> Boolean
    #   resp.data.db_cluster.pending_modified_values #=> Types::ClusterPendingModifiedValues
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.db_cluster_identifier #=> String
    #   resp.data.db_cluster.pending_modified_values.master_user_password #=> String
    #   resp.data.db_cluster.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.pending_modified_values.engine_version #=> String
    #   resp.data.db_cluster.db_cluster_instance_class #=> String
    #   resp.data.db_cluster.storage_type #=> String
    #   resp.data.db_cluster.iops #=> Integer
    #   resp.data.db_cluster.publicly_accessible #=> Boolean
    #   resp.data.db_cluster.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_cluster.monitoring_interval #=> Integer
    #   resp.data.db_cluster.monitoring_role_arn #=> String
    #   resp.data.db_cluster.performance_insights_enabled #=> Boolean
    #   resp.data.db_cluster.performance_insights_kms_key_id #=> String
    #   resp.data.db_cluster.performance_insights_retention_period #=> Integer
    #   resp.data.db_cluster.serverless_v2_scaling_configuration #=> Types::ServerlessV2ScalingConfigurationInfo
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.min_capacity #=> Float
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.max_capacity #=> Float
    #
    def promote_read_replica_db_cluster(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::PromoteReadReplicaDBClusterInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::PromoteReadReplicaDBClusterInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::PromoteReadReplicaDBCluster
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::InvalidDBClusterStateFault]),
        data_parser: Parsers::PromoteReadReplicaDBCluster
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::PromoteReadReplicaDBCluster,
        stubs: @stubs,
        params_class: Params::PromoteReadReplicaDBClusterOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :promote_read_replica_db_cluster
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Purchases a reserved DB instance offering.</p>
    #
    # @param [Hash] params
    #   See {Types::PurchaseReservedDBInstancesOfferingInput}.
    #
    # @option params [String] :reserved_db_instances_offering_id
    #   <p>The ID of the Reserved DB instance offering to purchase.</p>
    #           <p>Example: 438012d3-4052-4cc7-b2e3-8d3372e0e706</p>
    #
    # @option params [String] :reserved_db_instance_id
    #   <p>Customer-specified identifier to track this reservation.</p>
    #           <p>Example: myreservationID</p>
    #
    # @option params [Integer] :db_instance_count
    #   <p>The number of instances to reserve.</p>
    #           <p>Default: <code>1</code>
    #            </p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>A list of tags.
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.html">Tagging Amazon RDS Resources</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @return [Types::PurchaseReservedDBInstancesOfferingOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.purchase_reserved_db_instances_offering(
    #     reserved_db_instances_offering_id: 'ReservedDBInstancesOfferingId', # required
    #     reserved_db_instance_id: 'ReservedDBInstanceId',
    #     db_instance_count: 1,
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::PurchaseReservedDBInstancesOfferingOutput
    #   resp.data.reserved_db_instance #=> Types::ReservedDBInstance
    #   resp.data.reserved_db_instance.reserved_db_instance_id #=> String
    #   resp.data.reserved_db_instance.reserved_db_instances_offering_id #=> String
    #   resp.data.reserved_db_instance.db_instance_class #=> String
    #   resp.data.reserved_db_instance.start_time #=> Time
    #   resp.data.reserved_db_instance.duration #=> Integer
    #   resp.data.reserved_db_instance.fixed_price #=> Float
    #   resp.data.reserved_db_instance.usage_price #=> Float
    #   resp.data.reserved_db_instance.currency_code #=> String
    #   resp.data.reserved_db_instance.db_instance_count #=> Integer
    #   resp.data.reserved_db_instance.product_description #=> String
    #   resp.data.reserved_db_instance.offering_type #=> String
    #   resp.data.reserved_db_instance.multi_az #=> Boolean
    #   resp.data.reserved_db_instance.state #=> String
    #   resp.data.reserved_db_instance.recurring_charges #=> Array<RecurringCharge>
    #   resp.data.reserved_db_instance.recurring_charges[0] #=> Types::RecurringCharge
    #   resp.data.reserved_db_instance.recurring_charges[0].recurring_charge_amount #=> Float
    #   resp.data.reserved_db_instance.recurring_charges[0].recurring_charge_frequency #=> String
    #   resp.data.reserved_db_instance.reserved_db_instance_arn #=> String
    #   resp.data.reserved_db_instance.lease_id #=> String
    #
    def purchase_reserved_db_instances_offering(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::PurchaseReservedDBInstancesOfferingInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::PurchaseReservedDBInstancesOfferingInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::PurchaseReservedDBInstancesOffering
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::ReservedDBInstanceAlreadyExistsFault, Errors::ReservedDBInstancesOfferingNotFoundFault, Errors::ReservedDBInstanceQuotaExceededFault]),
        data_parser: Parsers::PurchaseReservedDBInstancesOffering
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::PurchaseReservedDBInstancesOffering,
        stubs: @stubs,
        params_class: Params::PurchaseReservedDBInstancesOfferingOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :purchase_reserved_db_instances_offering
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>You might need to reboot your DB cluster, usually for maintenance reasons.
    #           For example, if you make certain modifications,
    #           or if you change the DB cluster parameter group associated with the DB cluster,
    #           reboot the DB cluster for the changes to take effect.</p>
    #         <p>Rebooting a DB cluster restarts the database engine service. Rebooting a DB
    #           cluster results in a momentary outage, during which the DB cluster status is set to rebooting.</p>
    #         <p>Use this operation only for a non-Aurora Multi-AZ DB cluster.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #               Multi-AZ deployments with two readable standby DB instances</a> in the
    #           <i>Amazon RDS User Guide.</i>
    #          </p>
    #
    # @param [Hash] params
    #   See {Types::RebootDBClusterInput}.
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The DB cluster identifier. This parameter is stored as a lowercase string.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the identifier of an existing DBCluster.</p>
    #               </li>
    #            </ul>
    #
    # @return [Types::RebootDBClusterOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.reboot_db_cluster(
    #     db_cluster_identifier: 'DBClusterIdentifier' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::RebootDBClusterOutput
    #   resp.data.db_cluster #=> Types::DBCluster
    #   resp.data.db_cluster.allocated_storage #=> Integer
    #   resp.data.db_cluster.availability_zones #=> Array<String>
    #   resp.data.db_cluster.availability_zones[0] #=> String
    #   resp.data.db_cluster.backup_retention_period #=> Integer
    #   resp.data.db_cluster.character_set_name #=> String
    #   resp.data.db_cluster.database_name #=> String
    #   resp.data.db_cluster.db_cluster_identifier #=> String
    #   resp.data.db_cluster.db_cluster_parameter_group #=> String
    #   resp.data.db_cluster.db_subnet_group #=> String
    #   resp.data.db_cluster.status #=> String
    #   resp.data.db_cluster.automatic_restart_time #=> Time
    #   resp.data.db_cluster.percent_progress #=> String
    #   resp.data.db_cluster.earliest_restorable_time #=> Time
    #   resp.data.db_cluster.endpoint #=> String
    #   resp.data.db_cluster.reader_endpoint #=> String
    #   resp.data.db_cluster.custom_endpoints #=> Array<String>
    #   resp.data.db_cluster.custom_endpoints[0] #=> String
    #   resp.data.db_cluster.multi_az #=> Boolean
    #   resp.data.db_cluster.engine #=> String
    #   resp.data.db_cluster.engine_version #=> String
    #   resp.data.db_cluster.latest_restorable_time #=> Time
    #   resp.data.db_cluster.port #=> Integer
    #   resp.data.db_cluster.master_username #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships #=> Array<DBClusterOptionGroupStatus>
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0] #=> Types::DBClusterOptionGroupStatus
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].db_cluster_option_group_name #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].status #=> String
    #   resp.data.db_cluster.preferred_backup_window #=> String
    #   resp.data.db_cluster.preferred_maintenance_window #=> String
    #   resp.data.db_cluster.replication_source_identifier #=> String
    #   resp.data.db_cluster.read_replica_identifiers #=> Array<String>
    #   resp.data.db_cluster.read_replica_identifiers[0] #=> String
    #   resp.data.db_cluster.db_cluster_members #=> Array<DBClusterMember>
    #   resp.data.db_cluster.db_cluster_members[0] #=> Types::DBClusterMember
    #   resp.data.db_cluster.db_cluster_members[0].db_instance_identifier #=> String
    #   resp.data.db_cluster.db_cluster_members[0].is_cluster_writer #=> Boolean
    #   resp.data.db_cluster.db_cluster_members[0].db_cluster_parameter_group_status #=> String
    #   resp.data.db_cluster.db_cluster_members[0].promotion_tier #=> Integer
    #   resp.data.db_cluster.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_cluster.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_cluster.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_cluster.vpc_security_groups[0].status #=> String
    #   resp.data.db_cluster.hosted_zone_id #=> String
    #   resp.data.db_cluster.storage_encrypted #=> Boolean
    #   resp.data.db_cluster.kms_key_id #=> String
    #   resp.data.db_cluster.db_cluster_resource_id #=> String
    #   resp.data.db_cluster.db_cluster_arn #=> String
    #   resp.data.db_cluster.associated_roles #=> Array<DBClusterRole>
    #   resp.data.db_cluster.associated_roles[0] #=> Types::DBClusterRole
    #   resp.data.db_cluster.associated_roles[0].role_arn #=> String
    #   resp.data.db_cluster.associated_roles[0].status #=> String
    #   resp.data.db_cluster.associated_roles[0].feature_name #=> String
    #   resp.data.db_cluster.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.clone_group_id #=> String
    #   resp.data.db_cluster.cluster_create_time #=> Time
    #   resp.data.db_cluster.earliest_backtrack_time #=> Time
    #   resp.data.db_cluster.backtrack_window #=> Integer
    #   resp.data.db_cluster.backtrack_consumed_change_records #=> Integer
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports[0] #=> String
    #   resp.data.db_cluster.capacity #=> Integer
    #   resp.data.db_cluster.engine_mode #=> String
    #   resp.data.db_cluster.scaling_configuration_info #=> Types::ScalingConfigurationInfo
    #   resp.data.db_cluster.scaling_configuration_info.min_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.max_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.auto_pause #=> Boolean
    #   resp.data.db_cluster.scaling_configuration_info.seconds_until_auto_pause #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.timeout_action #=> String
    #   resp.data.db_cluster.scaling_configuration_info.seconds_before_timeout #=> Integer
    #   resp.data.db_cluster.deletion_protection #=> Boolean
    #   resp.data.db_cluster.http_endpoint_enabled #=> Boolean
    #   resp.data.db_cluster.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_cluster.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_cluster.activity_stream_kms_key_id #=> String
    #   resp.data.db_cluster.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_cluster.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_cluster.cross_account_clone #=> Boolean
    #   resp.data.db_cluster.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_cluster.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_cluster.domain_memberships[0].domain #=> String
    #   resp.data.db_cluster.domain_memberships[0].status #=> String
    #   resp.data.db_cluster.domain_memberships[0].fqdn #=> String
    #   resp.data.db_cluster.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_cluster.tag_list #=> Array<Tag>
    #   resp.data.db_cluster.tag_list[0] #=> Types::Tag
    #   resp.data.db_cluster.tag_list[0].key #=> String
    #   resp.data.db_cluster.tag_list[0].value #=> String
    #   resp.data.db_cluster.global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.db_cluster.global_write_forwarding_requested #=> Boolean
    #   resp.data.db_cluster.pending_modified_values #=> Types::ClusterPendingModifiedValues
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.db_cluster_identifier #=> String
    #   resp.data.db_cluster.pending_modified_values.master_user_password #=> String
    #   resp.data.db_cluster.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.pending_modified_values.engine_version #=> String
    #   resp.data.db_cluster.db_cluster_instance_class #=> String
    #   resp.data.db_cluster.storage_type #=> String
    #   resp.data.db_cluster.iops #=> Integer
    #   resp.data.db_cluster.publicly_accessible #=> Boolean
    #   resp.data.db_cluster.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_cluster.monitoring_interval #=> Integer
    #   resp.data.db_cluster.monitoring_role_arn #=> String
    #   resp.data.db_cluster.performance_insights_enabled #=> Boolean
    #   resp.data.db_cluster.performance_insights_kms_key_id #=> String
    #   resp.data.db_cluster.performance_insights_retention_period #=> Integer
    #   resp.data.db_cluster.serverless_v2_scaling_configuration #=> Types::ServerlessV2ScalingConfigurationInfo
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.min_capacity #=> Float
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.max_capacity #=> Float
    #
    def reboot_db_cluster(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::RebootDBClusterInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::RebootDBClusterInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::RebootDBCluster
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::InvalidDBClusterStateFault, Errors::InvalidDBInstanceStateFault]),
        data_parser: Parsers::RebootDBCluster
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::RebootDBCluster,
        stubs: @stubs,
        params_class: Params::RebootDBClusterOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :reboot_db_cluster
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>You might need to reboot your DB instance, usually for maintenance reasons.
    #         For example, if you make certain modifications,
    #         or if you change the DB parameter group associated with the DB instance,
    #         you must reboot the instance for the changes to take effect.</p>
    #         <p>Rebooting a DB instance restarts the database engine service.
    #         Rebooting a DB instance results in a momentary outage, during which the DB instance status is set to rebooting.</p>
    #         <p>For more information about rebooting, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_RebootInstance.html">Rebooting a DB Instance</a> in the <i>Amazon RDS User Guide.</i>
    #          </p>
    #         <p>This command doesn't apply to RDS Custom.</p>
    #
    # @param [Hash] params
    #   See {Types::RebootDBInstanceInput}.
    #
    # @option params [String] :db_instance_identifier
    #   <p>The DB instance identifier. This parameter is stored as a lowercase string.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the identifier of an existing DBInstance.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Boolean] :force_failover
    #   <p>A value that indicates whether the reboot is conducted through a Multi-AZ failover.</p>
    #           <p>Constraint: You can't enable force failover if the instance isn't configured for Multi-AZ.</p>
    #
    # @return [Types::RebootDBInstanceOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.reboot_db_instance(
    #     db_instance_identifier: 'DBInstanceIdentifier', # required
    #     force_failover: false
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::RebootDBInstanceOutput
    #   resp.data.db_instance #=> Types::DBInstance
    #   resp.data.db_instance.db_instance_identifier #=> String
    #   resp.data.db_instance.db_instance_class #=> String
    #   resp.data.db_instance.engine #=> String
    #   resp.data.db_instance.db_instance_status #=> String
    #   resp.data.db_instance.automatic_restart_time #=> Time
    #   resp.data.db_instance.master_username #=> String
    #   resp.data.db_instance.db_name #=> String
    #   resp.data.db_instance.endpoint #=> Types::Endpoint
    #   resp.data.db_instance.endpoint.address #=> String
    #   resp.data.db_instance.endpoint.port #=> Integer
    #   resp.data.db_instance.endpoint.hosted_zone_id #=> String
    #   resp.data.db_instance.allocated_storage #=> Integer
    #   resp.data.db_instance.instance_create_time #=> Time
    #   resp.data.db_instance.preferred_backup_window #=> String
    #   resp.data.db_instance.backup_retention_period #=> Integer
    #   resp.data.db_instance.db_security_groups #=> Array<DBSecurityGroupMembership>
    #   resp.data.db_instance.db_security_groups[0] #=> Types::DBSecurityGroupMembership
    #   resp.data.db_instance.db_security_groups[0].db_security_group_name #=> String
    #   resp.data.db_instance.db_security_groups[0].status #=> String
    #   resp.data.db_instance.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_instance.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_instance.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_instance.vpc_security_groups[0].status #=> String
    #   resp.data.db_instance.db_parameter_groups #=> Array<DBParameterGroupStatus>
    #   resp.data.db_instance.db_parameter_groups[0] #=> Types::DBParameterGroupStatus
    #   resp.data.db_instance.db_parameter_groups[0].db_parameter_group_name #=> String
    #   resp.data.db_instance.db_parameter_groups[0].parameter_apply_status #=> String
    #   resp.data.db_instance.availability_zone #=> String
    #   resp.data.db_instance.db_subnet_group #=> Types::DBSubnetGroup
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_name #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_description #=> String
    #   resp.data.db_instance.db_subnet_group.vpc_id #=> String
    #   resp.data.db_instance.db_subnet_group.subnet_group_status #=> String
    #   resp.data.db_instance.db_subnet_group.subnets #=> Array<Subnet>
    #   resp.data.db_instance.db_subnet_group.subnets[0] #=> Types::Subnet
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_identifier #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone #=> Types::AvailabilityZone
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone.name #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost #=> Types::Outpost
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost.arn #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_status #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_arn #=> String
    #   resp.data.db_instance.db_subnet_group.supported_network_types #=> Array<String>
    #   resp.data.db_instance.db_subnet_group.supported_network_types[0] #=> String
    #   resp.data.db_instance.preferred_maintenance_window #=> String
    #   resp.data.db_instance.pending_modified_values #=> Types::PendingModifiedValues
    #   resp.data.db_instance.pending_modified_values.db_instance_class #=> String
    #   resp.data.db_instance.pending_modified_values.allocated_storage #=> Integer
    #   resp.data.db_instance.pending_modified_values.master_user_password #=> String
    #   resp.data.db_instance.pending_modified_values.port #=> Integer
    #   resp.data.db_instance.pending_modified_values.backup_retention_period #=> Integer
    #   resp.data.db_instance.pending_modified_values.multi_az #=> Boolean
    #   resp.data.db_instance.pending_modified_values.engine_version #=> String
    #   resp.data.db_instance.pending_modified_values.license_model #=> String
    #   resp.data.db_instance.pending_modified_values.iops #=> Integer
    #   resp.data.db_instance.pending_modified_values.db_instance_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.storage_type #=> String
    #   resp.data.db_instance.pending_modified_values.ca_certificate_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.db_subnet_group_name #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable[0] #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.pending_modified_values.processor_features[0] #=> Types::ProcessorFeature
    #   resp.data.db_instance.pending_modified_values.processor_features[0].name #=> String
    #   resp.data.db_instance.pending_modified_values.processor_features[0].value #=> String
    #   resp.data.db_instance.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.pending_modified_values.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.pending_modified_values.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.latest_restorable_time #=> Time
    #   resp.data.db_instance.multi_az #=> Boolean
    #   resp.data.db_instance.engine_version #=> String
    #   resp.data.db_instance.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_instance.read_replica_source_db_instance_identifier #=> String
    #   resp.data.db_instance.read_replica_db_instance_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_instance_identifiers[0] #=> String
    #   resp.data.db_instance.read_replica_db_cluster_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_cluster_identifiers[0] #=> String
    #   resp.data.db_instance.replica_mode #=> String, one of ["open-read-only", "mounted"]
    #   resp.data.db_instance.license_model #=> String
    #   resp.data.db_instance.iops #=> Integer
    #   resp.data.db_instance.option_group_memberships #=> Array<OptionGroupMembership>
    #   resp.data.db_instance.option_group_memberships[0] #=> Types::OptionGroupMembership
    #   resp.data.db_instance.option_group_memberships[0].option_group_name #=> String
    #   resp.data.db_instance.option_group_memberships[0].status #=> String
    #   resp.data.db_instance.character_set_name #=> String
    #   resp.data.db_instance.nchar_character_set_name #=> String
    #   resp.data.db_instance.secondary_availability_zone #=> String
    #   resp.data.db_instance.publicly_accessible #=> Boolean
    #   resp.data.db_instance.status_infos #=> Array<DBInstanceStatusInfo>
    #   resp.data.db_instance.status_infos[0] #=> Types::DBInstanceStatusInfo
    #   resp.data.db_instance.status_infos[0].status_type #=> String
    #   resp.data.db_instance.status_infos[0].normal #=> Boolean
    #   resp.data.db_instance.status_infos[0].status #=> String
    #   resp.data.db_instance.status_infos[0].message #=> String
    #   resp.data.db_instance.storage_type #=> String
    #   resp.data.db_instance.tde_credential_arn #=> String
    #   resp.data.db_instance.db_instance_port #=> Integer
    #   resp.data.db_instance.db_cluster_identifier #=> String
    #   resp.data.db_instance.storage_encrypted #=> Boolean
    #   resp.data.db_instance.kms_key_id #=> String
    #   resp.data.db_instance.dbi_resource_id #=> String
    #   resp.data.db_instance.ca_certificate_identifier #=> String
    #   resp.data.db_instance.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_instance.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_instance.domain_memberships[0].domain #=> String
    #   resp.data.db_instance.domain_memberships[0].status #=> String
    #   resp.data.db_instance.domain_memberships[0].fqdn #=> String
    #   resp.data.db_instance.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_instance.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_instance.monitoring_interval #=> Integer
    #   resp.data.db_instance.enhanced_monitoring_resource_arn #=> String
    #   resp.data.db_instance.monitoring_role_arn #=> String
    #   resp.data.db_instance.promotion_tier #=> Integer
    #   resp.data.db_instance.db_instance_arn #=> String
    #   resp.data.db_instance.timezone #=> String
    #   resp.data.db_instance.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_kms_key_id #=> String
    #   resp.data.db_instance.performance_insights_retention_period #=> Integer
    #   resp.data.db_instance.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_instance.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.deletion_protection #=> Boolean
    #   resp.data.db_instance.associated_roles #=> Array<DBInstanceRole>
    #   resp.data.db_instance.associated_roles[0] #=> Types::DBInstanceRole
    #   resp.data.db_instance.associated_roles[0].role_arn #=> String
    #   resp.data.db_instance.associated_roles[0].feature_name #=> String
    #   resp.data.db_instance.associated_roles[0].status #=> String
    #   resp.data.db_instance.listener_endpoint #=> Types::Endpoint
    #   resp.data.db_instance.max_allocated_storage #=> Integer
    #   resp.data.db_instance.tag_list #=> Array<Tag>
    #   resp.data.db_instance.tag_list[0] #=> Types::Tag
    #   resp.data.db_instance.tag_list[0].key #=> String
    #   resp.data.db_instance.tag_list[0].value #=> String
    #   resp.data.db_instance.db_instance_automated_backups_replications #=> Array<DBInstanceAutomatedBackupsReplication>
    #   resp.data.db_instance.db_instance_automated_backups_replications[0] #=> Types::DBInstanceAutomatedBackupsReplication
    #   resp.data.db_instance.db_instance_automated_backups_replications[0].db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance.customer_owned_ip_enabled #=> Boolean
    #   resp.data.db_instance.aws_backup_recovery_point_arn #=> String
    #   resp.data.db_instance.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_instance.activity_stream_kms_key_id #=> String
    #   resp.data.db_instance.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_instance.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_instance.activity_stream_engine_native_audit_fields_included #=> Boolean
    #   resp.data.db_instance.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.custom_iam_instance_profile #=> String
    #   resp.data.db_instance.backup_target #=> String
    #   resp.data.db_instance.network_type #=> String
    #
    def reboot_db_instance(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::RebootDBInstanceInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::RebootDBInstanceInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::RebootDBInstance
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBInstanceNotFoundFault, Errors::InvalidDBInstanceStateFault]),
        data_parser: Parsers::RebootDBInstance
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::RebootDBInstance,
        stubs: @stubs,
        params_class: Params::RebootDBInstanceOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :reboot_db_instance
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Associate one or more <code>DBProxyTarget</code> data structures with a <code>DBProxyTargetGroup</code>.</p>
    #
    # @param [Hash] params
    #   See {Types::RegisterDBProxyTargetsInput}.
    #
    # @option params [String] :db_proxy_name
    #   <p>The identifier of the <code>DBProxy</code> that is associated with the <code>DBProxyTargetGroup</code>.</p>
    #
    # @option params [String] :target_group_name
    #   <p>The identifier of the <code>DBProxyTargetGroup</code>.</p>
    #
    # @option params [Array<String>] :db_instance_identifiers
    #   <p>One or more DB instance identifiers.</p>
    #
    # @option params [Array<String>] :db_cluster_identifiers
    #   <p>One or more DB cluster identifiers.</p>
    #
    # @return [Types::RegisterDBProxyTargetsOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.register_db_proxy_targets(
    #     db_proxy_name: 'DBProxyName', # required
    #     target_group_name: 'TargetGroupName',
    #     db_instance_identifiers: [
    #       'member'
    #     ],
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::RegisterDBProxyTargetsOutput
    #   resp.data.db_proxy_targets #=> Array<DBProxyTarget>
    #   resp.data.db_proxy_targets[0] #=> Types::DBProxyTarget
    #   resp.data.db_proxy_targets[0].target_arn #=> String
    #   resp.data.db_proxy_targets[0].endpoint #=> String
    #   resp.data.db_proxy_targets[0].tracked_cluster_id #=> String
    #   resp.data.db_proxy_targets[0].rds_resource_id #=> String
    #   resp.data.db_proxy_targets[0].port #=> Integer
    #   resp.data.db_proxy_targets[0].type #=> String, one of ["RDS_INSTANCE", "RDS_SERVERLESS_ENDPOINT", "TRACKED_CLUSTER"]
    #   resp.data.db_proxy_targets[0].role #=> String, one of ["READ_WRITE", "READ_ONLY", "UNKNOWN"]
    #   resp.data.db_proxy_targets[0].target_health #=> Types::TargetHealth
    #   resp.data.db_proxy_targets[0].target_health.state #=> String, one of ["REGISTERING", "AVAILABLE", "UNAVAILABLE"]
    #   resp.data.db_proxy_targets[0].target_health.reason #=> String, one of ["UNREACHABLE", "CONNECTION_FAILED", "AUTH_FAILURE", "PENDING_PROXY_CAPACITY", "INVALID_REPLICATION_STATE"]
    #   resp.data.db_proxy_targets[0].target_health.description #=> String
    #
    def register_db_proxy_targets(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::RegisterDBProxyTargetsInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::RegisterDBProxyTargetsInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::RegisterDBProxyTargets
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::DBInstanceNotFoundFault, Errors::DBProxyTargetGroupNotFoundFault, Errors::DBProxyNotFoundFault, Errors::InvalidDBClusterStateFault, Errors::InsufficientAvailableIPsInSubnetFault, Errors::DBProxyTargetAlreadyRegisteredFault, Errors::InvalidDBInstanceStateFault, Errors::InvalidDBProxyStateFault]),
        data_parser: Parsers::RegisterDBProxyTargets
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::RegisterDBProxyTargets,
        stubs: @stubs,
        params_class: Params::RegisterDBProxyTargetsOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :register_db_proxy_targets
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Detaches an Aurora secondary cluster from an Aurora global database cluster. The cluster becomes a
    #         standalone cluster with read-write capability instead of being read-only and receiving data from a
    #         primary cluster in a different Region.</p>
    #         <note>
    #             <p>This action only applies to Aurora DB clusters.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::RemoveFromGlobalClusterInput}.
    #
    # @option params [String] :global_cluster_identifier
    #   <p>The cluster identifier to detach from the Aurora global database cluster.</p>
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The Amazon Resource Name (ARN) identifying the cluster that was detached from the Aurora global database cluster.</p>
    #
    # @return [Types::RemoveFromGlobalClusterOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.remove_from_global_cluster(
    #     global_cluster_identifier: 'GlobalClusterIdentifier',
    #     db_cluster_identifier: 'DbClusterIdentifier'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::RemoveFromGlobalClusterOutput
    #   resp.data.global_cluster #=> Types::GlobalCluster
    #   resp.data.global_cluster.global_cluster_identifier #=> String
    #   resp.data.global_cluster.global_cluster_resource_id #=> String
    #   resp.data.global_cluster.global_cluster_arn #=> String
    #   resp.data.global_cluster.status #=> String
    #   resp.data.global_cluster.engine #=> String
    #   resp.data.global_cluster.engine_version #=> String
    #   resp.data.global_cluster.database_name #=> String
    #   resp.data.global_cluster.storage_encrypted #=> Boolean
    #   resp.data.global_cluster.deletion_protection #=> Boolean
    #   resp.data.global_cluster.global_cluster_members #=> Array<GlobalClusterMember>
    #   resp.data.global_cluster.global_cluster_members[0] #=> Types::GlobalClusterMember
    #   resp.data.global_cluster.global_cluster_members[0].db_cluster_arn #=> String
    #   resp.data.global_cluster.global_cluster_members[0].readers #=> Array<String>
    #   resp.data.global_cluster.global_cluster_members[0].readers[0] #=> String
    #   resp.data.global_cluster.global_cluster_members[0].is_writer #=> Boolean
    #   resp.data.global_cluster.global_cluster_members[0].global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.global_cluster.failover_state #=> Types::FailoverState
    #   resp.data.global_cluster.failover_state.status #=> String, one of ["pending", "failing-over", "cancelling"]
    #   resp.data.global_cluster.failover_state.from_db_cluster_arn #=> String
    #   resp.data.global_cluster.failover_state.to_db_cluster_arn #=> String
    #
    def remove_from_global_cluster(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::RemoveFromGlobalClusterInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::RemoveFromGlobalClusterInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::RemoveFromGlobalCluster
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::GlobalClusterNotFoundFault, Errors::InvalidGlobalClusterStateFault]),
        data_parser: Parsers::RemoveFromGlobalCluster
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::RemoveFromGlobalCluster,
        stubs: @stubs,
        params_class: Params::RemoveFromGlobalClusterOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :remove_from_global_cluster
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Removes the asssociation of an Amazon Web Services Identity and Access Management (IAM) role from a
    #             DB cluster.</p>
    #         <p>For more information on Amazon Aurora DB clusters, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #                 What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #                 Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide.</i>
    #          </p>
    #
    # @param [Hash] params
    #   See {Types::RemoveRoleFromDBClusterInput}.
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The name of the DB cluster to disassociate the IAM role from.</p>
    #
    # @option params [String] :role_arn
    #   <p>The Amazon Resource Name (ARN) of the IAM role to disassociate from the Aurora DB cluster, for example
    #           <code>arn:aws:iam::123456789012:role/AuroraAccessRole</code>.</p>
    #
    # @option params [String] :feature_name
    #   <p>The name of the feature for the DB cluster that the IAM role is to be disassociated from.
    #               For information about supported feature names, see <a>DBEngineVersion</a>.</p>
    #
    # @return [Types::RemoveRoleFromDBClusterOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.remove_role_from_db_cluster(
    #     db_cluster_identifier: 'DBClusterIdentifier', # required
    #     role_arn: 'RoleArn', # required
    #     feature_name: 'FeatureName'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::RemoveRoleFromDBClusterOutput
    #
    def remove_role_from_db_cluster(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::RemoveRoleFromDBClusterInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::RemoveRoleFromDBClusterInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::RemoveRoleFromDBCluster
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::DBClusterRoleNotFoundFault, Errors::InvalidDBClusterStateFault]),
        data_parser: Parsers::RemoveRoleFromDBCluster
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::RemoveRoleFromDBCluster,
        stubs: @stubs,
        params_class: Params::RemoveRoleFromDBClusterOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :remove_role_from_db_cluster
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Disassociates an Amazon Web Services Identity and Access Management (IAM) role from a DB instance.</p>
    #
    # @param [Hash] params
    #   See {Types::RemoveRoleFromDBInstanceInput}.
    #
    # @option params [String] :db_instance_identifier
    #   <p>The name of the DB instance to disassociate the IAM role from.</p>
    #
    # @option params [String] :role_arn
    #   <p>The Amazon Resource Name (ARN) of the IAM role to disassociate from the DB instance,
    #               for example, <code>arn:aws:iam::123456789012:role/AccessRole</code>.</p>
    #
    # @option params [String] :feature_name
    #   <p>The name of the feature for the DB instance that the IAM role is to be disassociated from.
    #               For information about supported feature names, see <code>DBEngineVersion</code>.</p>
    #
    # @return [Types::RemoveRoleFromDBInstanceOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.remove_role_from_db_instance(
    #     db_instance_identifier: 'DBInstanceIdentifier', # required
    #     role_arn: 'RoleArn', # required
    #     feature_name: 'FeatureName' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::RemoveRoleFromDBInstanceOutput
    #
    def remove_role_from_db_instance(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::RemoveRoleFromDBInstanceInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::RemoveRoleFromDBInstanceInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::RemoveRoleFromDBInstance
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBInstanceRoleNotFoundFault, Errors::DBInstanceNotFoundFault, Errors::InvalidDBInstanceStateFault]),
        data_parser: Parsers::RemoveRoleFromDBInstance
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::RemoveRoleFromDBInstance,
        stubs: @stubs,
        params_class: Params::RemoveRoleFromDBInstanceOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :remove_role_from_db_instance
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Removes a source identifier from an existing RDS event notification subscription.</p>
    #
    # @param [Hash] params
    #   See {Types::RemoveSourceIdentifierFromSubscriptionInput}.
    #
    # @option params [String] :subscription_name
    #   <p>The name of the RDS event notification subscription you want to remove a source identifier from.</p>
    #
    # @option params [String] :source_identifier
    #   <p>The source identifier to be removed from the subscription, such as the <b>DB instance identifier</b>
    #               for a DB instance or the name of a security group.</p>
    #
    # @return [Types::RemoveSourceIdentifierFromSubscriptionOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.remove_source_identifier_from_subscription(
    #     subscription_name: 'SubscriptionName', # required
    #     source_identifier: 'SourceIdentifier' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::RemoveSourceIdentifierFromSubscriptionOutput
    #   resp.data.event_subscription #=> Types::EventSubscription
    #   resp.data.event_subscription.customer_aws_id #=> String
    #   resp.data.event_subscription.cust_subscription_id #=> String
    #   resp.data.event_subscription.sns_topic_arn #=> String
    #   resp.data.event_subscription.status #=> String
    #   resp.data.event_subscription.subscription_creation_time #=> String
    #   resp.data.event_subscription.source_type #=> String
    #   resp.data.event_subscription.source_ids_list #=> Array<String>
    #   resp.data.event_subscription.source_ids_list[0] #=> String
    #   resp.data.event_subscription.event_categories_list #=> Array<String>
    #   resp.data.event_subscription.event_categories_list[0] #=> String
    #   resp.data.event_subscription.enabled #=> Boolean
    #   resp.data.event_subscription.event_subscription_arn #=> String
    #
    def remove_source_identifier_from_subscription(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::RemoveSourceIdentifierFromSubscriptionInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::RemoveSourceIdentifierFromSubscriptionInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::RemoveSourceIdentifierFromSubscription
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::SubscriptionNotFoundFault, Errors::SourceNotFoundFault]),
        data_parser: Parsers::RemoveSourceIdentifierFromSubscription
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::RemoveSourceIdentifierFromSubscription,
        stubs: @stubs,
        params_class: Params::RemoveSourceIdentifierFromSubscriptionOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :remove_source_identifier_from_subscription
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Removes metadata tags from an Amazon RDS resource.</p>
    #         <p>For an overview on tagging an Amazon RDS resource,
    #           see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Tagging.html">Tagging Amazon RDS Resources</a>
    #           in the <i>Amazon RDS User Guide.</i>
    #          </p>
    #
    # @param [Hash] params
    #   See {Types::RemoveTagsFromResourceInput}.
    #
    # @option params [String] :resource_name
    #   <p>The Amazon RDS resource that the tags are removed from. This value is an Amazon Resource Name (ARN). For information about
    #               creating an ARN,
    #               see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.ARN.html#USER_Tagging.ARN.Constructing">
    #                   Constructing an ARN for Amazon RDS</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @option params [Array<String>] :tag_keys
    #   <p>The tag key (name) of the tag to be removed.</p>
    #
    # @return [Types::RemoveTagsFromResourceOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.remove_tags_from_resource(
    #     resource_name: 'ResourceName', # required
    #     tag_keys: [
    #       'member'
    #     ] # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::RemoveTagsFromResourceOutput
    #
    def remove_tags_from_resource(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::RemoveTagsFromResourceInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::RemoveTagsFromResourceInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::RemoveTagsFromResource
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::DBInstanceNotFoundFault, Errors::DBProxyTargetGroupNotFoundFault, Errors::DBProxyNotFoundFault, Errors::DBSnapshotNotFoundFault]),
        data_parser: Parsers::RemoveTagsFromResource
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::RemoveTagsFromResource,
        stubs: @stubs,
        params_class: Params::RemoveTagsFromResourceOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :remove_tags_from_resource
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Modifies the parameters of a DB cluster parameter group to the default value. To
    #             reset specific parameters submit a list of the following: <code>ParameterName</code>
    #             and <code>ApplyMethod</code>. To reset the
    #             entire DB cluster parameter group, specify the <code>DBClusterParameterGroupName</code>
    #             and <code>ResetAllParameters</code> parameters.</p>
    #         <p>When resetting the entire group, dynamic parameters are updated immediately and static parameters
    #             are set to <code>pending-reboot</code> to take effect on the next DB instance restart
    #             or <code>RebootDBInstance</code> request. You must call <code>RebootDBInstance</code> for every
    #             DB instance in your DB cluster that you want the updated static parameter to apply to.</p>
    #         <p>For more information on Amazon Aurora DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #               What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #               Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide.</i>
    #          </p>
    #
    # @param [Hash] params
    #   See {Types::ResetDBClusterParameterGroupInput}.
    #
    # @option params [String] :db_cluster_parameter_group_name
    #   <p>The name of the DB cluster parameter group to reset.</p>
    #
    # @option params [Boolean] :reset_all_parameters
    #   <p>A value that indicates whether to reset all parameters in the DB cluster parameter group
    #           to their default values. You can't use this parameter if there
    #           is a list of parameter names specified for the <code>Parameters</code> parameter.</p>
    #
    # @option params [Array<Parameter>] :parameters
    #   <p>A list of parameter names in the DB cluster parameter group to reset to the default values. You can't use this
    #           parameter if the <code>ResetAllParameters</code> parameter is enabled.</p>
    #
    # @return [Types::ResetDBClusterParameterGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.reset_db_cluster_parameter_group(
    #     db_cluster_parameter_group_name: 'DBClusterParameterGroupName', # required
    #     reset_all_parameters: false,
    #     parameters: [
    #       {
    #         parameter_name: 'ParameterName',
    #         parameter_value: 'ParameterValue',
    #         description: 'Description',
    #         source: 'Source',
    #         apply_type: 'ApplyType',
    #         data_type: 'DataType',
    #         allowed_values: 'AllowedValues',
    #         is_modifiable: false,
    #         minimum_engine_version: 'MinimumEngineVersion',
    #         apply_method: 'immediate', # accepts ["immediate", "pending-reboot"]
    #         supported_engine_modes: [
    #           'member'
    #         ]
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ResetDBClusterParameterGroupOutput
    #   resp.data.db_cluster_parameter_group_name #=> String
    #
    def reset_db_cluster_parameter_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ResetDBClusterParameterGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ResetDBClusterParameterGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ResetDBClusterParameterGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidDBParameterGroupStateFault, Errors::DBParameterGroupNotFoundFault]),
        data_parser: Parsers::ResetDBClusterParameterGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ResetDBClusterParameterGroup,
        stubs: @stubs,
        params_class: Params::ResetDBClusterParameterGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :reset_db_cluster_parameter_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Modifies the parameters of a DB parameter group to the engine/system default value.
    #             To reset specific parameters, provide a list of the following:
    #                 <code>ParameterName</code> and <code>ApplyMethod</code>. To reset the entire DB
    #             parameter group, specify the <code>DBParameterGroup</code> name and
    #                 <code>ResetAllParameters</code> parameters. When resetting the entire group, dynamic
    #             parameters are updated immediately and static parameters are set to
    #                 <code>pending-reboot</code> to take effect on the next DB instance restart or
    #                 <code>RebootDBInstance</code> request.</p>
    #
    # @param [Hash] params
    #   See {Types::ResetDBParameterGroupInput}.
    #
    # @option params [String] :db_parameter_group_name
    #   <p>The name of the DB parameter group.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the name of an existing <code>DBParameterGroup</code>.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Boolean] :reset_all_parameters
    #   <p>A value that indicates whether to reset all parameters in the DB parameter group to default values.
    #             By default, all parameters in the DB parameter group are reset to default values.</p>
    #
    # @option params [Array<Parameter>] :parameters
    #   <p>To reset the entire DB parameter group, specify the <code>DBParameterGroup</code>
    #               name and <code>ResetAllParameters</code> parameters. To reset specific parameters,
    #               provide a list of the following: <code>ParameterName</code> and
    #               <code>ApplyMethod</code>. A maximum of 20 parameters can be modified in a single
    #               request.</p>
    #           <p>
    #               <b>MySQL</b>
    #            </p>
    #           <p>Valid Values (for Apply method): <code>immediate</code> | <code>pending-reboot</code>
    #            </p>
    #           <p>You can use the immediate value with dynamic parameters only. You can use
    #               the <code>pending-reboot</code> value for both dynamic and static parameters, and changes
    #               are applied when DB instance reboots.</p>
    #           <p>
    #               <b>MariaDB</b>
    #            </p>
    #           <p>Valid Values (for Apply method): <code>immediate</code> | <code>pending-reboot</code>
    #            </p>
    #           <p>You can use the immediate value with dynamic parameters only. You can use
    #         the <code>pending-reboot</code> value for both dynamic and static parameters, and changes
    #         are applied when DB instance reboots.</p>
    #           <p>
    #               <b>Oracle</b>
    #            </p>
    #           <p>Valid Values (for Apply method): <code>pending-reboot</code>
    #            </p>
    #
    # @return [Types::ResetDBParameterGroupOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.reset_db_parameter_group(
    #     db_parameter_group_name: 'DBParameterGroupName', # required
    #     reset_all_parameters: false,
    #     parameters: [
    #       {
    #         parameter_name: 'ParameterName',
    #         parameter_value: 'ParameterValue',
    #         description: 'Description',
    #         source: 'Source',
    #         apply_type: 'ApplyType',
    #         data_type: 'DataType',
    #         allowed_values: 'AllowedValues',
    #         is_modifiable: false,
    #         minimum_engine_version: 'MinimumEngineVersion',
    #         apply_method: 'immediate', # accepts ["immediate", "pending-reboot"]
    #         supported_engine_modes: [
    #           'member'
    #         ]
    #       }
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::ResetDBParameterGroupOutput
    #   resp.data.db_parameter_group_name #=> String
    #
    def reset_db_parameter_group(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::ResetDBParameterGroupInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::ResetDBParameterGroupInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::ResetDBParameterGroup
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidDBParameterGroupStateFault, Errors::DBParameterGroupNotFoundFault]),
        data_parser: Parsers::ResetDBParameterGroup
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::ResetDBParameterGroup,
        stubs: @stubs,
        params_class: Params::ResetDBParameterGroupOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :reset_db_parameter_group
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates an Amazon Aurora DB cluster from MySQL data stored in an Amazon S3 bucket.
    #             Amazon RDS must be authorized to access the Amazon S3 bucket and the data must be
    #             created using the Percona XtraBackup utility as described in <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Migrating.ExtMySQL.html#AuroraMySQL.Migrating.ExtMySQL.S3"> Migrating Data from MySQL by Using an Amazon S3 Bucket</a> in the
    #                 <i>Amazon Aurora User Guide</i>.</p>
    #         <note>
    #             <p>This action only restores the DB cluster, not the DB instances for that DB
    #                   cluster. You must invoke the <code>CreateDBInstance</code> action to create DB
    #                   instances for the restored DB cluster, specifying the identifier of the restored DB
    #                   cluster in <code>DBClusterIdentifier</code>. You can create DB instances only after
    #                   the <code>RestoreDBClusterFromS3</code> action has completed and the DB
    #                   cluster is available.</p>
    #         </note>
    #         <p>For more information on Amazon Aurora, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #                 What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <note>
    #             <p>This action only applies to Aurora DB clusters. The source DB engine must be
    #                 MySQL.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::RestoreDBClusterFromS3Input}.
    #
    # @option params [Array<String>] :availability_zones
    #   <p>A list of Availability Zones (AZs) where instances in the restored DB cluster can be created.</p>
    #
    # @option params [Integer] :backup_retention_period
    #   <p>The number of days for which automated backups of the restored DB cluster are retained. You must specify a minimum value of 1.</p>
    #           <p>Default: 1</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be a value from 1 to 35</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :character_set_name
    #   <p>A value that indicates that the restored DB cluster should be associated with the specified CharacterSet.</p>
    #
    # @option params [String] :database_name
    #   <p>The database name for the restored DB cluster.</p>
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The name of the DB cluster to create from the source data in the Amazon S3 bucket. This parameter isn't case-sensitive.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain from 1 to 63 letters, numbers, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens.</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-cluster1</code>
    #            </p>
    #
    # @option params [String] :db_cluster_parameter_group_name
    #   <p>The name of the DB cluster parameter group to associate
    #               with the restored DB cluster. If this argument is omitted, <code>default.aurora5.6</code> is used.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match the name of an existing DBClusterParameterGroup.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Array<String>] :vpc_security_group_ids
    #   <p>A list of EC2 VPC security groups to associate with the restored DB cluster.</p>
    #
    # @option params [String] :db_subnet_group_name
    #   <p>A DB subnet group to associate with the restored DB cluster.</p>
    #           <p>Constraints: If supplied, must match the name of an existing DBSubnetGroup.</p>
    #           <p>Example: <code>mydbsubnetgroup</code>
    #            </p>
    #
    # @option params [String] :engine
    #   <p>The name of the database engine to be used for this DB cluster.</p>
    #           <p>Valid Values: <code>aurora</code> (for MySQL 5.6-compatible Aurora), <code>aurora-mysql</code> (for MySQL 5.7-compatible and MySQL 8.0-compatible Aurora), and <code>aurora-postgresql</code>
    #            </p>
    #
    # @option params [String] :engine_version
    #   <p>The version number of the database engine to use.</p>
    #           <p>To list all of the available engine versions for <code>aurora</code> (for MySQL 5.6-compatible Aurora), use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine aurora --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>To list all of the available engine versions for <code>aurora-mysql</code> (for MySQL 5.7-compatible and MySQL 8.0-compatible Aurora), use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine aurora-mysql --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>To list all of the available engine versions for <code>aurora-postgresql</code>, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine aurora-postgresql --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>
    #               <b>Aurora MySQL</b>
    #            </p>
    #           <p>Example: <code>5.6.10a</code>, <code>5.6.mysql_aurora.1.19.2</code>, <code>5.7.12</code>, <code>5.7.mysql_aurora.2.04.5</code>, <code>8.0.mysql_aurora.3.01.0</code>
    #            </p>
    #           <p>
    #               <b>Aurora PostgreSQL</b>
    #            </p>
    #           <p>Example: <code>9.6.3</code>, <code>10.7</code>
    #            </p>
    #
    # @option params [Integer] :port
    #   <p>The port number on which the instances in the restored DB cluster accept connections.</p>
    #           <p>Default: <code>3306</code>
    #            </p>
    #
    # @option params [String] :master_username
    #   <p>The name of the master user for the restored DB cluster.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be 1 to 16 letters or numbers.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't be a reserved word for the chosen database engine.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :master_user_password
    #   <p>The password for the master database user. This password can contain any printable ASCII character except "/", """, or "@".</p>
    #           <p>Constraints: Must contain from 8 to 41 characters.</p>
    #
    # @option params [String] :option_group_name
    #   <p>A value that indicates that the restored DB cluster should be associated with the specified option group.</p>
    #           <p>Permanent options can't be removed from an option group. An option group can't be removed from a
    #               DB cluster once it is associated with a DB cluster.</p>
    #
    # @option params [String] :preferred_backup_window
    #   <p>The daily time range during which automated backups are created
    #               if automated backups are enabled
    #               using the <code>BackupRetentionPeriod</code> parameter.</p>
    #           <p>The default is a 30-minute window selected at random from an
    #               8-hour block of time for each Amazon Web Services Region.
    #               To view the time blocks available, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Managing.Backups.html#Aurora.Managing.Backups.BackupWindow">
    #                   Backup window</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be in the format <code>hh24:mi-hh24:mi</code>.</p>
    #               </li>
    #               <li>
    #                   <p>Must be in Universal Coordinated Time (UTC).</p>
    #               </li>
    #               <li>
    #                   <p>Must not conflict with the preferred maintenance window.</p>
    #               </li>
    #               <li>
    #                   <p>Must be at least 30 minutes.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :preferred_maintenance_window
    #   <p>The weekly time range during which system maintenance can occur, in Universal Coordinated Time (UTC).</p>
    #           <p>Format: <code>ddd:hh24:mi-ddd:hh24:mi</code>
    #            </p>
    #           <p>The default is a 30-minute window selected at random from an
    #               8-hour block of time for each Amazon Web Services Region, occurring on a random day of the
    #               week. To see the time blocks available, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_UpgradeDBInstance.Maintenance.html#AdjustingTheMaintenanceWindow.Aurora">
    #                   Adjusting the Preferred Maintenance Window</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Valid Days: Mon, Tue, Wed, Thu, Fri, Sat, Sun.</p>
    #           <p>Constraints: Minimum 30-minute window.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>A list of tags.
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.html">Tagging Amazon RDS Resources</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @option params [Boolean] :storage_encrypted
    #   <p>A value that indicates whether the restored DB cluster is encrypted.</p>
    #
    # @option params [String] :kms_key_id
    #   <p>The Amazon Web Services KMS key identifier for an encrypted DB cluster.</p>
    #           <p>The Amazon Web Services KMS key identifier is the key ARN, key ID, alias ARN, or alias name for the KMS key.
    #               To use a KMS key in a different Amazon Web Services account, specify the key ARN or alias ARN.</p>
    #           <p>If the StorageEncrypted parameter is enabled, and you do
    #               not specify a value for the <code>KmsKeyId</code> parameter, then
    #               Amazon RDS will use your default KMS key. There is a
    #               default KMS key for your Amazon Web Services account. Your Amazon Web Services account has a different
    #               default KMS key for each Amazon Web Services Region.</p>
    #
    # @option params [Boolean] :enable_iam_database_authentication
    #   <p>A value that indicates whether to enable mapping of Amazon Web Services Identity and Access
    #               Management (IAM) accounts to database accounts. By default, mapping isn't
    #               enabled.</p>
    #           <p>For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/UsingWithRDS.IAMDBAuth.html">
    #                   IAM Database Authentication</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #
    # @option params [String] :source_engine
    #   <p>The identifier for the database engine that was backed up to create the files stored in the
    #               Amazon S3 bucket.</p>
    #           <p>Valid values: <code>mysql</code>
    #            </p>
    #
    # @option params [String] :source_engine_version
    #   <p>The version of the database that the backup files were created from.</p>
    #           <p>MySQL versions 5.5, 5.6, and 5.7 are supported.</p>
    #           <p>Example: <code>5.6.40</code>, <code>5.7.28</code>
    #            </p>
    #
    # @option params [String] :s3_bucket_name
    #   <p>The name of the Amazon S3 bucket that contains the data used to create the Amazon Aurora DB cluster.</p>
    #
    # @option params [String] :s3_prefix
    #   <p>The prefix for all of the file names that contain the data used to create the Amazon Aurora DB cluster.
    #           If you do not specify a <b>SourceS3Prefix</b> value, then the Amazon Aurora DB cluster is
    #           created by using all of the files in the Amazon S3 bucket.</p>
    #
    # @option params [String] :s3_ingestion_role_arn
    #   <p>The Amazon Resource Name (ARN) of the Amazon Web Services Identity and Access Management (IAM) role that authorizes
    #           Amazon RDS to access the Amazon S3 bucket on your behalf.</p>
    #
    # @option params [Integer] :backtrack_window
    #   <p>The target backtrack window, in seconds. To disable backtracking, set this value to
    #               0.</p>
    #           <note>
    #               <p>Currently, Backtrack is only supported for Aurora MySQL DB clusters.</p>
    #           </note>
    #           <p>Default: 0</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If specified, this value must be set to a number from 0 to 259,200 (72 hours).</p>
    #               </li>
    #            </ul>
    #
    # @option params [Array<String>] :enable_cloudwatch_logs_exports
    #   <p>The list of logs that the restored DB cluster is to export to CloudWatch Logs. The values
    #               in the list depend on the DB engine being used.</p>
    #           <p>
    #               <b>Aurora MySQL</b>
    #            </p>
    #           <p>Possible values are <code>audit</code>, <code>error</code>, <code>general</code>, and <code>slowquery</code>.</p>
    #           <p>
    #               <b>Aurora PostgreSQL</b>
    #            </p>
    #           <p>Possible value is <code>postgresql</code>.</p>
    #           <p>For more information about exporting CloudWatch Logs for Amazon Aurora, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_LogAccess.html#USER_LogAccess.Procedural.UploadtoCloudWatch">Publishing Database Logs to Amazon CloudWatch Logs</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #
    # @option params [Boolean] :deletion_protection
    #   <p>A value that indicates whether the DB cluster has deletion protection enabled.
    #               The database can't be deleted when deletion protection is enabled. By default,
    #               deletion protection isn't enabled.</p>
    #
    # @option params [Boolean] :copy_tags_to_snapshot
    #   <p>A value that indicates whether to copy all tags from the restored DB cluster to snapshots of the restored DB cluster. The default is not to copy them.</p>
    #
    # @option params [String] :domain
    #   <p>Specify the Active Directory directory ID to restore the DB cluster in.
    #             The domain must be created prior to this operation.</p>
    #           <p>For Amazon Aurora DB clusters, Amazon RDS can use Kerberos Authentication to authenticate users that connect to the DB cluster.
    #           For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/kerberos-authentication.html">Kerberos Authentication</a>
    #           in the <i>Amazon Aurora User Guide</i>.</p>
    #
    # @option params [String] :domain_iam_role_name
    #   <p>Specify the name of the IAM role to be used when making API calls to the Directory Service.</p>
    #
    # @option params [ServerlessV2ScalingConfiguration] :serverless_v2_scaling_configuration
    #   <p>Contains the scaling configuration of an Aurora Serverless v2 DB cluster.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v2.html">Using Amazon Aurora Serverless v2</a> in the
    #               <i>Amazon Aurora User Guide</i>.</p>
    #
    # @return [Types::RestoreDBClusterFromS3Output]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.restore_db_cluster_from_s3(
    #     availability_zones: [
    #       'member'
    #     ],
    #     backup_retention_period: 1,
    #     character_set_name: 'CharacterSetName',
    #     database_name: 'DatabaseName',
    #     db_cluster_identifier: 'DBClusterIdentifier', # required
    #     db_cluster_parameter_group_name: 'DBClusterParameterGroupName',
    #     vpc_security_group_ids: [
    #       'member'
    #     ],
    #     db_subnet_group_name: 'DBSubnetGroupName',
    #     engine: 'Engine', # required
    #     engine_version: 'EngineVersion',
    #     port: 1,
    #     master_username: 'MasterUsername', # required
    #     master_user_password: 'MasterUserPassword', # required
    #     option_group_name: 'OptionGroupName',
    #     preferred_backup_window: 'PreferredBackupWindow',
    #     preferred_maintenance_window: 'PreferredMaintenanceWindow',
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ],
    #     storage_encrypted: false,
    #     kms_key_id: 'KmsKeyId',
    #     enable_iam_database_authentication: false,
    #     source_engine: 'SourceEngine', # required
    #     source_engine_version: 'SourceEngineVersion', # required
    #     s3_bucket_name: 'S3BucketName', # required
    #     s3_prefix: 'S3Prefix',
    #     s3_ingestion_role_arn: 'S3IngestionRoleArn', # required
    #     backtrack_window: 1,
    #     enable_cloudwatch_logs_exports: [
    #       'member'
    #     ],
    #     deletion_protection: false,
    #     copy_tags_to_snapshot: false,
    #     domain: 'Domain',
    #     domain_iam_role_name: 'DomainIAMRoleName',
    #     serverless_v2_scaling_configuration: {
    #       min_capacity: 1.0,
    #       max_capacity: 1.0
    #     }
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::RestoreDBClusterFromS3Output
    #   resp.data.db_cluster #=> Types::DBCluster
    #   resp.data.db_cluster.allocated_storage #=> Integer
    #   resp.data.db_cluster.availability_zones #=> Array<String>
    #   resp.data.db_cluster.availability_zones[0] #=> String
    #   resp.data.db_cluster.backup_retention_period #=> Integer
    #   resp.data.db_cluster.character_set_name #=> String
    #   resp.data.db_cluster.database_name #=> String
    #   resp.data.db_cluster.db_cluster_identifier #=> String
    #   resp.data.db_cluster.db_cluster_parameter_group #=> String
    #   resp.data.db_cluster.db_subnet_group #=> String
    #   resp.data.db_cluster.status #=> String
    #   resp.data.db_cluster.automatic_restart_time #=> Time
    #   resp.data.db_cluster.percent_progress #=> String
    #   resp.data.db_cluster.earliest_restorable_time #=> Time
    #   resp.data.db_cluster.endpoint #=> String
    #   resp.data.db_cluster.reader_endpoint #=> String
    #   resp.data.db_cluster.custom_endpoints #=> Array<String>
    #   resp.data.db_cluster.custom_endpoints[0] #=> String
    #   resp.data.db_cluster.multi_az #=> Boolean
    #   resp.data.db_cluster.engine #=> String
    #   resp.data.db_cluster.engine_version #=> String
    #   resp.data.db_cluster.latest_restorable_time #=> Time
    #   resp.data.db_cluster.port #=> Integer
    #   resp.data.db_cluster.master_username #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships #=> Array<DBClusterOptionGroupStatus>
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0] #=> Types::DBClusterOptionGroupStatus
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].db_cluster_option_group_name #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].status #=> String
    #   resp.data.db_cluster.preferred_backup_window #=> String
    #   resp.data.db_cluster.preferred_maintenance_window #=> String
    #   resp.data.db_cluster.replication_source_identifier #=> String
    #   resp.data.db_cluster.read_replica_identifiers #=> Array<String>
    #   resp.data.db_cluster.read_replica_identifiers[0] #=> String
    #   resp.data.db_cluster.db_cluster_members #=> Array<DBClusterMember>
    #   resp.data.db_cluster.db_cluster_members[0] #=> Types::DBClusterMember
    #   resp.data.db_cluster.db_cluster_members[0].db_instance_identifier #=> String
    #   resp.data.db_cluster.db_cluster_members[0].is_cluster_writer #=> Boolean
    #   resp.data.db_cluster.db_cluster_members[0].db_cluster_parameter_group_status #=> String
    #   resp.data.db_cluster.db_cluster_members[0].promotion_tier #=> Integer
    #   resp.data.db_cluster.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_cluster.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_cluster.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_cluster.vpc_security_groups[0].status #=> String
    #   resp.data.db_cluster.hosted_zone_id #=> String
    #   resp.data.db_cluster.storage_encrypted #=> Boolean
    #   resp.data.db_cluster.kms_key_id #=> String
    #   resp.data.db_cluster.db_cluster_resource_id #=> String
    #   resp.data.db_cluster.db_cluster_arn #=> String
    #   resp.data.db_cluster.associated_roles #=> Array<DBClusterRole>
    #   resp.data.db_cluster.associated_roles[0] #=> Types::DBClusterRole
    #   resp.data.db_cluster.associated_roles[0].role_arn #=> String
    #   resp.data.db_cluster.associated_roles[0].status #=> String
    #   resp.data.db_cluster.associated_roles[0].feature_name #=> String
    #   resp.data.db_cluster.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.clone_group_id #=> String
    #   resp.data.db_cluster.cluster_create_time #=> Time
    #   resp.data.db_cluster.earliest_backtrack_time #=> Time
    #   resp.data.db_cluster.backtrack_window #=> Integer
    #   resp.data.db_cluster.backtrack_consumed_change_records #=> Integer
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports[0] #=> String
    #   resp.data.db_cluster.capacity #=> Integer
    #   resp.data.db_cluster.engine_mode #=> String
    #   resp.data.db_cluster.scaling_configuration_info #=> Types::ScalingConfigurationInfo
    #   resp.data.db_cluster.scaling_configuration_info.min_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.max_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.auto_pause #=> Boolean
    #   resp.data.db_cluster.scaling_configuration_info.seconds_until_auto_pause #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.timeout_action #=> String
    #   resp.data.db_cluster.scaling_configuration_info.seconds_before_timeout #=> Integer
    #   resp.data.db_cluster.deletion_protection #=> Boolean
    #   resp.data.db_cluster.http_endpoint_enabled #=> Boolean
    #   resp.data.db_cluster.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_cluster.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_cluster.activity_stream_kms_key_id #=> String
    #   resp.data.db_cluster.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_cluster.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_cluster.cross_account_clone #=> Boolean
    #   resp.data.db_cluster.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_cluster.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_cluster.domain_memberships[0].domain #=> String
    #   resp.data.db_cluster.domain_memberships[0].status #=> String
    #   resp.data.db_cluster.domain_memberships[0].fqdn #=> String
    #   resp.data.db_cluster.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_cluster.tag_list #=> Array<Tag>
    #   resp.data.db_cluster.tag_list[0] #=> Types::Tag
    #   resp.data.db_cluster.tag_list[0].key #=> String
    #   resp.data.db_cluster.tag_list[0].value #=> String
    #   resp.data.db_cluster.global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.db_cluster.global_write_forwarding_requested #=> Boolean
    #   resp.data.db_cluster.pending_modified_values #=> Types::ClusterPendingModifiedValues
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.db_cluster_identifier #=> String
    #   resp.data.db_cluster.pending_modified_values.master_user_password #=> String
    #   resp.data.db_cluster.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.pending_modified_values.engine_version #=> String
    #   resp.data.db_cluster.db_cluster_instance_class #=> String
    #   resp.data.db_cluster.storage_type #=> String
    #   resp.data.db_cluster.iops #=> Integer
    #   resp.data.db_cluster.publicly_accessible #=> Boolean
    #   resp.data.db_cluster.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_cluster.monitoring_interval #=> Integer
    #   resp.data.db_cluster.monitoring_role_arn #=> String
    #   resp.data.db_cluster.performance_insights_enabled #=> Boolean
    #   resp.data.db_cluster.performance_insights_kms_key_id #=> String
    #   resp.data.db_cluster.performance_insights_retention_period #=> Integer
    #   resp.data.db_cluster.serverless_v2_scaling_configuration #=> Types::ServerlessV2ScalingConfigurationInfo
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.min_capacity #=> Float
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.max_capacity #=> Float
    #
    def restore_db_cluster_from_s3(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::RestoreDBClusterFromS3Input.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::RestoreDBClusterFromS3Input,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::RestoreDBClusterFromS3
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::InvalidDBSubnetGroupStateFault, Errors::InsufficientStorageClusterCapacityFault, Errors::DBSubnetGroupNotFoundFault, Errors::KMSKeyNotAccessibleFault, Errors::DBClusterParameterGroupNotFoundFault, Errors::InvalidVPCNetworkStateFault, Errors::StorageQuotaExceededFault, Errors::InvalidSubnet, Errors::DBClusterAlreadyExistsFault, Errors::DomainNotFoundFault, Errors::DBClusterQuotaExceededFault, Errors::InvalidDBClusterStateFault, Errors::InvalidS3BucketFault]),
        data_parser: Parsers::RestoreDBClusterFromS3
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::RestoreDBClusterFromS3,
        stubs: @stubs,
        params_class: Params::RestoreDBClusterFromS3Output
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :restore_db_cluster_from_s3
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates a new DB cluster from a DB snapshot or DB cluster snapshot.</p>
    #         <p>The target DB cluster is created from the source snapshot with a default
    #             configuration. If you don't specify a security group, the new DB cluster is
    #             associated with the default security group.</p>
    #         <note>
    #             <p>This action only restores the DB cluster, not the DB instances for that DB
    #                 cluster. You must invoke the <code>CreateDBInstance</code> action to create DB
    #                 instances for the restored DB cluster, specifying the identifier of the restored DB
    #                 cluster in <code>DBClusterIdentifier</code>. You can create DB instances only after
    #                 the <code>RestoreDBClusterFromSnapshot</code> action has completed and the DB
    #                 cluster is available.</p>
    #         </note>
    #         <p>For more information on Amazon Aurora DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #               What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #               Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide.</i>
    #          </p>
    #
    # @param [Hash] params
    #   See {Types::RestoreDBClusterFromSnapshotInput}.
    #
    # @option params [Array<String>] :availability_zones
    #   <p>Provides the list of Availability Zones (AZs) where instances in the restored DB
    #               cluster can be created.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The name of the DB cluster to create from the DB snapshot or DB cluster snapshot.
    #               This parameter isn't case-sensitive.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain from 1 to 63 letters, numbers, or hyphens</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-snapshot-id</code>
    #            </p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :snapshot_identifier
    #   <p>The identifier for the DB snapshot or DB cluster snapshot to restore from.</p>
    #           <p>You can use either the name or the Amazon Resource Name (ARN) to specify a DB
    #               cluster snapshot. However, you can use only the ARN to specify a DB snapshot.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the identifier of an existing Snapshot.</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :engine
    #   <p>The database engine to use for the new DB cluster.</p>
    #           <p>Default: The same as source</p>
    #           <p>Constraint: Must be compatible with the engine of the source</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :engine_version
    #   <p>The version of the database engine to use for the new DB cluster.</p>
    #           <p>To list all of the available engine versions for MySQL 5.6-compatible Aurora, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine aurora --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>To list all of the available engine versions for MySQL 5.7-compatible and MySQL 8.0-compatible Aurora, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine aurora-mysql --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>To list all of the available engine versions for Aurora PostgreSQL, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine aurora-postgresql --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>To list all of the available engine versions for RDS for MySQL, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine mysql --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>To list all of the available engine versions for RDS for PostgreSQL, use the following command:</p>
    #           <p>
    #               <code>aws rds describe-db-engine-versions --engine postgres --query "DBEngineVersions[].EngineVersion"</code>
    #            </p>
    #           <p>
    #               <b>Aurora MySQL</b>
    #            </p>
    #           <p>See <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Updates.html">MySQL on Amazon RDS Versions</a> in the
    #             <i>Amazon Aurora User Guide</i>.</p>
    #           <p>
    #               <b>Aurora PostgreSQL</b>
    #            </p>
    #           <p>See <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.Updates.20180305.html">Amazon Aurora PostgreSQL releases and engine versions</a> in the
    #             <i>Amazon Aurora User Guide</i>.</p>
    #           <p>
    #               <b>MySQL</b>
    #            </p>
    #           <p>See <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_MySQL.html#MySQL.Concepts.VersionMgmt">MySQL on Amazon RDS Versions</a> in the
    #             <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>
    #               <b>PostgreSQL</b>
    #            </p>
    #           <p>See <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_PostgreSQL.html#PostgreSQL.Concepts">Amazon RDS for PostgreSQL versions and extensions</a> in the
    #             <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Integer] :port
    #   <p>The port number on which the new DB cluster accepts connections.</p>
    #           <p>Constraints: This value must be <code>1150-65535</code>
    #            </p>
    #           <p>Default: The same port as the original DB cluster.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :db_subnet_group_name
    #   <p>The name of the DB subnet group to use for the new DB cluster.</p>
    #           <p>Constraints: If supplied, must match the name of an existing DB subnet group.</p>
    #           <p>Example: <code>mydbsubnetgroup</code>
    #            </p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :database_name
    #   <p>The database name for the restored DB cluster.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :option_group_name
    #   <p>The name of the option group to use for the restored DB cluster.</p>
    #           <p>DB clusters are associated with a default option group that can't be modified.</p>
    #
    # @option params [Array<String>] :vpc_security_group_ids
    #   <p>A list of VPC security groups that the new DB cluster will belong to.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>The tags to be assigned to the restored DB cluster.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :kms_key_id
    #   <p>The Amazon Web Services KMS key identifier to use when restoring an encrypted DB cluster from a DB
    #               snapshot or DB cluster snapshot.</p>
    #           <p>The Amazon Web Services KMS key identifier is the key ARN, key ID, alias ARN, or alias name for the KMS key.
    #             To use a KMS key in a different Amazon Web Services account, specify the key ARN or alias ARN.</p>
    #           <p>When you don't specify a value for the <code>KmsKeyId</code> parameter, then the
    #               following occurs:</p>
    #           <ul>
    #               <li>
    #                   <p>If the DB snapshot or DB cluster snapshot in
    #                       <code>SnapshotIdentifier</code> is encrypted, then the restored DB cluster
    #                       is encrypted using the KMS key that was used to encrypt the DB snapshot or DB
    #                       cluster snapshot.</p>
    #               </li>
    #               <li>
    #                   <p>If the DB snapshot or DB cluster snapshot in
    #                       <code>SnapshotIdentifier</code> isn't encrypted, then the restored DB cluster
    #                       isn't encrypted.</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Boolean] :enable_iam_database_authentication
    #   <p>A value that indicates whether to enable mapping of Amazon Web Services Identity and Access
    #               Management (IAM) accounts to database accounts. By default, mapping isn't
    #               enabled.</p>
    #           <p>For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/UsingWithRDS.IAMDBAuth.html">
    #                   IAM Database Authentication</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [Integer] :backtrack_window
    #   <p>The target backtrack window, in seconds. To disable backtracking, set this value to
    #               0.</p>
    #           <note>
    #               <p>Currently, Backtrack is only supported for Aurora MySQL DB clusters.</p>
    #           </note>
    #           <p>Default: 0</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If specified, this value must be set to a number from 0 to 259,200 (72 hours).</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [Array<String>] :enable_cloudwatch_logs_exports
    #   <p>The list of logs that the restored DB cluster is to export to Amazon CloudWatch Logs.
    #               The values in the list depend on the DB engine being used.</p>
    #           <p>
    #               <b>RDS for MySQL</b>
    #            </p>
    #           <p>Possible values are <code>error</code>, <code>general</code>, and <code>slowquery</code>.</p>
    #           <p>
    #               <b>RDS for PostgreSQL</b>
    #            </p>
    #           <p>Possible values are <code>postgresql</code> and <code>upgrade</code>.</p>
    #           <p>
    #               <b>Aurora MySQL</b>
    #            </p>
    #           <p>Possible values are <code>audit</code>, <code>error</code>, <code>general</code>, and <code>slowquery</code>.</p>
    #           <p>
    #               <b>Aurora PostgreSQL</b>
    #            </p>
    #           <p>Possible value is <code>postgresql</code>.</p>
    #           <p>For more information about exporting CloudWatch Logs for Amazon RDS, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.html#USER_LogAccess.Procedural.UploadtoCloudWatch">Publishing Database Logs to Amazon CloudWatch Logs</a> in the <i>Amazon RDS User Guide.</i>.</p>
    #           <p>For more information about exporting CloudWatch Logs for Amazon Aurora, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_LogAccess.html#USER_LogAccess.Procedural.UploadtoCloudWatch">Publishing Database Logs to Amazon CloudWatch Logs</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :engine_mode
    #   <p>The DB engine mode of the DB cluster, either <code>provisioned</code>, <code>serverless</code>,
    #               <code>parallelquery</code>, <code>global</code>, or <code>multimaster</code>.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_CreateDBCluster.html">
    #               CreateDBCluster</a>.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [ScalingConfiguration] :scaling_configuration
    #   <p>For DB clusters in <code>serverless</code> DB engine mode, the scaling properties of the DB cluster.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [String] :db_cluster_parameter_group_name
    #   <p>The name of the DB cluster parameter group to associate with this DB cluster. If this
    #               argument is omitted, the default DB cluster parameter group for the specified engine is
    #               used.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match the name of an existing default DB cluster parameter group.</p>
    #               </li>
    #               <li>
    #                   <p>Must be 1 to 255 letters, numbers, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens.</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Boolean] :deletion_protection
    #   <p>A value that indicates whether the DB cluster has deletion protection enabled.
    #               The database can't be deleted when deletion protection is enabled. By default,
    #               deletion protection isn't enabled.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Boolean] :copy_tags_to_snapshot
    #   <p>A value that indicates whether to copy all tags from the restored DB cluster to snapshots of the restored DB cluster. The default is not to copy them.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :domain
    #   <p>Specify the Active Directory directory ID to restore the DB cluster in.
    #              The domain must be created prior to this operation. Currently, only MySQL, Microsoft SQL
    #              Server, Oracle, and PostgreSQL DB instances can be created in an Active Directory Domain.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/kerberos-authentication.html">
    #               Kerberos Authentication</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [String] :domain_iam_role_name
    #   <p>Specify the name of the IAM role to be used when making API calls to the Directory Service.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [String] :db_cluster_instance_class
    #   <p>The compute and memory capacity of the each DB instance in the Multi-AZ DB cluster, for example db.m6g.xlarge.
    #               Not all DB instance classes are available in all Amazon Web Services Regions, or for all database engines.</p>
    #           <p>For the full list of DB instance classes, and availability for your engine, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html">DB Instance Class</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [String] :storage_type
    #   <p>Specifies the storage type to be associated with the each DB instance in the Multi-AZ DB cluster.</p>
    #           <p>Valid values: <code>io1</code>
    #            </p>
    #           <p>When specified, a value for the <code>Iops</code> parameter is required.</p>
    #           <p>Default: <code>io1</code>
    #            </p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Integer] :iops
    #   <p>The amount of Provisioned IOPS (input/output operations per second) to be initially allocated for
    #               each DB instance in the Multi-AZ DB cluster.</p>
    #           <p>For information about valid Iops values, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html#USER_PIOPS">Amazon RDS Provisioned IOPS Storage to Improve Performance</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>Constraints: Must be a multiple between .5 and 50 of the storage amount for the DB instance.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Boolean] :publicly_accessible
    #   <p>A value that indicates whether the DB cluster is publicly accessible.</p>
    #           <p>When the DB cluster is publicly accessible, its Domain Name System (DNS) endpoint resolves to the private IP address
    #               from within the DB cluster's virtual private cloud (VPC). It resolves to the public IP address from outside of the DB cluster's VPC.
    #               Access to the DB cluster is ultimately controlled by the security group it uses.
    #               That public access is not permitted if the security group assigned to the DB cluster doesn't permit it.</p>
    #           <p>When the DB cluster isn't publicly accessible, it is an internal DB cluster with a DNS name that resolves to a private IP address.</p>
    #           <p>Default: The default behavior varies depending on whether <code>DBSubnetGroupName</code> is specified.</p>
    #           <p>If <code>DBSubnetGroupName</code> isn't specified, and <code>PubliclyAccessible</code> isn't specified, the following applies:</p>
    #           <ul>
    #               <li>
    #                   <p>If the default VPC in the target Region doesnt have an internet gateway attached to it, the DB cluster is private.</p>
    #               </li>
    #               <li>
    #                   <p>If the default VPC in the target Region has an internet gateway attached to it, the DB cluster is public.</p>
    #               </li>
    #            </ul>
    #           <p>If <code>DBSubnetGroupName</code> is specified, and <code>PubliclyAccessible</code> isn't specified, the following applies:</p>
    #           <ul>
    #               <li>
    #                   <p>If the subnets are part of a VPC that doesnt have an internet gateway attached to it, the DB cluster is private.</p>
    #               </li>
    #               <li>
    #                   <p>If the subnets are part of a VPC that has an internet gateway attached to it, the DB cluster is public.</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [ServerlessV2ScalingConfiguration] :serverless_v2_scaling_configuration
    #   <p>Contains the scaling configuration of an Aurora Serverless v2 DB cluster.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v2.html">Using Amazon Aurora Serverless v2</a> in the
    #               <i>Amazon Aurora User Guide</i>.</p>
    #
    # @return [Types::RestoreDBClusterFromSnapshotOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.restore_db_cluster_from_snapshot(
    #     availability_zones: [
    #       'member'
    #     ],
    #     db_cluster_identifier: 'DBClusterIdentifier', # required
    #     snapshot_identifier: 'SnapshotIdentifier', # required
    #     engine: 'Engine', # required
    #     engine_version: 'EngineVersion',
    #     port: 1,
    #     db_subnet_group_name: 'DBSubnetGroupName',
    #     database_name: 'DatabaseName',
    #     option_group_name: 'OptionGroupName',
    #     vpc_security_group_ids: [
    #       'member'
    #     ],
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ],
    #     kms_key_id: 'KmsKeyId',
    #     enable_iam_database_authentication: false,
    #     backtrack_window: 1,
    #     enable_cloudwatch_logs_exports: [
    #       'member'
    #     ],
    #     engine_mode: 'EngineMode',
    #     scaling_configuration: {
    #       min_capacity: 1,
    #       max_capacity: 1,
    #       auto_pause: false,
    #       seconds_until_auto_pause: 1,
    #       timeout_action: 'TimeoutAction',
    #       seconds_before_timeout: 1
    #     },
    #     db_cluster_parameter_group_name: 'DBClusterParameterGroupName',
    #     deletion_protection: false,
    #     copy_tags_to_snapshot: false,
    #     domain: 'Domain',
    #     domain_iam_role_name: 'DomainIAMRoleName',
    #     db_cluster_instance_class: 'DBClusterInstanceClass',
    #     storage_type: 'StorageType',
    #     iops: 1,
    #     publicly_accessible: false,
    #     serverless_v2_scaling_configuration: {
    #       min_capacity: 1.0,
    #       max_capacity: 1.0
    #     }
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::RestoreDBClusterFromSnapshotOutput
    #   resp.data.db_cluster #=> Types::DBCluster
    #   resp.data.db_cluster.allocated_storage #=> Integer
    #   resp.data.db_cluster.availability_zones #=> Array<String>
    #   resp.data.db_cluster.availability_zones[0] #=> String
    #   resp.data.db_cluster.backup_retention_period #=> Integer
    #   resp.data.db_cluster.character_set_name #=> String
    #   resp.data.db_cluster.database_name #=> String
    #   resp.data.db_cluster.db_cluster_identifier #=> String
    #   resp.data.db_cluster.db_cluster_parameter_group #=> String
    #   resp.data.db_cluster.db_subnet_group #=> String
    #   resp.data.db_cluster.status #=> String
    #   resp.data.db_cluster.automatic_restart_time #=> Time
    #   resp.data.db_cluster.percent_progress #=> String
    #   resp.data.db_cluster.earliest_restorable_time #=> Time
    #   resp.data.db_cluster.endpoint #=> String
    #   resp.data.db_cluster.reader_endpoint #=> String
    #   resp.data.db_cluster.custom_endpoints #=> Array<String>
    #   resp.data.db_cluster.custom_endpoints[0] #=> String
    #   resp.data.db_cluster.multi_az #=> Boolean
    #   resp.data.db_cluster.engine #=> String
    #   resp.data.db_cluster.engine_version #=> String
    #   resp.data.db_cluster.latest_restorable_time #=> Time
    #   resp.data.db_cluster.port #=> Integer
    #   resp.data.db_cluster.master_username #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships #=> Array<DBClusterOptionGroupStatus>
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0] #=> Types::DBClusterOptionGroupStatus
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].db_cluster_option_group_name #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].status #=> String
    #   resp.data.db_cluster.preferred_backup_window #=> String
    #   resp.data.db_cluster.preferred_maintenance_window #=> String
    #   resp.data.db_cluster.replication_source_identifier #=> String
    #   resp.data.db_cluster.read_replica_identifiers #=> Array<String>
    #   resp.data.db_cluster.read_replica_identifiers[0] #=> String
    #   resp.data.db_cluster.db_cluster_members #=> Array<DBClusterMember>
    #   resp.data.db_cluster.db_cluster_members[0] #=> Types::DBClusterMember
    #   resp.data.db_cluster.db_cluster_members[0].db_instance_identifier #=> String
    #   resp.data.db_cluster.db_cluster_members[0].is_cluster_writer #=> Boolean
    #   resp.data.db_cluster.db_cluster_members[0].db_cluster_parameter_group_status #=> String
    #   resp.data.db_cluster.db_cluster_members[0].promotion_tier #=> Integer
    #   resp.data.db_cluster.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_cluster.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_cluster.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_cluster.vpc_security_groups[0].status #=> String
    #   resp.data.db_cluster.hosted_zone_id #=> String
    #   resp.data.db_cluster.storage_encrypted #=> Boolean
    #   resp.data.db_cluster.kms_key_id #=> String
    #   resp.data.db_cluster.db_cluster_resource_id #=> String
    #   resp.data.db_cluster.db_cluster_arn #=> String
    #   resp.data.db_cluster.associated_roles #=> Array<DBClusterRole>
    #   resp.data.db_cluster.associated_roles[0] #=> Types::DBClusterRole
    #   resp.data.db_cluster.associated_roles[0].role_arn #=> String
    #   resp.data.db_cluster.associated_roles[0].status #=> String
    #   resp.data.db_cluster.associated_roles[0].feature_name #=> String
    #   resp.data.db_cluster.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.clone_group_id #=> String
    #   resp.data.db_cluster.cluster_create_time #=> Time
    #   resp.data.db_cluster.earliest_backtrack_time #=> Time
    #   resp.data.db_cluster.backtrack_window #=> Integer
    #   resp.data.db_cluster.backtrack_consumed_change_records #=> Integer
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports[0] #=> String
    #   resp.data.db_cluster.capacity #=> Integer
    #   resp.data.db_cluster.engine_mode #=> String
    #   resp.data.db_cluster.scaling_configuration_info #=> Types::ScalingConfigurationInfo
    #   resp.data.db_cluster.scaling_configuration_info.min_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.max_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.auto_pause #=> Boolean
    #   resp.data.db_cluster.scaling_configuration_info.seconds_until_auto_pause #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.timeout_action #=> String
    #   resp.data.db_cluster.scaling_configuration_info.seconds_before_timeout #=> Integer
    #   resp.data.db_cluster.deletion_protection #=> Boolean
    #   resp.data.db_cluster.http_endpoint_enabled #=> Boolean
    #   resp.data.db_cluster.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_cluster.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_cluster.activity_stream_kms_key_id #=> String
    #   resp.data.db_cluster.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_cluster.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_cluster.cross_account_clone #=> Boolean
    #   resp.data.db_cluster.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_cluster.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_cluster.domain_memberships[0].domain #=> String
    #   resp.data.db_cluster.domain_memberships[0].status #=> String
    #   resp.data.db_cluster.domain_memberships[0].fqdn #=> String
    #   resp.data.db_cluster.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_cluster.tag_list #=> Array<Tag>
    #   resp.data.db_cluster.tag_list[0] #=> Types::Tag
    #   resp.data.db_cluster.tag_list[0].key #=> String
    #   resp.data.db_cluster.tag_list[0].value #=> String
    #   resp.data.db_cluster.global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.db_cluster.global_write_forwarding_requested #=> Boolean
    #   resp.data.db_cluster.pending_modified_values #=> Types::ClusterPendingModifiedValues
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.db_cluster_identifier #=> String
    #   resp.data.db_cluster.pending_modified_values.master_user_password #=> String
    #   resp.data.db_cluster.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.pending_modified_values.engine_version #=> String
    #   resp.data.db_cluster.db_cluster_instance_class #=> String
    #   resp.data.db_cluster.storage_type #=> String
    #   resp.data.db_cluster.iops #=> Integer
    #   resp.data.db_cluster.publicly_accessible #=> Boolean
    #   resp.data.db_cluster.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_cluster.monitoring_interval #=> Integer
    #   resp.data.db_cluster.monitoring_role_arn #=> String
    #   resp.data.db_cluster.performance_insights_enabled #=> Boolean
    #   resp.data.db_cluster.performance_insights_kms_key_id #=> String
    #   resp.data.db_cluster.performance_insights_retention_period #=> Integer
    #   resp.data.db_cluster.serverless_v2_scaling_configuration #=> Types::ServerlessV2ScalingConfigurationInfo
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.min_capacity #=> Float
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.max_capacity #=> Float
    #
    def restore_db_cluster_from_snapshot(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::RestoreDBClusterFromSnapshotInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::RestoreDBClusterFromSnapshotInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::RestoreDBClusterFromSnapshot
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InsufficientDBClusterCapacityFault, Errors::InsufficientStorageClusterCapacityFault, Errors::DBSubnetGroupNotFoundFault, Errors::KMSKeyNotAccessibleFault, Errors::OptionGroupNotFoundFault, Errors::DBClusterParameterGroupNotFoundFault, Errors::DBClusterSnapshotNotFoundFault, Errors::InvalidVPCNetworkStateFault, Errors::StorageQuotaExceededFault, Errors::InvalidSubnet, Errors::InvalidDBSnapshotStateFault, Errors::DBSnapshotNotFoundFault, Errors::InvalidDBClusterSnapshotStateFault, Errors::DBClusterAlreadyExistsFault, Errors::DomainNotFoundFault, Errors::DBClusterQuotaExceededFault, Errors::InvalidRestoreFault]),
        data_parser: Parsers::RestoreDBClusterFromSnapshot
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::RestoreDBClusterFromSnapshot,
        stubs: @stubs,
        params_class: Params::RestoreDBClusterFromSnapshotOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :restore_db_cluster_from_snapshot
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Restores a DB cluster to an arbitrary point in time. Users can restore to any point
    #             in time before <code>LatestRestorableTime</code> for up to
    #                 <code>BackupRetentionPeriod</code> days. The target DB cluster is created from the
    #             source DB cluster with the same configuration as the original DB cluster, except that
    #             the new DB cluster is created with the default DB security group.</p>
    #         <note>
    #             <p>For Aurora, this action only restores the DB cluster, not the DB instances for that DB
    #                 cluster. You must invoke the <code>CreateDBInstance</code> action to create DB
    #                 instances for the restored DB cluster, specifying the identifier of the restored DB
    #                 cluster in <code>DBClusterIdentifier</code>. You can create DB instances only after
    #                 the <code>RestoreDBClusterToPointInTime</code> action has completed and the DB
    #                 cluster is available.</p>
    #         </note>
    #         <p>For more information on Amazon Aurora DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html">
    #               What is Amazon Aurora?</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <p>For more information on Multi-AZ DB clusters, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">
    #               Multi-AZ deployments with two readable standby DB instances</a> in the <i>Amazon RDS User Guide.</i>
    #          </p>
    #
    # @param [Hash] params
    #   See {Types::RestoreDBClusterToPointInTimeInput}.
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The name of the new DB cluster to be created.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain from 1 to 63 letters, numbers, or hyphens</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :restore_type
    #   <p>The type of restore to be performed. You can specify one of the following values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>full-copy</code> - The new DB cluster is restored as a full copy of the
    #                   source DB cluster.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>copy-on-write</code> - The new DB cluster is restored as a clone of the
    #                   source DB cluster.</p>
    #               </li>
    #            </ul>
    #           <p>Constraints: You can't specify <code>copy-on-write</code> if the engine version of the source DB cluster is earlier than 1.11.</p>
    #           <p>If you don't specify a <code>RestoreType</code> value, then the new DB cluster is
    #               restored as a full copy of the source DB cluster.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :source_db_cluster_identifier
    #   <p>The identifier of the source DB cluster from which to restore.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the identifier of an existing DBCluster.</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Time] :restore_to_time
    #   <p>The date and time to restore the DB cluster to.</p>
    #           <p>Valid Values: Value must be a time in Universal Coordinated Time (UTC) format</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be before the latest restorable time for the DB instance</p>
    #               </li>
    #               <li>
    #                   <p>Must be specified if <code>UseLatestRestorableTime</code> parameter isn't provided</p>
    #               </li>
    #               <li>
    #                   <p>Can't be specified if the <code>UseLatestRestorableTime</code> parameter is enabled</p>
    #               </li>
    #               <li>
    #                   <p>Can't be specified if the <code>RestoreType</code> parameter is <code>copy-on-write</code>
    #                  </p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>2015-03-07T23:45:00Z</code>
    #            </p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Boolean] :use_latest_restorable_time
    #   <p>A value that indicates whether to restore the DB cluster to the latest
    #               restorable backup time. By default, the DB cluster isn't restored to the latest
    #               restorable backup time.</p>
    #           <p>Constraints: Can't be specified if <code>RestoreToTime</code> parameter is provided.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Integer] :port
    #   <p>The port number on which the new DB cluster accepts connections.</p>
    #           <p>Constraints: A value from <code>1150-65535</code>.</p>
    #           <p>Default: The default port for the engine.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :db_subnet_group_name
    #   <p>The DB subnet group name to use for the new DB cluster.</p>
    #           <p>Constraints: If supplied, must match the name of an existing DBSubnetGroup.</p>
    #           <p>Example: <code>mydbsubnetgroup</code>
    #            </p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :option_group_name
    #   <p>The name of the option group for the new DB cluster.</p>
    #           <p>DB clusters are associated with a default option group that can't be modified.</p>
    #
    # @option params [Array<String>] :vpc_security_group_ids
    #   <p>A list of VPC security groups that the new DB cluster belongs to.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>A list of tags.
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.html">Tagging Amazon RDS Resources</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @option params [String] :kms_key_id
    #   <p>The Amazon Web Services KMS key identifier to use when restoring an encrypted DB cluster from an encrypted DB cluster.</p>
    #           <p>The Amazon Web Services KMS key identifier is the key ARN, key ID, alias ARN, or alias name for the KMS key.
    #             To use a KMS key in a different Amazon Web Services account, specify the key ARN or alias ARN.</p>
    #           <p>You can restore to a new DB cluster and encrypt the new DB cluster with a KMS key that is different from the
    #             KMS key used to encrypt the source DB cluster. The new DB cluster is encrypted with the KMS key
    #             identified by the <code>KmsKeyId</code> parameter.</p>
    #           <p>If you don't specify a value for the <code>KmsKeyId</code> parameter, then the following occurs:</p>
    #           <ul>
    #               <li>
    #                   <p>If the DB cluster is encrypted, then the restored DB cluster is encrypted using the KMS key that was used to encrypt the source DB cluster.</p>
    #               </li>
    #               <li>
    #                   <p>If the DB cluster isn't encrypted, then the restored DB cluster isn't encrypted.</p>
    #               </li>
    #            </ul>
    #           <p>If <code>DBClusterIdentifier</code> refers to a DB cluster that isn't encrypted, then the restore request
    #         is rejected.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Boolean] :enable_iam_database_authentication
    #   <p>A value that indicates whether to enable mapping of Amazon Web Services Identity and Access
    #               Management (IAM) accounts to database accounts. By default, mapping isn't
    #               enabled.</p>
    #           <p>For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/UsingWithRDS.IAMDBAuth.html">
    #                   IAM Database Authentication</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [Integer] :backtrack_window
    #   <p>The target backtrack window, in seconds. To disable backtracking, set this value to
    #               0.</p>
    #           <p>Default: 0</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If specified, this value must be set to a number from 0 to 259,200 (72 hours).</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora MySQL DB clusters only</p>
    #
    # @option params [Array<String>] :enable_cloudwatch_logs_exports
    #   <p>The list of logs that the restored DB cluster is to export to CloudWatch Logs. The values
    #               in the list depend on the DB engine being used.</p>
    #           <p>
    #               <b>RDS for MySQL</b>
    #            </p>
    #           <p>Possible values are <code>error</code>, <code>general</code>, and <code>slowquery</code>.</p>
    #           <p>
    #               <b>RDS for PostgreSQL</b>
    #            </p>
    #           <p>Possible values are <code>postgresql</code> and <code>upgrade</code>.</p>
    #           <p>
    #               <b>Aurora MySQL</b>
    #            </p>
    #           <p>Possible values are <code>audit</code>, <code>error</code>, <code>general</code>, and <code>slowquery</code>.</p>
    #           <p>
    #               <b>Aurora PostgreSQL</b>
    #            </p>
    #           <p>Possible value is <code>postgresql</code>.</p>
    #           <p>For more information about exporting CloudWatch Logs for Amazon RDS, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.html#USER_LogAccess.Procedural.UploadtoCloudWatch">Publishing Database Logs to Amazon CloudWatch Logs</a> in the <i>Amazon RDS User Guide.</i>.</p>
    #           <p>For more information about exporting CloudWatch Logs for Amazon Aurora, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_LogAccess.html#USER_LogAccess.Procedural.UploadtoCloudWatch">Publishing Database Logs to Amazon CloudWatch Logs</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :db_cluster_parameter_group_name
    #   <p>The name of the DB cluster parameter group to associate with this DB cluster.
    #               If this argument is omitted, the default DB cluster parameter group for the specified engine is used.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match the name of an existing DB cluster parameter group.</p>
    #               </li>
    #               <li>
    #                   <p>Must be 1 to 255 letters, numbers, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens.</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Boolean] :deletion_protection
    #   <p>A value that indicates whether the DB cluster has deletion protection enabled.
    #               The database can't be deleted when deletion protection is enabled. By default,
    #               deletion protection isn't enabled.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [Boolean] :copy_tags_to_snapshot
    #   <p>A value that indicates whether to copy all tags from the restored DB cluster to snapshots of the restored DB cluster. The default is not to copy them.</p>
    #           <p>Valid for: Aurora DB clusters and Multi-AZ DB clusters</p>
    #
    # @option params [String] :domain
    #   <p>Specify the Active Directory directory ID to restore the DB cluster in.
    #             The domain must be created prior to this operation.</p>
    #           <p>For Amazon Aurora DB clusters, Amazon RDS can use Kerberos Authentication to authenticate users that connect to the DB cluster.
    #           For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/kerberos-authentication.html">Kerberos Authentication</a>
    #           in the <i>Amazon Aurora User Guide</i>.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [String] :domain_iam_role_name
    #   <p>Specify the name of the IAM role to be used when making API calls to the Directory Service.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [ScalingConfiguration] :scaling_configuration
    #   <p>For DB clusters in <code>serverless</code> DB engine mode, the scaling properties of the DB cluster.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [String] :engine_mode
    #   <p>The engine mode of the new cluster. Specify <code>provisioned</code> or <code>serverless</code>,
    #         depending on the type of the cluster you are creating. You can create an Aurora Serverless v1 clone
    #         from a provisioned cluster, or a provisioned clone from an Aurora Serverless v1 cluster. To create a clone
    #         that is an Aurora Serverless v1 cluster, the original cluster must be an Aurora Serverless v1 cluster or
    #         an encrypted provisioned cluster.</p>
    #           <p>Valid for: Aurora DB clusters only</p>
    #
    # @option params [String] :db_cluster_instance_class
    #   <p>The compute and memory capacity of the each DB instance in the Multi-AZ DB cluster,
    #               for example db.m6g.xlarge. Not all DB instance classes are available in all Amazon Web Services
    #               Regions, or for all database engines.</p>
    #           <p>For the full list of DB instance classes, and availability for your engine, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html">DB instance class</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [String] :storage_type
    #   <p>Specifies the storage type to be associated with the each DB instance in the Multi-AZ DB cluster.</p>
    #           <p>Valid values: <code>io1</code>
    #            </p>
    #           <p>When specified, a value for the <code>Iops</code> parameter is required.</p>
    #           <p>Default: <code>io1</code>
    #            </p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [Boolean] :publicly_accessible
    #   <p>A value that indicates whether the DB cluster is publicly accessible.</p>
    #           <p>When the DB cluster is publicly accessible, its Domain Name System (DNS) endpoint resolves to the private IP address
    #               from within the DB cluster's virtual private cloud (VPC). It resolves
    #               to the public IP address from outside of the DB cluster's VPC.
    #               Access to the DB cluster is ultimately controlled by the security group it uses.
    #               That public access is not permitted if the security group assigned to the DB cluster doesn't permit it.</p>
    #           <p>When the DB cluster isn't publicly accessible, it is an internal DB cluster with a DNS name that resolves to a private IP address.</p>
    #           <p>Default: The default behavior varies depending on whether <code>DBSubnetGroupName</code> is specified.</p>
    #           <p>If <code>DBSubnetGroupName</code> isn't specified, and <code>PubliclyAccessible</code> isn't specified, the following applies:</p>
    #           <ul>
    #               <li>
    #                   <p>If the default VPC in the target Region doesnt have an internet gateway attached to it, the DB cluster is private.</p>
    #               </li>
    #               <li>
    #                   <p>If the default VPC in the target Region has an internet gateway attached to it, the DB cluster is public.</p>
    #               </li>
    #            </ul>
    #           <p>If <code>DBSubnetGroupName</code> is specified, and <code>PubliclyAccessible</code> isn't specified, the following applies:</p>
    #           <ul>
    #               <li>
    #                   <p>If the subnets are part of a VPC that doesnt have an internet gateway attached to it, the DB cluster is private.</p>
    #               </li>
    #               <li>
    #                   <p>If the subnets are part of a VPC that has an internet gateway attached to it, the DB cluster is public.</p>
    #               </li>
    #            </ul>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [Integer] :iops
    #   <p>The amount of Provisioned IOPS (input/output operations per second) to be initially allocated for
    #               each DB instance in the Multi-AZ DB cluster.</p>
    #           <p>For information about valid <code>Iops</code> values, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html#USER_PIOPS">Amazon RDS Provisioned IOPS storage to improve performance</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>Constraints: Must be a multiple between .5 and 50 of the storage amount for the DB instance.</p>
    #           <p>Valid for: Multi-AZ DB clusters only</p>
    #
    # @option params [ServerlessV2ScalingConfiguration] :serverless_v2_scaling_configuration
    #   <p>Contains the scaling configuration of an Aurora Serverless v2 DB cluster.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v2.html">Using Amazon Aurora Serverless v2</a> in the
    #               <i>Amazon Aurora User Guide</i>.</p>
    #
    # @return [Types::RestoreDBClusterToPointInTimeOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.restore_db_cluster_to_point_in_time(
    #     db_cluster_identifier: 'DBClusterIdentifier', # required
    #     restore_type: 'RestoreType',
    #     source_db_cluster_identifier: 'SourceDBClusterIdentifier', # required
    #     restore_to_time: Time.now,
    #     use_latest_restorable_time: false,
    #     port: 1,
    #     db_subnet_group_name: 'DBSubnetGroupName',
    #     option_group_name: 'OptionGroupName',
    #     vpc_security_group_ids: [
    #       'member'
    #     ],
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ],
    #     kms_key_id: 'KmsKeyId',
    #     enable_iam_database_authentication: false,
    #     backtrack_window: 1,
    #     enable_cloudwatch_logs_exports: [
    #       'member'
    #     ],
    #     db_cluster_parameter_group_name: 'DBClusterParameterGroupName',
    #     deletion_protection: false,
    #     copy_tags_to_snapshot: false,
    #     domain: 'Domain',
    #     domain_iam_role_name: 'DomainIAMRoleName',
    #     scaling_configuration: {
    #       min_capacity: 1,
    #       max_capacity: 1,
    #       auto_pause: false,
    #       seconds_until_auto_pause: 1,
    #       timeout_action: 'TimeoutAction',
    #       seconds_before_timeout: 1
    #     },
    #     engine_mode: 'EngineMode',
    #     db_cluster_instance_class: 'DBClusterInstanceClass',
    #     storage_type: 'StorageType',
    #     publicly_accessible: false,
    #     iops: 1,
    #     serverless_v2_scaling_configuration: {
    #       min_capacity: 1.0,
    #       max_capacity: 1.0
    #     }
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::RestoreDBClusterToPointInTimeOutput
    #   resp.data.db_cluster #=> Types::DBCluster
    #   resp.data.db_cluster.allocated_storage #=> Integer
    #   resp.data.db_cluster.availability_zones #=> Array<String>
    #   resp.data.db_cluster.availability_zones[0] #=> String
    #   resp.data.db_cluster.backup_retention_period #=> Integer
    #   resp.data.db_cluster.character_set_name #=> String
    #   resp.data.db_cluster.database_name #=> String
    #   resp.data.db_cluster.db_cluster_identifier #=> String
    #   resp.data.db_cluster.db_cluster_parameter_group #=> String
    #   resp.data.db_cluster.db_subnet_group #=> String
    #   resp.data.db_cluster.status #=> String
    #   resp.data.db_cluster.automatic_restart_time #=> Time
    #   resp.data.db_cluster.percent_progress #=> String
    #   resp.data.db_cluster.earliest_restorable_time #=> Time
    #   resp.data.db_cluster.endpoint #=> String
    #   resp.data.db_cluster.reader_endpoint #=> String
    #   resp.data.db_cluster.custom_endpoints #=> Array<String>
    #   resp.data.db_cluster.custom_endpoints[0] #=> String
    #   resp.data.db_cluster.multi_az #=> Boolean
    #   resp.data.db_cluster.engine #=> String
    #   resp.data.db_cluster.engine_version #=> String
    #   resp.data.db_cluster.latest_restorable_time #=> Time
    #   resp.data.db_cluster.port #=> Integer
    #   resp.data.db_cluster.master_username #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships #=> Array<DBClusterOptionGroupStatus>
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0] #=> Types::DBClusterOptionGroupStatus
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].db_cluster_option_group_name #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].status #=> String
    #   resp.data.db_cluster.preferred_backup_window #=> String
    #   resp.data.db_cluster.preferred_maintenance_window #=> String
    #   resp.data.db_cluster.replication_source_identifier #=> String
    #   resp.data.db_cluster.read_replica_identifiers #=> Array<String>
    #   resp.data.db_cluster.read_replica_identifiers[0] #=> String
    #   resp.data.db_cluster.db_cluster_members #=> Array<DBClusterMember>
    #   resp.data.db_cluster.db_cluster_members[0] #=> Types::DBClusterMember
    #   resp.data.db_cluster.db_cluster_members[0].db_instance_identifier #=> String
    #   resp.data.db_cluster.db_cluster_members[0].is_cluster_writer #=> Boolean
    #   resp.data.db_cluster.db_cluster_members[0].db_cluster_parameter_group_status #=> String
    #   resp.data.db_cluster.db_cluster_members[0].promotion_tier #=> Integer
    #   resp.data.db_cluster.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_cluster.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_cluster.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_cluster.vpc_security_groups[0].status #=> String
    #   resp.data.db_cluster.hosted_zone_id #=> String
    #   resp.data.db_cluster.storage_encrypted #=> Boolean
    #   resp.data.db_cluster.kms_key_id #=> String
    #   resp.data.db_cluster.db_cluster_resource_id #=> String
    #   resp.data.db_cluster.db_cluster_arn #=> String
    #   resp.data.db_cluster.associated_roles #=> Array<DBClusterRole>
    #   resp.data.db_cluster.associated_roles[0] #=> Types::DBClusterRole
    #   resp.data.db_cluster.associated_roles[0].role_arn #=> String
    #   resp.data.db_cluster.associated_roles[0].status #=> String
    #   resp.data.db_cluster.associated_roles[0].feature_name #=> String
    #   resp.data.db_cluster.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.clone_group_id #=> String
    #   resp.data.db_cluster.cluster_create_time #=> Time
    #   resp.data.db_cluster.earliest_backtrack_time #=> Time
    #   resp.data.db_cluster.backtrack_window #=> Integer
    #   resp.data.db_cluster.backtrack_consumed_change_records #=> Integer
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports[0] #=> String
    #   resp.data.db_cluster.capacity #=> Integer
    #   resp.data.db_cluster.engine_mode #=> String
    #   resp.data.db_cluster.scaling_configuration_info #=> Types::ScalingConfigurationInfo
    #   resp.data.db_cluster.scaling_configuration_info.min_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.max_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.auto_pause #=> Boolean
    #   resp.data.db_cluster.scaling_configuration_info.seconds_until_auto_pause #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.timeout_action #=> String
    #   resp.data.db_cluster.scaling_configuration_info.seconds_before_timeout #=> Integer
    #   resp.data.db_cluster.deletion_protection #=> Boolean
    #   resp.data.db_cluster.http_endpoint_enabled #=> Boolean
    #   resp.data.db_cluster.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_cluster.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_cluster.activity_stream_kms_key_id #=> String
    #   resp.data.db_cluster.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_cluster.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_cluster.cross_account_clone #=> Boolean
    #   resp.data.db_cluster.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_cluster.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_cluster.domain_memberships[0].domain #=> String
    #   resp.data.db_cluster.domain_memberships[0].status #=> String
    #   resp.data.db_cluster.domain_memberships[0].fqdn #=> String
    #   resp.data.db_cluster.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_cluster.tag_list #=> Array<Tag>
    #   resp.data.db_cluster.tag_list[0] #=> Types::Tag
    #   resp.data.db_cluster.tag_list[0].key #=> String
    #   resp.data.db_cluster.tag_list[0].value #=> String
    #   resp.data.db_cluster.global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.db_cluster.global_write_forwarding_requested #=> Boolean
    #   resp.data.db_cluster.pending_modified_values #=> Types::ClusterPendingModifiedValues
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.db_cluster_identifier #=> String
    #   resp.data.db_cluster.pending_modified_values.master_user_password #=> String
    #   resp.data.db_cluster.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.pending_modified_values.engine_version #=> String
    #   resp.data.db_cluster.db_cluster_instance_class #=> String
    #   resp.data.db_cluster.storage_type #=> String
    #   resp.data.db_cluster.iops #=> Integer
    #   resp.data.db_cluster.publicly_accessible #=> Boolean
    #   resp.data.db_cluster.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_cluster.monitoring_interval #=> Integer
    #   resp.data.db_cluster.monitoring_role_arn #=> String
    #   resp.data.db_cluster.performance_insights_enabled #=> Boolean
    #   resp.data.db_cluster.performance_insights_kms_key_id #=> String
    #   resp.data.db_cluster.performance_insights_retention_period #=> Integer
    #   resp.data.db_cluster.serverless_v2_scaling_configuration #=> Types::ServerlessV2ScalingConfigurationInfo
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.min_capacity #=> Float
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.max_capacity #=> Float
    #
    def restore_db_cluster_to_point_in_time(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::RestoreDBClusterToPointInTimeInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::RestoreDBClusterToPointInTimeInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::RestoreDBClusterToPointInTime
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::InsufficientDBClusterCapacityFault, Errors::InsufficientStorageClusterCapacityFault, Errors::DBSubnetGroupNotFoundFault, Errors::KMSKeyNotAccessibleFault, Errors::OptionGroupNotFoundFault, Errors::DBClusterParameterGroupNotFoundFault, Errors::DBClusterSnapshotNotFoundFault, Errors::InvalidVPCNetworkStateFault, Errors::StorageQuotaExceededFault, Errors::InvalidSubnet, Errors::InvalidDBSnapshotStateFault, Errors::InvalidDBClusterSnapshotStateFault, Errors::DBClusterAlreadyExistsFault, Errors::DomainNotFoundFault, Errors::DBClusterQuotaExceededFault, Errors::InvalidDBClusterStateFault, Errors::InvalidRestoreFault]),
        data_parser: Parsers::RestoreDBClusterToPointInTime
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::RestoreDBClusterToPointInTime,
        stubs: @stubs,
        params_class: Params::RestoreDBClusterToPointInTimeOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :restore_db_cluster_to_point_in_time
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Creates a new DB instance from a DB snapshot. The target database is created from the source database restore point with most
    #             of the source's original configuration, including the default security group and DB parameter group. By default, the new DB
    #             instance is created as a Single-AZ deployment, except when the instance is a SQL Server instance that has an option group
    #             associated with mirroring. In this case, the instance becomes a Multi-AZ deployment, not a Single-AZ deployment.</p>
    #         <p>If you want to replace your original DB instance with the new, restored DB instance, then rename your original DB instance
    #             before you call the RestoreDBInstanceFromDBSnapshot action. RDS doesn't allow two DB instances with the same name. After you
    #             have renamed your original DB instance with a different identifier, then you can pass the original name of the DB instance as
    #             the DBInstanceIdentifier in the call to the RestoreDBInstanceFromDBSnapshot action. The result is that you replace the original
    #             DB instance with the DB instance created from the snapshot.</p>
    #         <p>If you are restoring from a shared manual DB snapshot, the <code>DBSnapshotIdentifier</code>
    #       must be the ARN of the shared DB snapshot.</p>
    #         <note>
    #             <p>This command doesn't apply to Aurora MySQL and Aurora PostgreSQL. For Aurora, use <code>RestoreDBClusterFromSnapshot</code>.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::RestoreDBInstanceFromDBSnapshotInput}.
    #
    # @option params [String] :db_instance_identifier
    #   <p>Name of the DB instance to create from the DB snapshot. This parameter isn't case-sensitive.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain from 1 to 63 numbers, letters, or hyphens</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>my-snapshot-id</code>
    #            </p>
    #
    # @option params [String] :db_snapshot_identifier
    #   <p>The identifier for the DB snapshot to restore from.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the identifier of an existing DBSnapshot.</p>
    #               </li>
    #               <li>
    #                   <p>If you are restoring from a shared manual DB snapshot, the <code>DBSnapshotIdentifier</code>
    #                 must be the ARN of the shared DB snapshot.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :db_instance_class
    #   <p>The compute and memory capacity of the Amazon RDS DB instance, for example db.m4.large.
    #             Not all DB instance classes are available in all Amazon Web Services Regions, or for all database engines.
    #             For the full list of DB instance classes,
    #             and availability for your engine, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html">DB Instance Class</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>Default: The same DBInstanceClass as the original DB instance.</p>
    #
    # @option params [Integer] :port
    #   <p>The port number on which the database accepts connections.</p>
    #           <p>Default: The same port as the original DB instance</p>
    #           <p>Constraints: Value must be <code>1150-65535</code>
    #            </p>
    #
    # @option params [String] :availability_zone
    #   <p>The Availability Zone (AZ) where the DB instance will be created.</p>
    #           <p>Default: A random, system-chosen Availability Zone.</p>
    #           <p>Constraint: You can't specify the <code>AvailabilityZone</code> parameter if the DB instance is a Multi-AZ deployment.</p>
    #           <p>Example: <code>us-east-1a</code>
    #            </p>
    #
    # @option params [String] :db_subnet_group_name
    #   <p>The DB subnet group name to use for the new instance.</p>
    #           <p>Constraints: If supplied, must match the name of an existing DBSubnetGroup.</p>
    #           <p>Example: <code>mydbsubnetgroup</code>
    #            </p>
    #
    # @option params [Boolean] :multi_az
    #   <p>A value that indicates whether the DB instance is a Multi-AZ deployment.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Constraint: You can't specify the <code>AvailabilityZone</code> parameter if the DB instance is a Multi-AZ deployment.</p>
    #
    # @option params [Boolean] :publicly_accessible
    #   <p>A value that indicates whether the DB instance is publicly accessible.</p>
    #           <p>When the DB instance is publicly accessible, its Domain Name System (DNS) endpoint resolves to the private IP address
    #             from within the DB instance's virtual private cloud (VPC).
    #             It resolves to the public IP address from outside of the DB instance's VPC. Access to the DB instance is ultimately controlled
    #             by the security group it uses. That public access is not permitted if the security group assigned to the DB instance doesn't permit it.</p>
    #           <p>When the DB instance isn't publicly accessible, it is an internal DB instance with a DNS name that resolves to a private IP address.</p>
    #           <p>For more information, see <a>CreateDBInstance</a>.</p>
    #
    # @option params [Boolean] :auto_minor_version_upgrade
    #   <p>A value that indicates whether minor version upgrades are applied automatically to the DB instance
    #             during the maintenance window.</p>
    #           <p>If you restore an RDS Custom DB instance, you must disable this parameter.</p>
    #
    # @option params [String] :license_model
    #   <p>License model information for the restored DB instance.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Default: Same as source.</p>
    #           <p>Valid values:  <code>license-included</code> | <code>bring-your-own-license</code> | <code>general-public-license</code>
    #            </p>
    #
    # @option params [String] :db_name
    #   <p>The database name for the restored DB instance.</p>
    #           <p>This parameter doesn't apply to the MySQL, PostgreSQL, or MariaDB engines. It also doesn't apply to RDS
    #             Custom DB instances.</p>
    #
    # @option params [String] :engine
    #   <p>The database engine to use for the new instance.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Default: The same as source</p>
    #           <p>Constraint: Must be compatible with the engine of the source. For example, you can restore a MariaDB 10.1 DB instance from a MySQL 5.6 snapshot.</p>
    #           <p>Valid Values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>mariadb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mysql</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>postgres</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-se</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ex</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-web</code>
    #                  </p>
    #               </li>
    #            </ul>
    #
    # @option params [Integer] :iops
    #   <p>Specifies the amount of provisioned IOPS for the DB instance, expressed in I/O operations per second.
    #             If this parameter isn't specified, the IOPS value is taken from the backup.
    #             If this parameter is set to 0, the new instance is converted to a non-PIOPS instance.
    #             The conversion takes additional time, though your DB instance is available for connections before the conversion starts.</p>
    #           <p>The provisioned IOPS value must follow the requirements for your database engine.
    #             For more information, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html#USER_PIOPS">Amazon RDS Provisioned IOPS Storage to Improve Performance</a>
    #             in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>Constraints: Must be an integer greater than 1000.</p>
    #
    # @option params [String] :option_group_name
    #   <p>The name of the option group to be used for the restored DB instance.</p>
    #
    #
    #           <p>Permanent options, such as the TDE option for Oracle Advanced Security TDE, can't be removed from an option
    #           group, and that option group can't be removed from a DB instance after it is associated with a DB instance.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>A list of tags.
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.html">Tagging Amazon RDS Resources</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @option params [String] :storage_type
    #   <p>Specifies the storage type to be associated with the DB instance.</p>
    #           <p>Valid values: <code>standard | gp2 | io1</code>
    #            </p>
    #           <p>If you specify <code>io1</code>, you must also include a value for the
    #               <code>Iops</code> parameter.</p>
    #           <p>Default: <code>io1</code> if the <code>Iops</code> parameter
    #               is specified, otherwise <code>gp2</code>
    #            </p>
    #
    # @option params [String] :tde_credential_arn
    #   <p>The ARN from the key store with which to associate the instance for TDE encryption.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :tde_credential_password
    #   <p>The password for the given ARN from the key store in order to access the device.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Array<String>] :vpc_security_group_ids
    #   <p>A list of EC2 VPC security groups to associate with this DB instance.</p>
    #           <p>Default: The default EC2 VPC security group for the DB subnet group's VPC.</p>
    #
    # @option params [String] :domain
    #   <p>Specify the Active Directory directory ID to restore the DB instance in.
    #              The domain/ must be created prior to this operation. Currently, you can create only MySQL, Microsoft SQL
    #              Server, Oracle, and PostgreSQL DB instances in an Active Directory Domain.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/kerberos-authentication.html">
    #              Kerberos Authentication</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :copy_tags_to_snapshot
    #   <p>A value that indicates whether to copy all tags from the restored DB instance to snapshots of the DB instance.</p>
    #           <p>In most cases, tags aren't copied by default. However, when you restore a DB instance from a DB snapshot, RDS checks whether you
    #             specify new tags. If yes, the new tags are added to the restored DB instance. If there are no new tags, RDS looks for the tags from
    #             the source DB instance for the DB snapshot, and then adds those tags to the restored DB instance.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.html#USER_Tagging.CopyTags">
    #             Copying tags to DB instance snapshots</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @option params [String] :domain_iam_role_name
    #   <p>Specify the name of the IAM role to be used when making API calls to the Directory Service.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :enable_iam_database_authentication
    #   <p>A value that indicates whether to enable mapping of Amazon Web Services Identity and Access
    #             Management (IAM) accounts to database accounts. By default, mapping is disabled.</p>
    #           <p>For more information about IAM database authentication, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.html">
    #                 IAM Database Authentication for MySQL and PostgreSQL</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Array<String>] :enable_cloudwatch_logs_exports
    #   <p>The list of logs that the restored DB instance is to export to CloudWatch Logs. The values
    #               in the list depend on the DB engine being used. For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.html#USER_LogAccess.Procedural.UploadtoCloudWatch">Publishing Database Logs to Amazon CloudWatch Logs</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Array<ProcessorFeature>] :processor_features
    #   <p>The number of CPU cores and the number of threads per core for the DB instance class of the DB instance.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :use_default_processor_features
    #   <p>A value that indicates whether the DB instance class of the DB instance uses its default
    #               processor features.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :db_parameter_group_name
    #   <p>The name of the DB parameter group to associate with this DB instance.</p>
    #           <p>If you don't specify a value for <code>DBParameterGroupName</code>, then RDS uses the default <code>DBParameterGroup</code>
    #               for the specified DB engine.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match the name of an existing DBParameterGroup.</p>
    #               </li>
    #               <li>
    #                   <p>Must be 1 to 255 letters, numbers, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Boolean] :deletion_protection
    #   <p>A value that indicates whether the DB instance has deletion protection enabled.
    #               The database can't be deleted when deletion protection is enabled. By default,
    #               deletion protection isn't enabled. For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_DeleteInstance.html">
    #                   Deleting a DB Instance</a>.</p>
    #
    # @option params [Boolean] :enable_customer_owned_ip
    #   <p>A value that indicates whether to enable a customer-owned IP address (CoIP) for an RDS on Outposts DB instance.</p>
    #           <p>A <i>CoIP</i> provides local or external connectivity to resources in
    #               your Outpost subnets through your on-premises network. For some use cases, a CoIP can
    #               provide lower latency for connections to the DB instance from outside of its virtual
    #               private cloud (VPC) on your local network.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>For more information about RDS on Outposts, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-on-outposts.html">Working with Amazon RDS on Amazon Web Services Outposts</a>
    #               in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>For more information about CoIPs, see <a href="https://docs.aws.amazon.com/outposts/latest/userguide/outposts-networking-components.html#ip-addressing">Customer-owned IP addresses</a>
    #               in the <i>Amazon Web Services Outposts User Guide</i>.</p>
    #
    # @option params [String] :custom_iam_instance_profile
    #   <p>The instance profile associated with the underlying Amazon EC2 instance of an
    #               RDS Custom DB instance. The instance profile must meet the following requirements:</p>
    #           <ul>
    #               <li>
    #                   <p>The profile must exist in your account.</p>
    #               </li>
    #               <li>
    #                   <p>The profile must have an IAM role that Amazon EC2 has permissions to assume.</p>
    #               </li>
    #               <li>
    #                   <p>The instance profile name and the associated IAM role name must start with the prefix <code>AWSRDSCustom</code>.</p>
    #               </li>
    #            </ul>
    #           <p>For the list of permissions required for the IAM role, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/custom-setup-orcl.html#custom-setup-orcl.iam-vpc">
    #                   Configure IAM and your VPC</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting is required for RDS Custom.</p>
    #
    # @option params [String] :backup_target
    #   <p>Specifies where automated backups and manual snapshots are stored for the restored DB instance.</p>
    #           <p>Possible values are <code>outposts</code> (Amazon Web Services Outposts) and <code>region</code> (Amazon Web Services Region). The default is <code>region</code>.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-on-outposts.html">Working
    #               with Amazon RDS on Amazon Web Services Outposts</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @option params [String] :network_type
    #   <p>The network type of the DB instance.</p>
    #           <p>Valid values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>IPV4</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>DUAL</code>
    #                  </p>
    #               </li>
    #            </ul>
    #           <p>The network type is determined by the <code>DBSubnetGroup</code> specified for the DB instance.
    #               A <code>DBSubnetGroup</code> can support only the IPv4 protocol or the IPv4 and the IPv6
    #               protocols (<code>DUAL</code>).</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.WorkingWithRDSInstanceinaVPC.html">
    #               Working with a DB instance in a VPC</a> in the
    #               <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @return [Types::RestoreDBInstanceFromDBSnapshotOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.restore_db_instance_from_db_snapshot(
    #     db_instance_identifier: 'DBInstanceIdentifier', # required
    #     db_snapshot_identifier: 'DBSnapshotIdentifier', # required
    #     db_instance_class: 'DBInstanceClass',
    #     port: 1,
    #     availability_zone: 'AvailabilityZone',
    #     db_subnet_group_name: 'DBSubnetGroupName',
    #     multi_az: false,
    #     publicly_accessible: false,
    #     auto_minor_version_upgrade: false,
    #     license_model: 'LicenseModel',
    #     db_name: 'DBName',
    #     engine: 'Engine',
    #     iops: 1,
    #     option_group_name: 'OptionGroupName',
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ],
    #     storage_type: 'StorageType',
    #     tde_credential_arn: 'TdeCredentialArn',
    #     tde_credential_password: 'TdeCredentialPassword',
    #     vpc_security_group_ids: [
    #       'member'
    #     ],
    #     domain: 'Domain',
    #     copy_tags_to_snapshot: false,
    #     domain_iam_role_name: 'DomainIAMRoleName',
    #     enable_iam_database_authentication: false,
    #     enable_cloudwatch_logs_exports: [
    #       'member'
    #     ],
    #     processor_features: [
    #       {
    #         name: 'Name',
    #         value: 'Value'
    #       }
    #     ],
    #     use_default_processor_features: false,
    #     db_parameter_group_name: 'DBParameterGroupName',
    #     deletion_protection: false,
    #     enable_customer_owned_ip: false,
    #     custom_iam_instance_profile: 'CustomIamInstanceProfile',
    #     backup_target: 'BackupTarget',
    #     network_type: 'NetworkType'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::RestoreDBInstanceFromDBSnapshotOutput
    #   resp.data.db_instance #=> Types::DBInstance
    #   resp.data.db_instance.db_instance_identifier #=> String
    #   resp.data.db_instance.db_instance_class #=> String
    #   resp.data.db_instance.engine #=> String
    #   resp.data.db_instance.db_instance_status #=> String
    #   resp.data.db_instance.automatic_restart_time #=> Time
    #   resp.data.db_instance.master_username #=> String
    #   resp.data.db_instance.db_name #=> String
    #   resp.data.db_instance.endpoint #=> Types::Endpoint
    #   resp.data.db_instance.endpoint.address #=> String
    #   resp.data.db_instance.endpoint.port #=> Integer
    #   resp.data.db_instance.endpoint.hosted_zone_id #=> String
    #   resp.data.db_instance.allocated_storage #=> Integer
    #   resp.data.db_instance.instance_create_time #=> Time
    #   resp.data.db_instance.preferred_backup_window #=> String
    #   resp.data.db_instance.backup_retention_period #=> Integer
    #   resp.data.db_instance.db_security_groups #=> Array<DBSecurityGroupMembership>
    #   resp.data.db_instance.db_security_groups[0] #=> Types::DBSecurityGroupMembership
    #   resp.data.db_instance.db_security_groups[0].db_security_group_name #=> String
    #   resp.data.db_instance.db_security_groups[0].status #=> String
    #   resp.data.db_instance.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_instance.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_instance.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_instance.vpc_security_groups[0].status #=> String
    #   resp.data.db_instance.db_parameter_groups #=> Array<DBParameterGroupStatus>
    #   resp.data.db_instance.db_parameter_groups[0] #=> Types::DBParameterGroupStatus
    #   resp.data.db_instance.db_parameter_groups[0].db_parameter_group_name #=> String
    #   resp.data.db_instance.db_parameter_groups[0].parameter_apply_status #=> String
    #   resp.data.db_instance.availability_zone #=> String
    #   resp.data.db_instance.db_subnet_group #=> Types::DBSubnetGroup
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_name #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_description #=> String
    #   resp.data.db_instance.db_subnet_group.vpc_id #=> String
    #   resp.data.db_instance.db_subnet_group.subnet_group_status #=> String
    #   resp.data.db_instance.db_subnet_group.subnets #=> Array<Subnet>
    #   resp.data.db_instance.db_subnet_group.subnets[0] #=> Types::Subnet
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_identifier #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone #=> Types::AvailabilityZone
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone.name #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost #=> Types::Outpost
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost.arn #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_status #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_arn #=> String
    #   resp.data.db_instance.db_subnet_group.supported_network_types #=> Array<String>
    #   resp.data.db_instance.db_subnet_group.supported_network_types[0] #=> String
    #   resp.data.db_instance.preferred_maintenance_window #=> String
    #   resp.data.db_instance.pending_modified_values #=> Types::PendingModifiedValues
    #   resp.data.db_instance.pending_modified_values.db_instance_class #=> String
    #   resp.data.db_instance.pending_modified_values.allocated_storage #=> Integer
    #   resp.data.db_instance.pending_modified_values.master_user_password #=> String
    #   resp.data.db_instance.pending_modified_values.port #=> Integer
    #   resp.data.db_instance.pending_modified_values.backup_retention_period #=> Integer
    #   resp.data.db_instance.pending_modified_values.multi_az #=> Boolean
    #   resp.data.db_instance.pending_modified_values.engine_version #=> String
    #   resp.data.db_instance.pending_modified_values.license_model #=> String
    #   resp.data.db_instance.pending_modified_values.iops #=> Integer
    #   resp.data.db_instance.pending_modified_values.db_instance_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.storage_type #=> String
    #   resp.data.db_instance.pending_modified_values.ca_certificate_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.db_subnet_group_name #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable[0] #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.pending_modified_values.processor_features[0] #=> Types::ProcessorFeature
    #   resp.data.db_instance.pending_modified_values.processor_features[0].name #=> String
    #   resp.data.db_instance.pending_modified_values.processor_features[0].value #=> String
    #   resp.data.db_instance.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.pending_modified_values.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.pending_modified_values.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.latest_restorable_time #=> Time
    #   resp.data.db_instance.multi_az #=> Boolean
    #   resp.data.db_instance.engine_version #=> String
    #   resp.data.db_instance.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_instance.read_replica_source_db_instance_identifier #=> String
    #   resp.data.db_instance.read_replica_db_instance_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_instance_identifiers[0] #=> String
    #   resp.data.db_instance.read_replica_db_cluster_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_cluster_identifiers[0] #=> String
    #   resp.data.db_instance.replica_mode #=> String, one of ["open-read-only", "mounted"]
    #   resp.data.db_instance.license_model #=> String
    #   resp.data.db_instance.iops #=> Integer
    #   resp.data.db_instance.option_group_memberships #=> Array<OptionGroupMembership>
    #   resp.data.db_instance.option_group_memberships[0] #=> Types::OptionGroupMembership
    #   resp.data.db_instance.option_group_memberships[0].option_group_name #=> String
    #   resp.data.db_instance.option_group_memberships[0].status #=> String
    #   resp.data.db_instance.character_set_name #=> String
    #   resp.data.db_instance.nchar_character_set_name #=> String
    #   resp.data.db_instance.secondary_availability_zone #=> String
    #   resp.data.db_instance.publicly_accessible #=> Boolean
    #   resp.data.db_instance.status_infos #=> Array<DBInstanceStatusInfo>
    #   resp.data.db_instance.status_infos[0] #=> Types::DBInstanceStatusInfo
    #   resp.data.db_instance.status_infos[0].status_type #=> String
    #   resp.data.db_instance.status_infos[0].normal #=> Boolean
    #   resp.data.db_instance.status_infos[0].status #=> String
    #   resp.data.db_instance.status_infos[0].message #=> String
    #   resp.data.db_instance.storage_type #=> String
    #   resp.data.db_instance.tde_credential_arn #=> String
    #   resp.data.db_instance.db_instance_port #=> Integer
    #   resp.data.db_instance.db_cluster_identifier #=> String
    #   resp.data.db_instance.storage_encrypted #=> Boolean
    #   resp.data.db_instance.kms_key_id #=> String
    #   resp.data.db_instance.dbi_resource_id #=> String
    #   resp.data.db_instance.ca_certificate_identifier #=> String
    #   resp.data.db_instance.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_instance.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_instance.domain_memberships[0].domain #=> String
    #   resp.data.db_instance.domain_memberships[0].status #=> String
    #   resp.data.db_instance.domain_memberships[0].fqdn #=> String
    #   resp.data.db_instance.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_instance.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_instance.monitoring_interval #=> Integer
    #   resp.data.db_instance.enhanced_monitoring_resource_arn #=> String
    #   resp.data.db_instance.monitoring_role_arn #=> String
    #   resp.data.db_instance.promotion_tier #=> Integer
    #   resp.data.db_instance.db_instance_arn #=> String
    #   resp.data.db_instance.timezone #=> String
    #   resp.data.db_instance.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_kms_key_id #=> String
    #   resp.data.db_instance.performance_insights_retention_period #=> Integer
    #   resp.data.db_instance.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_instance.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.deletion_protection #=> Boolean
    #   resp.data.db_instance.associated_roles #=> Array<DBInstanceRole>
    #   resp.data.db_instance.associated_roles[0] #=> Types::DBInstanceRole
    #   resp.data.db_instance.associated_roles[0].role_arn #=> String
    #   resp.data.db_instance.associated_roles[0].feature_name #=> String
    #   resp.data.db_instance.associated_roles[0].status #=> String
    #   resp.data.db_instance.listener_endpoint #=> Types::Endpoint
    #   resp.data.db_instance.max_allocated_storage #=> Integer
    #   resp.data.db_instance.tag_list #=> Array<Tag>
    #   resp.data.db_instance.tag_list[0] #=> Types::Tag
    #   resp.data.db_instance.tag_list[0].key #=> String
    #   resp.data.db_instance.tag_list[0].value #=> String
    #   resp.data.db_instance.db_instance_automated_backups_replications #=> Array<DBInstanceAutomatedBackupsReplication>
    #   resp.data.db_instance.db_instance_automated_backups_replications[0] #=> Types::DBInstanceAutomatedBackupsReplication
    #   resp.data.db_instance.db_instance_automated_backups_replications[0].db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance.customer_owned_ip_enabled #=> Boolean
    #   resp.data.db_instance.aws_backup_recovery_point_arn #=> String
    #   resp.data.db_instance.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_instance.activity_stream_kms_key_id #=> String
    #   resp.data.db_instance.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_instance.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_instance.activity_stream_engine_native_audit_fields_included #=> Boolean
    #   resp.data.db_instance.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.custom_iam_instance_profile #=> String
    #   resp.data.db_instance.backup_target #=> String
    #   resp.data.db_instance.network_type #=> String
    #
    def restore_db_instance_from_db_snapshot(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::RestoreDBInstanceFromDBSnapshotInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::RestoreDBInstanceFromDBSnapshotInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::RestoreDBInstanceFromDBSnapshot
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBSubnetGroupDoesNotCoverEnoughAZs, Errors::DBSubnetGroupNotFoundFault, Errors::KMSKeyNotAccessibleFault, Errors::InstanceQuotaExceededFault, Errors::OptionGroupNotFoundFault, Errors::InvalidVPCNetworkStateFault, Errors::StorageQuotaExceededFault, Errors::InvalidSubnet, Errors::DBInstanceAlreadyExistsFault, Errors::InvalidDBSnapshotStateFault, Errors::InsufficientDBInstanceCapacityFault, Errors::DBSnapshotNotFoundFault, Errors::NetworkTypeNotSupported, Errors::DBSecurityGroupNotFoundFault, Errors::DomainNotFoundFault, Errors::ProvisionedIopsNotAvailableInAZFault, Errors::AuthorizationNotFoundFault, Errors::StorageTypeNotSupportedFault, Errors::DBParameterGroupNotFoundFault, Errors::BackupPolicyNotFoundFault, Errors::InvalidRestoreFault]),
        data_parser: Parsers::RestoreDBInstanceFromDBSnapshot
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::RestoreDBInstanceFromDBSnapshot,
        stubs: @stubs,
        params_class: Params::RestoreDBInstanceFromDBSnapshotOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :restore_db_instance_from_db_snapshot
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Amazon Relational Database Service (Amazon RDS)
    #             supports importing MySQL databases by using backup files.
    #             You can create a backup of your on-premises database,
    #             store it on Amazon Simple Storage Service (Amazon S3),
    #             and then restore the backup file onto a new Amazon RDS DB instance running MySQL.
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/MySQL.Procedural.Importing.html">Importing Data into an Amazon RDS MySQL DB Instance</a>
    #             in the <i>Amazon RDS User Guide.</i>
    #          </p>
    #         <p>This command doesn't apply to RDS Custom.</p>
    #
    # @param [Hash] params
    #   See {Types::RestoreDBInstanceFromS3Input}.
    #
    # @option params [String] :db_name
    #   <p>The name of the database to create when the DB instance is created.
    #               Follow the naming rules specified in <code>CreateDBInstance</code>.</p>
    #
    # @option params [String] :db_instance_identifier
    #   <p>The DB instance identifier. This parameter is stored as a lowercase string.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain from 1 to 63 letters, numbers, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens.</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>mydbinstance</code>
    #            </p>
    #
    # @option params [Integer] :allocated_storage
    #   <p>The amount of storage (in gigabytes) to allocate initially for the DB instance.
    #               Follow the allocation rules specified in <code>CreateDBInstance</code>.</p>
    #           <note>
    #               <p>Be sure to allocate enough memory for your new DB instance
    #                   so that the restore operation can succeed.
    #                   You can also allocate additional memory for future growth.</p>
    #           </note>
    #
    # @option params [String] :db_instance_class
    #   <p>The compute and memory capacity of the DB instance,
    #               for example db.m4.large.
    #               Not all DB instance classes are available in all Amazon Web Services Regions,
    #               or for all database engines.
    #               For the full list of DB instance classes,
    #               and availability for your engine, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html">DB Instance Class</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>Importing from Amazon S3 isn't supported on the db.t2.micro DB instance class.</p>
    #
    # @option params [String] :engine
    #   <p>The name of the database engine to be used for this instance.</p>
    #           <p>Valid Values:
    #               <code>mysql</code>
    #            </p>
    #
    # @option params [String] :master_username
    #   <p>The name for the master user.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be 1 to 16 letters or numbers.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't be a reserved word for the chosen database engine.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :master_user_password
    #   <p>The password for the master user.
    #               The password can include any printable ASCII character except "/", """, or "@".</p>
    #           <p>Constraints: Must contain from 8 to 41 characters.</p>
    #
    # @option params [Array<String>] :db_security_groups
    #   <p>A list of DB security groups to associate with this DB instance.</p>
    #           <p>Default: The default DB security group for the database engine.</p>
    #
    # @option params [Array<String>] :vpc_security_group_ids
    #   <p>A list of VPC security groups to associate with this DB instance.</p>
    #
    # @option params [String] :availability_zone
    #   <p>The Availability Zone that the DB instance is created in.
    #               For information about Amazon Web Services Regions and Availability Zones, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html">Regions and Availability Zones</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>Default: A random, system-chosen Availability Zone in the endpoint's Amazon Web Services Region.</p>
    #           <p>Example: <code>us-east-1d</code>
    #            </p>
    #           <p>Constraint: The <code>AvailabilityZone</code> parameter can't be specified if the DB instance is a Multi-AZ deployment.
    #               The specified Availability Zone must be in the same Amazon Web Services Region as the current endpoint.</p>
    #
    # @option params [String] :db_subnet_group_name
    #   <p>A DB subnet group to associate with this DB instance.</p>
    #           <p>Constraints: If supplied, must match the name of an existing DBSubnetGroup.</p>
    #           <p>Example: <code>mydbsubnetgroup</code>
    #            </p>
    #
    # @option params [String] :preferred_maintenance_window
    #   <p>The time range each week during which system maintenance can occur,
    #               in Universal Coordinated Time (UTC).
    #               For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.Maintenance.html#Concepts.DBMaintenance">Amazon RDS Maintenance Window</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be in the format <code>ddd:hh24:mi-ddd:hh24:mi</code>.</p>
    #               </li>
    #               <li>
    #                   <p>Valid Days: Mon, Tue, Wed, Thu, Fri, Sat, Sun.</p>
    #               </li>
    #               <li>
    #                   <p>Must be in Universal Coordinated Time (UTC).</p>
    #               </li>
    #               <li>
    #                   <p>Must not conflict with the preferred backup window.</p>
    #               </li>
    #               <li>
    #                   <p>Must be at least 30 minutes.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :db_parameter_group_name
    #   <p>The name of the DB parameter group to associate with this DB instance.</p>
    #           <p>If you do not specify a value for <code>DBParameterGroupName</code>, then the default <code>DBParameterGroup</code>
    #               for the specified DB engine is used.</p>
    #
    # @option params [Integer] :backup_retention_period
    #   <p>The number of days for which automated backups are retained.
    #               Setting this parameter to a positive number enables backups.
    #               For more information, see <code>CreateDBInstance</code>.</p>
    #
    # @option params [String] :preferred_backup_window
    #   <p>The time range each day
    #               during which automated backups are created
    #               if automated backups are enabled.
    #               For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html#USER_WorkingWithAutomatedBackups.BackupWindow">Backup window</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be in the format <code>hh24:mi-hh24:mi</code>.</p>
    #               </li>
    #               <li>
    #                   <p>Must be in Universal Coordinated Time (UTC).</p>
    #               </li>
    #               <li>
    #                   <p>Must not conflict with the preferred maintenance window.</p>
    #               </li>
    #               <li>
    #                   <p>Must be at least 30 minutes.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Integer] :port
    #   <p>The port number on which the database accepts connections.</p>
    #           <p>Type: Integer</p>
    #           <p>Valid Values: <code>1150</code>-<code>65535</code>
    #            </p>
    #           <p>Default: <code>3306</code>
    #            </p>
    #
    # @option params [Boolean] :multi_az
    #   <p>A value that indicates whether the DB instance is a Multi-AZ deployment.
    #               If the DB instance is a Multi-AZ deployment, you can't set the <code>AvailabilityZone</code> parameter.</p>
    #
    # @option params [String] :engine_version
    #   <p>The version number of the database engine to use.
    #               Choose the latest minor version of your database engine.
    #               For information about engine versions, see <code>CreateDBInstance</code>, or call <code>DescribeDBEngineVersions</code>.</p>
    #
    # @option params [Boolean] :auto_minor_version_upgrade
    #   <p>A value that indicates whether minor engine upgrades are applied automatically
    #               to the DB instance during the maintenance window. By default, minor engine upgrades
    #               are not applied automatically.</p>
    #
    # @option params [String] :license_model
    #   <p>The license model for this DB instance.
    #               Use <code>general-public-license</code>.</p>
    #
    # @option params [Integer] :iops
    #   <p>The amount of Provisioned IOPS (input/output operations per second)
    #               to allocate initially for the DB instance.
    #               For information about valid Iops values, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html#USER_PIOPS">Amazon RDS Provisioned IOPS Storage to Improve Performance</a>
    #               in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @option params [String] :option_group_name
    #   <p>The name of the option group to associate with this DB instance.
    #               If this argument is omitted, the default option group for the specified engine is used.</p>
    #
    # @option params [Boolean] :publicly_accessible
    #   <p>A value that indicates whether the DB instance is publicly accessible.</p>
    #           <p>When the DB instance is publicly accessible, its Domain Name System (DNS) endpoint resolves to the private IP address
    #               from within the DB instance's virtual private cloud (VPC).
    #               It resolves to the public IP address from outside of the DB instance's VPC.
    #               Access to the DB instance is ultimately controlled by the security group it uses.
    #               That public access is not permitted if the security group assigned to the DB instance doesn't permit it.</p>
    #           <p>When the DB instance isn't publicly accessible, it is an internal DB instance with a DNS name that resolves to a private IP address.</p>
    #           <p>For more information, see <a>CreateDBInstance</a>.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>A list of tags to associate with this DB instance.
    #               For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.html">Tagging Amazon RDS Resources</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @option params [String] :storage_type
    #   <p>Specifies the storage type to be associated with the DB instance.</p>
    #           <p>Valid values: <code>standard</code> | <code>gp2</code> | <code>io1</code>
    #            </p>
    #           <p>If you specify <code>io1</code>,
    #               you must also include a value for the <code>Iops</code> parameter.</p>
    #           <p>Default: <code>io1</code>
    #               if the <code>Iops</code> parameter is specified;
    #               otherwise <code>gp2</code>
    #            </p>
    #
    # @option params [Boolean] :storage_encrypted
    #   <p>A value that indicates whether the new DB instance is encrypted or not.</p>
    #
    # @option params [String] :kms_key_id
    #   <p>The Amazon Web Services KMS key identifier for an encrypted DB instance.</p>
    #           <p>The Amazon Web Services KMS key identifier is the key ARN, key ID, alias ARN, or alias name for the KMS key.
    #               To use a KMS key in a different Amazon Web Services account, specify the key ARN or alias ARN.</p>
    #           <p>If the <code>StorageEncrypted</code> parameter is enabled,
    #               and you do not specify a value for the <code>KmsKeyId</code> parameter,
    #               then Amazon RDS will use your default KMS key.
    #               There is a default KMS key for your Amazon Web Services account.
    #               Your Amazon Web Services account has a different default KMS key for each Amazon Web Services Region.</p>
    #
    # @option params [Boolean] :copy_tags_to_snapshot
    #   <p>A value that indicates whether to copy all tags from the DB instance to snapshots of the DB instance. By default, tags are not copied.</p>
    #
    # @option params [Integer] :monitoring_interval
    #   <p>The interval, in seconds,
    #               between points when Enhanced Monitoring metrics are collected for the DB instance.
    #               To disable collecting Enhanced Monitoring metrics, specify 0.</p>
    #           <p>If <code>MonitoringRoleArn</code> is specified,
    #               then you must also set <code>MonitoringInterval</code> to a value other than 0.</p>
    #           <p>Valid Values: 0, 1, 5, 10, 15, 30, 60</p>
    #           <p>Default: <code>0</code>
    #            </p>
    #
    # @option params [String] :monitoring_role_arn
    #   <p>The ARN for the IAM role that permits RDS
    #               to send enhanced monitoring metrics to Amazon CloudWatch Logs.
    #               For example, <code>arn:aws:iam:123456789012:role/emaccess</code>.
    #               For information on creating a monitoring role, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.OS.html#USER_Monitoring.OS.Enabling">Setting Up and Enabling Enhanced Monitoring</a>
    #               in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #           <p>If <code>MonitoringInterval</code> is set to a value other than 0,
    #               then you must supply a <code>MonitoringRoleArn</code> value.</p>
    #
    # @option params [Boolean] :enable_iam_database_authentication
    #   <p>A value that indicates whether to enable mapping of Amazon Web Services Identity and Access Management
    #               (IAM) accounts to database accounts. By default, mapping isn't enabled.</p>
    #           <p>For more information about IAM database authentication, see
    #            <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.html">
    #                IAM Database Authentication for MySQL and PostgreSQL</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @option params [String] :source_engine
    #   <p>The name of the engine of your source database.</p>
    #           <p>Valid Values:
    #               <code>mysql</code>
    #            </p>
    #
    # @option params [String] :source_engine_version
    #   <p>The version of the database that the backup files were created from.</p>
    #           <p>MySQL versions 5.6 and 5.7 are supported.</p>
    #           <p>Example: <code>5.6.40</code>
    #            </p>
    #
    # @option params [String] :s3_bucket_name
    #   <p>The name of your Amazon S3 bucket
    #               that contains your database backup file.</p>
    #
    # @option params [String] :s3_prefix
    #   <p>The prefix of your Amazon S3 bucket.</p>
    #
    # @option params [String] :s3_ingestion_role_arn
    #   <p>An Amazon Web Services Identity and Access Management (IAM) role to allow Amazon RDS to access your Amazon S3 bucket.</p>
    #
    # @option params [Boolean] :enable_performance_insights
    #   <p>A value that indicates whether to enable Performance Insights for the DB instance.</p>
    #           <p>For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PerfInsights.html">Using Amazon Performance Insights</a> in the <i>Amazon RDS User Guide.</i>.</p>
    #
    # @option params [String] :performance_insights_kms_key_id
    #   <p>The Amazon Web Services KMS key identifier for encryption of Performance Insights data.</p>
    #           <p>The Amazon Web Services KMS key identifier is the key ARN, key ID, alias ARN, or alias name for the KMS key.</p>
    #           <p>If you do not specify a value for <code>PerformanceInsightsKMSKeyId</code>, then Amazon RDS
    #               uses your default KMS key. There is a default KMS key for your Amazon Web Services account.
    #               Your Amazon Web Services account has a different default KMS key for each Amazon Web Services Region.</p>
    #
    # @option params [Integer] :performance_insights_retention_period
    #   <p>The amount of time, in days, to retain Performance Insights data. Valid values are 7 or 731 (2 years).</p>
    #
    # @option params [Array<String>] :enable_cloudwatch_logs_exports
    #   <p>The list of logs that the restored DB instance is to export to CloudWatch Logs. The values
    #               in the list depend on the DB engine being used. For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.html#USER_LogAccess.Procedural.UploadtoCloudWatch">Publishing Database Logs to Amazon CloudWatch Logs</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @option params [Array<ProcessorFeature>] :processor_features
    #   <p>The number of CPU cores and the number of threads per core for the DB instance class of the DB instance.</p>
    #
    # @option params [Boolean] :use_default_processor_features
    #   <p>A value that indicates whether the DB instance class of the DB instance uses its default
    #               processor features.</p>
    #
    # @option params [Boolean] :deletion_protection
    #   <p>A value that indicates whether the DB instance has deletion protection enabled.
    #               The database can't be deleted when deletion protection is enabled. By default,
    #               deletion protection isn't enabled. For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_DeleteInstance.html">
    #                   Deleting a DB Instance</a>.</p>
    #
    # @option params [Integer] :max_allocated_storage
    #   <p>The upper limit in gibibytes (GiB) to which Amazon RDS can automatically scale the storage of the DB instance.</p>
    #           <p>For more information about this setting, including limitations that apply to it, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIOPS.StorageTypes.html#USER_PIOPS.Autoscaling">
    #                   Managing capacity automatically with Amazon RDS storage autoscaling</a>
    #               in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @option params [String] :network_type
    #   <p>The network type of the DB instance.</p>
    #           <p>Valid values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>IPV4</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>DUAL</code>
    #                  </p>
    #               </li>
    #            </ul>
    #           <p>The network type is determined by the <code>DBSubnetGroup</code> specified for the DB instance.
    #               A <code>DBSubnetGroup</code> can support only the IPv4 protocol or the IPv4 and the IPv6
    #               protocols (<code>DUAL</code>).</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.WorkingWithRDSInstanceinaVPC.html">
    #               Working with a DB instance in a VPC</a> in the
    #               <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @return [Types::RestoreDBInstanceFromS3Output]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.restore_db_instance_from_s3(
    #     db_name: 'DBName',
    #     db_instance_identifier: 'DBInstanceIdentifier', # required
    #     allocated_storage: 1,
    #     db_instance_class: 'DBInstanceClass', # required
    #     engine: 'Engine', # required
    #     master_username: 'MasterUsername',
    #     master_user_password: 'MasterUserPassword',
    #     db_security_groups: [
    #       'member'
    #     ],
    #     vpc_security_group_ids: [
    #       'member'
    #     ],
    #     availability_zone: 'AvailabilityZone',
    #     db_subnet_group_name: 'DBSubnetGroupName',
    #     preferred_maintenance_window: 'PreferredMaintenanceWindow',
    #     db_parameter_group_name: 'DBParameterGroupName',
    #     backup_retention_period: 1,
    #     preferred_backup_window: 'PreferredBackupWindow',
    #     port: 1,
    #     multi_az: false,
    #     engine_version: 'EngineVersion',
    #     auto_minor_version_upgrade: false,
    #     license_model: 'LicenseModel',
    #     iops: 1,
    #     option_group_name: 'OptionGroupName',
    #     publicly_accessible: false,
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ],
    #     storage_type: 'StorageType',
    #     storage_encrypted: false,
    #     kms_key_id: 'KmsKeyId',
    #     copy_tags_to_snapshot: false,
    #     monitoring_interval: 1,
    #     monitoring_role_arn: 'MonitoringRoleArn',
    #     enable_iam_database_authentication: false,
    #     source_engine: 'SourceEngine', # required
    #     source_engine_version: 'SourceEngineVersion', # required
    #     s3_bucket_name: 'S3BucketName', # required
    #     s3_prefix: 'S3Prefix',
    #     s3_ingestion_role_arn: 'S3IngestionRoleArn', # required
    #     enable_performance_insights: false,
    #     performance_insights_kms_key_id: 'PerformanceInsightsKMSKeyId',
    #     performance_insights_retention_period: 1,
    #     enable_cloudwatch_logs_exports: [
    #       'member'
    #     ],
    #     processor_features: [
    #       {
    #         name: 'Name',
    #         value: 'Value'
    #       }
    #     ],
    #     use_default_processor_features: false,
    #     deletion_protection: false,
    #     max_allocated_storage: 1,
    #     network_type: 'NetworkType'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::RestoreDBInstanceFromS3Output
    #   resp.data.db_instance #=> Types::DBInstance
    #   resp.data.db_instance.db_instance_identifier #=> String
    #   resp.data.db_instance.db_instance_class #=> String
    #   resp.data.db_instance.engine #=> String
    #   resp.data.db_instance.db_instance_status #=> String
    #   resp.data.db_instance.automatic_restart_time #=> Time
    #   resp.data.db_instance.master_username #=> String
    #   resp.data.db_instance.db_name #=> String
    #   resp.data.db_instance.endpoint #=> Types::Endpoint
    #   resp.data.db_instance.endpoint.address #=> String
    #   resp.data.db_instance.endpoint.port #=> Integer
    #   resp.data.db_instance.endpoint.hosted_zone_id #=> String
    #   resp.data.db_instance.allocated_storage #=> Integer
    #   resp.data.db_instance.instance_create_time #=> Time
    #   resp.data.db_instance.preferred_backup_window #=> String
    #   resp.data.db_instance.backup_retention_period #=> Integer
    #   resp.data.db_instance.db_security_groups #=> Array<DBSecurityGroupMembership>
    #   resp.data.db_instance.db_security_groups[0] #=> Types::DBSecurityGroupMembership
    #   resp.data.db_instance.db_security_groups[0].db_security_group_name #=> String
    #   resp.data.db_instance.db_security_groups[0].status #=> String
    #   resp.data.db_instance.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_instance.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_instance.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_instance.vpc_security_groups[0].status #=> String
    #   resp.data.db_instance.db_parameter_groups #=> Array<DBParameterGroupStatus>
    #   resp.data.db_instance.db_parameter_groups[0] #=> Types::DBParameterGroupStatus
    #   resp.data.db_instance.db_parameter_groups[0].db_parameter_group_name #=> String
    #   resp.data.db_instance.db_parameter_groups[0].parameter_apply_status #=> String
    #   resp.data.db_instance.availability_zone #=> String
    #   resp.data.db_instance.db_subnet_group #=> Types::DBSubnetGroup
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_name #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_description #=> String
    #   resp.data.db_instance.db_subnet_group.vpc_id #=> String
    #   resp.data.db_instance.db_subnet_group.subnet_group_status #=> String
    #   resp.data.db_instance.db_subnet_group.subnets #=> Array<Subnet>
    #   resp.data.db_instance.db_subnet_group.subnets[0] #=> Types::Subnet
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_identifier #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone #=> Types::AvailabilityZone
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone.name #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost #=> Types::Outpost
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost.arn #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_status #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_arn #=> String
    #   resp.data.db_instance.db_subnet_group.supported_network_types #=> Array<String>
    #   resp.data.db_instance.db_subnet_group.supported_network_types[0] #=> String
    #   resp.data.db_instance.preferred_maintenance_window #=> String
    #   resp.data.db_instance.pending_modified_values #=> Types::PendingModifiedValues
    #   resp.data.db_instance.pending_modified_values.db_instance_class #=> String
    #   resp.data.db_instance.pending_modified_values.allocated_storage #=> Integer
    #   resp.data.db_instance.pending_modified_values.master_user_password #=> String
    #   resp.data.db_instance.pending_modified_values.port #=> Integer
    #   resp.data.db_instance.pending_modified_values.backup_retention_period #=> Integer
    #   resp.data.db_instance.pending_modified_values.multi_az #=> Boolean
    #   resp.data.db_instance.pending_modified_values.engine_version #=> String
    #   resp.data.db_instance.pending_modified_values.license_model #=> String
    #   resp.data.db_instance.pending_modified_values.iops #=> Integer
    #   resp.data.db_instance.pending_modified_values.db_instance_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.storage_type #=> String
    #   resp.data.db_instance.pending_modified_values.ca_certificate_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.db_subnet_group_name #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable[0] #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.pending_modified_values.processor_features[0] #=> Types::ProcessorFeature
    #   resp.data.db_instance.pending_modified_values.processor_features[0].name #=> String
    #   resp.data.db_instance.pending_modified_values.processor_features[0].value #=> String
    #   resp.data.db_instance.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.pending_modified_values.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.pending_modified_values.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.latest_restorable_time #=> Time
    #   resp.data.db_instance.multi_az #=> Boolean
    #   resp.data.db_instance.engine_version #=> String
    #   resp.data.db_instance.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_instance.read_replica_source_db_instance_identifier #=> String
    #   resp.data.db_instance.read_replica_db_instance_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_instance_identifiers[0] #=> String
    #   resp.data.db_instance.read_replica_db_cluster_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_cluster_identifiers[0] #=> String
    #   resp.data.db_instance.replica_mode #=> String, one of ["open-read-only", "mounted"]
    #   resp.data.db_instance.license_model #=> String
    #   resp.data.db_instance.iops #=> Integer
    #   resp.data.db_instance.option_group_memberships #=> Array<OptionGroupMembership>
    #   resp.data.db_instance.option_group_memberships[0] #=> Types::OptionGroupMembership
    #   resp.data.db_instance.option_group_memberships[0].option_group_name #=> String
    #   resp.data.db_instance.option_group_memberships[0].status #=> String
    #   resp.data.db_instance.character_set_name #=> String
    #   resp.data.db_instance.nchar_character_set_name #=> String
    #   resp.data.db_instance.secondary_availability_zone #=> String
    #   resp.data.db_instance.publicly_accessible #=> Boolean
    #   resp.data.db_instance.status_infos #=> Array<DBInstanceStatusInfo>
    #   resp.data.db_instance.status_infos[0] #=> Types::DBInstanceStatusInfo
    #   resp.data.db_instance.status_infos[0].status_type #=> String
    #   resp.data.db_instance.status_infos[0].normal #=> Boolean
    #   resp.data.db_instance.status_infos[0].status #=> String
    #   resp.data.db_instance.status_infos[0].message #=> String
    #   resp.data.db_instance.storage_type #=> String
    #   resp.data.db_instance.tde_credential_arn #=> String
    #   resp.data.db_instance.db_instance_port #=> Integer
    #   resp.data.db_instance.db_cluster_identifier #=> String
    #   resp.data.db_instance.storage_encrypted #=> Boolean
    #   resp.data.db_instance.kms_key_id #=> String
    #   resp.data.db_instance.dbi_resource_id #=> String
    #   resp.data.db_instance.ca_certificate_identifier #=> String
    #   resp.data.db_instance.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_instance.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_instance.domain_memberships[0].domain #=> String
    #   resp.data.db_instance.domain_memberships[0].status #=> String
    #   resp.data.db_instance.domain_memberships[0].fqdn #=> String
    #   resp.data.db_instance.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_instance.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_instance.monitoring_interval #=> Integer
    #   resp.data.db_instance.enhanced_monitoring_resource_arn #=> String
    #   resp.data.db_instance.monitoring_role_arn #=> String
    #   resp.data.db_instance.promotion_tier #=> Integer
    #   resp.data.db_instance.db_instance_arn #=> String
    #   resp.data.db_instance.timezone #=> String
    #   resp.data.db_instance.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_kms_key_id #=> String
    #   resp.data.db_instance.performance_insights_retention_period #=> Integer
    #   resp.data.db_instance.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_instance.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.deletion_protection #=> Boolean
    #   resp.data.db_instance.associated_roles #=> Array<DBInstanceRole>
    #   resp.data.db_instance.associated_roles[0] #=> Types::DBInstanceRole
    #   resp.data.db_instance.associated_roles[0].role_arn #=> String
    #   resp.data.db_instance.associated_roles[0].feature_name #=> String
    #   resp.data.db_instance.associated_roles[0].status #=> String
    #   resp.data.db_instance.listener_endpoint #=> Types::Endpoint
    #   resp.data.db_instance.max_allocated_storage #=> Integer
    #   resp.data.db_instance.tag_list #=> Array<Tag>
    #   resp.data.db_instance.tag_list[0] #=> Types::Tag
    #   resp.data.db_instance.tag_list[0].key #=> String
    #   resp.data.db_instance.tag_list[0].value #=> String
    #   resp.data.db_instance.db_instance_automated_backups_replications #=> Array<DBInstanceAutomatedBackupsReplication>
    #   resp.data.db_instance.db_instance_automated_backups_replications[0] #=> Types::DBInstanceAutomatedBackupsReplication
    #   resp.data.db_instance.db_instance_automated_backups_replications[0].db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance.customer_owned_ip_enabled #=> Boolean
    #   resp.data.db_instance.aws_backup_recovery_point_arn #=> String
    #   resp.data.db_instance.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_instance.activity_stream_kms_key_id #=> String
    #   resp.data.db_instance.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_instance.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_instance.activity_stream_engine_native_audit_fields_included #=> Boolean
    #   resp.data.db_instance.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.custom_iam_instance_profile #=> String
    #   resp.data.db_instance.backup_target #=> String
    #   resp.data.db_instance.network_type #=> String
    #
    def restore_db_instance_from_s3(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::RestoreDBInstanceFromS3Input.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::RestoreDBInstanceFromS3Input,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::RestoreDBInstanceFromS3
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBSubnetGroupDoesNotCoverEnoughAZs, Errors::DBSubnetGroupNotFoundFault, Errors::KMSKeyNotAccessibleFault, Errors::InstanceQuotaExceededFault, Errors::OptionGroupNotFoundFault, Errors::InvalidVPCNetworkStateFault, Errors::StorageQuotaExceededFault, Errors::InvalidSubnet, Errors::DBInstanceAlreadyExistsFault, Errors::InsufficientDBInstanceCapacityFault, Errors::NetworkTypeNotSupported, Errors::DBSecurityGroupNotFoundFault, Errors::ProvisionedIopsNotAvailableInAZFault, Errors::AuthorizationNotFoundFault, Errors::InvalidS3BucketFault, Errors::StorageTypeNotSupportedFault, Errors::DBParameterGroupNotFoundFault, Errors::BackupPolicyNotFoundFault]),
        data_parser: Parsers::RestoreDBInstanceFromS3
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::RestoreDBInstanceFromS3,
        stubs: @stubs,
        params_class: Params::RestoreDBInstanceFromS3Output
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :restore_db_instance_from_s3
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Restores a DB instance to an arbitrary point in time. You can restore to any point in time before the time identified by the LatestRestorableTime property. You can restore to a point up to the number of days specified by the BackupRetentionPeriod property.</p>
    #         <p>The target database is created with most of the original configuration, but in a
    #             system-selected Availability Zone, with the default security group, the default subnet
    #             group, and the default DB parameter group. By default, the new DB instance is created as
    #             a single-AZ deployment except when the instance is a SQL Server instance that has an
    #             option group that is associated with mirroring; in this case, the instance becomes a
    #             mirrored deployment and not a single-AZ deployment.</p>
    #         <note>
    #             <p>This command doesn't apply to Aurora MySQL and Aurora PostgreSQL. For Aurora, use <code>RestoreDBClusterToPointInTime</code>.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::RestoreDBInstanceToPointInTimeInput}.
    #
    # @option params [String] :source_db_instance_identifier
    #   <p>The identifier of the source DB instance from which to restore.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must match the identifier of an existing DB instance.</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :target_db_instance_identifier
    #   <p>The name of the new DB instance to be created.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must contain from 1 to 63 letters, numbers, or hyphens</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens</p>
    #               </li>
    #            </ul>
    #
    # @option params [Time] :restore_time
    #   <p>The date and time to restore from.</p>
    #           <p>Valid Values: Value must be a time in Universal Coordinated Time (UTC) format</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>Must be before the latest restorable time for the DB instance</p>
    #               </li>
    #               <li>
    #                   <p>Can't be specified if the <code>UseLatestRestorableTime</code> parameter is enabled</p>
    #               </li>
    #            </ul>
    #           <p>Example: <code>2009-09-07T23:45:00Z</code>
    #            </p>
    #
    # @option params [Boolean] :use_latest_restorable_time
    #   <p>A value that indicates whether the DB instance is restored from the latest backup time. By default, the DB instance
    #             isn't restored from the latest backup time.</p>
    #           <p>Constraints: Can't be specified if the <code>RestoreTime</code> parameter is provided.</p>
    #
    # @option params [String] :db_instance_class
    #   <p>The compute and memory capacity of the Amazon RDS DB instance, for example
    #                   db.m4.large. Not all DB instance classes are available in all Amazon Web Services
    #               Regions, or for all database engines. For the full list of DB instance classes, and
    #               availability for your engine, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html">DB Instance
    #                   Class</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>Default: The same DBInstanceClass as the original DB instance.</p>
    #
    # @option params [Integer] :port
    #   <p>The port number on which the database accepts connections.</p>
    #           <p>Constraints: Value must be <code>1150-65535</code>
    #            </p>
    #           <p>Default: The same port as the original DB instance.</p>
    #
    # @option params [String] :availability_zone
    #   <p>The Availability Zone (AZ) where the DB instance will be created.</p>
    #           <p>Default: A random, system-chosen Availability Zone.</p>
    #           <p>Constraint: You can't specify the <code>AvailabilityZone</code> parameter if the DB instance is a Multi-AZ deployment.</p>
    #           <p>Example: <code>us-east-1a</code>
    #            </p>
    #
    # @option params [String] :db_subnet_group_name
    #   <p>The DB subnet group name to use for the new instance.</p>
    #           <p>Constraints: If supplied, must match the name of an existing DBSubnetGroup.</p>
    #           <p>Example: <code>mydbsubnetgroup</code>
    #            </p>
    #
    # @option params [Boolean] :multi_az
    #   <p>A value that indicates whether the DB instance is a Multi-AZ deployment.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Constraint: You can't specify the <code>AvailabilityZone</code> parameter if the DB instance is a
    #             Multi-AZ deployment.</p>
    #
    # @option params [Boolean] :publicly_accessible
    #   <p>A value that indicates whether the DB instance is publicly accessible.</p>
    #           <p>When the DB cluster is publicly accessible, its Domain Name System (DNS) endpoint
    #             resolves to the private IP address from within the DB cluster's virtual private cloud
    #             (VPC). It resolves to the public IP address from outside of the DB cluster's VPC. Access
    #             to the DB cluster is ultimately controlled by the security group it uses. That public
    #             access isn't permitted if the security group assigned to the DB cluster doesn't permit
    #             it.</p>
    #           <p>When the DB instance isn't publicly accessible, it is an internal DB instance with a DNS name that resolves to a private IP address.</p>
    #           <p>For more information, see <a>CreateDBInstance</a>.</p>
    #
    # @option params [Boolean] :auto_minor_version_upgrade
    #   <p>A value that indicates whether minor version upgrades are applied automatically to the
    #             DB instance during the maintenance window.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :license_model
    #   <p>License model information for the restored DB instance.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Default: Same as source.</p>
    #           <p>Valid values:  <code>license-included</code> | <code>bring-your-own-license</code> | <code>general-public-license</code>
    #            </p>
    #
    # @option params [String] :db_name
    #   <p>The database name for the restored DB instance.</p>
    #           <note>
    #               <p>This parameter isn't supported for the MySQL or MariaDB engines. It also doesn't apply to RDS Custom.</p>
    #           </note>
    #
    # @option params [String] :engine
    #   <p>The database engine to use for the new instance.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Default: The same as source</p>
    #           <p>Constraint: Must be compatible with the engine of the source</p>
    #           <p>Valid Values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>mariadb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>mysql</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-ee-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>oracle-se2-cdb</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>postgres</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ee</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-se</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-ex</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>sqlserver-web</code>
    #                  </p>
    #               </li>
    #            </ul>
    #
    # @option params [Integer] :iops
    #   <p>The amount of Provisioned IOPS (input/output operations per second) to be initially allocated for the DB instance.</p>
    #           <p>Constraints: Must be an integer greater than 1000.</p>
    #           <p>
    #               <b>SQL Server</b>
    #            </p>
    #           <p>Setting the IOPS value for the SQL Server database engine isn't supported.</p>
    #
    # @option params [String] :option_group_name
    #   <p>The name of the option group to be used for the restored DB instance.</p>
    #
    #
    #           <p>Permanent options, such as the TDE option for Oracle Advanced Security TDE, can't be removed from an
    #           option group, and that option group can't be removed from a DB instance after it is associated with a DB instance</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :copy_tags_to_snapshot
    #   <p>A value that indicates whether to copy all tags from the restored DB instance to snapshots of the DB instance. By default, tags are not copied.</p>
    #
    # @option params [Array<Tag>] :tags
    #   <p>A list of tags.
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Tagging.html">Tagging Amazon RDS Resources</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @option params [String] :storage_type
    #   <p>Specifies the storage type to be associated with the DB instance.</p>
    #           <p>Valid values: <code>standard | gp2 | io1</code>
    #            </p>
    #           <p>If you specify <code>io1</code>, you must also include a value for the
    #               <code>Iops</code> parameter.</p>
    #           <p>Default: <code>io1</code> if the <code>Iops</code> parameter
    #               is specified, otherwise <code>gp2</code>
    #            </p>
    #
    # @option params [String] :tde_credential_arn
    #   <p>The ARN from the key store with which to associate the instance for TDE encryption.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :tde_credential_password
    #   <p>The password for the given ARN from the key store in order to access the device.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Array<String>] :vpc_security_group_ids
    #   <p>A list of EC2 VPC security groups to associate with this DB instance.</p>
    #           <p>Default: The default EC2 VPC security group for the DB subnet group's VPC.</p>
    #
    # @option params [String] :domain
    #   <p>Specify the Active Directory directory ID to restore the DB instance in.
    #             Create the domain before running this command. Currently, you can create only the MySQL, Microsoft SQL
    #             Server, Oracle, and PostgreSQL DB instances in an Active Directory Domain.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/kerberos-authentication.html">
    #             Kerberos Authentication</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @option params [String] :domain_iam_role_name
    #   <p>Specify the name of the IAM role to be used when making API calls to the Directory Service.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :enable_iam_database_authentication
    #   <p>A value that indicates whether to enable mapping of Amazon Web Services Identity and Access Management
    #               (IAM) accounts to database accounts. By default, mapping isn't enabled.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>For more information about IAM database authentication, see
    #           <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.html">
    #               IAM Database Authentication for MySQL and PostgreSQL</a> in the <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @option params [Array<String>] :enable_cloudwatch_logs_exports
    #   <p>The list of logs that the restored DB instance is to export to CloudWatch Logs. The values
    #               in the list depend on the DB engine being used. For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.html#USER_LogAccess.Procedural.UploadtoCloudWatch">Publishing Database Logs to Amazon CloudWatch Logs</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Array<ProcessorFeature>] :processor_features
    #   <p>The number of CPU cores and the number of threads per core for the DB instance class of the DB instance.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :use_default_processor_features
    #   <p>A value that indicates whether the DB instance class of the DB instance uses its default processor features.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :db_parameter_group_name
    #   <p>The name of the DB parameter group to associate with this DB instance.</p>
    #           <p>If you do not specify a value for <code>DBParameterGroupName</code>, then the default <code>DBParameterGroup</code>
    #                   for the specified DB engine is used.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>Constraints:</p>
    #           <ul>
    #               <li>
    #                   <p>If supplied, must match the name of an existing DBParameterGroup.</p>
    #               </li>
    #               <li>
    #                   <p>Must be 1 to 255 letters, numbers, or hyphens.</p>
    #               </li>
    #               <li>
    #                   <p>First character must be a letter.</p>
    #               </li>
    #               <li>
    #                   <p>Can't end with a hyphen or contain two consecutive hyphens.</p>
    #               </li>
    #            </ul>
    #
    # @option params [Boolean] :deletion_protection
    #   <p>A value that indicates whether the DB instance has deletion protection enabled.
    #               The database can't be deleted when deletion protection is enabled. By default,
    #               deletion protection isn't enabled. For more information, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_DeleteInstance.html">
    #                   Deleting a DB Instance</a>.</p>
    #
    # @option params [String] :source_dbi_resource_id
    #   <p>The resource ID of the source DB instance from which to restore.</p>
    #
    # @option params [Integer] :max_allocated_storage
    #   <p>The upper limit in gibibytes (GiB) to which Amazon RDS can automatically scale the storage of the DB instance.</p>
    #           <p>For more information about this setting, including limitations that apply to it, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIOPS.StorageTypes.html#USER_PIOPS.Autoscaling">
    #                 Managing capacity automatically with Amazon RDS storage autoscaling</a>
    #             in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [String] :source_db_instance_automated_backups_arn
    #   <p>The Amazon Resource Name (ARN) of the replicated automated backups from which to restore, for example,
    #               <code>arn:aws:rds:useast-1:123456789012:auto-backup:ab-L2IJCEXJP7XQ7HOJ4SIEXAMPLE</code>.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #
    # @option params [Boolean] :enable_customer_owned_ip
    #   <p>A value that indicates whether to enable a customer-owned IP address (CoIP) for an RDS on Outposts DB instance.</p>
    #           <p>A <i>CoIP</i> provides local or external connectivity to resources in
    #               your Outpost subnets through your on-premises network. For some use cases, a CoIP can
    #               provide lower latency for connections to the DB instance from outside of its virtual
    #               private cloud (VPC) on your local network.</p>
    #           <p>This setting doesn't apply to RDS Custom.</p>
    #           <p>For more information about RDS on Outposts, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-on-outposts.html">Working with Amazon RDS on Amazon Web Services Outposts</a>
    #               in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>For more information about CoIPs, see <a href="https://docs.aws.amazon.com/outposts/latest/userguide/outposts-networking-components.html#ip-addressing">Customer-owned IP addresses</a>
    #               in the <i>Amazon Web Services Outposts User Guide</i>.</p>
    #
    # @option params [String] :custom_iam_instance_profile
    #   <p>The instance profile associated with the underlying Amazon EC2 instance of an
    #               RDS Custom DB instance. The instance profile must meet the following requirements:</p>
    #           <ul>
    #               <li>
    #                   <p>The profile must exist in your account.</p>
    #               </li>
    #               <li>
    #                   <p>The profile must have an IAM role that Amazon EC2 has permissions to assume.</p>
    #               </li>
    #               <li>
    #                   <p>The instance profile name and the associated IAM role name must start with the prefix <code>AWSRDSCustom</code>.</p>
    #               </li>
    #            </ul>
    #           <p>For the list of permissions required for the IAM role, see
    #               <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/custom-setup-orcl.html#custom-setup-orcl.iam-vpc">
    #                   Configure IAM and your VPC</a> in the <i>Amazon RDS User Guide</i>.</p>
    #           <p>This setting is required for RDS Custom.</p>
    #
    # @option params [String] :backup_target
    #   <p>Specifies where automated backups and manual snapshots are stored for the restored DB instance.</p>
    #           <p>Possible values are <code>outposts</code> (Amazon Web Services Outposts) and <code>region</code> (Amazon Web Services Region). The default is <code>region</code>.</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-on-outposts.html">Working
    #               with Amazon RDS on Amazon Web Services Outposts</a> in the <i>Amazon RDS User Guide</i>.</p>
    #
    # @option params [String] :network_type
    #   <p>The network type of the DB instance.</p>
    #           <p>Valid values:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>IPV4</code>
    #                  </p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>DUAL</code>
    #                  </p>
    #               </li>
    #            </ul>
    #           <p>The network type is determined by the <code>DBSubnetGroup</code> specified for the DB instance.
    #               A <code>DBSubnetGroup</code> can support only the IPv4 protocol or the IPv4 and the IPv6
    #               protocols (<code>DUAL</code>).</p>
    #           <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.WorkingWithRDSInstanceinaVPC.html">
    #               Working with a DB instance in a VPC</a> in the
    #               <i>Amazon RDS User Guide.</i>
    #            </p>
    #
    # @return [Types::RestoreDBInstanceToPointInTimeOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.restore_db_instance_to_point_in_time(
    #     source_db_instance_identifier: 'SourceDBInstanceIdentifier',
    #     target_db_instance_identifier: 'TargetDBInstanceIdentifier', # required
    #     restore_time: Time.now,
    #     use_latest_restorable_time: false,
    #     db_instance_class: 'DBInstanceClass',
    #     port: 1,
    #     availability_zone: 'AvailabilityZone',
    #     db_subnet_group_name: 'DBSubnetGroupName',
    #     multi_az: false,
    #     publicly_accessible: false,
    #     auto_minor_version_upgrade: false,
    #     license_model: 'LicenseModel',
    #     db_name: 'DBName',
    #     engine: 'Engine',
    #     iops: 1,
    #     option_group_name: 'OptionGroupName',
    #     copy_tags_to_snapshot: false,
    #     tags: [
    #       {
    #         key: 'Key',
    #         value: 'Value'
    #       }
    #     ],
    #     storage_type: 'StorageType',
    #     tde_credential_arn: 'TdeCredentialArn',
    #     tde_credential_password: 'TdeCredentialPassword',
    #     vpc_security_group_ids: [
    #       'member'
    #     ],
    #     domain: 'Domain',
    #     domain_iam_role_name: 'DomainIAMRoleName',
    #     enable_iam_database_authentication: false,
    #     enable_cloudwatch_logs_exports: [
    #       'member'
    #     ],
    #     processor_features: [
    #       {
    #         name: 'Name',
    #         value: 'Value'
    #       }
    #     ],
    #     use_default_processor_features: false,
    #     db_parameter_group_name: 'DBParameterGroupName',
    #     deletion_protection: false,
    #     source_dbi_resource_id: 'SourceDbiResourceId',
    #     max_allocated_storage: 1,
    #     source_db_instance_automated_backups_arn: 'SourceDBInstanceAutomatedBackupsArn',
    #     enable_customer_owned_ip: false,
    #     custom_iam_instance_profile: 'CustomIamInstanceProfile',
    #     backup_target: 'BackupTarget',
    #     network_type: 'NetworkType'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::RestoreDBInstanceToPointInTimeOutput
    #   resp.data.db_instance #=> Types::DBInstance
    #   resp.data.db_instance.db_instance_identifier #=> String
    #   resp.data.db_instance.db_instance_class #=> String
    #   resp.data.db_instance.engine #=> String
    #   resp.data.db_instance.db_instance_status #=> String
    #   resp.data.db_instance.automatic_restart_time #=> Time
    #   resp.data.db_instance.master_username #=> String
    #   resp.data.db_instance.db_name #=> String
    #   resp.data.db_instance.endpoint #=> Types::Endpoint
    #   resp.data.db_instance.endpoint.address #=> String
    #   resp.data.db_instance.endpoint.port #=> Integer
    #   resp.data.db_instance.endpoint.hosted_zone_id #=> String
    #   resp.data.db_instance.allocated_storage #=> Integer
    #   resp.data.db_instance.instance_create_time #=> Time
    #   resp.data.db_instance.preferred_backup_window #=> String
    #   resp.data.db_instance.backup_retention_period #=> Integer
    #   resp.data.db_instance.db_security_groups #=> Array<DBSecurityGroupMembership>
    #   resp.data.db_instance.db_security_groups[0] #=> Types::DBSecurityGroupMembership
    #   resp.data.db_instance.db_security_groups[0].db_security_group_name #=> String
    #   resp.data.db_instance.db_security_groups[0].status #=> String
    #   resp.data.db_instance.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_instance.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_instance.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_instance.vpc_security_groups[0].status #=> String
    #   resp.data.db_instance.db_parameter_groups #=> Array<DBParameterGroupStatus>
    #   resp.data.db_instance.db_parameter_groups[0] #=> Types::DBParameterGroupStatus
    #   resp.data.db_instance.db_parameter_groups[0].db_parameter_group_name #=> String
    #   resp.data.db_instance.db_parameter_groups[0].parameter_apply_status #=> String
    #   resp.data.db_instance.availability_zone #=> String
    #   resp.data.db_instance.db_subnet_group #=> Types::DBSubnetGroup
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_name #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_description #=> String
    #   resp.data.db_instance.db_subnet_group.vpc_id #=> String
    #   resp.data.db_instance.db_subnet_group.subnet_group_status #=> String
    #   resp.data.db_instance.db_subnet_group.subnets #=> Array<Subnet>
    #   resp.data.db_instance.db_subnet_group.subnets[0] #=> Types::Subnet
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_identifier #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone #=> Types::AvailabilityZone
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone.name #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost #=> Types::Outpost
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost.arn #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_status #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_arn #=> String
    #   resp.data.db_instance.db_subnet_group.supported_network_types #=> Array<String>
    #   resp.data.db_instance.db_subnet_group.supported_network_types[0] #=> String
    #   resp.data.db_instance.preferred_maintenance_window #=> String
    #   resp.data.db_instance.pending_modified_values #=> Types::PendingModifiedValues
    #   resp.data.db_instance.pending_modified_values.db_instance_class #=> String
    #   resp.data.db_instance.pending_modified_values.allocated_storage #=> Integer
    #   resp.data.db_instance.pending_modified_values.master_user_password #=> String
    #   resp.data.db_instance.pending_modified_values.port #=> Integer
    #   resp.data.db_instance.pending_modified_values.backup_retention_period #=> Integer
    #   resp.data.db_instance.pending_modified_values.multi_az #=> Boolean
    #   resp.data.db_instance.pending_modified_values.engine_version #=> String
    #   resp.data.db_instance.pending_modified_values.license_model #=> String
    #   resp.data.db_instance.pending_modified_values.iops #=> Integer
    #   resp.data.db_instance.pending_modified_values.db_instance_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.storage_type #=> String
    #   resp.data.db_instance.pending_modified_values.ca_certificate_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.db_subnet_group_name #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable[0] #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.pending_modified_values.processor_features[0] #=> Types::ProcessorFeature
    #   resp.data.db_instance.pending_modified_values.processor_features[0].name #=> String
    #   resp.data.db_instance.pending_modified_values.processor_features[0].value #=> String
    #   resp.data.db_instance.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.pending_modified_values.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.pending_modified_values.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.latest_restorable_time #=> Time
    #   resp.data.db_instance.multi_az #=> Boolean
    #   resp.data.db_instance.engine_version #=> String
    #   resp.data.db_instance.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_instance.read_replica_source_db_instance_identifier #=> String
    #   resp.data.db_instance.read_replica_db_instance_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_instance_identifiers[0] #=> String
    #   resp.data.db_instance.read_replica_db_cluster_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_cluster_identifiers[0] #=> String
    #   resp.data.db_instance.replica_mode #=> String, one of ["open-read-only", "mounted"]
    #   resp.data.db_instance.license_model #=> String
    #   resp.data.db_instance.iops #=> Integer
    #   resp.data.db_instance.option_group_memberships #=> Array<OptionGroupMembership>
    #   resp.data.db_instance.option_group_memberships[0] #=> Types::OptionGroupMembership
    #   resp.data.db_instance.option_group_memberships[0].option_group_name #=> String
    #   resp.data.db_instance.option_group_memberships[0].status #=> String
    #   resp.data.db_instance.character_set_name #=> String
    #   resp.data.db_instance.nchar_character_set_name #=> String
    #   resp.data.db_instance.secondary_availability_zone #=> String
    #   resp.data.db_instance.publicly_accessible #=> Boolean
    #   resp.data.db_instance.status_infos #=> Array<DBInstanceStatusInfo>
    #   resp.data.db_instance.status_infos[0] #=> Types::DBInstanceStatusInfo
    #   resp.data.db_instance.status_infos[0].status_type #=> String
    #   resp.data.db_instance.status_infos[0].normal #=> Boolean
    #   resp.data.db_instance.status_infos[0].status #=> String
    #   resp.data.db_instance.status_infos[0].message #=> String
    #   resp.data.db_instance.storage_type #=> String
    #   resp.data.db_instance.tde_credential_arn #=> String
    #   resp.data.db_instance.db_instance_port #=> Integer
    #   resp.data.db_instance.db_cluster_identifier #=> String
    #   resp.data.db_instance.storage_encrypted #=> Boolean
    #   resp.data.db_instance.kms_key_id #=> String
    #   resp.data.db_instance.dbi_resource_id #=> String
    #   resp.data.db_instance.ca_certificate_identifier #=> String
    #   resp.data.db_instance.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_instance.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_instance.domain_memberships[0].domain #=> String
    #   resp.data.db_instance.domain_memberships[0].status #=> String
    #   resp.data.db_instance.domain_memberships[0].fqdn #=> String
    #   resp.data.db_instance.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_instance.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_instance.monitoring_interval #=> Integer
    #   resp.data.db_instance.enhanced_monitoring_resource_arn #=> String
    #   resp.data.db_instance.monitoring_role_arn #=> String
    #   resp.data.db_instance.promotion_tier #=> Integer
    #   resp.data.db_instance.db_instance_arn #=> String
    #   resp.data.db_instance.timezone #=> String
    #   resp.data.db_instance.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_kms_key_id #=> String
    #   resp.data.db_instance.performance_insights_retention_period #=> Integer
    #   resp.data.db_instance.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_instance.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.deletion_protection #=> Boolean
    #   resp.data.db_instance.associated_roles #=> Array<DBInstanceRole>
    #   resp.data.db_instance.associated_roles[0] #=> Types::DBInstanceRole
    #   resp.data.db_instance.associated_roles[0].role_arn #=> String
    #   resp.data.db_instance.associated_roles[0].feature_name #=> String
    #   resp.data.db_instance.associated_roles[0].status #=> String
    #   resp.data.db_instance.listener_endpoint #=> Types::Endpoint
    #   resp.data.db_instance.max_allocated_storage #=> Integer
    #   resp.data.db_instance.tag_list #=> Array<Tag>
    #   resp.data.db_instance.tag_list[0] #=> Types::Tag
    #   resp.data.db_instance.tag_list[0].key #=> String
    #   resp.data.db_instance.tag_list[0].value #=> String
    #   resp.data.db_instance.db_instance_automated_backups_replications #=> Array<DBInstanceAutomatedBackupsReplication>
    #   resp.data.db_instance.db_instance_automated_backups_replications[0] #=> Types::DBInstanceAutomatedBackupsReplication
    #   resp.data.db_instance.db_instance_automated_backups_replications[0].db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance.customer_owned_ip_enabled #=> Boolean
    #   resp.data.db_instance.aws_backup_recovery_point_arn #=> String
    #   resp.data.db_instance.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_instance.activity_stream_kms_key_id #=> String
    #   resp.data.db_instance.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_instance.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_instance.activity_stream_engine_native_audit_fields_included #=> Boolean
    #   resp.data.db_instance.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.custom_iam_instance_profile #=> String
    #   resp.data.db_instance.backup_target #=> String
    #   resp.data.db_instance.network_type #=> String
    #
    def restore_db_instance_to_point_in_time(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::RestoreDBInstanceToPointInTimeInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::RestoreDBInstanceToPointInTimeInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::RestoreDBInstanceToPointInTime
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBSubnetGroupDoesNotCoverEnoughAZs, Errors::DBSubnetGroupNotFoundFault, Errors::DBInstanceAutomatedBackupNotFoundFault, Errors::KMSKeyNotAccessibleFault, Errors::InstanceQuotaExceededFault, Errors::OptionGroupNotFoundFault, Errors::InvalidVPCNetworkStateFault, Errors::StorageQuotaExceededFault, Errors::InvalidSubnet, Errors::DBInstanceAlreadyExistsFault, Errors::InvalidDBInstanceStateFault, Errors::InsufficientDBInstanceCapacityFault, Errors::NetworkTypeNotSupported, Errors::DBInstanceNotFoundFault, Errors::DBSecurityGroupNotFoundFault, Errors::DomainNotFoundFault, Errors::ProvisionedIopsNotAvailableInAZFault, Errors::AuthorizationNotFoundFault, Errors::StorageTypeNotSupportedFault, Errors::DBParameterGroupNotFoundFault, Errors::BackupPolicyNotFoundFault, Errors::InvalidRestoreFault, Errors::PointInTimeRestoreNotEnabledFault]),
        data_parser: Parsers::RestoreDBInstanceToPointInTime
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::RestoreDBInstanceToPointInTime,
        stubs: @stubs,
        params_class: Params::RestoreDBInstanceToPointInTimeOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :restore_db_instance_to_point_in_time
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Revokes ingress from a DBSecurityGroup for previously authorized IP ranges or EC2 or VPC security groups. Required parameters for this API are one of CIDRIP, EC2SecurityGroupId for VPC, or (EC2SecurityGroupOwnerId and either EC2SecurityGroupName or EC2SecurityGroupId).</p>
    #
    # @param [Hash] params
    #   See {Types::RevokeDBSecurityGroupIngressInput}.
    #
    # @option params [String] :db_security_group_name
    #   <p>The name of the DB security group to revoke ingress from.</p>
    #
    # @option params [String] :cidrip
    #   <p>The IP range to revoke access from.
    #           Must be a valid CIDR range. If <code>CIDRIP</code> is specified,
    #           <code>EC2SecurityGroupName</code>, <code>EC2SecurityGroupId</code> and <code>EC2SecurityGroupOwnerId</code>
    #           can't be provided.</p>
    #
    # @option params [String] :ec2_security_group_name
    #   <p>The name of the EC2 security group to revoke access from.
    #           For VPC DB security groups, <code>EC2SecurityGroupId</code> must be provided.
    #           Otherwise, EC2SecurityGroupOwnerId and either <code>EC2SecurityGroupName</code> or <code>EC2SecurityGroupId</code> must be provided.</p>
    #
    # @option params [String] :ec2_security_group_id
    #   <p>The id of the EC2 security group to revoke access from.
    #           For VPC DB security groups, <code>EC2SecurityGroupId</code> must be provided.
    #           Otherwise, EC2SecurityGroupOwnerId and either <code>EC2SecurityGroupName</code> or <code>EC2SecurityGroupId</code> must be provided.</p>
    #
    # @option params [String] :ec2_security_group_owner_id
    #   <p>The Amazon Web Services account number of the owner of the EC2 security group
    #           specified in the <code>EC2SecurityGroupName</code> parameter.
    #           The Amazon Web Services access key ID isn't an acceptable value.
    #           For VPC DB security groups, <code>EC2SecurityGroupId</code> must be provided.
    #           Otherwise, EC2SecurityGroupOwnerId and either <code>EC2SecurityGroupName</code> or <code>EC2SecurityGroupId</code> must be provided.</p>
    #
    # @return [Types::RevokeDBSecurityGroupIngressOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.revoke_db_security_group_ingress(
    #     db_security_group_name: 'DBSecurityGroupName', # required
    #     cidrip: 'CIDRIP',
    #     ec2_security_group_name: 'EC2SecurityGroupName',
    #     ec2_security_group_id: 'EC2SecurityGroupId',
    #     ec2_security_group_owner_id: 'EC2SecurityGroupOwnerId'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::RevokeDBSecurityGroupIngressOutput
    #   resp.data.db_security_group #=> Types::DBSecurityGroup
    #   resp.data.db_security_group.owner_id #=> String
    #   resp.data.db_security_group.db_security_group_name #=> String
    #   resp.data.db_security_group.db_security_group_description #=> String
    #   resp.data.db_security_group.vpc_id #=> String
    #   resp.data.db_security_group.ec2_security_groups #=> Array<EC2SecurityGroup>
    #   resp.data.db_security_group.ec2_security_groups[0] #=> Types::EC2SecurityGroup
    #   resp.data.db_security_group.ec2_security_groups[0].status #=> String
    #   resp.data.db_security_group.ec2_security_groups[0].ec2_security_group_name #=> String
    #   resp.data.db_security_group.ec2_security_groups[0].ec2_security_group_id #=> String
    #   resp.data.db_security_group.ec2_security_groups[0].ec2_security_group_owner_id #=> String
    #   resp.data.db_security_group.ip_ranges #=> Array<IPRange>
    #   resp.data.db_security_group.ip_ranges[0] #=> Types::IPRange
    #   resp.data.db_security_group.ip_ranges[0].status #=> String
    #   resp.data.db_security_group.ip_ranges[0].cidrip #=> String
    #   resp.data.db_security_group.db_security_group_arn #=> String
    #
    def revoke_db_security_group_ingress(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::RevokeDBSecurityGroupIngressInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::RevokeDBSecurityGroupIngressInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::RevokeDBSecurityGroupIngress
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBSecurityGroupNotFoundFault, Errors::AuthorizationNotFoundFault, Errors::InvalidDBSecurityGroupStateFault]),
        data_parser: Parsers::RevokeDBSecurityGroupIngress
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::RevokeDBSecurityGroupIngress,
        stubs: @stubs,
        params_class: Params::RevokeDBSecurityGroupIngressOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :revoke_db_security_group_ingress
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Starts a database activity stream to monitor activity on the database.
    #             For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/DBActivityStreams.html">Database Activity Streams</a>
    #             in the <i>Amazon Aurora User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::StartActivityStreamInput}.
    #
    # @option params [String] :resource_arn
    #   <p>The Amazon Resource Name (ARN) of the DB cluster,
    #               for example, <code>arn:aws:rds:us-east-1:12345667890:cluster:das-cluster</code>.</p>
    #
    # @option params [String] :mode
    #   <p>Specifies the mode of the database activity stream.
    #               Database events such as a change or access generate an activity stream event.
    #               The database session can handle these events either synchronously or asynchronously.</p>
    #
    # @option params [String] :kms_key_id
    #   <p>The Amazon Web Services KMS key identifier for encrypting messages in the database activity stream.
    #               The Amazon Web Services KMS key identifier is the key ARN, key ID, alias ARN, or alias name for the KMS key.</p>
    #
    # @option params [Boolean] :apply_immediately
    #   <p>Specifies whether or not the database activity stream is to start as soon as possible,
    #               regardless of the maintenance window for the database.</p>
    #
    # @option params [Boolean] :engine_native_audit_fields_included
    #   <p>Specifies whether the database activity stream includes engine-native audit fields. This option only applies
    #           to an Oracle DB instance. By default, no engine-native audit fields are included.</p>
    #
    # @return [Types::StartActivityStreamOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.start_activity_stream(
    #     resource_arn: 'ResourceArn', # required
    #     mode: 'sync', # required - accepts ["sync", "async"]
    #     kms_key_id: 'KmsKeyId', # required
    #     apply_immediately: false,
    #     engine_native_audit_fields_included: false
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::StartActivityStreamOutput
    #   resp.data.kms_key_id #=> String
    #   resp.data.kinesis_stream_name #=> String
    #   resp.data.status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.mode #=> String, one of ["sync", "async"]
    #   resp.data.apply_immediately #=> Boolean
    #   resp.data.engine_native_audit_fields_included #=> Boolean
    #
    def start_activity_stream(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::StartActivityStreamInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::StartActivityStreamInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::StartActivityStream
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::DBInstanceNotFoundFault, Errors::KMSKeyNotAccessibleFault, Errors::InvalidDBClusterStateFault, Errors::InvalidDBInstanceStateFault, Errors::ResourceNotFoundFault]),
        data_parser: Parsers::StartActivityStream
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::StartActivityStream,
        stubs: @stubs,
        params_class: Params::StartActivityStreamOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :start_activity_stream
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Starts an Amazon Aurora DB cluster that was stopped using the Amazon Web Services console, the stop-db-cluster
    #        CLI command, or the StopDBCluster action.</p>
    #         <p>For more information, see
    #            <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-cluster-stop-start.html">
    #                Stopping and Starting an Aurora Cluster</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <note>
    #             <p>This action only applies to Aurora DB clusters.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::StartDBClusterInput}.
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The DB cluster identifier of the Amazon Aurora DB cluster to be started. This parameter is stored as
    #           a lowercase string.</p>
    #
    # @return [Types::StartDBClusterOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.start_db_cluster(
    #     db_cluster_identifier: 'DBClusterIdentifier' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::StartDBClusterOutput
    #   resp.data.db_cluster #=> Types::DBCluster
    #   resp.data.db_cluster.allocated_storage #=> Integer
    #   resp.data.db_cluster.availability_zones #=> Array<String>
    #   resp.data.db_cluster.availability_zones[0] #=> String
    #   resp.data.db_cluster.backup_retention_period #=> Integer
    #   resp.data.db_cluster.character_set_name #=> String
    #   resp.data.db_cluster.database_name #=> String
    #   resp.data.db_cluster.db_cluster_identifier #=> String
    #   resp.data.db_cluster.db_cluster_parameter_group #=> String
    #   resp.data.db_cluster.db_subnet_group #=> String
    #   resp.data.db_cluster.status #=> String
    #   resp.data.db_cluster.automatic_restart_time #=> Time
    #   resp.data.db_cluster.percent_progress #=> String
    #   resp.data.db_cluster.earliest_restorable_time #=> Time
    #   resp.data.db_cluster.endpoint #=> String
    #   resp.data.db_cluster.reader_endpoint #=> String
    #   resp.data.db_cluster.custom_endpoints #=> Array<String>
    #   resp.data.db_cluster.custom_endpoints[0] #=> String
    #   resp.data.db_cluster.multi_az #=> Boolean
    #   resp.data.db_cluster.engine #=> String
    #   resp.data.db_cluster.engine_version #=> String
    #   resp.data.db_cluster.latest_restorable_time #=> Time
    #   resp.data.db_cluster.port #=> Integer
    #   resp.data.db_cluster.master_username #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships #=> Array<DBClusterOptionGroupStatus>
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0] #=> Types::DBClusterOptionGroupStatus
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].db_cluster_option_group_name #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].status #=> String
    #   resp.data.db_cluster.preferred_backup_window #=> String
    #   resp.data.db_cluster.preferred_maintenance_window #=> String
    #   resp.data.db_cluster.replication_source_identifier #=> String
    #   resp.data.db_cluster.read_replica_identifiers #=> Array<String>
    #   resp.data.db_cluster.read_replica_identifiers[0] #=> String
    #   resp.data.db_cluster.db_cluster_members #=> Array<DBClusterMember>
    #   resp.data.db_cluster.db_cluster_members[0] #=> Types::DBClusterMember
    #   resp.data.db_cluster.db_cluster_members[0].db_instance_identifier #=> String
    #   resp.data.db_cluster.db_cluster_members[0].is_cluster_writer #=> Boolean
    #   resp.data.db_cluster.db_cluster_members[0].db_cluster_parameter_group_status #=> String
    #   resp.data.db_cluster.db_cluster_members[0].promotion_tier #=> Integer
    #   resp.data.db_cluster.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_cluster.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_cluster.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_cluster.vpc_security_groups[0].status #=> String
    #   resp.data.db_cluster.hosted_zone_id #=> String
    #   resp.data.db_cluster.storage_encrypted #=> Boolean
    #   resp.data.db_cluster.kms_key_id #=> String
    #   resp.data.db_cluster.db_cluster_resource_id #=> String
    #   resp.data.db_cluster.db_cluster_arn #=> String
    #   resp.data.db_cluster.associated_roles #=> Array<DBClusterRole>
    #   resp.data.db_cluster.associated_roles[0] #=> Types::DBClusterRole
    #   resp.data.db_cluster.associated_roles[0].role_arn #=> String
    #   resp.data.db_cluster.associated_roles[0].status #=> String
    #   resp.data.db_cluster.associated_roles[0].feature_name #=> String
    #   resp.data.db_cluster.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.clone_group_id #=> String
    #   resp.data.db_cluster.cluster_create_time #=> Time
    #   resp.data.db_cluster.earliest_backtrack_time #=> Time
    #   resp.data.db_cluster.backtrack_window #=> Integer
    #   resp.data.db_cluster.backtrack_consumed_change_records #=> Integer
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports[0] #=> String
    #   resp.data.db_cluster.capacity #=> Integer
    #   resp.data.db_cluster.engine_mode #=> String
    #   resp.data.db_cluster.scaling_configuration_info #=> Types::ScalingConfigurationInfo
    #   resp.data.db_cluster.scaling_configuration_info.min_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.max_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.auto_pause #=> Boolean
    #   resp.data.db_cluster.scaling_configuration_info.seconds_until_auto_pause #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.timeout_action #=> String
    #   resp.data.db_cluster.scaling_configuration_info.seconds_before_timeout #=> Integer
    #   resp.data.db_cluster.deletion_protection #=> Boolean
    #   resp.data.db_cluster.http_endpoint_enabled #=> Boolean
    #   resp.data.db_cluster.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_cluster.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_cluster.activity_stream_kms_key_id #=> String
    #   resp.data.db_cluster.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_cluster.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_cluster.cross_account_clone #=> Boolean
    #   resp.data.db_cluster.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_cluster.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_cluster.domain_memberships[0].domain #=> String
    #   resp.data.db_cluster.domain_memberships[0].status #=> String
    #   resp.data.db_cluster.domain_memberships[0].fqdn #=> String
    #   resp.data.db_cluster.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_cluster.tag_list #=> Array<Tag>
    #   resp.data.db_cluster.tag_list[0] #=> Types::Tag
    #   resp.data.db_cluster.tag_list[0].key #=> String
    #   resp.data.db_cluster.tag_list[0].value #=> String
    #   resp.data.db_cluster.global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.db_cluster.global_write_forwarding_requested #=> Boolean
    #   resp.data.db_cluster.pending_modified_values #=> Types::ClusterPendingModifiedValues
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.db_cluster_identifier #=> String
    #   resp.data.db_cluster.pending_modified_values.master_user_password #=> String
    #   resp.data.db_cluster.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.pending_modified_values.engine_version #=> String
    #   resp.data.db_cluster.db_cluster_instance_class #=> String
    #   resp.data.db_cluster.storage_type #=> String
    #   resp.data.db_cluster.iops #=> Integer
    #   resp.data.db_cluster.publicly_accessible #=> Boolean
    #   resp.data.db_cluster.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_cluster.monitoring_interval #=> Integer
    #   resp.data.db_cluster.monitoring_role_arn #=> String
    #   resp.data.db_cluster.performance_insights_enabled #=> Boolean
    #   resp.data.db_cluster.performance_insights_kms_key_id #=> String
    #   resp.data.db_cluster.performance_insights_retention_period #=> Integer
    #   resp.data.db_cluster.serverless_v2_scaling_configuration #=> Types::ServerlessV2ScalingConfigurationInfo
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.min_capacity #=> Float
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.max_capacity #=> Float
    #
    def start_db_cluster(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::StartDBClusterInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::StartDBClusterInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::StartDBCluster
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::InvalidDBClusterStateFault, Errors::InvalidDBInstanceStateFault]),
        data_parser: Parsers::StartDBCluster
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::StartDBCluster,
        stubs: @stubs,
        params_class: Params::StartDBClusterOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :start_db_cluster
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Starts an Amazon RDS DB instance that was stopped using the Amazon Web Services console, the stop-db-instance CLI command, or the StopDBInstance action.</p>
    #         <p>For more information, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_StartInstance.html">
    #                 Starting an Amazon RDS DB instance That Was Previously Stopped</a> in the
    #             <i>Amazon RDS User Guide.</i>
    #          </p>
    #         <note>
    #             <p>This command doesn't apply to RDS Custom, Aurora MySQL, and Aurora PostgreSQL.
    #             For Aurora DB clusters, use <code>StartDBCluster</code> instead.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::StartDBInstanceInput}.
    #
    # @option params [String] :db_instance_identifier
    #   <p>The user-supplied instance identifier.</p>
    #
    # @return [Types::StartDBInstanceOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.start_db_instance(
    #     db_instance_identifier: 'DBInstanceIdentifier' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::StartDBInstanceOutput
    #   resp.data.db_instance #=> Types::DBInstance
    #   resp.data.db_instance.db_instance_identifier #=> String
    #   resp.data.db_instance.db_instance_class #=> String
    #   resp.data.db_instance.engine #=> String
    #   resp.data.db_instance.db_instance_status #=> String
    #   resp.data.db_instance.automatic_restart_time #=> Time
    #   resp.data.db_instance.master_username #=> String
    #   resp.data.db_instance.db_name #=> String
    #   resp.data.db_instance.endpoint #=> Types::Endpoint
    #   resp.data.db_instance.endpoint.address #=> String
    #   resp.data.db_instance.endpoint.port #=> Integer
    #   resp.data.db_instance.endpoint.hosted_zone_id #=> String
    #   resp.data.db_instance.allocated_storage #=> Integer
    #   resp.data.db_instance.instance_create_time #=> Time
    #   resp.data.db_instance.preferred_backup_window #=> String
    #   resp.data.db_instance.backup_retention_period #=> Integer
    #   resp.data.db_instance.db_security_groups #=> Array<DBSecurityGroupMembership>
    #   resp.data.db_instance.db_security_groups[0] #=> Types::DBSecurityGroupMembership
    #   resp.data.db_instance.db_security_groups[0].db_security_group_name #=> String
    #   resp.data.db_instance.db_security_groups[0].status #=> String
    #   resp.data.db_instance.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_instance.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_instance.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_instance.vpc_security_groups[0].status #=> String
    #   resp.data.db_instance.db_parameter_groups #=> Array<DBParameterGroupStatus>
    #   resp.data.db_instance.db_parameter_groups[0] #=> Types::DBParameterGroupStatus
    #   resp.data.db_instance.db_parameter_groups[0].db_parameter_group_name #=> String
    #   resp.data.db_instance.db_parameter_groups[0].parameter_apply_status #=> String
    #   resp.data.db_instance.availability_zone #=> String
    #   resp.data.db_instance.db_subnet_group #=> Types::DBSubnetGroup
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_name #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_description #=> String
    #   resp.data.db_instance.db_subnet_group.vpc_id #=> String
    #   resp.data.db_instance.db_subnet_group.subnet_group_status #=> String
    #   resp.data.db_instance.db_subnet_group.subnets #=> Array<Subnet>
    #   resp.data.db_instance.db_subnet_group.subnets[0] #=> Types::Subnet
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_identifier #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone #=> Types::AvailabilityZone
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone.name #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost #=> Types::Outpost
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost.arn #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_status #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_arn #=> String
    #   resp.data.db_instance.db_subnet_group.supported_network_types #=> Array<String>
    #   resp.data.db_instance.db_subnet_group.supported_network_types[0] #=> String
    #   resp.data.db_instance.preferred_maintenance_window #=> String
    #   resp.data.db_instance.pending_modified_values #=> Types::PendingModifiedValues
    #   resp.data.db_instance.pending_modified_values.db_instance_class #=> String
    #   resp.data.db_instance.pending_modified_values.allocated_storage #=> Integer
    #   resp.data.db_instance.pending_modified_values.master_user_password #=> String
    #   resp.data.db_instance.pending_modified_values.port #=> Integer
    #   resp.data.db_instance.pending_modified_values.backup_retention_period #=> Integer
    #   resp.data.db_instance.pending_modified_values.multi_az #=> Boolean
    #   resp.data.db_instance.pending_modified_values.engine_version #=> String
    #   resp.data.db_instance.pending_modified_values.license_model #=> String
    #   resp.data.db_instance.pending_modified_values.iops #=> Integer
    #   resp.data.db_instance.pending_modified_values.db_instance_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.storage_type #=> String
    #   resp.data.db_instance.pending_modified_values.ca_certificate_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.db_subnet_group_name #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable[0] #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.pending_modified_values.processor_features[0] #=> Types::ProcessorFeature
    #   resp.data.db_instance.pending_modified_values.processor_features[0].name #=> String
    #   resp.data.db_instance.pending_modified_values.processor_features[0].value #=> String
    #   resp.data.db_instance.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.pending_modified_values.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.pending_modified_values.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.latest_restorable_time #=> Time
    #   resp.data.db_instance.multi_az #=> Boolean
    #   resp.data.db_instance.engine_version #=> String
    #   resp.data.db_instance.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_instance.read_replica_source_db_instance_identifier #=> String
    #   resp.data.db_instance.read_replica_db_instance_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_instance_identifiers[0] #=> String
    #   resp.data.db_instance.read_replica_db_cluster_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_cluster_identifiers[0] #=> String
    #   resp.data.db_instance.replica_mode #=> String, one of ["open-read-only", "mounted"]
    #   resp.data.db_instance.license_model #=> String
    #   resp.data.db_instance.iops #=> Integer
    #   resp.data.db_instance.option_group_memberships #=> Array<OptionGroupMembership>
    #   resp.data.db_instance.option_group_memberships[0] #=> Types::OptionGroupMembership
    #   resp.data.db_instance.option_group_memberships[0].option_group_name #=> String
    #   resp.data.db_instance.option_group_memberships[0].status #=> String
    #   resp.data.db_instance.character_set_name #=> String
    #   resp.data.db_instance.nchar_character_set_name #=> String
    #   resp.data.db_instance.secondary_availability_zone #=> String
    #   resp.data.db_instance.publicly_accessible #=> Boolean
    #   resp.data.db_instance.status_infos #=> Array<DBInstanceStatusInfo>
    #   resp.data.db_instance.status_infos[0] #=> Types::DBInstanceStatusInfo
    #   resp.data.db_instance.status_infos[0].status_type #=> String
    #   resp.data.db_instance.status_infos[0].normal #=> Boolean
    #   resp.data.db_instance.status_infos[0].status #=> String
    #   resp.data.db_instance.status_infos[0].message #=> String
    #   resp.data.db_instance.storage_type #=> String
    #   resp.data.db_instance.tde_credential_arn #=> String
    #   resp.data.db_instance.db_instance_port #=> Integer
    #   resp.data.db_instance.db_cluster_identifier #=> String
    #   resp.data.db_instance.storage_encrypted #=> Boolean
    #   resp.data.db_instance.kms_key_id #=> String
    #   resp.data.db_instance.dbi_resource_id #=> String
    #   resp.data.db_instance.ca_certificate_identifier #=> String
    #   resp.data.db_instance.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_instance.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_instance.domain_memberships[0].domain #=> String
    #   resp.data.db_instance.domain_memberships[0].status #=> String
    #   resp.data.db_instance.domain_memberships[0].fqdn #=> String
    #   resp.data.db_instance.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_instance.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_instance.monitoring_interval #=> Integer
    #   resp.data.db_instance.enhanced_monitoring_resource_arn #=> String
    #   resp.data.db_instance.monitoring_role_arn #=> String
    #   resp.data.db_instance.promotion_tier #=> Integer
    #   resp.data.db_instance.db_instance_arn #=> String
    #   resp.data.db_instance.timezone #=> String
    #   resp.data.db_instance.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_kms_key_id #=> String
    #   resp.data.db_instance.performance_insights_retention_period #=> Integer
    #   resp.data.db_instance.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_instance.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.deletion_protection #=> Boolean
    #   resp.data.db_instance.associated_roles #=> Array<DBInstanceRole>
    #   resp.data.db_instance.associated_roles[0] #=> Types::DBInstanceRole
    #   resp.data.db_instance.associated_roles[0].role_arn #=> String
    #   resp.data.db_instance.associated_roles[0].feature_name #=> String
    #   resp.data.db_instance.associated_roles[0].status #=> String
    #   resp.data.db_instance.listener_endpoint #=> Types::Endpoint
    #   resp.data.db_instance.max_allocated_storage #=> Integer
    #   resp.data.db_instance.tag_list #=> Array<Tag>
    #   resp.data.db_instance.tag_list[0] #=> Types::Tag
    #   resp.data.db_instance.tag_list[0].key #=> String
    #   resp.data.db_instance.tag_list[0].value #=> String
    #   resp.data.db_instance.db_instance_automated_backups_replications #=> Array<DBInstanceAutomatedBackupsReplication>
    #   resp.data.db_instance.db_instance_automated_backups_replications[0] #=> Types::DBInstanceAutomatedBackupsReplication
    #   resp.data.db_instance.db_instance_automated_backups_replications[0].db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance.customer_owned_ip_enabled #=> Boolean
    #   resp.data.db_instance.aws_backup_recovery_point_arn #=> String
    #   resp.data.db_instance.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_instance.activity_stream_kms_key_id #=> String
    #   resp.data.db_instance.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_instance.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_instance.activity_stream_engine_native_audit_fields_included #=> Boolean
    #   resp.data.db_instance.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.custom_iam_instance_profile #=> String
    #   resp.data.db_instance.backup_target #=> String
    #   resp.data.db_instance.network_type #=> String
    #
    def start_db_instance(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::StartDBInstanceInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::StartDBInstanceInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::StartDBInstance
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::DBInstanceNotFoundFault, Errors::DBSubnetGroupDoesNotCoverEnoughAZs, Errors::DBSubnetGroupNotFoundFault, Errors::KMSKeyNotAccessibleFault, Errors::InvalidDBClusterStateFault, Errors::AuthorizationNotFoundFault, Errors::InvalidVPCNetworkStateFault, Errors::InvalidSubnet, Errors::InvalidDBInstanceStateFault, Errors::InsufficientDBInstanceCapacityFault]),
        data_parser: Parsers::StartDBInstance
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::StartDBInstance,
        stubs: @stubs,
        params_class: Params::StartDBInstanceOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :start_db_instance
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Enables replication of automated backups to a different Amazon Web Services Region.</p>
    #         <p>This command doesn't apply to RDS Custom.</p>
    #         <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReplicateBackups.html">
    #             Replicating Automated Backups to Another Amazon Web Services Region</a> in the <i>Amazon RDS User Guide.</i>
    #          </p>
    #
    # @param [Hash] params
    #   See {Types::StartDBInstanceAutomatedBackupsReplicationInput}.
    #
    # @option params [String] :source_db_instance_arn
    #   <p>The Amazon Resource Name (ARN) of the source DB instance for the replicated automated backups, for example,
    #               <code>arn:aws:rds:us-west-2:123456789012:db:mydatabase</code>.</p>
    #
    # @option params [Integer] :backup_retention_period
    #   <p>The retention period for the replicated automated backups.</p>
    #
    # @option params [String] :kms_key_id
    #   <p>The Amazon Web Services KMS key identifier for encryption of the replicated automated backups. The KMS key ID is the
    #               Amazon Resource Name (ARN) for the KMS encryption key in the destination Amazon Web Services Region, for example,
    #               <code>arn:aws:kms:us-east-1:123456789012:key/AKIAIOSFODNN7EXAMPLE</code>.</p>
    #
    # @option params [String] :pre_signed_url
    #   <p>A URL that contains a Signature Version 4 signed request for the StartDBInstanceAutomatedBackupsReplication action to be
    #               called in the Amazon Web Services Region of the source DB instance. The presigned URL must be a valid request for the
    #               StartDBInstanceAutomatedBackupsReplication API action that can be executed in the Amazon Web Services Region that contains
    #               the source DB instance.</p>
    #
    # @return [Types::StartDBInstanceAutomatedBackupsReplicationOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.start_db_instance_automated_backups_replication(
    #     source_db_instance_arn: 'SourceDBInstanceArn', # required
    #     backup_retention_period: 1,
    #     kms_key_id: 'KmsKeyId',
    #     pre_signed_url: 'PreSignedUrl'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::StartDBInstanceAutomatedBackupsReplicationOutput
    #   resp.data.db_instance_automated_backup #=> Types::DBInstanceAutomatedBackup
    #   resp.data.db_instance_automated_backup.db_instance_arn #=> String
    #   resp.data.db_instance_automated_backup.dbi_resource_id #=> String
    #   resp.data.db_instance_automated_backup.region #=> String
    #   resp.data.db_instance_automated_backup.db_instance_identifier #=> String
    #   resp.data.db_instance_automated_backup.restore_window #=> Types::RestoreWindow
    #   resp.data.db_instance_automated_backup.restore_window.earliest_time #=> Time
    #   resp.data.db_instance_automated_backup.restore_window.latest_time #=> Time
    #   resp.data.db_instance_automated_backup.allocated_storage #=> Integer
    #   resp.data.db_instance_automated_backup.status #=> String
    #   resp.data.db_instance_automated_backup.port #=> Integer
    #   resp.data.db_instance_automated_backup.availability_zone #=> String
    #   resp.data.db_instance_automated_backup.vpc_id #=> String
    #   resp.data.db_instance_automated_backup.instance_create_time #=> Time
    #   resp.data.db_instance_automated_backup.master_username #=> String
    #   resp.data.db_instance_automated_backup.engine #=> String
    #   resp.data.db_instance_automated_backup.engine_version #=> String
    #   resp.data.db_instance_automated_backup.license_model #=> String
    #   resp.data.db_instance_automated_backup.iops #=> Integer
    #   resp.data.db_instance_automated_backup.option_group_name #=> String
    #   resp.data.db_instance_automated_backup.tde_credential_arn #=> String
    #   resp.data.db_instance_automated_backup.encrypted #=> Boolean
    #   resp.data.db_instance_automated_backup.storage_type #=> String
    #   resp.data.db_instance_automated_backup.kms_key_id #=> String
    #   resp.data.db_instance_automated_backup.timezone #=> String
    #   resp.data.db_instance_automated_backup.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance_automated_backup.backup_retention_period #=> Integer
    #   resp.data.db_instance_automated_backup.db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance_automated_backup.db_instance_automated_backups_replications #=> Array<DBInstanceAutomatedBackupsReplication>
    #   resp.data.db_instance_automated_backup.db_instance_automated_backups_replications[0] #=> Types::DBInstanceAutomatedBackupsReplication
    #   resp.data.db_instance_automated_backup.db_instance_automated_backups_replications[0].db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance_automated_backup.backup_target #=> String
    #
    def start_db_instance_automated_backups_replication(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::StartDBInstanceAutomatedBackupsReplicationInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::StartDBInstanceAutomatedBackupsReplicationInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::StartDBInstanceAutomatedBackupsReplication
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBInstanceNotFoundFault, Errors::KMSKeyNotAccessibleFault, Errors::DBInstanceAutomatedBackupQuotaExceededFault, Errors::StorageTypeNotSupportedFault, Errors::InvalidDBInstanceStateFault]),
        data_parser: Parsers::StartDBInstanceAutomatedBackupsReplication
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::StartDBInstanceAutomatedBackupsReplication,
        stubs: @stubs,
        params_class: Params::StartDBInstanceAutomatedBackupsReplicationOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :start_db_instance_automated_backups_replication
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Starts an export of a snapshot to Amazon S3.
    #             The provided IAM role must have access to the S3 bucket.</p>
    #         <p>This command doesn't apply to RDS Custom.</p>
    #
    # @param [Hash] params
    #   See {Types::StartExportTaskInput}.
    #
    # @option params [String] :export_task_identifier
    #   <p>A unique identifier for the snapshot export task. This ID isn't an identifier for
    #               the Amazon S3 bucket where the snapshot is to be exported to.</p>
    #
    # @option params [String] :source_arn
    #   <p>The Amazon Resource Name (ARN) of the snapshot to export to Amazon S3.</p>
    #
    # @option params [String] :s3_bucket_name
    #   <p>The name of the Amazon S3 bucket to export the snapshot to.</p>
    #
    # @option params [String] :iam_role_arn
    #   <p>The name of the IAM role to use for writing to the Amazon S3 bucket
    #               when exporting a snapshot.</p>
    #
    # @option params [String] :kms_key_id
    #   <p>The ID of the Amazon Web Services KMS key to use to encrypt the snapshot exported to Amazon S3. The Amazon Web Services KMS
    #               key identifier is the key ARN, key ID, alias ARN, or alias name for the KMS key.
    #               The caller of this operation must be authorized to execute the following operations.
    #               These can be set in the Amazon Web Services KMS key policy:</p>
    #           <ul>
    #               <li>
    #                   <p>GrantOperation.Encrypt</p>
    #               </li>
    #               <li>
    #                   <p>GrantOperation.Decrypt</p>
    #               </li>
    #               <li>
    #                   <p>GrantOperation.GenerateDataKey</p>
    #               </li>
    #               <li>
    #                   <p>GrantOperation.GenerateDataKeyWithoutPlaintext</p>
    #               </li>
    #               <li>
    #                   <p>GrantOperation.ReEncryptFrom</p>
    #               </li>
    #               <li>
    #                   <p>GrantOperation.ReEncryptTo</p>
    #               </li>
    #               <li>
    #                   <p>GrantOperation.CreateGrant</p>
    #               </li>
    #               <li>
    #                   <p>GrantOperation.DescribeKey</p>
    #               </li>
    #               <li>
    #                   <p>GrantOperation.RetireGrant</p>
    #               </li>
    #            </ul>
    #
    # @option params [String] :s3_prefix
    #   <p>The Amazon S3 bucket prefix to use as the file name and path of the exported snapshot.</p>
    #
    # @option params [Array<String>] :export_only
    #   <p>The data to be exported from the snapshot.
    #               If this parameter is not provided, all the snapshot data is exported.
    #               Valid values are the following:</p>
    #           <ul>
    #               <li>
    #                   <p>
    #                     <code>database</code> - Export all the data from a specified database.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>database.table</code>
    #                       <i>table-name</i> -
    #                   Export a table of the snapshot. This format is valid only for RDS for MySQL, RDS for MariaDB, and Aurora MySQL.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>database.schema</code>
    #                       <i>schema-name</i> - Export a database schema of the snapshot.
    #                   This format is valid only for RDS for PostgreSQL and Aurora PostgreSQL.</p>
    #               </li>
    #               <li>
    #                   <p>
    #                     <code>database.schema.table</code>
    #                       <i>table-name</i> - Export a table of the database schema.
    #                   This format is valid only for RDS for PostgreSQL and Aurora PostgreSQL.</p>
    #               </li>
    #            </ul>
    #
    # @return [Types::StartExportTaskOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.start_export_task(
    #     export_task_identifier: 'ExportTaskIdentifier', # required
    #     source_arn: 'SourceArn', # required
    #     s3_bucket_name: 'S3BucketName', # required
    #     iam_role_arn: 'IamRoleArn', # required
    #     kms_key_id: 'KmsKeyId', # required
    #     s3_prefix: 'S3Prefix',
    #     export_only: [
    #       'member'
    #     ]
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::StartExportTaskOutput
    #   resp.data.export_task_identifier #=> String
    #   resp.data.source_arn #=> String
    #   resp.data.export_only #=> Array<String>
    #   resp.data.export_only[0] #=> String
    #   resp.data.snapshot_time #=> Time
    #   resp.data.task_start_time #=> Time
    #   resp.data.task_end_time #=> Time
    #   resp.data.s3_bucket #=> String
    #   resp.data.s3_prefix #=> String
    #   resp.data.iam_role_arn #=> String
    #   resp.data.kms_key_id #=> String
    #   resp.data.status #=> String
    #   resp.data.percent_progress #=> Integer
    #   resp.data.total_extracted_data_in_gb #=> Integer
    #   resp.data.failure_cause #=> String
    #   resp.data.warning_message #=> String
    #
    def start_export_task(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::StartExportTaskInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::StartExportTaskInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::StartExportTask
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::InvalidExportSourceStateFault, Errors::KMSKeyNotAccessibleFault, Errors::IamRoleNotFoundFault, Errors::DBClusterSnapshotNotFoundFault, Errors::InvalidS3BucketFault, Errors::ExportTaskAlreadyExistsFault, Errors::DBSnapshotNotFoundFault, Errors::IamRoleMissingPermissionsFault, Errors::InvalidExportOnlyFault]),
        data_parser: Parsers::StartExportTask
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::StartExportTask,
        stubs: @stubs,
        params_class: Params::StartExportTaskOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :start_export_task
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Stops a database activity stream that was started using the Amazon Web Services console,
    #             the <code>start-activity-stream</code> CLI command, or the <code>StartActivityStream</code> action.</p>
    #         <p>For more information, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/DBActivityStreams.html">Database Activity Streams</a>
    #             in the <i>Amazon Aurora User Guide</i>.</p>
    #
    # @param [Hash] params
    #   See {Types::StopActivityStreamInput}.
    #
    # @option params [String] :resource_arn
    #   <p>The Amazon Resource Name (ARN) of the DB cluster for the database activity stream.
    #               For example, <code>arn:aws:rds:us-east-1:12345667890:cluster:das-cluster</code>.</p>
    #
    # @option params [Boolean] :apply_immediately
    #   <p>Specifies whether or not the database activity stream is to stop as soon as possible,
    #               regardless of the maintenance window for the database.</p>
    #
    # @return [Types::StopActivityStreamOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.stop_activity_stream(
    #     resource_arn: 'ResourceArn', # required
    #     apply_immediately: false
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::StopActivityStreamOutput
    #   resp.data.kms_key_id #=> String
    #   resp.data.kinesis_stream_name #=> String
    #   resp.data.status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #
    def stop_activity_stream(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::StopActivityStreamInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::StopActivityStreamInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::StopActivityStream
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::DBInstanceNotFoundFault, Errors::InvalidDBClusterStateFault, Errors::InvalidDBInstanceStateFault, Errors::ResourceNotFoundFault]),
        data_parser: Parsers::StopActivityStream
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::StopActivityStream,
        stubs: @stubs,
        params_class: Params::StopActivityStreamOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :stop_activity_stream
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Stops an Amazon Aurora DB cluster. When you stop a DB cluster, Aurora retains the DB cluster's
    #        metadata, including its endpoints and DB parameter groups. Aurora also
    #        retains the transaction logs so you can do a point-in-time restore if necessary.</p>
    #         <p>For more information, see
    #            <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-cluster-stop-start.html">
    #                Stopping and Starting an Aurora Cluster</a> in the <i>Amazon Aurora User Guide</i>.</p>
    #         <note>
    #             <p>This action only applies to Aurora DB clusters.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::StopDBClusterInput}.
    #
    # @option params [String] :db_cluster_identifier
    #   <p>The DB cluster identifier of the Amazon Aurora DB cluster to be stopped. This parameter is stored as
    #           a lowercase string.</p>
    #
    # @return [Types::StopDBClusterOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.stop_db_cluster(
    #     db_cluster_identifier: 'DBClusterIdentifier' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::StopDBClusterOutput
    #   resp.data.db_cluster #=> Types::DBCluster
    #   resp.data.db_cluster.allocated_storage #=> Integer
    #   resp.data.db_cluster.availability_zones #=> Array<String>
    #   resp.data.db_cluster.availability_zones[0] #=> String
    #   resp.data.db_cluster.backup_retention_period #=> Integer
    #   resp.data.db_cluster.character_set_name #=> String
    #   resp.data.db_cluster.database_name #=> String
    #   resp.data.db_cluster.db_cluster_identifier #=> String
    #   resp.data.db_cluster.db_cluster_parameter_group #=> String
    #   resp.data.db_cluster.db_subnet_group #=> String
    #   resp.data.db_cluster.status #=> String
    #   resp.data.db_cluster.automatic_restart_time #=> Time
    #   resp.data.db_cluster.percent_progress #=> String
    #   resp.data.db_cluster.earliest_restorable_time #=> Time
    #   resp.data.db_cluster.endpoint #=> String
    #   resp.data.db_cluster.reader_endpoint #=> String
    #   resp.data.db_cluster.custom_endpoints #=> Array<String>
    #   resp.data.db_cluster.custom_endpoints[0] #=> String
    #   resp.data.db_cluster.multi_az #=> Boolean
    #   resp.data.db_cluster.engine #=> String
    #   resp.data.db_cluster.engine_version #=> String
    #   resp.data.db_cluster.latest_restorable_time #=> Time
    #   resp.data.db_cluster.port #=> Integer
    #   resp.data.db_cluster.master_username #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships #=> Array<DBClusterOptionGroupStatus>
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0] #=> Types::DBClusterOptionGroupStatus
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].db_cluster_option_group_name #=> String
    #   resp.data.db_cluster.db_cluster_option_group_memberships[0].status #=> String
    #   resp.data.db_cluster.preferred_backup_window #=> String
    #   resp.data.db_cluster.preferred_maintenance_window #=> String
    #   resp.data.db_cluster.replication_source_identifier #=> String
    #   resp.data.db_cluster.read_replica_identifiers #=> Array<String>
    #   resp.data.db_cluster.read_replica_identifiers[0] #=> String
    #   resp.data.db_cluster.db_cluster_members #=> Array<DBClusterMember>
    #   resp.data.db_cluster.db_cluster_members[0] #=> Types::DBClusterMember
    #   resp.data.db_cluster.db_cluster_members[0].db_instance_identifier #=> String
    #   resp.data.db_cluster.db_cluster_members[0].is_cluster_writer #=> Boolean
    #   resp.data.db_cluster.db_cluster_members[0].db_cluster_parameter_group_status #=> String
    #   resp.data.db_cluster.db_cluster_members[0].promotion_tier #=> Integer
    #   resp.data.db_cluster.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_cluster.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_cluster.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_cluster.vpc_security_groups[0].status #=> String
    #   resp.data.db_cluster.hosted_zone_id #=> String
    #   resp.data.db_cluster.storage_encrypted #=> Boolean
    #   resp.data.db_cluster.kms_key_id #=> String
    #   resp.data.db_cluster.db_cluster_resource_id #=> String
    #   resp.data.db_cluster.db_cluster_arn #=> String
    #   resp.data.db_cluster.associated_roles #=> Array<DBClusterRole>
    #   resp.data.db_cluster.associated_roles[0] #=> Types::DBClusterRole
    #   resp.data.db_cluster.associated_roles[0].role_arn #=> String
    #   resp.data.db_cluster.associated_roles[0].status #=> String
    #   resp.data.db_cluster.associated_roles[0].feature_name #=> String
    #   resp.data.db_cluster.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.clone_group_id #=> String
    #   resp.data.db_cluster.cluster_create_time #=> Time
    #   resp.data.db_cluster.earliest_backtrack_time #=> Time
    #   resp.data.db_cluster.backtrack_window #=> Integer
    #   resp.data.db_cluster.backtrack_consumed_change_records #=> Integer
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_cluster.enabled_cloudwatch_logs_exports[0] #=> String
    #   resp.data.db_cluster.capacity #=> Integer
    #   resp.data.db_cluster.engine_mode #=> String
    #   resp.data.db_cluster.scaling_configuration_info #=> Types::ScalingConfigurationInfo
    #   resp.data.db_cluster.scaling_configuration_info.min_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.max_capacity #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.auto_pause #=> Boolean
    #   resp.data.db_cluster.scaling_configuration_info.seconds_until_auto_pause #=> Integer
    #   resp.data.db_cluster.scaling_configuration_info.timeout_action #=> String
    #   resp.data.db_cluster.scaling_configuration_info.seconds_before_timeout #=> Integer
    #   resp.data.db_cluster.deletion_protection #=> Boolean
    #   resp.data.db_cluster.http_endpoint_enabled #=> Boolean
    #   resp.data.db_cluster.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_cluster.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_cluster.activity_stream_kms_key_id #=> String
    #   resp.data.db_cluster.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_cluster.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_cluster.cross_account_clone #=> Boolean
    #   resp.data.db_cluster.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_cluster.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_cluster.domain_memberships[0].domain #=> String
    #   resp.data.db_cluster.domain_memberships[0].status #=> String
    #   resp.data.db_cluster.domain_memberships[0].fqdn #=> String
    #   resp.data.db_cluster.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_cluster.tag_list #=> Array<Tag>
    #   resp.data.db_cluster.tag_list[0] #=> Types::Tag
    #   resp.data.db_cluster.tag_list[0].key #=> String
    #   resp.data.db_cluster.tag_list[0].value #=> String
    #   resp.data.db_cluster.global_write_forwarding_status #=> String, one of ["enabled", "disabled", "enabling", "disabling", "unknown"]
    #   resp.data.db_cluster.global_write_forwarding_requested #=> Boolean
    #   resp.data.db_cluster.pending_modified_values #=> Types::ClusterPendingModifiedValues
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_cluster.pending_modified_values.db_cluster_identifier #=> String
    #   resp.data.db_cluster.pending_modified_values.master_user_password #=> String
    #   resp.data.db_cluster.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_cluster.pending_modified_values.engine_version #=> String
    #   resp.data.db_cluster.db_cluster_instance_class #=> String
    #   resp.data.db_cluster.storage_type #=> String
    #   resp.data.db_cluster.iops #=> Integer
    #   resp.data.db_cluster.publicly_accessible #=> Boolean
    #   resp.data.db_cluster.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_cluster.monitoring_interval #=> Integer
    #   resp.data.db_cluster.monitoring_role_arn #=> String
    #   resp.data.db_cluster.performance_insights_enabled #=> Boolean
    #   resp.data.db_cluster.performance_insights_kms_key_id #=> String
    #   resp.data.db_cluster.performance_insights_retention_period #=> Integer
    #   resp.data.db_cluster.serverless_v2_scaling_configuration #=> Types::ServerlessV2ScalingConfigurationInfo
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.min_capacity #=> Float
    #   resp.data.db_cluster.serverless_v2_scaling_configuration.max_capacity #=> Float
    #
    def stop_db_cluster(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::StopDBClusterInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::StopDBClusterInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::StopDBCluster
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBClusterNotFoundFault, Errors::InvalidDBClusterStateFault, Errors::InvalidDBInstanceStateFault]),
        data_parser: Parsers::StopDBCluster
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::StopDBCluster,
        stubs: @stubs,
        params_class: Params::StopDBClusterOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :stop_db_cluster
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Stops an Amazon RDS DB instance. When you stop a DB instance, Amazon RDS retains the DB instance's metadata, including its endpoint,
    #             DB parameter group, and option group membership. Amazon RDS also retains the transaction logs so you can do a point-in-time restore if
    #             necessary.</p>
    #         <p>For more information, see
    #             <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_StopInstance.html">
    #                 Stopping an Amazon RDS DB Instance Temporarily</a> in the
    #             <i>Amazon RDS User Guide.</i>
    #          </p>
    #         <note>
    #             <p>This command doesn't apply to RDS Custom, Aurora MySQL, and Aurora PostgreSQL.
    #             For Aurora clusters, use <code>StopDBCluster</code> instead.</p>
    #         </note>
    #
    # @param [Hash] params
    #   See {Types::StopDBInstanceInput}.
    #
    # @option params [String] :db_instance_identifier
    #   <p>The user-supplied instance identifier.</p>
    #
    # @option params [String] :db_snapshot_identifier
    #   <p>The user-supplied instance identifier of the DB Snapshot created immediately before the DB instance is stopped.</p>
    #
    # @return [Types::StopDBInstanceOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.stop_db_instance(
    #     db_instance_identifier: 'DBInstanceIdentifier', # required
    #     db_snapshot_identifier: 'DBSnapshotIdentifier'
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::StopDBInstanceOutput
    #   resp.data.db_instance #=> Types::DBInstance
    #   resp.data.db_instance.db_instance_identifier #=> String
    #   resp.data.db_instance.db_instance_class #=> String
    #   resp.data.db_instance.engine #=> String
    #   resp.data.db_instance.db_instance_status #=> String
    #   resp.data.db_instance.automatic_restart_time #=> Time
    #   resp.data.db_instance.master_username #=> String
    #   resp.data.db_instance.db_name #=> String
    #   resp.data.db_instance.endpoint #=> Types::Endpoint
    #   resp.data.db_instance.endpoint.address #=> String
    #   resp.data.db_instance.endpoint.port #=> Integer
    #   resp.data.db_instance.endpoint.hosted_zone_id #=> String
    #   resp.data.db_instance.allocated_storage #=> Integer
    #   resp.data.db_instance.instance_create_time #=> Time
    #   resp.data.db_instance.preferred_backup_window #=> String
    #   resp.data.db_instance.backup_retention_period #=> Integer
    #   resp.data.db_instance.db_security_groups #=> Array<DBSecurityGroupMembership>
    #   resp.data.db_instance.db_security_groups[0] #=> Types::DBSecurityGroupMembership
    #   resp.data.db_instance.db_security_groups[0].db_security_group_name #=> String
    #   resp.data.db_instance.db_security_groups[0].status #=> String
    #   resp.data.db_instance.vpc_security_groups #=> Array<VpcSecurityGroupMembership>
    #   resp.data.db_instance.vpc_security_groups[0] #=> Types::VpcSecurityGroupMembership
    #   resp.data.db_instance.vpc_security_groups[0].vpc_security_group_id #=> String
    #   resp.data.db_instance.vpc_security_groups[0].status #=> String
    #   resp.data.db_instance.db_parameter_groups #=> Array<DBParameterGroupStatus>
    #   resp.data.db_instance.db_parameter_groups[0] #=> Types::DBParameterGroupStatus
    #   resp.data.db_instance.db_parameter_groups[0].db_parameter_group_name #=> String
    #   resp.data.db_instance.db_parameter_groups[0].parameter_apply_status #=> String
    #   resp.data.db_instance.availability_zone #=> String
    #   resp.data.db_instance.db_subnet_group #=> Types::DBSubnetGroup
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_name #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_description #=> String
    #   resp.data.db_instance.db_subnet_group.vpc_id #=> String
    #   resp.data.db_instance.db_subnet_group.subnet_group_status #=> String
    #   resp.data.db_instance.db_subnet_group.subnets #=> Array<Subnet>
    #   resp.data.db_instance.db_subnet_group.subnets[0] #=> Types::Subnet
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_identifier #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone #=> Types::AvailabilityZone
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_availability_zone.name #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost #=> Types::Outpost
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_outpost.arn #=> String
    #   resp.data.db_instance.db_subnet_group.subnets[0].subnet_status #=> String
    #   resp.data.db_instance.db_subnet_group.db_subnet_group_arn #=> String
    #   resp.data.db_instance.db_subnet_group.supported_network_types #=> Array<String>
    #   resp.data.db_instance.db_subnet_group.supported_network_types[0] #=> String
    #   resp.data.db_instance.preferred_maintenance_window #=> String
    #   resp.data.db_instance.pending_modified_values #=> Types::PendingModifiedValues
    #   resp.data.db_instance.pending_modified_values.db_instance_class #=> String
    #   resp.data.db_instance.pending_modified_values.allocated_storage #=> Integer
    #   resp.data.db_instance.pending_modified_values.master_user_password #=> String
    #   resp.data.db_instance.pending_modified_values.port #=> Integer
    #   resp.data.db_instance.pending_modified_values.backup_retention_period #=> Integer
    #   resp.data.db_instance.pending_modified_values.multi_az #=> Boolean
    #   resp.data.db_instance.pending_modified_values.engine_version #=> String
    #   resp.data.db_instance.pending_modified_values.license_model #=> String
    #   resp.data.db_instance.pending_modified_values.iops #=> Integer
    #   resp.data.db_instance.pending_modified_values.db_instance_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.storage_type #=> String
    #   resp.data.db_instance.pending_modified_values.ca_certificate_identifier #=> String
    #   resp.data.db_instance.pending_modified_values.db_subnet_group_name #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports #=> Types::PendingCloudwatchLogsExports
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_enable[0] #=> String
    #   resp.data.db_instance.pending_modified_values.pending_cloudwatch_logs_exports.log_types_to_disable #=> Array<String>
    #   resp.data.db_instance.pending_modified_values.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.pending_modified_values.processor_features[0] #=> Types::ProcessorFeature
    #   resp.data.db_instance.pending_modified_values.processor_features[0].name #=> String
    #   resp.data.db_instance.pending_modified_values.processor_features[0].value #=> String
    #   resp.data.db_instance.pending_modified_values.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.pending_modified_values.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.pending_modified_values.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.latest_restorable_time #=> Time
    #   resp.data.db_instance.multi_az #=> Boolean
    #   resp.data.db_instance.engine_version #=> String
    #   resp.data.db_instance.auto_minor_version_upgrade #=> Boolean
    #   resp.data.db_instance.read_replica_source_db_instance_identifier #=> String
    #   resp.data.db_instance.read_replica_db_instance_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_instance_identifiers[0] #=> String
    #   resp.data.db_instance.read_replica_db_cluster_identifiers #=> Array<String>
    #   resp.data.db_instance.read_replica_db_cluster_identifiers[0] #=> String
    #   resp.data.db_instance.replica_mode #=> String, one of ["open-read-only", "mounted"]
    #   resp.data.db_instance.license_model #=> String
    #   resp.data.db_instance.iops #=> Integer
    #   resp.data.db_instance.option_group_memberships #=> Array<OptionGroupMembership>
    #   resp.data.db_instance.option_group_memberships[0] #=> Types::OptionGroupMembership
    #   resp.data.db_instance.option_group_memberships[0].option_group_name #=> String
    #   resp.data.db_instance.option_group_memberships[0].status #=> String
    #   resp.data.db_instance.character_set_name #=> String
    #   resp.data.db_instance.nchar_character_set_name #=> String
    #   resp.data.db_instance.secondary_availability_zone #=> String
    #   resp.data.db_instance.publicly_accessible #=> Boolean
    #   resp.data.db_instance.status_infos #=> Array<DBInstanceStatusInfo>
    #   resp.data.db_instance.status_infos[0] #=> Types::DBInstanceStatusInfo
    #   resp.data.db_instance.status_infos[0].status_type #=> String
    #   resp.data.db_instance.status_infos[0].normal #=> Boolean
    #   resp.data.db_instance.status_infos[0].status #=> String
    #   resp.data.db_instance.status_infos[0].message #=> String
    #   resp.data.db_instance.storage_type #=> String
    #   resp.data.db_instance.tde_credential_arn #=> String
    #   resp.data.db_instance.db_instance_port #=> Integer
    #   resp.data.db_instance.db_cluster_identifier #=> String
    #   resp.data.db_instance.storage_encrypted #=> Boolean
    #   resp.data.db_instance.kms_key_id #=> String
    #   resp.data.db_instance.dbi_resource_id #=> String
    #   resp.data.db_instance.ca_certificate_identifier #=> String
    #   resp.data.db_instance.domain_memberships #=> Array<DomainMembership>
    #   resp.data.db_instance.domain_memberships[0] #=> Types::DomainMembership
    #   resp.data.db_instance.domain_memberships[0].domain #=> String
    #   resp.data.db_instance.domain_memberships[0].status #=> String
    #   resp.data.db_instance.domain_memberships[0].fqdn #=> String
    #   resp.data.db_instance.domain_memberships[0].iam_role_name #=> String
    #   resp.data.db_instance.copy_tags_to_snapshot #=> Boolean
    #   resp.data.db_instance.monitoring_interval #=> Integer
    #   resp.data.db_instance.enhanced_monitoring_resource_arn #=> String
    #   resp.data.db_instance.monitoring_role_arn #=> String
    #   resp.data.db_instance.promotion_tier #=> Integer
    #   resp.data.db_instance.db_instance_arn #=> String
    #   resp.data.db_instance.timezone #=> String
    #   resp.data.db_instance.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_enabled #=> Boolean
    #   resp.data.db_instance.performance_insights_kms_key_id #=> String
    #   resp.data.db_instance.performance_insights_retention_period #=> Integer
    #   resp.data.db_instance.enabled_cloudwatch_logs_exports #=> Array<String>
    #   resp.data.db_instance.processor_features #=> Array<ProcessorFeature>
    #   resp.data.db_instance.deletion_protection #=> Boolean
    #   resp.data.db_instance.associated_roles #=> Array<DBInstanceRole>
    #   resp.data.db_instance.associated_roles[0] #=> Types::DBInstanceRole
    #   resp.data.db_instance.associated_roles[0].role_arn #=> String
    #   resp.data.db_instance.associated_roles[0].feature_name #=> String
    #   resp.data.db_instance.associated_roles[0].status #=> String
    #   resp.data.db_instance.listener_endpoint #=> Types::Endpoint
    #   resp.data.db_instance.max_allocated_storage #=> Integer
    #   resp.data.db_instance.tag_list #=> Array<Tag>
    #   resp.data.db_instance.tag_list[0] #=> Types::Tag
    #   resp.data.db_instance.tag_list[0].key #=> String
    #   resp.data.db_instance.tag_list[0].value #=> String
    #   resp.data.db_instance.db_instance_automated_backups_replications #=> Array<DBInstanceAutomatedBackupsReplication>
    #   resp.data.db_instance.db_instance_automated_backups_replications[0] #=> Types::DBInstanceAutomatedBackupsReplication
    #   resp.data.db_instance.db_instance_automated_backups_replications[0].db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance.customer_owned_ip_enabled #=> Boolean
    #   resp.data.db_instance.aws_backup_recovery_point_arn #=> String
    #   resp.data.db_instance.activity_stream_status #=> String, one of ["stopped", "starting", "started", "stopping"]
    #   resp.data.db_instance.activity_stream_kms_key_id #=> String
    #   resp.data.db_instance.activity_stream_kinesis_stream_name #=> String
    #   resp.data.db_instance.activity_stream_mode #=> String, one of ["sync", "async"]
    #   resp.data.db_instance.activity_stream_engine_native_audit_fields_included #=> Boolean
    #   resp.data.db_instance.automation_mode #=> String, one of ["full", "all-paused"]
    #   resp.data.db_instance.resume_full_automation_mode_time #=> Time
    #   resp.data.db_instance.custom_iam_instance_profile #=> String
    #   resp.data.db_instance.backup_target #=> String
    #   resp.data.db_instance.network_type #=> String
    #
    def stop_db_instance(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::StopDBInstanceInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::StopDBInstanceInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::StopDBInstance
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBInstanceNotFoundFault, Errors::SnapshotQuotaExceededFault, Errors::InvalidDBClusterStateFault, Errors::DBSnapshotAlreadyExistsFault, Errors::InvalidDBInstanceStateFault]),
        data_parser: Parsers::StopDBInstance
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::StopDBInstance,
        stubs: @stubs,
        params_class: Params::StopDBInstanceOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :stop_db_instance
        )
      )
      raise resp.error if resp.error
      resp
    end

    # <p>Stops automated backup replication for a DB instance.</p>
    #         <p>This command doesn't apply to RDS Custom.</p>
    #         <p>For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReplicateBackups.html">
    #             Replicating Automated Backups to Another Amazon Web Services Region</a> in the <i>Amazon RDS User Guide.</i>
    #          </p>
    #
    # @param [Hash] params
    #   See {Types::StopDBInstanceAutomatedBackupsReplicationInput}.
    #
    # @option params [String] :source_db_instance_arn
    #   <p>The Amazon Resource Name (ARN) of the source DB instance for which to stop replicating automated backups, for example,
    #               <code>arn:aws:rds:us-west-2:123456789012:db:mydatabase</code>.</p>
    #
    # @return [Types::StopDBInstanceAutomatedBackupsReplicationOutput]
    #
    # @example Request syntax with placeholder values
    #
    #   resp = client.stop_db_instance_automated_backups_replication(
    #     source_db_instance_arn: 'SourceDBInstanceArn' # required
    #   )
    #
    # @example Response structure
    #
    #   resp.data #=> Types::StopDBInstanceAutomatedBackupsReplicationOutput
    #   resp.data.db_instance_automated_backup #=> Types::DBInstanceAutomatedBackup
    #   resp.data.db_instance_automated_backup.db_instance_arn #=> String
    #   resp.data.db_instance_automated_backup.dbi_resource_id #=> String
    #   resp.data.db_instance_automated_backup.region #=> String
    #   resp.data.db_instance_automated_backup.db_instance_identifier #=> String
    #   resp.data.db_instance_automated_backup.restore_window #=> Types::RestoreWindow
    #   resp.data.db_instance_automated_backup.restore_window.earliest_time #=> Time
    #   resp.data.db_instance_automated_backup.restore_window.latest_time #=> Time
    #   resp.data.db_instance_automated_backup.allocated_storage #=> Integer
    #   resp.data.db_instance_automated_backup.status #=> String
    #   resp.data.db_instance_automated_backup.port #=> Integer
    #   resp.data.db_instance_automated_backup.availability_zone #=> String
    #   resp.data.db_instance_automated_backup.vpc_id #=> String
    #   resp.data.db_instance_automated_backup.instance_create_time #=> Time
    #   resp.data.db_instance_automated_backup.master_username #=> String
    #   resp.data.db_instance_automated_backup.engine #=> String
    #   resp.data.db_instance_automated_backup.engine_version #=> String
    #   resp.data.db_instance_automated_backup.license_model #=> String
    #   resp.data.db_instance_automated_backup.iops #=> Integer
    #   resp.data.db_instance_automated_backup.option_group_name #=> String
    #   resp.data.db_instance_automated_backup.tde_credential_arn #=> String
    #   resp.data.db_instance_automated_backup.encrypted #=> Boolean
    #   resp.data.db_instance_automated_backup.storage_type #=> String
    #   resp.data.db_instance_automated_backup.kms_key_id #=> String
    #   resp.data.db_instance_automated_backup.timezone #=> String
    #   resp.data.db_instance_automated_backup.iam_database_authentication_enabled #=> Boolean
    #   resp.data.db_instance_automated_backup.backup_retention_period #=> Integer
    #   resp.data.db_instance_automated_backup.db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance_automated_backup.db_instance_automated_backups_replications #=> Array<DBInstanceAutomatedBackupsReplication>
    #   resp.data.db_instance_automated_backup.db_instance_automated_backups_replications[0] #=> Types::DBInstanceAutomatedBackupsReplication
    #   resp.data.db_instance_automated_backup.db_instance_automated_backups_replications[0].db_instance_automated_backups_arn #=> String
    #   resp.data.db_instance_automated_backup.backup_target #=> String
    #
    def stop_db_instance_automated_backups_replication(params = {}, options = {}, &block)
      stack = Hearth::MiddlewareStack.new
      input = Params::StopDBInstanceAutomatedBackupsReplicationInput.build(params)
      response_body = ::StringIO.new
      stack.use(Hearth::Middleware::Validate,
        validator: Validators::StopDBInstanceAutomatedBackupsReplicationInput,
        validate_input: @config.validate_input
      )
      stack.use(Hearth::Middleware::Build,
        builder: Builders::StopDBInstanceAutomatedBackupsReplication
      )
      stack.use(Hearth::HTTP::Middleware::ContentLength)
      stack.use(Hearth::Middleware::Retry,
        retry_mode: @config.retry_mode,
        error_inspector_class: Hearth::Retry::ErrorInspector,
        retry_quota: @retry_quota,
        max_attempts: @config.max_attempts,
        client_rate_limiter: @client_rate_limiter,
        adaptive_retry_wait_to_fill: @config.adaptive_retry_wait_to_fill
      )
      stack.use(Hearth::Middleware::Parse,
        error_parser: Hearth::HTTP::ErrorParser.new(error_module: Errors, success_status: 200, errors: [Errors::DBInstanceNotFoundFault, Errors::InvalidDBInstanceStateFault]),
        data_parser: Parsers::StopDBInstanceAutomatedBackupsReplication
      )
      stack.use(Middleware::RequestId)
      stack.use(Hearth::Middleware::Send,
        stub_responses: @config.stub_responses,
        client: Hearth::HTTP::Client.new(logger: @config.logger, http_wire_trace: options.fetch(:http_wire_trace, @config.http_wire_trace)),
        stub_class: Stubs::StopDBInstanceAutomatedBackupsReplication,
        stubs: @stubs,
        params_class: Params::StopDBInstanceAutomatedBackupsReplicationOutput
      )
      apply_middleware(stack, options[:middleware])

      resp = stack.run(
        input: input,
        context: Hearth::Context.new(
          request: Hearth::HTTP::Request.new(url: options.fetch(:endpoint, @config.endpoint)),
          response: Hearth::HTTP::Response.new(body: response_body),
          params: params,
          logger: @config.logger,
          operation_name: :stop_db_instance_automated_backups_replication
        )
      )
      raise resp.error if resp.error
      resp
    end

    private

    def apply_middleware(middleware_stack, middleware)
      Client.middleware.apply(middleware_stack)
      @middleware.apply(middleware_stack)
      Hearth::MiddlewareBuilder.new(middleware).apply(middleware_stack)
    end
  end
end
